[{"title":"浅谈用一维数组dp解决0/1背包问题","path":"/2022/02/24/dp01bag/","content":"本篇博客主要是受《牛客网入学考试》题目启发，拓展浅谈一下自己对于从用二维数组dp解决0/1背包问题优化成用一维数组dp解决0/1背包问题的算法理解。 用二维数组dp解决0/1背包问题 其实这个问题在数月前曾总结过一次，在《动态规划》中我曾总结过使用二维数组打表解决0/1背包问题的方法，并且也介绍了使用元组法尝试优化二维数组dp的思路，但是并没有给出具体的实现。这里我想重新定义一下二维数组dp解决0/1背包的问题。在之前的博客中我们介绍到打表时使用的函数定义如下： 但是这貌似和大多数人的二维数组的板子不太一样，因为这里我定义的是f(i,y)为背包剩余容量为y时，在物品i~n中选取。然后每次打表都是让i从n开始递减到1，所以递归式是由后向前即根据i+1推出i。这里我重新修正定义f(i,y)函数含义为背包剩余容量为y时，在物品1~i中选取。那么我们在打表时，应该是让i从0逐渐递增打表，所以递归式应该修改为 f[i][y]={max{f[i−1][y],f[i−1][y−wi]+pi},y&gt;=wi//能放入物品if(i−1，y),0&lt;=y&lt;wif[i][y]= \\begin{cases} max\\{f[i-1][y],f[i-1][y-wi]+pi\\},y&gt;=wi//能放入物品i\\\\ f(i-1，y),0&lt;=y&lt;wi \\end{cases} f[i][y]={max{f[i−1][y],f[i−1][y−wi]+pi},y&gt;=wi//能放入物品if(i−1，y),0&lt;=y&lt;wi​ 即对于每一行i的表格，要根据前一行i-1来推出下一行第i行的数值（之前是根据前一行i+1来推出下一行第i行的数值）。但是我们发现重定义完f(i,y)函数以后实际上本质上打表思路还是一样的，都是对于不同的i各自对应着表格的一行，然后对于每一行又会根据y的值对应不同的效益值。只是打表的行顺序变了而已，如下图： 对于之前的i从n开始的打表： 现在改为i从1开始打表 i\\y 0 1 2 3 4 5 6 7 8 9 10 1 0 0 6 6 6 6 6 6 6 6 6 2 0 0 6 6 9 9 9 9 9 9 9 3 0 0 6 6 6 6 9 9 9 9 14 4 0 0 6 6 6 6 9 9 9 9 14 5 0 0 6 6 6 6 12 12 12 12 15 上表中具体的数值不用在意，只是我们要理解打表的流程，上图中都是先对第一行对应的i不同的y进行打表，然后在后面的行中使用递归式进行打表。但是无论是哪种f(i,y)的定义，我们发现在打表时都是默认的y从0到最大值c递增对应的不同情况打表。这是因为二维数组dp时，递归式中的右边项总是来自已经存储于前一行中的数值。所以y是正序递增从0~c打表即可并无问题。板子如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243//代码转载于https://blog.csdn.net/weixin_41061962/article/details/80319436，非常感谢#include&lt;bits/stdc++.h&gt;using namespace std;struct KNAP&#123;\tint w; //weight;\tint v; //value,or portfolio;&#125;;//二维的方式void solveKPd(vector&lt;KNAP&gt; cknap, vector&lt;vector&lt;int&gt; &gt; &amp;dp, int n, int Tw)&#123;\tfor (int i = 0; i &lt; n; i++)\t&#123; for (int j = 0; j &lt;=Tw; j++) &#123; //先检验能否装入物品i if (j&lt;cknap[i].w) dp[i+1][j] = dp[i][j]; //j是每一个子问题的w上界,这里与整体的Tw无关 //然后根据递归取最大值，其中这些右边的数值都来自于表的前一行 else if (dp[i][j] &lt; dp[i][j - cknap[i].w] + cknap[i].v) dp[i+1][j] = dp[i][j - cknap[i].w] + cknap[i].v; else dp[i+1][j] = dp[i][j]; &#125;\t&#125;\tcout &lt;&lt; dp[n][Tw] &lt;&lt; endl;&#125;int main()&#123;\tint Tw; int n;\tcin &gt;&gt; Tw &gt;&gt; n;\tvector&lt;KNAP&gt; cknap;\tfor (int i = 0; i &lt; n; i++)\t&#123; KNAP temp; cin &gt;&gt; temp.w &gt;&gt; temp.v; cknap.push_back(temp);\t&#125;\tvector&lt; vector&lt;int&gt; &gt; dp(n+1, vector&lt;int&gt;(Tw+1,0));\tsolveKPd(cknap, dp, n, Tw);\tsystem(&quot;pause&quot;);\treturn 0;&#125; 用一维数组dp解决0/1背包问题 现在我们思考一下用一维数组dp解决0/1背包问题，那么我们使用一维数组的思想就是每次打印第i行时都能够刚好把第i-1行的数据覆盖掉，这样，就不是二维打表了，永远是在一个一维数组中进行。所以很明显f(i,y)函数中的i就不需要了，因为永远只有一行。所以变为了f(y)，即只有一个自变量参数背包剩余容量y。那么我们知道无论如何，第i行的数据肯定是需要与来自于第i-1行的数据比较的，只是在一维数组的方法中，使用完这个第i-1行数据以后就用新的第i行数据覆盖掉了。所以我们在推导第i行的数据时要保证他需要的第i-1行数据还存在。此时我们可以遇见到一个问题，即y是从小到大递增还是从大到小递减进行打表求解？ 首先我们知道递归式应该如下了： f[y]=max{f[y],f[y−wi]+pi}f[y]=max\\{f[y], f[y-wi]+pi\\} f[y]=max{f[y],f[y−wi]+pi} 我们假设此时还是沿用之前的思路，y从小到大开始递增进行打表，那么板子应该如下： 123456789//此时每次遍历i就是打印一行for (i = 1; i &lt;= n; i++)&#123; //注意，此时y还是从小到大 for (y = 0; y &lt;=c&amp;&amp;y&gt;=w[i]; y++)&#123; //右边的都是第i-1次循环的结果 f[y] = max(f[y], f[y - w[i]] + p[i]); &#125;&#125; 我们发现有点bug,就是假设现在打印完了i=1情况下的所有f(y)的值，那么此时f(0)~f©表示的都是i=1情况下的值（注意此时f函数的自变量参数为背包剩余容量y)。那么如果按照递增打印，此时我们要打印i=2情况了，y从0开始根据推导式求得了i=2时的f(0)，那么此时f(0)就要更新为i=2的情况了，所以此时一维数组中f(0)是对应的i=2,其他f(2)~f(n)对应的还是i=1的情况，那么此时我们要求解i=2情况下的f(1)可能会用到i=1情况下的f(0)（比如此时根据递归式f(1)=max[f(1),f(1-w[1])+p1)],恰巧后一项的f(1-w[1])=f(0)），那么就会用到i=1时的f(0)）。但是我们惊讶的发现此时f(0)已经不是i=1的情况了，而是更新成了i=2的情况了，所以此时i=2情况下的f(1)就不能求解了因为缺少上一行i=1时的f(0)值。所以y正序打印是不行的，我们需要让y倒序打印，即板子修改为： 12345678//此时每次遍历i就是打印一行for (i = 1; i &lt;= n; i++)&#123; //注意，此时y还是从大到小 for (y = c; y&gt;=w[i]; y--)&#123; //右边的都是第i-1次循环的结果 f[y] = max(f[y], f[y - w[i]] + p[i]); &#125;&#125; 此时我们再分析一下，当i=1这行打完表以后，我们按照上面的代码，是先根据i=1的值推导出了i=2情况下的f©并且更新f©为i=2的值，此时f(0)~f(c-1)还是i=1的情况f©是i=2的值，我们要打印f(c-1)了，可能f(c-1)会用到i=1时的f(c-3),我们发现此时f(c-3)确实还是i=1的值，恰好可以用。所以y从大到小打印刚好可以使用到之前的值，并且更新以后的值不会影响后面的推导。 最后我们总结一句话，就是对于f[y], 它要调用的f[y-w[i]]一定是第i层循环还没有更新过的, 换言之, f[y-wi]只有可能是第i-1层存储的数据。这就是y要逆序打印的原因，至于i可以正序也可以逆序，只是对应着不同的f函数的定义。 核心板子 因此一维数组dp解决0/1背包板子如下： 12345678//此时每次遍历i就是打印一行for (i = 1; i &lt;= n; i++)&#123; //注意，此时y还是从大到小 for (y = c; y&gt;=w[i]; y--)&#123; //右边的都是第i-1次循环的结果 f[y] = max(f[y], f[y - w[i]] + p[i]); &#125;&#125; 思考：物品能否放入背包的特判放到了哪里？ 此时物品能够放入背包的特判放到了第二个for循环中了，这也是巧合之处。只有满足了特判条件才能够进行下面的更新，并且此时你可能会有疑虑，一旦不满足了情况就会退出y循环，那么这行值是否会出现还未打印完的情况，即前面还是未更新的值，此时我们细想一下，未更新的值实际上也可以看成是更新的值了，只是由于为装入物品i所以，值并未变化，直接沿用之前的i-1的值即可了。所以二维与一维最大的区别有 二维y是从小到大和从大到小均可以，但是一维y必须从大到小逆序 二维数组中的递归式目的是填写值，必须每一个位置都重新通过递归式进行填值，但是在一维方法中递归式的目的是更新值，如果不满足物品i可以装入的条件，那么前面的所有值均不会变化，也就无需更新，直接退出循环即可。 思考：二维方法与一维方法的结果特点对比？ 二维方法中我们求解完以后是一张完整的表格，他里面填写了对于不同的i不同的y情况时的效益值，但是在一维方法中最终我们求得的是一个向量，只保存了i=n,不同y情况的效益值，一维方法的其他i情况的值在多次推导和更新中被更新的值覆盖了。但是，最终我们需要的只是满足题干的f(n,c)或者f©而已，所以两个方法均可以使用，但是一维方法更简单高效。","tags":["dp","背包问题"],"categories":["算法总结"]},{"title":"前后端跨域请求解决策略","path":"/2022/01/11/cross-origin/","content":"在前后端分离开发的项目中，我们总是会遇到请求跨域的问题，每一次都避免不了开发人员之间的对线，为了缓解同事友谊，翀翀特此提供一篇完美解决前后端跨域请求的攻略😉~ 什么是跨域 我们在进行本地前后端项目的接口对接或者是项目打包部署到线上以后（但是前后端项目部署到了不同的服务器上），那么此时就可能会出现跨域的问题，他总是出现如下的报错： 如上所示，控制台警告信息中提示我们这个从本地http://localhost:8080发起的向http://api.cheeseburgerim.space/api/user/login的请求被跨域限制策略所阻挡了，并且如果想要通过请在请求函数中添加一系列请求头，但是往往我们在添加以后仍然不能解决。 如果想要解决这个跨域问题，我们首先需要了解跨域请求被阻拦的原因： 跨域请求产生的原因 我们首先要了解什么是跨域,跨域是因为浏览器的同源策略限制，是浏览器的一种安全机制，服务端之间就不会产生跨域的。所谓同源就是指两个页面具有相同的协议，相同的主机和相同的端口，三者之中有一个不同的时候就会产生跨域。如下所示： 当前页面url 被请求页面url 是否跨域 产生原因 http://www.test.com/ http://www.test.com/index.html 否 同源（协议、域名、端口号均相同） http://www.test.com/ https://www.test.com/index.html 是 协议不同（http/https) http://www.test.com/ http://www.baidu.com/ 是 主域名不同（test/baidu） http://www/test.com/ http://api.test.com/ 是 子域名不同（www/api) http://www.test.com:8080/ http://test.com:7001/ 是 端口号不同（8080/7001) 我们可以总结出不产生跨请求域的条件是：①协议必须一致②域名必须完全相同③端口号必须一致 简单请求/非简单请求 然后接下来我们再来了解一下简单请求和非简单请求，在有时候我们会发现请求发出以后在控制的network栏监控处可以发现有些请求明明应该只执行一次，但是实际上他会执行两次，这是因为它属于非简单请求，此时会先发送一个预检验请求如下所示： 我们在一些传送复杂文件的请求A中就会发现在这个请求发送之前，他会先发送一个如上所示的OPTIONS请求并且通常返还的是200，包括了响应请求的信息即对方服务器关于请求的一些限制信息，然后接下来才会发送这个真正的传输文件的请求A，如果不满足对方的要求就会报错。 简单请求 但是一般情况下我们使用的都是简单请求，他包括： 请求方法为：HEAD、GET、POST中的一种 HTTP请求头中字段不超过：Accept、Accept-Language、Content-Language、Last-Event-ID Content-Type字段值为application/x-www-form-urlencoded、multipart/form-data、text/plain中的一种 非简单请求 对于简单请求不会发起预检验请求，而以下的这些就是非简单请求，他在请求真正发起之前会先进行预检验请求可以获取到服务器设置的响应请求信息以及对发起请求的限制： 请求方法为PUT、DELETE 发送JSON格式的ajax请求 http中带自定义请求头 简单请求的跨域 对于简单请求，如果浏览器发现是跨域请求，就会自动在请求头中加入Origin字段，代表请求来自哪个域（协议+主机名+端口号），服务器收到请求以后，根据请求头中Origin中字段值来判断是否允许跨域请求通过。如果想要解决跨域问题，只需要在服务器的响应头Access-Control-Allow-Origin字段中设置指定的域名，表示允许这些域名的跨域请求。如果请求头中Origin字段的域名包含在这些域名中，则可以实现跨域请求（当然有时候还需要结合其他字段来判断），否则不通过。 非简单请求的跨域 而对于非简单请求的跨域，会先发送一次“预检”（OPTIONS)请求。预检请求会事先询问服务器，当前域名是否在服务器允许的范围内，以及可以使用那些HTTP动词和信息字段。只有得到肯定答复以后，浏览器才会发出真正的HTTP请求，否则就会报错。 了解完以上的信息以后，我们会发现无论是哪种跨域，实际上解决办法就是两种策略：①代理请求端使其请求源和服务端一致②后端服务器配置请求允许不同源的请求 开发环境解决跨域 在开发环境中我们可以向后端大大为我们配置跨域允许，这样我们前端就无需在配置任何东西了，但是俗话说的好：“自己动手，丰衣足食”，我们才不要作一个看后端开发脸色的前端攻城狮🤣，因此我们可以在开发环境中在前端自己解决跨域问题： 要注意，如果你在开发时使用POSTman进行接口的调试工作，那么请注意POSTman是默认永远不会产生跨域的，因此如果你的请求在POSTman中请求成功了并不一定就不会产生跨域而被浏览器所拦截。 策略一：chrome插件代理 在前端配置解决跨域的策略无非就是使用代理，让我们的请求在被封装以后能够以同源的身份被后台服务器所能允许接收，此时我们可以使用代码进行配置，但是如果你是小白的话，完全可以试一试这种使用插件代理的方法： 这里给出插件的百度网盘地址 提取码：wssbhttps://pan.baidu.com/s/1koaZyGBNhKp6uZOVlTP5iQ 下载完成以后，在chrome中打开扩展程序选择开发者模式将这个插件进行安装： 安装完成以后将会这个插件开启并置顶，那么我们就可以使用这个插件进行代理了： 策略二：vue中proxyTable代理 如果你前端使用的是vue框架，那么可以试试这种方法，即使用vue提供的ProxyTable进行代理从而实现同源请求，假设现在我们要请求的是一个登录接口：https://api.coolchong.cn/api/user/login,同时其他的请求接口也类似比如注册是https://api.coolchong.cn/api/user/register等等，而我们本地开发时热加载预览的地址是http://localhost:8080, 此时为了解决跨域，我们需要将我们的源也代理成https://coolchong.cn，此时我们就可以使用proxyTable，如果你的vue也是2.x版本那么可以直接在/config/index.js中找到如下代码，如果是vue3.x那么也可以在类似的路径中找到： 123456789101112// Paths assetsSubDirectory: &#x27;static&#x27;, assetsPublicPath: &#x27;/&#x27;, proxyTable: &#123; &#x27;/apis&#x27;: &#123; target: &#x27;https://api.coolchong.cn&#x27;, // 你要代理的域名和端口号，要加上http changeOrigin: true, // 跨域 pathRewrite: &#123; &#x27;^/apis&#x27;: &#x27;&#x27; // 这里用‘/apis’代替target里面的地址，组件中调用接口时直接用api代替 比如我要调用&#x27;http://xxx.com:8080/api/NEWS/getNews.json?page=1&amp;pageSize=10&#x27;，直接写‘/api/NEWS/getNews.json?page=1&amp;pageSize=10’即可 &#125; &#125; &#125;, 一定要注意修改的是dev即开发环境下的proxyTable，不要改错了。同时当修改了配置以后需要重启这个项目才能加载新的配置。 配置完成以后，如果此时我们再在本地请求这个接口时，使用/apis/user/login代替https://api.coolchong.cn/api/user/login,用/api/user/register代替htts://api.coolchong.cn/api/user/register即可。如下我用axios来演示一下写法： 自此我们就完成了开发环境下前端解决跨域问题的配置。 部署线上解决跨域 但是我们会发现上面这种方法只适用于本地开发调试环境时使用，一个项目真正打包完成部署上去还是会面临跨域，因此接下来我们讲一讲后台的配置来解决项目打包部署线上的跨域问题解决策略。此时我们还是以上面的例子作为讲解。 我们知道实际上前端最终要进行请求的接口还是https://api.coolchong.cn/api/user/login，因此我们在完成开发以后部署前先将axios的默认地址baseURL更改回： 同时在项目打包前将代理proxyTable注释掉： 那么很显然此时项目的所有请求都会处于跨域状态，但是不用担心，此时我们是在后端解决跨域，因此前端可以直接打包部署了，具体流程参考本篇博客： vue项目部署https://scholar.coolchong.cn/2021/10/18/nginx-web/ 接下来我们进行后端的配置，此时的跨域解决策略就是后端允许任何不同源的请求进行响应，操作很简单，我们只需要为项目添加一个/configuration/WebMvcConfig.java配置类，代码如下： 12345678910111213141516171819202122232425262728package com.example.deliverysystem.configuration;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;/** * @Author Lang wenchong * @Date 2021/12/25 21:55 * @Version 1.0 */@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowCredentials(true) .allowedOriginPatterns(&quot;*&quot;) .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;) .allowedHeaders(&quot;*&quot;) .exposedHeaders(&quot;origin&quot;); &#125;&#125; 这样我们再将后端代码打包成jar包部署到服务器即可，此时前后端部署的主机不同也不会产生跨域请求了，解决了线上部署环境下的跨域问题。","tags":["跨域","springboot"],"categories":["开发技能"]},{"title":"vuex从入门到实战","path":"/2021/12/12/vuex/","content":"vuex是一款针对vue.js中复杂的通信场景下衍生的技术插件，他可以有效的帮助我们轻松完成大范围内的组件通信，还不快进来学习😋？ vuex简介 什么是 vuex？这是每一个新手小白都很好奇的问题，我们要知道任何一种新技术的产生肯定都是为了解决某种复杂的问题，而vuex就是为了解决大范围内vue组件中通信问题的。这里我们从组件的通信方式入手来逐步了解vuex产生的缘由以及他的作用。 传统组件通信方式 我们回忆一下我们之前学习的组件通信的方式，常用的是父子组件之间的通信，此时父组件通过 :bind绑定一个值给子组件，然后子组件通过 props接收这个值，此时这个从父组件拿到的值是响应式的，但是仅仅是单向更新，即子组件只能接受到父组件更新的这个值，而子组件是不能修改父组件中的值的，为了能实现子组件向父组件更新这个值，子组件需要通过 $emit触发父组件提前为子组件分配并绑定方法实现更新，如下图所示是一个简单的父子组件通信demo: Tab/index.vueApp.vue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;template&gt; &lt;div&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(1)&quot; :class=&quot;[&#123; current: curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(2)&quot; :class=&quot;[&#123; current: curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(3)&quot; :class=&quot;[&#123; current: curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(4)&quot; :class=&quot;[&#123; current: curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;Tab&quot;, //接收父组件传递进来的curIdx的值 props: &#123; curIdx: Number, &#125;, //点击触发父组件更新curIdx值 methods: &#123; changeTab(i) &#123; this.$emit(&quot;changeTab&quot;, i); &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 传递给子组件Tab的值以及为他绑定一个方法用来通知父组件更新值 --&gt; &lt;Tab :curIdx=&quot;curIdx&quot; @changeTab=&quot;changeTab&quot; /&gt; &lt;!-- &lt;Page :curIdx=&quot;curIdx&quot;&gt;&lt;/Page&gt; --&gt; &lt;!-- &lt;img src=&quot;./assets/logo.png&quot;&gt; --&gt; &lt;!-- &lt;router-view/&gt; --&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Tab from &quot;@/components/Tab&quot;;// import Page from &quot;@/components/Page&quot;;export default &#123; name: &quot;App&quot;, components: &#123; Tab, // Page, &#125;, data() &#123; return &#123; curIdx: 0, &#125;; &#125;, methods: &#123; changeTab(i) &#123; this.curIdx = i; &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &quot;Avenir&quot;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; /* text-align: center; */ color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; 此时我们会得到一个如上图简单的父子组件通信的小demo，我们可以点击不同的链接按钮，然后链接按钮被点击后会变成黑色且无下划线，这是通过父组件操控子组件中的curIdx动态的为子组件中的四个a标签绑定 current类实现的，同时我们在点击子组件Tab中不同的a标签后会触发 changeTab方法来更新父组件中的curIdx值，进一步子组件在通过prop更新自己的curIdx实现的动态绑定current类到对应被点击的a标签的。如果你对这个简单的小demo还无法理解的话请先查看此篇教程： 父子组件通信https://www.cnblogs.com/HouJiao/p/12421851.html 接下来我们再尝试加入一个兄弟组件通信的场景，假设此时我们不仅仅需要通过curIdx来实时更新渲染Tab子组件中的被选中a标签，同时我们还希望可以通过curIdx实时刷新显示Tab栏下方的 Content页面中的内容，那么我们需要再新建一个组件Page同时在App.vue中引入并使用这个子组件如下 Page/index.vueApp.vue1234567891011121314151617181920212223&lt;template&gt; &lt;div&gt;&#123;&#123; content[curIdx - 1] &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;Page&quot;, props: &#123; curIdx: Number, &#125;, data() &#123; return &#123; // 根据prop接收的curIdx动态显示内容 content: [&quot;页面1&quot;, &quot;页面2&quot;, &quot;页面3&quot;, &quot;页面4&quot;], &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 传递给子组件Tab的值以及为他绑定一个方法用来通知父组件更新值 --&gt; &lt;Tab :curIdx=&quot;curIdx&quot; @changeTab=&quot;changeTab&quot; /&gt; &lt;!-- Page组件也接受这个curIdx值 --&gt; &lt;Page :curIdx=&quot;curIdx&quot;&gt;&lt;/Page&gt; &lt;!-- &lt;img src=&quot;./assets/logo.png&quot;&gt; --&gt; &lt;!-- &lt;router-view/&gt; --&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Tab from &quot;@/components/Tab&quot;;import Page from &quot;@/components/Page&quot;;export default &#123; name: &quot;App&quot;, components: &#123; Tab, Page, &#125;, data() &#123; return &#123; curIdx: 0, &#125;; &#125;, methods: &#123; changeTab(i) &#123; this.curIdx = i; &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &quot;Avenir&quot;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; /* text-align: center; */ color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; 此时我们就得到了一个最经典的vue兄弟组件传值的demo,即Tab栏中的a标签被点击后会通过 $emit触发changeTab函数来更新父组件中的curIdx值，然后Page组件接收到这个新更新的curIdx值来动态显示内容，这样就实现了点击不同的标签显示对应不同的内容。 思考：上面的例子中父组件的作用？ 我们考虑一下上面的实例代码即最传统的兄弟组件的通信方式有没有什么弊端。我们发现父组件完全就是承担了连个兄弟组件中的桥梁作用，父组件自己并不需要使用curIdx值和changeTab方法，但是为了能够让Tab和Page两个兄弟组件通信，又不得不加入这些内容，显然这种实现逻辑很奇怪，为什么不能直接让两个兄弟组件直接通信呢？进一步考虑，如果是两个有共同祖先的兄弟组件通信可就不仅仅是需要父组件承担桥梁身份这么简单了，可能会涉及到更多的祖先组件加入许多没用的东西，即如下图所示的场景： 很显然这种方式的通信一旦面对较为庞大且复杂的应用场景效率会极低，因此我们需要一个第三方插件能够专业的承担这个桥梁的作用，同时它不仅仅能够实现简单的拥有共同父祖先子组件之间的通信，甚至可以实现任意多个组件之间的通信，此时我们就会用到 vuex了！它提供了一个store仓库用来维护所有组件需要通信时用到的数据，并提供对应的方法来为通信的组件实时更新值，这就是vuex的由来，如下图就是它工作的原理： 我们可以很容易的看出使用 vuex的优势： 能够在vuex中集中管理共享的数据，易于开发和后期维护 能够高效地实现组件之间的数据共享，提高开发效率 存储在vuex中的数据都是响应式的，能够实时保持数据与页面的同步 既然vuex的好处那么多，接下来我们就来学习使用vuex吧😀！ vuex工作流程 首先我们来学习一下vuex中的几个基本概念，如下图是vuex的一个工作流程： VueComponents：需要进行通信的vue组件，不在vuexAPI范围之内 State：一个对象，类似于data对象用来存储维护通信需要使用到的所有数据 Mutations：也是一个对象，类似于methods存储了更新State数据的方法，只有Mutations中的方法可以更新State中的数据 Actions：如果需要异步调用Mutations方法，那么所有的异步操作都要在Actions中完成 Devtools：热加载插件，不用管 Getters：除了上图中这些概念，还有一个Getters，他是类似于computed可以根据State中的值进一步封装操作得到一个新数据并返还 Modules：如果是针对于企业级项目，还有一个Modules属性用来分模块引入并应用vuex，后面我们也会学习到。 要注意除了State剩下的都是复数形式这是因为它可以存储多个方法或者数据，因此是Mutations、Actions、Getters、Modules。 Vuex应用 vuex安装 接下来我们就尝试将上面的例子使用 vuex来实现。首先我们需要安装vuex,只需要在终端输入如下命令即可： 1npm install vuex --save 安装完成以后为了方便管理，我们在根目录下创建一个新的文件夹为store并在其下新建一个入口文件index.js如下图： 并在index.js中加入如下内容用来引入并挂在vuex： 12345678910111213141516171819202122import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 &#125;, mutations: &#123; // 用来定义修改state中数据的方法 &#125;, actions: &#123; // 异步操作 &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 现在我们就来使用vuex更改刚刚的代码。 state使用 由于我们之前使用的是curIdx来进行的兄弟组件之间的通信，因此很显然这个curIdx就是一个需要vuex维护的值，我们将其定义到vuex的state中而不再在父组件app.vue中定义。同时在Tab中和Page中我们也无需在通过prop来接收这个curIdx值了，而是改用vuex的state来获取这个值，如下图是两种不同的写法。 首先无论是哪种写法我们都需要在store/index.js中声明定义这个curIdx如下： 12345678910111213141516171819202122import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 curIdx: 0, &#125;, mutations: &#123; // 用来定义修改state中数据的方法 &#125;, actions: &#123; // 异步操作 &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 然后我们取消父组件中所有的有关传值数据，如下图父组件不再需要定义curIdx了并且引用子组件时也无需在为他们传递一个curIdx了即从父组件的角度来看他根本就不知到curIdx的存在： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 传递给子组件Tab的值以及为他绑定一个方法用来通知父组件更新值 --&gt; &lt;!-- &lt;Tab :curIdx=&quot;curIdx&quot; @changeTab=&quot;changeTab&quot; /&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;Tab @changeTab=&quot;changeTab&quot; /&gt; &lt;!-- Page组件也接受这个curIdx值 --&gt; &lt;!-- &lt;Page :curIdx=&quot;curIdx&quot;&gt;&lt;/Page&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;Page &gt;&lt;/Page&gt; &lt;!-- &lt;img src=&quot;./assets/logo.png&quot;&gt; --&gt; &lt;!-- &lt;router-view/&gt; --&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Tab from &quot;@/components/Tab&quot;;import Page from &quot;@/components/Page&quot;;export default &#123; name: &quot;App&quot;, components: &#123; Tab, Page, &#125;, // 无需在定义curIdx了 // data() &#123; // return &#123; // curIdx: 0, // &#125;; // &#125;, methods: &#123; changeTab(i) &#123; this.curIdx = i; &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &quot;Avenir&quot;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; /* text-align: center; */ color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; 接下来我们需要修改组件Tab和Page的代码去获取vuex中的curIdx,这里涉及到两种实现方法： 方法一 首先我们为了能够保证全局组件中this中含有 $store这个对象，我们需要全局挂载一下store，只需要在main.js中加入如下代码即可： 12345678910111213141516171819202122// The Vue build version to load with the `import` command// (runtime-only or standalone) has been set in webpack.base.conf with an alias.import Vue from &#x27;vue&#x27;import App from &#x27;./App&#x27;import router from &#x27;./router&#x27;Vue.config.productionTip = false// 首先从store文件夹下引入store(默认回去index.js中获取)// 因此这里路径写道文件夹即可import store from &#x27;../store&#x27;/* eslint-disable no-new */new Vue(&#123; el: &#x27;#app&#x27;, router, components: &#123; App &#125;, template: &#x27;&lt;App/&gt;&#x27;, // 在这里挂在store对象 store&#125;) 这里以Tab作为示例，我们可以直接通过 this.$store.state.curIdx即可获取到这个值，因此Tab修改后的代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;template&gt; &lt;div&gt; &lt;!-- 不在使用prop而是使用this.$store.state.curIdx获取 --&gt; &lt;!-- 由于vue中template无需使用this --&gt; &lt;!-- 因此直接使用$store.state.curIdx即可 --&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(1)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(2)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(3)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;changeTab(4)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;Tab&quot;, //接收父组件传递进来的curIdx的值 // props: &#123; // curIdx: Number, // &#125;, //点击触发父组件更新curIdx值 methods: &#123; changeTab(i) &#123; this.$emit(&quot;changeTab&quot;, i); &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 这样我们就获取到了vuex.store对象中的state对象内存储的curIdx值了，并且这个值也是动态响应变化的，可以实时更新，但是我们会发现这样写有一个小瑕疵就是每一次书写都要加上 this.$store.state太麻烦了，因此出现了方法二。 方法二 这里我们以Page为例，方法二使用了 mapState辅助函数，这样我们就可以得到一个map对象，输入需要的变量名即可获取到这个state中存储的值，我们将其映射到我们自己的组件上，由于这个值是动态变化的，因此我们需要将他放到 coputed下如下 12345678910111213141516171819202122232425262728293031323334353637&lt;template&gt; &lt;div&gt;&#123;&#123; content[curIdx - 1] &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123;mapState&#125; from &#x27;vuex&#x27;export default &#123; name: &quot;Page&quot;, // 不在需要使用prop接受值 // props: &#123; // curIdx: Number, // &#125;, computed:&#123; //要注意其本身是一个计算函数，因此外部有一个括号包裹 ...mapState(&#123; // 箭头函数可使代码更简练 curIdx:state=&gt;state.curIdx, // 下面这种书写也可以 // curIdx:&#x27;curIdx&#x27;, &#125;), // 当映射的计算属性的名称与 state 的子节点名称相同时，我们也可以给 mapState 传一个字符串数组 // ...mapState([&#x27;curIdx&#x27;]) &#125;, data() &#123; return &#123; // 根据prop接收的curIdx动态显示内容 content: [&quot;页面1&quot;, &quot;页面2&quot;, &quot;页面3&quot;, &quot;页面4&quot;], &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 注意如果我们需要在获取到这个state中的值以后进一步和data中的值进行加工，那么此时需要使用到this来执行当前的vue实例，为了能够正确只想，此时就不能在使用箭头函数了比如：12345// 为了能够使用 `this` 获取局部状态，必须使用常规函数 countPlusLocalState (state) &#123; return state.count + this.localCount &#125; &#125;) mutations使用 此时我们只是完成了子组件使用vuex中的curIdx,但是我们还需要更新这个curIdx，因此此时我们需要定义一个方法来更新它，此时就会用到mutations，我们在mutations中定义一个新的方法setCurIdx，要注意我们mutations中定义的方法默认的第一个参数永远是state指向state这样我们才能修改state中的值，因此加入setCurIdx后store/index.js代码如下 12345678910111213141516171819202122232425262728import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 curIdx: 1, &#125;, mutations: &#123; // 用来定义修改state中数据的方法 // 用来修改state中的curIdx // 默认第一个参数永远是state setCurIdx(state, idx) &#123; state.curIdx = idx; &#125; &#125;, actions: &#123; // 异步操作 &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 同样的子组件调用mutations中函数的方式也有两种如下所示 方法一 我们可以在methods中定义一个新方法，然后通过如下指令触发调用mutations中的方法 12//commit的第一个参数是要触发调用的函数名，第二个是传递的参数this.$store.commit(&#x27;setCurIdx&#x27;,idx) 此时Tab的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;template&gt; &lt;div&gt; &lt;!-- 不在使用prop而是使用this.$store.state.curIdx获取 --&gt; &lt;!-- 由于vue中template无需使用this --&gt; &lt;!-- 因此直接使用$store.state.curIdx即可 --&gt; &lt;!-- 由于setCurIdx已经映射为了自己的方法因此直接调用即可 --&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(1)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(2)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(3)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(4)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapMutations &#125; from &quot;vuex&quot;;export default &#123; name: &quot;Tab&quot;, //接收父组件传递进来的curIdx的值 // props: &#123; // curIdx: Number, // &#125;, //点击触发父组件更新curIdx值 methods: &#123; // 当然也可以不映射，而是直接调用this.$store.mutations.setCurIdx()修改 setCurIdx(idx) &#123; this.$store.commit(&quot;setCurIdx&quot;, idx); &#125;, //甚至可以 &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 思考：能否不调用mutations中的方法而是直接操作curIdx？ 肯定会有同学想到了一个简单的方法即下面代码可以直接修改state中的数据 1this.$store.state.curIdx=idx; 一定要注意这种方法是万万不可以的！因为虽然此时可以修改这个值，但是当应用逐渐庞大以后这种不通过mutations修改state中值的操作会难以跟踪，不方便后期bug的查找，因此一定不要这样写！ 方法二 另一种方法就是还是通过辅助函数mapMutations来获取到这个方法并调用如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;template&gt; &lt;div&gt; &lt;!-- 不在使用prop而是使用this.$store.state.curIdx获取 --&gt; &lt;!-- 由于vue中template无需使用this --&gt; &lt;!-- 因此直接使用$store.state.curIdx即可 --&gt; &lt;!-- 由于setCurIdx已经映射为了自己的方法因此直接调用即可 --&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(1)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(2)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(3)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;setCurIdx(4)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapMutations &#125; from &quot;vuex&quot;;export default &#123; name: &quot;Tab&quot;, //接收父组件传递进来的curIdx的值 // props: &#123; // curIdx: Number, // &#125;, //点击触发父组件更新curIdx值 methods: &#123; // 使用映射的方法获取setCurIdx方法 ...mapMutations([&#x27;setCurIdx&#x27;]), // changeTab(i) &#123; // this.$emit(&quot;changeTab&quot;, i); // &#125;, //我们甚至可以进一步封装将setCurIdx改个名字 // ...mapMutations([&#x27;setCurIdx&#x27;]), // changeTab(idx)&#123; // this.setCurIdx(idx); // &#125; &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 思考：如果需要传递多个参数怎么办？ 此时并不是在commit（）方法后面追加多个参数，而是将所有的数据打包封装成一个对象传递，这个对象又称为 payload，学名 提交载荷。如下 store/index.jsvue组件调用12345678// ...mutations: &#123; increment (state, payload) &#123; state.count += payload.amount1; state.count += payload.amount2; &#125;&#125; 1234store.commit(&#x27;increment&#x27;, &#123; amount1: 10, amount2:20&#125;) 当然，当只有一个参数时直接使用即可。 现在我们再来看一下父组件App.vue的代码，会发现他已经没有任何有关兄弟组件通信的代码了，即此时父组件无需在承担这个桥梁者的身份了，更加简洁优雅。第三方桥梁者身份由vuex来提供了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 传递给子组件Tab的值以及为他绑定一个方法用来通知父组件更新值 --&gt; &lt;!-- &lt;Tab :curIdx=&quot;curIdx&quot; @changeTab=&quot;changeTab&quot; /&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;!-- &lt;Tab @changeTab=&quot;changeTab&quot; /&gt; --&gt; &lt;!-- 也无需在为子组件提供方法了 --&gt; &lt;Tab /&gt; &lt;!-- Page组件也接受这个curIdx值 --&gt; &lt;!-- &lt;Page :curIdx=&quot;curIdx&quot;&gt;&lt;/Page&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;Page &gt;&lt;/Page&gt; &lt;!-- &lt;img src=&quot;./assets/logo.png&quot;&gt; --&gt; &lt;!-- &lt;router-view/&gt; --&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Tab from &quot;@/components/Tab&quot;;import Page from &quot;@/components/Page&quot;;export default &#123; name: &quot;App&quot;, components: &#123; Tab, Page, &#125;, // 无需在定义curIdx了 // data() &#123; // return &#123; // curIdx: 0, // &#125;; // &#125;, // 无需在定义这个方法了 // methods: &#123; // changeTab(i) &#123; // this.curIdx = i; // &#125;, // &#125;,&#125;;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &quot;Avenir&quot;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; /* text-align: center; */ color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; getters使用 实际上getters很好理解，他就是把对数据的多重操作不再在组件中使用computed进行封装返还，而是可以在vuex中使用getters即可得到。还是之前的那个例子，现在我希望下方的页面可以实时显示一句话即 当前显示的时第curIdx个标签对应的页面的内容。这句话很明显需要随时跟着curIdx变动更新，我们第一想法就是获取到这个curIdx然后再在page组件中新声明一个计算元素来生成这句话，但是我们其实可以完全在getters就是先这个功能，这样类似需求的组件就无需再重复写这种计算方法了，而是都可以通过getters统一拿到这个随时变化的字符串，首先我们需要在store/index.js中声明一个getters方法 12345678910111213141516171819202122232425262728293031323334import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 curIdx: 1, &#125;, getters:&#123; // 形参和mutations类似，第一个永远是state,第二个是payload content(state)&#123; return `当前显示的时第$&#123;state.curIdx&#125;个标签对应的页面的内容` &#125; &#125;, mutations: &#123; // 用来定义修改state中数据的方法 // 用来修改state中的curIdx // 默认第一个参数永远是state setCurIdx(state, idx) &#123; state.curIdx = idx; &#125; &#125;, actions: &#123; // 异步操作 &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 类似的，gettes中的方法返还的值和state中的值一样也有两种接受方法 方法一 第一种就是直接在html中双括号中引入即可，由于vuex中的数据也是动态响应的，因此从getters中获取的数据也是动态的，当源数据发生了变化，他也会跟着变化。如下 12345678910111213141516171819202122232425262728293031323334353637&lt;template&gt; &lt;!-- &lt;div&gt;&#123;&#123; content[curIdx - 1] &#125;&#125;&lt;/div&gt; --&gt; &lt;div&gt;&#123;&#123; this.$store.getters.content &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapState &#125; from &quot;vuex&quot;;export default &#123; name: &quot;Page&quot;, // 不在需要使用prop接受值 // props: &#123; // curIdx: Number, // &#125;, computed: &#123; //要注意其本身是一个计算函数，因此外部有一个括号包裹 ...mapState(&#123; // 箭头函数可使代码更简练 curIdx: (state) =&gt; state.curIdx, // 下面这种书写也可以 // curIdx:&#x27;curIdx&#x27;, &#125;), // 当映射的计算属性的名称与 state 的子节点名称相同时，我们也可以给 mapState 传一个字符串数组 // ...mapState([&#x27;curIdx&#x27;]) &#125;, data() &#123; return &#123; // 根据prop接收的curIdx动态显示内容 content: [&quot;页面1&quot;, &quot;页面2&quot;, &quot;页面3&quot;, &quot;页面4&quot;], &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 最终得到的效果图就是下方的内容会实时根据上方被选中的a标签发生变化 方法二 当然我们也可以借助 mapGetters辅助函数，同样的由于同时动态变化的，我们需要将其映射到computed属性下，此时组件就可以任意使用这个值了。如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;template&gt; &lt;!-- &lt;div&gt;&#123;&#123; content[curIdx - 1] &#125;&#125;&lt;/div&gt; --&gt; &lt;!-- &lt;div&gt;&#123;&#123; this.$store.getters.content &#125;&#125;&lt;/div&gt; --&gt; &lt;div&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapState &#125; from &quot;vuex&quot;;import &#123;mapGetters&#125; from &#x27;vuex&#x27;export default &#123; name: &quot;Page&quot;, // 不在需要使用prop接受值 // props: &#123; // curIdx: Number, // &#125;, computed: &#123; //要注意其本身是一个计算函数，因此外部有一个括号包裹 ...mapState(&#123; // 箭头函数可使代码更简练 curIdx: (state) =&gt; state.curIdx, // 下面这种书写也可以 // curIdx:&#x27;curIdx&#x27;, &#125;), // 当映射的计算属性的名称与 state 的子节点名称相同时，我们也可以给 mapState 传一个字符串数组 // ...mapState([&#x27;curIdx&#x27;]) // 由于下方已经存在了一个content数组，为了不重名我们需要修改一下这个getters返还的值名称为msg ...mapGetters(&#123; msg:&#x27;content&#x27; &#125;) &#125;, data() &#123; return &#123; // 根据prop接收的curIdx动态显示内容 content: [&quot;页面1&quot;, &quot;页面2&quot;, &quot;页面3&quot;, &quot;页面4&quot;], &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; actions使用 首先我们要知道actions的作用时用来处理异步操作的，但是什么是异步操作呢？所谓异步就是当执行这个代码以后程序并不会等待其成功结束并返还结果以后再继续向下走，而是这个异步操作自己去一边运行而主程序继续向下执行后面的代码，当之前的代码完成后再处理返还结果，这就是异步，而同步就是必须等待之前的代码成功运行并返还以后再向下执行代码。很显然setTimeout以及主流的接口调用获取数据的代码都是异步操作，这是因为以防出现阻塞以及页面长时间加载空白的问题。但是为什么这些异步操作要在actions中执行而不能再mutations中执行呢？这是因为vue官方插件专门提供了一个调试区域可以实时跟踪并显示vuex中state的值，但是如果mutations中的方法出现异步操作可能会造成跟踪出现异常。 如果你还没有vuex官方插件，可以点击下方链接前往极简插件商城下载 vue插件下载https://chrome.zzzmh.cn/info?token=nhdogjmejiglipccpnnnanhbledajbpd 这里我们举一个小例子，加入现在我们并不像setCurIdx的值立刻更新，而是等待1s后在更新。现在我们将延时函数setTimeout写到mutations内部如下 实际上此时vuex内部的curIdx就4，但是这个插件跟踪出现了异常，为了避免这种情况的发生，我们需要将异步操作放置到actions中，但是actions中并不能直接操作state中的数据，因此他需要等待1s以后调用mutations中的方法进行state中curIdx值的更新，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 curIdx: 1, &#125;, getters: &#123; // 形参和mutations类似，第一个永远是state,第二个是payload content(state) &#123; return `当前显示的时第$&#123;state.curIdx&#125;个标签对应的页面的内容` &#125; &#125;, mutations: &#123; // 用来定义修改state中数据的方法 // 用来修改state中的curIdx // 默认第一个参数永远是state setCurIdx(state, idx) &#123; state.curIdx = idx; // z这种异步操作在mutations中要避免 // setTimeout(()=&gt;&#123; // state.curIdx = idx; // &#125;, 1000) &#125; &#125;, actions: &#123; // 异步操作 // 注意第一个形参不是state而是context即this.$store因此后面可以跟commit调用mutattions中的函数 updateCurIdx(context, idx) &#123; setTimeout(() =&gt; &#123; context.commit(&#x27;setCurIdx&#x27;, idx); &#125;,1000) &#125; &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 此时我们还需要更改Tab中的代码让其不再直接调用setCurIdx()而是调用updateCurIdx()，这里同样有两种方法。 方法一 直接通过 this.$store.dispatch.updateCurIdx()实现，这里的dispatch作用和mutations中的commit类似，意为调用触发vuex中指定的方法，因此同样第一个参数是方法名，第二个参数是传值对象payload。此时Tab组件代码修改为 方法二 类似的就是借用 mapActions辅助函数啦，如下映射到methods即可了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;template&gt; &lt;div&gt; &lt;!-- 不在使用prop而是使用this.$store.state.curIdx获取 --&gt; &lt;!-- 由于vue中template无需使用this --&gt; &lt;!-- 因此直接使用$store.state.curIdx即可 --&gt; &lt;!-- 由于setCurIdx已经映射为了自己的方法因此直接调用即可 --&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(1)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(2)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(3)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(4)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapMutations &#125; from &quot;vuex&quot;;import &#123;mapActions&#125; from &#x27;vuex&#x27;export default &#123; name: &quot;Tab&quot;, //接收父组件传递进来的curIdx的值 // props: &#123; // curIdx: Number, // &#125;, //点击触发父组件更新curIdx值 methods: &#123; // 使用映射的方法获取setCurIdx方法 ...mapMutations([&quot;setCurIdx&quot;]), // 映射引入actions ...mapActions([&#x27;updateCurIdx&#x27;]), // changeTab(i) &#123; // this.$emit(&quot;changeTab&quot;, i); // &#125;, // 当然也可以不映射，而是直接调用this.$store.mutations.setCurIdx()修改 // setCurIdx(idx) &#123; // this.$store.commit(&quot;setCurIdx&quot;, idx); // &#125;, //我们甚至可以进一步封装将setCurIdx改个名字 // ...mapMutations([&#x27;setCurIdx&#x27;]), // changeTab(idx)&#123; // this.setCurIdx(idx); // &#125; // updateCurIdx(idx) &#123; // this.$store.dispatch(&quot;updateCurIdx&quot;, idx); // &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 应用实战 但是实际上我们大部分场景用不到setTimeout异步函数来操作vuex中的数据，更常见的是通过fetch、ajax或者axios拿去数据来为vuex中的值进行初始化，由于这些操作都是异步的，因此我们需要在actions中执行这些请求操作，获取到响应请求数据后再通过调用mutations中的方法来为state中的值进行初始化赋值。现在我们假设一开始并不知道哪一个a标签被选中，即curIdx值并不确定，我们需要通过一个api从后台去获取这个初始值，此时我们就会用到异步请求函数，假设curIdx初始值是3，我们现在需要调用接口 /init来获取到这个初始curIdx值，由于我们没有后台，因此使用axios+mock.js的方式来演示，首先我们需要安装axios 1npm install axios --save 然后我们在main.js中全局引入axios并挂载到vue的原型上，这样我们在任意位置处都可以使用axios请求函数。 1234// 引入axiosimport axios from &#x27;axios&#x27;;// 挂载到vue原型链上Vue.prototype.axios = axios; 然后我们再在根目录下创建一个axios文件夹并且在文件夹下创建index.js用来返还使用接口请求函数同时创建一个api.js用来存放具体的请求函数内容如下图 然后我们在两个文件中加入如下代码来向外暴露一个请求数据的方法这样子写的好处是当我们需要进行许多数据的请求时都只需要在这里定义好请求方法，然后组件一行调用这个向外暴露的方法即可，既保证了组件内部没有具体的请求函数内容，简洁优雅，同时所有的具体请求内容都放置到了api.js中方便后期维护（从此不再需要去组件中的各个位置去修改请求代码了😎） index.jsapi.js1234// 读取api.js内部定义的请求方法import * as apis from &#x27;./api.js&#x27;// 暴露给外部以便调用，此时所有的api方法整合到了一起形成一个对象命名为apisexport default apis 1234567891011121314import axios from &#x27;axios&#x27; // 默认接口头部公有的ip地址，由于这里是本机假请求并使用mock.js拦截返还// 因此使用本地回环地址127.0.0.1同时默认是80端口axios.defaults.baseURL = &#x27;http://127.0.0.1:80&#x27;;//该地址就叫URL（Uniform Resource Locator,统一资源定位器）//Axios 是一个基于 promise 的 HTTP 库，可以用在浏览器和 node.js 中。//API（Application Programming Interface，应用程序接口）// 没有传递的参数// 使用gei或者post都可以，我这里使用get请求export const initData = () =&gt; &#123; return axios.get(&#x27;/initData&#x27;);&#125; 然后我们再安装mock.js和axios-mock-adapter 123npm install mockjs --save//用来模拟仿真请求返回，可以拦截并解析得到去除ip后的路径npm install axios-mock-adapter --save-dev //开发环境依赖 然后为了方便管理我们再在根目录下新建一个mock文件夹并新建index.js用来存放所有的mock拦截函数，然后我们再在mock文件夹下创建一个data文件夹，其内部再创建一个data.js用来存储具体的初始化数据如下图： 我们分别在各个文件中加入如下代码 index.jsdata/data.js123456789101112131415161718192021222324252627282930313233// 通过axios-mock-adapter生成代理api地址，可以模拟后台的数据返还import axios from &quot;axios&quot;;import MockAdapter from &quot;axios-mock-adapter&quot;;import &#123; initData&#125; from &#x27;./data/data.js&#x27;export default &#123; // 第一个拦截返还函数 init() &#123; // 新建一个拦截对象 let mock = new MockAdapter(axios); mock.onGet(&#x27;/initData&#x27;).reply( // 无传进来的参数，因此是无参箭头函数 () =&gt; &#123; // 如果时有参数的请求，那么可以在这里进行解析 // 返还一个Promise对象 return new Promise(resolve =&gt; &#123; // resolve表示成功返还 // 是一个数组，其中第一个200是返还数据的头部信息状态code resolve([200, &#123; // 这里供开发者使用 code: 200, // 重点是要将初始的数据拿过来 initData, &#125;]); &#125;) &#125; ) &#125;&#125; 123456// 设置为常量不能被修改const initData=&#123; curIdx:3&#125;// 向外暴露export &#123;initData&#125; 拦截函数完成以后我们同样在main.js中引入 12345// 引入这个对象//默认引入mock文件夹下入口js文件index.js返还的对象import Mock from &#x27;../mock&#x27;// 加入init拦截函数Mock.init(); 此时我们已经完成了请求axios和拦截响应模块的准备，接下来我们进行演示，首先我们需要自定义一个新的actions函数同时他会调用axios向外暴露的请求函数initData，当请求成功发送后会被mock.js拦截然后返还响应，我们这里可以先打印一下返还信息res如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import axios from &quot;axios&quot;;import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;//默认引入index.js下的向外暴露的apis对象// 引入这个这个包含了所有请求函数的对象import apis from &#x27;../axios&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: &#123; // 用来维护通信使用的数据 curIdx: 1, &#125;, getters: &#123; // 形参和mutations类似，第一个永远是state,第二个是payload content(state) &#123; return `当前显示的时第$&#123;state.curIdx&#125;个标签对应的页面的内容` &#125; &#125;, mutations: &#123; // 用来定义修改state中数据的方法 // 用来修改state中的curIdx // 默认第一个参数永远是state setCurIdx(state, idx) &#123; state.curIdx = idx; // z这种异步操作在mutations中要避免 // setTimeout(()=&gt;&#123; // state.curIdx = idx; // &#125;, 1000) &#125; &#125;, actions: &#123; // 异步操作 // 注意第一个形参不是state而是context即this.$store因此后面可以跟commit调用mutattions中的函数 updateCurIdx(context, idx) &#123; setTimeout(() =&gt; &#123; context.commit(&#x27;setCurIdx&#x27;, idx); &#125;, 1000) &#125;, init() &#123; // 调用它的initData()方法进行初始化 apis.initData().then(res =&gt; &#123; console.log(res) &#125;); &#125; &#125;, modules: &#123; // 分模块引入 &#125;&#125;) 然后我们在Tab组件中的created钩子函数下触发这个actions函数，如果能够成功被拦截那么控制台将会打印返还信息如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;template&gt; &lt;div&gt; &lt;!-- 不在使用prop而是使用this.$store.state.curIdx获取 --&gt; &lt;!-- 由于vue中template无需使用this --&gt; &lt;!-- 因此直接使用$store.state.curIdx即可 --&gt; &lt;!-- 由于setCurIdx已经映射为了自己的方法因此直接调用即可 --&gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(1)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 1 &#125;]&quot; &gt; 选项1&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(2)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 2 &#125;]&quot; &gt; 选项2&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(3)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 3 &#125;]&quot; &gt; 选项3&lt;/a &gt; &lt;a href=&quot;javascript:;&quot; @click=&quot;updateCurIdx(4)&quot; :class=&quot;[&#123; current: $store.state.curIdx === 4 &#125;]&quot; &gt; 选项4&lt;/a &gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapMutations &#125; from &quot;vuex&quot;;import &#123;mapActions&#125; from &#x27;vuex&#x27;export default &#123; name: &quot;Tab&quot;, //调用actions进行curIndex的初始化 created() &#123; this.$store.dispatch(&quot;init&quot;); &#125;, //接收父组件传递进来的curIdx的值 // props: &#123; // curIdx: Number, // &#125;, //点击触发父组件更新curIdx值 methods: &#123; // 使用映射的方法获取setCurIdx方法 ...mapMutations([&quot;setCurIdx&quot;]), // 映射引入actions ...mapActions([&#x27;updateCurIdx&#x27;]), // changeTab(i) &#123; // this.$emit(&quot;changeTab&quot;, i); // &#125;, // 当然也可以不映射，而是直接调用this.$store.mutations.setCurIdx()修改 // setCurIdx(idx) &#123; // this.$store.commit(&quot;setCurIdx&quot;, idx); // &#125;, //我们甚至可以进一步封装将setCurIdx改个名字 // ...mapMutations([&#x27;setCurIdx&#x27;]), // changeTab(idx)&#123; // this.setCurIdx(idx); // &#125; // updateCurIdx(idx) &#123; // this.$store.dispatch(&quot;updateCurIdx&quot;, idx); // &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;a &#123; margin-right: 10px;&#125;.current &#123; color: #000; text-decoration: none;&#125;&lt;/style&gt; 控制台出现下图即说明成功！ 很明显data中是我们需要的数据，因此我们在actions中的init函数中进行解析然后调用setCurIdx进行state中的curIdx赋值就行了。 1234567init(context) &#123; // 调用它的initData()方法进行初始化 apis.initData().then(res =&gt; &#123; console.log(res) context.commit(&#x27;setCurIdx&#x27;,res.data.initData.curIdx) &#125;); &#125; 自此我们就完成了vuex中curIdx的异步调用请求接口进行初始化的工作，我们会发现刷新页面以后默认被选中的标签就是第三个同时下方的内容也是第三个内容 这就是一个典型的异步请求数据并初始化的流程，同时我们还熟悉了标准的axios和mock.js的使用。 关于异步执行的问题 我们知道js在执行函数时是异步执行的，即解释器在执行触发函数的代码以后并不会像c一样等大函数执行完毕并返还结果再执行接下来的代码，而是让函数先执行，自己继续进行下面代码的解释和运行，即 异步执行。我们先看一个简单的例子，如下所示，我们希望在Tab中created声明钩子函数中调用的dispatch触发hello这个action异步函数以后可以等待函数执行完毕后返还true并给suc赋值，我们第一时间想到的代码就是： store/actions.jsTab/index.vue1234567hello()&#123; // 1s以后执行打印操作，然后返还true给suc赋值 setTimeout(()=&gt;&#123; console.log(`hello`); return true; &#125;,1000); &#125; 12345created() &#123; this.$store.dispatch(&quot;init&quot;); var suc = this.$store.dispatch(&quot;hello&quot;); console.log(suc); &#125;, 我们会发现他返还给suc是一个Promise对象，但是这样并没有能够成功给suc赋值true suc被初始化赋值成了一个Promise对象了，但是并没有达到我们的预期效果（我们是希望他变为布尔类型的true值）。可是我们从中可以发现actions函数触发执行完代码以后会返还一个Primise对象,这样的话我们是否可以直接调用then来进行同步等待后的赋值呢？如下所示 1234567created() &#123; this.$store.dispatch(&quot;init&quot;); this.$store.dispatch(&quot;hello&quot;).then(()=&gt;&#123; var suc=true; console.log(suc) &#125;) &#125;, 我们得到了预期的效果，此时我们可以利用Promise对象的特点在执行完成以后在执行then后面的函数进行赋值，即同步等待前面的函数执行完成以后我们再进行后面的代码。但是此时我们并不能接收到hello函数返还的参数，加入我们现在希望hello在返还’success’字符串以后才能给suc赋值true,那么此时我们仅仅使用actions默认返还的Promise对象明显做不到了，此时我们可以手动创建一个Promise返还对象并且使用resolve()函数传递我们要返还的值代码如下： store/actions.jsTab/index.vue123456789101112hello() &#123; //嵌套在最外面 return new Promise((resolve, reject) =&gt; &#123; // 1s以后执行打印操作，然后返还success给suc赋值 setTimeout(() =&gt; &#123; console.log(`hello`); //手动加入执行完成后的resolve函数 // 这样后面的then可以捕捉到继续执行函数 resolve(&quot;success&quot;); &#125;, 1000); &#125;) &#125; 123456789created() &#123; this.$store.dispatch(&quot;init&quot;); this.$store.dispatch(&quot;hello&quot;).then((data) =&gt; &#123; if (data === `success`) &#123; var suc = true; console.log(suc); &#125; &#125;); &#125;, 此时我们仅在hello方法返还success字符串变量以后才会对suc赋值为true,这样我们就可以根据不同的返还值执行不同的操作了。 要注意dispatch默认返还的是一个Promise对象，因此我们可以链式执行，同时可以和async/await结合使用来等待所有的异步操作完成以后再返还Promise对象。 我们知道async是声明一个函数f为异步函数，那么此时f的返回值将是一个Promise对象，因此后面可以接f.then()来进行链式操作并且在里面进行同步等待后的数据处理操作。同时await就是async await的简写，他会阻塞等待后面所接的异步函数执行完resolve后获取resolve返还值才继续执行下面的代码，即同步等待。要注意await只能放在async函数内部使用 思考：await和.then都可以完成同步等待执行后面的代码操作，那么两者有何区别？ await可以实现正常的表达式赋值，如下两者是等价的 .then实现await实现1234567891011//f会返还Promise对象，异步函数async f()&#123; ... resolve(true)&#125;test()&#123; f.then((data)=&gt;&#123; //接下来给suc赋值true var suc=data &#125;)&#125; 123456789async f()&#123; ... resolve(true)&#125;//注意此时test需要声明为async，这样其内部才能使用awaitasync test()&#123; //同样实现了给suc赋值true var suc=await f();&#125; 那么我们在多重actions方法调用的情况下也可以使用这两个关键字完成等待所有的异步函数执行完成后返还Promise的操作如下 1234567891011121314// 假设 getData() 和 getOtherData() 返回的是 Promiseactions: &#123; //actions A会等待getData这个异步函数resolve()后再返还Promise async actionA (&#123; commit &#125;) &#123; commit(&#x27;gotData&#x27;, await getData()) &#125;, async actionB (&#123; dispatch, commit &#125;) &#123; await dispatch(&#x27;actionA&#x27;) // 等待 actionA 完成返还Promise //同时还要等待getOtherData()方法也resolve()返还Promise commit(&#x27;gotOtherData&#x27;, await getOtherData()) //只有如上的所有等待异步函数全部返还后actionB才会返还Promise &#125;&#125; 此时我们就实现了actionB同步等待函数内部的两行代码出发的所有异步函数全部执行完成以后再返还Promise的操作了。 文件结构整理 现在我们已经掌握了vuex的基础操作，但是此时的所有有关vuex的属性全部都是存储都一个store/index.js文件下，这样子的目录结构很不合理，只能适用于简单的项目中，为了能够方便管理，并且在项目后期规模日渐庞大的情况下易于维护，我们通常会将这几个属性分别使用一个js文件来存储，然后统一引入到index.js中。这样我们就需要创建几个新的js文件分别是state.js、mutations.js、getters.js、actions.js(当然modules也可以独立存储到一个modules.js中)如下所示 index.jsstate.jsgetters.jsmutations.jsactions.js1234567891011121314151617181920212223242526import axios from &quot;axios&quot;;import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 引入各个属性对象import state from &#x27;./state&#x27;;import getters from &#x27;./getters&#x27;import mutations from &#x27;./mutations&#x27;import actions from &#x27;./actions&#x27;// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: state, getters: getters, mutations: mutations, actions: actions, modules: &#123; // 分模块引入 &#125;&#125;) 12345export default &#123; // 用来维护通信使用的数据 curIdx: 1,&#125; 1234567export default &#123; // 形参和mutations类似，第一个永远是state,第二个是payload content(state) &#123; return `当前显示的时第$&#123;state.curIdx&#125;个标签对应的页面的内容` &#125;&#125; 12345678910111213export default &#123; // 用来定义修改state中数据的方法 // 用来修改state中的curIdx // 默认第一个参数永远是state setCurIdx(state, idx) &#123; state.curIdx = idx; // z这种异步操作在mutations中要避免 // setTimeout(()=&gt;&#123; // state.curIdx = idx; // &#125;, 1000) &#125;&#125; 123456789101112131415161718192021//默认引入index.js下的向外暴露的apis对象// 引入这个这个包含了所有请求函数的对象import apis from &#x27;../axios&#x27;export default &#123; // 异步操作 // 注意第一个形参不是state而是context即this.$store因此后面可以跟commit调用mutattions中的函数 updateCurIdx(context, idx) &#123; setTimeout(() =&gt; &#123; context.commit(&#x27;setCurIdx&#x27;, idx); &#125;, 1000) &#125;, init(context) &#123; // 调用它的initData()方法进行初始化 apis.initData().then(res =&gt; &#123; console.log(res) context.commit(&#x27;setCurIdx&#x27;, res.data.initData.curIdx) &#125;); &#125;&#125; 按照如上的文件结构来存储可以方便管理，因为伴随着项目的开发，每一个属性下面都会存在大量的数据、方法。 modules使用 接下来我们再学习一下modules属性，它通常会在多人合作的企业项目中使用。我们现在考虑一个问题，某一个项目会根据功能模块进行划分，然后每一个开发人员负责一个模块的划分，此时毋庸置疑几个模块是并行开发的，最后再合并分支形成完整的项目。那么在开发过程中每一个开发人员都肯定会用到vuex，此时可能开发人员小明使用了一个count变量，并且还定义了setCount方法，而开发人员小红也自己定义了一个count变量，并且也定义了setCount方法，那么合并以后很明显会出现一个问题，即count到底属于哪一个功能模块？因此在合作开发中为了避免多个人使用的vuex存在大量重名变量而不知道归属的情况就引入了modules概念。它很好理解，解决的办法类似于vue中组件的使用，每一个人的vuex都有一个自己的文件夹存储自己需要的东西，然后我们按照模块导入使用即可，那么为了区分不同vuex模块中的同名变量和同名方法很明显我们需要为每一个模块都起一个独特的名字即 命名空间。 现在我们以一个例子来讲解如何使用modules，假设现在我们有两个加法器组件counter1和counter2，他们都使用了模块对应的vuex中的count变量，并且可以调用自己对应的vuex中mutations存储的addCount方法进行加操作，此时很显然我们希望两个加法器的count和setCount互不干扰，此时我们就需要使用modules属性了，首先我们需要建立两个新的vuex模块，只需要在store文件夹下建立两个新文件夹counter1和counter2同时这两个文件夹都有完整的vuex结构如下 首先给出counter1模块下的代码 counter1/index.jscounter1/state.jscounter1/mutations.js123456789101112import mutations from &quot;./mutations&quot;;import state from &quot;./state&quot;;// 要注意返还仅仅是一个对象，而不是new Vuex.store// Vuex.store只会有一个export default &#123; //开启命名空间。那么调用它的属性时需要加上名字前缀counter1 namespaced: true, state: state, mutations: mutations,&#125; 123export default&#123; count:0,&#125; 123456export default &#123; setCount(state, num) &#123; state.count += num; &#125;&#125; 然后我们再给出counter2模块下的代码 counter2/index.jscounter2/state.jscounter2/mutations.js123456789101112import mutations from &quot;./mutations&quot;;import state from &quot;./state&quot;;// 要注意返还仅仅是一个对象，而不是new Vuex.store// Vuex.store只会有一个export default &#123; //开启命名空间。那么调用它的属性时需要加上名字前缀counter2 namespaced: true, state: state, mutations: mutations,&#125; 123export default&#123; count:2,&#125; 123456export default &#123; setCount(state, num) &#123; state.count += num; &#125; &#125; 首先要注意模块的index.js返还的仅仅是个对象而不是store对象，同时命名空间属性是namespaced要设置为true 我们会发现这两个模块的数据和方法名称是相同的，但是我们为这两个模块的counter设置的初始值略有不同。然后我们将这两个模块引入到vuex中，只需要再store/index.js中引入这两个modules即可 123456789101112131415161718192021222324252627282930import axios from &quot;axios&quot;;import Vue from &quot;vue&quot;;import Vuex from &#x27;vuex&#x27;// 由于是插件，因此需要将其挂载到vue上Vue.use(Vuex)// 引入各个属性对象import state from &#x27;./state&#x27;;import getters from &#x27;./getters&#x27;import mutations from &#x27;./mutations&#x27;import actions from &#x27;./actions&#x27;// 引入counter1和counter2两个模块import counter1 from &#x27;./counter1&#x27;import counter2 from &#x27;./counter2&#x27;// 注意返还的是一个vuex的仓库对象export default new Vuex.Store(&#123; // 里面包含之前介绍的几个属性 state: state, getters: getters, mutations: mutations, actions: actions, modules: &#123; // 分模块引入 counter1, counter2, &#125;&#125;) 此时我们再来编写两个加法器Counter1和Counter2他们分别使用对应vuex模块下的变量和方法。 Counter1/index.vueCounter2/index.vue1234567891011121314151617181920212223242526&lt;template&gt; &lt;div&gt; &lt;h2&gt;Counter1&lt;/h2&gt; &lt;div&gt;Counter1:&#123;&#123; count &#125;&#125;&lt;/div&gt; &lt;button @click=&quot;setCount(1)&quot;&gt;add&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapState, mapMutations &#125; from &quot;vuex&quot;;export default &#123; name: &quot;Counter1&quot;, computed: &#123; // 注意，此时要额外再传一个参数即命名空间这里是counter1 // 后面的写法是一样的，数组或者对象形式都可以 ...mapState(&quot;counter1&quot;, [&quot;count&quot;]), &#125;, methods: &#123; ...mapMutations(&quot;counter1&quot;, [&quot;setCount&quot;]), &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 1234567891011121314151617181920212223242526&lt;template&gt; &lt;div&gt; &lt;h2&gt;Counter2&lt;/h2&gt; &lt;div&gt;counter1:&#123;&#123; count &#125;&#125;&lt;/div&gt; &lt;button @click=&quot;setCount(2)&quot;&gt;add&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; mapState, mapMutations &#125; from &quot;vuex&quot;;export default &#123; name: &quot;Counter2&quot;, computed: &#123; // 注意，此时要额外再传一个参数即命名空间这里是counter1 // 后面的写法是一样的，数组或者对象形式都可以 ...mapState(&quot;counter2&quot;, [&quot;count&quot;]), &#125;, methods: &#123; ...mapMutations(&quot;counter2&quot;, [&quot;setCount&quot;]), &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 这里的两个加法器也基本一样，但是要注意他们的映射辅助函数传进去的命名空间是不同的，同时我们规定加法器1每次按按钮只进行加一，而加法器2每一次按按钮是加二。然后我们再在App.vue中引入并使用这两个加法器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 传递给子组件Tab的值以及为他绑定一个方法用来通知父组件更新值 --&gt; &lt;!-- &lt;Tab :curIdx=&quot;curIdx&quot; @changeTab=&quot;changeTab&quot; /&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;!-- &lt;Tab @changeTab=&quot;changeTab&quot; /&gt; --&gt; &lt;!-- 也无需在为子组件提供方法了 --&gt; &lt;Tab /&gt; &lt;!-- Page组件也接受这个curIdx值 --&gt; &lt;!-- &lt;Page :curIdx=&quot;curIdx&quot;&gt;&lt;/Page&gt; --&gt; &lt;!-- 不在需要传递curIdx了 --&gt; &lt;Page&gt;&lt;/Page&gt; &lt;!-- &lt;img src=&quot;./assets/logo.png&quot;&gt; --&gt; &lt;!-- &lt;router-view/&gt; --&gt; &lt;Counter1&gt;&lt;/Counter1&gt; &lt;Counter2&gt;&lt;/Counter2&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Tab from &quot;@/components/Tab&quot;;import Page from &quot;@/components/Page&quot;;// 引入两个加法器import Counter1 from &quot;@/components/Counter1&quot;;import Counter2 from &quot;@/components/Counter2&quot;;export default &#123; name: &quot;App&quot;, components: &#123; Tab, Page, Counter1, Counter2, &#125;, // 无需在定义curIdx了 // data() &#123; // return &#123; // curIdx: 0, // &#125;; // &#125;, // 无需在定义这个方法了 // methods: &#123; // changeTab(i) &#123; // this.curIdx = i; // &#125;, // &#125;,&#125;;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &quot;Avenir&quot;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; /* text-align: center; */ color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; 最后我们即可得到如下效果图，会发现上下两个加法器之间数据互不干扰 总结 自此我们基本上就掌握了大部分的vuex技能，同时用demo学习实战了如何进行vuex分模块的操作。最后强烈建议虽然映射的写法比较难以理解，但是理解后使用映射的方法更加优雅且易于维护，再真正的大型项目中强推分模块使用vuex！ 如果您还有任何疑惑可以参考官方文档 vuex文档https://vuex.vuejs.org/zh/#%E4%BB%80%E4%B9%88%E6%98%AF-%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%E6%A8%A1%E5%BC%8F 同时这里左上方给出了上面博客演示时使用的代码，整理不易，如果喜欢还请转载时带上署名😣","tags":["vue","vuex"],"categories":["开发技能"]},{"title":"浅谈vue项目部署到nginx","path":"/2021/10/18/nginx-web/","content":"针对小白的快速前端vue项目打包部署教程，包含二级域名解析配置以及https认证等，还不赶快进来看看👀？ 前言 由于我最近写了一个基于vue实现的代码缺陷自动检测的前端项目，又恰巧买了一个腾讯云服务器，因此想借此机会尝试部署到nginx上，但是博客已经占用了 coolchong.cn域名，因此想尝试部署到二级域名上，但是查阅了csdn上众多 水文后，发现大部分内容实在是晦涩难懂、一言难尽😅。幸好chongchong最终耗时一晚成功部署到了服务器上，为了防止以后忘记，也为了让电脑前的你能够少走点弯路，因此诞生了这篇博文。 准备工作 在部署之前，我们需要进行一些准备工作，您可以参考我下方给出的清单: 拥有一个待部署的vue项目 拥有一个云服务器，最好是centOS6以上 服务器上已经安装了nginx 拥有一个域名 拥有xshell和xftp软件 可能你还没有xshell和xftp软件，不用担心，你无需去冒着风险下载破解版本，NETSARANG公司已经提供了个人免费版本，你只需要点击下方链接简单填写姓名和邮件即可下载： xshell和xftp下载https://www.netsarang.com/zh/free-for-home-school/ vue项目打包 准备工作完成后我们首先要将待部署的vue项目进行打包，因为在我们开发时使用的是vue文件，方便进行热加载随时动态更新我们的修改，但是在部署到服务器后我们只需要放置静态的html资源即可，因此我们首先要进行vue的打包，打包步骤很简单，照着下面操作即可。 1.修改资源路径 我们首先打开 config/index.js文件，然后在build环境下加入 assetsPublicPath:'./如下图： 然后为了保证静态的资源(包括图片，elementui组件的icon图标等）正常加载显示，我们需要打开 build/utils.js文件，然后在 fallback下加入 publicPath:'../../'如下图： 2.关闭跨域代理 在开发时，我们为了解决前后端跨域问题，修改 proxyTable,但是部署到服务器后项目统一放置在一个文件件内，是无需在配置跨域代理，因此我们将 config/index.js文件的 proxyTable处的 '/api'后面的代码注释掉： 3.项目打包 新建终端，输入 npm run biuld打包项目，项目会生成一个index.html文件和一个用来存储静态依赖的static文件夹，统一放置在dist文件夹下如下图： 自此我们就已经完成了vue项目的打包了，然后我们打开这个index.html查看能否正常显示页面，当不是一篇空白正常显示时即说明打包完成了。同时如果你是用了elementui组件库的话，请检查icon图标是否也能够正常显示。 vue项目部署到nginx 接下来我们就需要通过xshell和xftp远程连接我们的服务器了，然后将打包好的dist文件夹放到特定的位置再修改一下nginx.conf文件的配置重启服务即可了。请参考下面步骤进行： 1.xshell连接远程服务器 首先如果你是第一次使用xshell的话需要新建一个会话，即记录一下这个会话连接的是你的那个服务器，如下图是配置界面： ①首先我们需要填写我们要连接的服务器的相关信息 ②然后我们点击用户身份验证，需要填写用来登录服务器的身份验证的账号和密码，这个根据你当时配置的账号名和密码填写即可： ③连接服务器 然后我们保存配置双击这个会话即会连接服务器，当成功连接以后会话界面左上角会呈现绿色，并且终端处于等待输入指令的状态： 2.xftp连接远程服务器 ①首先配置也和xshell类似我们先新建一个会话，然后和xshell一样填写相关的配置信息： ②保存配置后双击连接服务器，如果成功后可以得到下图图示，左侧是当前本地电脑的文件目录，右侧是远程服务器的文件目录： 3.将dist文件夹放置到远程服务器 我们会发现这个服务器里有许多文件夹，那么dist文件夹放到哪里比较好呢？我推荐你和我一样，将所有我们上传的项目统一放到 /home路径下，如下图我的博客，还有前端项目都放到了这里： 为了方便区分多个文件夹，我们可以将dist更改名称易于区别，例如我这里的代码缺陷自动检测项目就是将dist文件夹更名为了compile文件夹。上传的文件的操作很简单，拖拽上传即可： 4.配置nginx二级域名解析 我们现在已经将项目文件夹放到了服务器上了，但是现在还不能通过域名解析访问到这个项目，因此接下来我们需要修改nginx配置。如果你还没有nginx也不用担心，上网百度一下安装即可，就是几行指令就轻松安装了。由于我已经使用了 coolchong.cn作为了博客的解析域名，因此这里我将演示如何部署到二级域名 compile.wenchong.sapce下，当然一级域名部署也类似。 ①去dns解析平台新建二级域名，首先我们需要创建一个新的二级域名以便后面分配给这个项目，我用的是腾讯云，这里以腾讯云演示，登录腾讯云dns平台后进行域名解析管理，然后新建解析一定要保证是A类型，然后主机记录就是二级域名名称，线路类型默认就行，重点是记录值一定要填写服务器的公网ip如下图： ②保存这个新添加的解析并且开启解析，然后我们去配置 nginx.conf，在xftp中按照 /etc/nginx/找到nginx.conf文件，然后右键以记事本形式打开，我们填写如下代码到最下方： 1234567891011121314server &#123; #监听端口号,一般就用80,别标新立异 listen 80; #要分配的域名 server_name compile.coolchong.cn; #默认是根路径/ location / &#123; #指向的项目文件夹就是我们刚刚传的dist文件夹的位置 root /home/compile; #入口文件，肯定是index.html啦 index index.html; &#125; &#125; 然后保存退出，自此我们就完成了nginx的配置。 ③重启nginx服务，由于我们修改了nginx的配置，因此我们要重启服务，打开xshell，输入以下指令首先进入到nginx 1cd /etc/nginx ④然后我们输入如下指令检查nginx配置是否语法正确 1nginx -t 如果没有语法错误则会出现如下信息 12nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful ⑤然后我们输入如下指令重启nginx服务 1systemctl restart nginx.service 当没有任何响应时及说明重启成功，然后我们输入刚刚填写的二级域名 compile.coolchong.cn会发现已经成功部署可以正常解析了： 但是我们会发现有一点小问题，即上方提示此页面不安全，这是因为使用的是http而非https，当我们输入https开头时会发现无法正常加载，这是因此我们还没有为这个新的二级域名配置ssl证书，因此无法使用https。 5.为二级域名配置https(选做) 如果我们要追求完美，那么还需要再配置一下https的证书。操作很简单如下： ①前往腾讯云申请证书，腾讯云可以为我们提供一年免费的ssl的证书，首先我们进入官网首先然后在云产品中选择ssl证书到达如下界面： 然后我们点击左侧 我的证书一栏既可以看到当前我们已经拥有的证书，这里选择申请免费证书使用默认的亚洲诚信即可： 然后我们下一步后会获得一个txt记录类型记录需要添加到域名解析处，直接按照腾讯云推荐自动添加即可，添加完成后我们就会得到一条新的域名解析记录如下图： 然后我们继续下一步等待5分钟后一般就审核通过了，然后会跳转到一个提供下载zip压缩包的页面，我们需要下载这个压缩包，里面有我们需要配置到nginx、tomcat或者Apache的内容，我们解压缩后只需要使用里面nginx文件夹下的内容，里面会有两个东西，一个是crt证书，另一个是key文件，我们使用拖拽的方法将两个文件放置到xftp连接的远程服务器文件目录中的 /etc/ssl下如下图： ②然后我们需要再配置一下 nginx.conf文件，之前我们http使用的是80端口监听，而https一般是443，我们在 nginx.conf最下面再写一个新的server代码如下： 12345678910111213141516171819server &#123; #https使用443监听 listen 443 ssl; #注意填写自己的二级域名 server_name compile.coolchong.cn; #下面两行的xxxx出改为自己的域名，值和server_name一样即可 ssl_certificate /etc/ssl/1_xxxxx.crt; ssl_certificate_key /etc/ssl/2_xxxxx.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers PROFILE=SYSTEM; ssl_prefer_server_ciphers on; location / &#123; #注意指向dist路径该改为自己的 root /home/compile; index index.html; &#125; &#125; ③然后我们在输入如下指令重新启动nginx服务 1234#检查nginx配置是否正确nginx -t#重启nginx服务systemctl restart nginx.service ④重启成功后，我们在搜索引擎搜索栏中输入https开头的二级域名就可以安全解析到之前的项目了，并且此时浏览器会提示此页面安全了！ 反思与总结 在经过这次配置后总算是对服务器相关的nginx服务有了一定的了解了。这里给出我的一些理解，实际上server就是服务的意思，因此当我们需要使用nginx配置不同域名、不同端口时都需要重新新建一个server，server_name是匹配的域名，一般是可以匹配到的并且优先匹配优先使用这个server进行服务，但是当我们在nginx.conf中未找到dns中添加的域名记录时，那么会默认使用第一个或者是标记为默认的server进行解析。这也是为什么我的博客在nginx中没有添加 www.coolchong.cn的server也可以正确解析到博客的原因，因此我server_name为 coolchong.cn的server标记为了默认服务，因此当输入 www.coolchong.cn时dns解析发现有这条记录却并没未在nginx中找到对应匹配的服务就会抛给默认server进行服务因此解析到了 wenchong.sapce即博客地址了。同时这次我使用的是二级域名指向不同项目的方法来部署的，但是不同的项目实际上有三种不同的方法进行部署，这里我只使用了最常用的方法，另外两种可以参考这篇文章 nginx部署多个项目https://www.cnblogs.com/zhaoxxnbsp/p/12691398.html 同时本篇博客的理解参考了如下文章，特此鸣谢： nginx心得https://www.cnblogs.com/zhaoxxnbsp/p/12691398.html 最后我想说，虽然第一次配置的过程异常痛苦，但是相比于日日夜夜进行crud操作，我认为大学生多勇于尝试探索新事物更加有意义！祝愿你我都能够坚守乐于学习的初衷，早日成为传说中的大牛！","tags":["nginx","vue"],"categories":["开发技能"]},{"title":"浅谈《SpringBoot》数据请求响应","path":"/2021/08/30/request/","content":"SpringBoot入门笔记，本篇记录翀翀对数据请求响应的方法：RequestMapping,GetMapping和PostMapping的总结。 快速创建项目 这里我们使用Spring Initializer来快速创建一个项目，在选择应用场景依赖时我们选择如下三个即可： 由于我们的JDK版本是1.8因此需要将java编译配置更改为java 8,然后选择Spring Web、JDBC API和MysqlDriver(后两项依赖是我们通过jdbc方式连接和操作数据库时需要用到的，方便下一篇文章《SpringBoot》操作数据库的演示）: 创建完成后我们就完成了一个SpringBoot的项目创建，其文件结构如下图： 然后我们在demo下创建一个新的文件controller\\sqlController，我们将在这里编写持久化服务函数方法来进行数据请求的相应。 我们一定要注意DemoApplication是起始函数，他将在同级和下一级的文件中进行方法的运行，因此我们的Controller层的方法必须建立在与DemoApplication同级包下，因此controller在demo包下。 然后我们在设置一下端口，由于前端vue项目的运行也是在8080端口上，为了避免端口冲突，我一般将SpringBoot项目的端口设置为8888，我们在main/sources下可以看见已经创建了一个application.properties文件了，他是用来存储项目配置的。但是我更青睐于使用格式更加优雅的application.yml进行配置，因此我们在main/source下创建yml文件，并且添上端口号： 12server:\tport:8888 自此我们的项目就快速创建成功了。然后我们进行一个简单的测试，我们打开sqlController文件并编写以下函数： 1234@GetMapping(&quot;/hello&quot;) public String hellosql() &#123; return &quot;hello sql!&quot;; &#125; 然后我们运行项目后打开网址http://localhost:8888/hello当页面中可以显示hello sql及说明项目配置成功： GetMapping响应请求 在SpringBoot中我们常用的一种响应请求的方法就是使用@GetMapping注解标记的方法。他有以下两种写法，但是无论哪种写法最终参数都会在路径url中显示： @PathVarialble 我们在sqlController.java中编写以下函数： 1234@GetMapping(&quot;/query/&#123;name&#125;&quot;) public String PrintName(@PathVariable(&quot;name&quot;) String name)&#123; return &quot;Good morning!&quot;+name+&quot;~&quot;; &#125; 假设我们现在要通过上面的这个方法上传参数name为chongchong，那么最终的url为http:localhost:8888/query/chongchong即我们直接在/query/的后面加上我们要写的参数即可，如下图是最终的测试结果： 上面的测试软件是PostMan,可以点击这里下载： PostMan下载https://www.postman.com/downloads/ 我们要注意一下几点事项： 当使用@GetMapping注解时，请一定要将请求头的方法使用Get请求而不是Post请求，否则会返还错误码405表示方法不正确 注解下方的函数名字没有特殊要求我们可以自己命名例如我这里命名为了PrintName url中/&#123;var&#125;表示的是要填写的参数，而前面的query来标记此时调用该方法 参数中前必须使用@PathVariable来获取路径中填写的参数，其中注解后方括号内部的name必须与路径上的参数同名，但是后面的String name可以修改为其他参数名来方便方法内部使用，比如我们可以修改为 public String PrintName(@PathVariable(&quot;name&quot;) String n)&#123;此时内部的参数需要使用n来表示 @PathVariable最大的特点就是每一个参数直接使用/var/的方式填写即可。并且要注意每次我们修改了controller的代码都需要重新运行SpringBoot项目！ @RequestParam 使用这个注解的方法更加普遍，他支持不同形式的参数包括map,List，对象形式等。他的最大特点是请求路径url后面的参数使用?var=value的形式表示。 获取基本类型参数 我们使用@RequestParam的方法再重写一下上面的相应方法： 1234@GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam(&quot;name&quot;) String n)&#123; return&quot;Good morning!&quot;+n+&quot;~&quot;; &#125; 因此此时我们的请求url是http://localhost:8888/query?name=chongchong，测试结果如下图： 并且@RequestParam还可以使用defaultValue填写默认的参数值，此时如果后面我们并没有添加参数那么他将会使用默认值替代，如下： 1234@GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam(value = &quot;name&quot;,defaultValue = &quot;chongchong&quot;) String n)&#123; return&quot;Good morning!&quot;+n+&quot;~&quot;; &#125; 此时我输入http://localhost:8888/query并没有添加参数值chongchong,但是他仍然会返还上面的那句话： 同时@RequestParam还提供了required=false来设置参数为非必输项，如下： 1234567@GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam(value = &quot;firstName&quot;, required = false) String fn, @RequestParam(value = &quot;lastName&quot;, required = true) String ln ) &#123; //填写姓氏就加上，否则只输出名 return fn == null ? &quot;Good morning!&quot; + ln + &quot;~&quot; : &quot;Good morning!&quot; + fn + ln + &quot;~&quot;; &#125; 我们现在只加上lastName参数为wenchong,FirstName不写，那么测试结果如下图： 我们发现此时fistName不是必输项因此后台仍然给出了相应。但是我们要注意非必输项为填写时那么将被设置为空即null值，如下图我们打印出firstName的值： 为了避免出现此类现象，我们可以使用defaulValue来为其设置默认值 使用map来接收参数 我们还可以使用mao来接收一组参数，但是这个方法并没有简化输入url，我们在url中还是要输入所有的参数，只是在接收相应方法中我们不需要再枚举形参了，如下： 12345@GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam Map&lt;String,Object&gt; args) &#123; //map接收了参数，用get声明参数名字 return &quot;Good morning!&quot; + args.get(&quot;firstName&quot;) + args.get(&quot;lastName&quot;) + &quot;~&quot;; &#125; 此时我们输入的url还是http://localhost:8888/query/?firstName=Lang&amp;lastName=wenchong,并没有变短，但是此时方法中的参数声明就要简化了许多，当涉及到多个参数时使用此方法效果极佳。此时我们的测试结果如下图： 思考：Map泛型为什么是String-Object类型？ 我们要注意参数的形式是key-value键值对，其中前面部分是形参名称必定是字符串的，但是后面传递的值可能是int,long,String等类型，因此我们需要使用一个更大的父类形式Object来统一表示。 同样的我们还可以使用List或者Array进行接收但是不常用，因为写法很不友好并且接收的是同类型参数，这里仅给出测试代码： 123456789101112 //使用数组接收 @GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam(&quot;name&quot;) String[] args) &#123; //参数顺序、数组大小都要给定 return &quot;Good morning!&quot; + args[0] + args[1] + &quot;~&quot;; &#125;//使用List接收@GetMapping(&quot;/query&quot;) public String PrintName(@RequestParam(&quot;name&quot;) List&lt;Object&gt; args) &#123; //参数顺序、List大小都要给定 return &quot;Good morning!&quot; + args.get(0) + args.get(1) + &quot;~&quot;; &#125; 使用对象来接收参数 这个方法也常用，他通常用来处理某些具有特殊特殊身份的参数集合使用，如下是一个案例，我们假设要设定chongchong去新华书店购买图书，书名叫做《SpringBoot入门到入土》并且标价20元，此时如果我们要按照基本类型参数一个一个传递，很显然非常的复杂，并且关系不明确，此时我们可以事先定义两个具有特殊关系的对象来分别接收如下： 首先我们需要在demo下新建一个包sqlObject然后分别在下面建立两个实体类，分别是User和Book： 12345678910111213141516171819202122//sqlObject.User.javapublic class User &#123; private String username; private String location; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getLocation() &#123; return location; &#125; public void setLocation(String location) &#123; this.location = location; &#125;&#125; 123456789101112131415161718192021//sqlObject.Book.javapublic class Book &#123; private String bookname; private Integer price; public String getBookname() &#123; return bookname; &#125; public void setBookname(String bookname) &#123; this.bookname = bookname; &#125; public Integer getPrice() &#123; return price; &#125; public void setPrice(Integer price) &#123; this.price = price; &#125;&#125; 然后我们再在sqlController中加入以下相应方法： 1234@GetMapping(&quot;/buy&quot;) public String BuyBook(User user, Book book)&#123; return user.getUsername()+&quot; go to &quot;+user.getLocation()+&quot; to buy a book called &quot;+ book.getBookname()+&quot; for ￥ &quot;+book.getPrice(); &#125; 测试结果如图： 注意我们在填写参数时必须按照先填写完obj1的所有成员参数再填写obj2所有成员参数的顺序填写，因此SptingBoot不会去自动识别那个参数属于哪一个类，同时为了避免某个成员参数二次赋值，需要保证两个不用类的参数名称不同。如上图User使用的是username,Book使用的是bookname，当他们同时使用name时那么传参时就会出现name二次赋值的现象。 BUG问题：二次赋值现象？ 如下图就是一个二次赋值的现象，假设此时我们要求User必须使用name指定人名，Book也必须使用name指定书名，那么我们的对象定义就改为： 1234567891011121314151617181920212223//sqlObject.User.javapublic class User &#123; private String name; private String location; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getLocation() &#123; return location; &#125; public void setLocation(String location) &#123; this.location = location; &#125;&#125; 12345678910111213141516171819202122//sqlObject.Book.javapublic class Book &#123; private String name; private Integer price; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getPrice() &#123; return price; &#125; public void setPrice(Integer price) &#123; this.price = price; &#125;&#125; controller层响应方法如下： 1234@GetMapping(&quot;/buy&quot;) public String BuyBook(User user, Book book)&#123; return user.getName()+&quot; go to &quot;+user.getLocation()+&quot; to buy a book called &quot;+ book.getName()+&quot; for ￥ &quot;+book.getPrice(); &#125; 此时我们进行测试，最终结果如下了二次赋值的现象： 思考：有没有什么更好的方法解决上面的不同类对象同名成员属性参数的区分？ 我们虽然可以使用不同的参数来避免二次赋值，但是当面临多个类时很显然上面的方法并不合适，比如有多个类他们都会有同名属性比如id,name等，那么难道每次我们都要绞尽脑汁给他们改成不同的名字吗？没有必要，我们可以使用@InitBinder指定前缀绑定来解决问题。 @InitBinder应用 我们使用@InitBinder注解来解决User和Book添加了相同的属性name的赋值问题，此时我们在controller层加入以下响应请求方法： 1234567891011121314@InitBinder(&quot;u&quot;) private void initBinderU(WebDataBinder binder)&#123; //要求用@InitBinder(&quot;u&quot;)绑定的对象属性参数加上前缀u. binder.setFieldDefaultPrefix(&quot;u.&quot;); &#125; @InitBinder(&quot;b&quot;) private void initBinderB(WebDataBinder binder)&#123; //要求用@InitBinder(&quot;b&quot;)绑定的对象属性参数加上前缀b. binder.setFieldDefaultPrefix(&quot;b.&quot;); &#125; @GetMapping(&quot;/buy&quot;) public String BuyBook(@ModelAttribute(&quot;u&quot;) User user,@ModelAttribute(&quot;b&quot;) Book book)&#123; return user.getName()+&quot; go to &quot;+user.getLocation()+&quot; to buy a book called &quot;+ book.getName()+&quot; for ￥ &quot;+book.getPrice(); &#125; 此时我们在输入参数时就要求需要加上前缀了，这就有点类似于sql语句中的前缀，如下图是测试图： 这样我们通过添加前缀的方式就完美解决了不同类相同属性参数的传值问题。 @PathVariable和@RequestParam混用 实际上我们甚至可以混用两种注解，如下： 1234@GetMapping(&quot;/hello/&#123;id&#125;&quot;) public String hellosql(@PathVariable(&quot;id&quot;) Integer id,@RequestParam(&quot;name&quot;) String name) &#123; return &quot;hello！ &quot;+id+&quot;号：&quot;+name; &#125; PostMapping响应请求 在学习完GetMapping后我们已经可以完成少量参数时的数据请求了，但是我们发现此时有几个弊端： url中暴露隐私信息 当涉及多个参数时，即使使用对象作为参数写起来也非常的复杂 我们发现之所以出现如上的问题是因为我们总是在基于基础类型变量进行传值，即使是使用了对象也仅仅是在controller层进行了参数接收的简化，但是在传值时还是在一个属性一个属性的传递，因此会出现多参数时url复杂并且暴露隐私信息的问题。那么我们通过PostMapping就可以解决上面的问题，他的特点是将所有的变量封装在一个对象中，然后将对象传递，也就是说对象好像一个盒子，里面盛放了许多信息，这样我们在传递时就不用在url中逐一枚举所有变量了，而是直接上传对象了。 基本接收方法 我们以下图为了讲解一下最简单的PostMapping实现，我们在controller层加入以下函数： 1234@PostMapping(&quot;/query&quot;) public String PringtName(@RequestParam(&quot;name&quot;) String name) &#123; return &quot;Good afternoon!&quot; + name + &quot;~&quot;; &#125; 然后在postman中进行测试，我们需要注意因为此时我们不是在传递基础变量参数了，而是在传递一个对象，因此我们需要在body/for-data进行中填写键值对： 这就类似于我们传递了一个&#123;name:&quot;chongchong&quot;&#125;对象，并且要注意方法使用post形式，此时我们就可以正确得到相应了，并且我们观察此时的url并未携带我们的name信息，隐私信息得到了保障。 info同样的，postMapping也有defaultValue和required=false设置默认项和非必输项等属性，请自行尝试。 使用Map传递 PostMapping和GetMapping仅仅是在url形式和传输的数据形式上有所区别，最终实现的效果是一致的，因此PostMapping也有用Map传递参数的方法，只是要注意在测试时我们需要在body/form-data中进行信息填写： 12345@PostMapping(&quot;/query&quot;) public String PrintName(@RequestParam Map&lt;String,Object&gt; args) &#123; //map接收了参数，用get声明参数名字 return &quot;Good afternoon!&quot; + args.get(&quot;firstName&quot;) + args.get(&quot;lastName&quot;) + &quot;~&quot;; &#125; 同理，PostMapping中也有使用数组，List传递参数的方法。 使用Json数据传输 这是PostMapping中最大的特点，他可以使用json数据形式来传递数据，这样我们只需在前端中创建多个键值对对象就可以直接交付到后端完成多对象的传值，我们只需要在对象参数前面加上@RequestBody即可，如下图我们还是来实现买书： 首先我们定义BuyBook类： 123456789101112131415161718192021222324252627282930313233343536373839public class BuyBook &#123; private String username; private String location; private String bookname; private String price; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getLocation() &#123; return location; &#125; public void setLocation(String location) &#123; this.location = location; &#125; public String getBookname() &#123; return bookname; &#125; public void setBookname(String bookname) &#123; this.bookname = bookname; &#125; public String getPrice() &#123; return price; &#125; public void setPrice(String price) &#123; this.price = price; &#125;&#125; 然后在Controller层加入如下相应函数： 12345@PostMapping(&quot;/buy&quot;)//只能是一个接收类 public String BuyBook(@RequestBody BuyBook bb) &#123; return bb.getUsername() + &quot; go to &quot; + bb.getLocation() + &quot; to buy a book called &quot; + bb.getBookname() + &quot; for ￥ &quot; + bb.getPrice(); &#125; 这样我们在测试时使用postman并且改为body/raw/json格式加入键值对即可： 这样我们就轻松完成了买书的各种参数的传递。 RequestMapping 实际上我们前面所学到的GetMapping，PostMapping都是RequestMapping的子类，因此我们可以统一使用RequestMapping来代替前两者。其对应关系为： @RequestMapping @GetMapping&amp;@PostMapping @RequestMapping(path = “path”, method=RequestMethod.GET) @GetMapping(path=“path”) @RequestMapping(path = “path”, method=RequestMethod.POST) @PostMapping(path=“path”)","tags":["java","http request"],"categories":["开发技能"]},{"title":"序言--博客再起航寄语","path":"/2020/10/21/hello-world/","content":"hi👋~，看这里，博主在这里发表了重要的讲话！还不来看一看😊? 再起航 距离第一天建站已经过去700多天了，时光如白驹过隙般飞逝，最近一年中由于考研、备赛等各种原因造成了一段时间的停更，幸好最终长时间的努力没有辜负取得了较为满意的结果，如今不忘初心决定继续运营维护博客。 数十月的博客运营经历，也让我萌生了重新建站的想法，一来是hexo静态博客操作复杂，不易于随时随地进行维护更新，二来伴随着文章数量的递增，我深感生活随想与学习笔记专栏分开的必要性，同时volantis主题虽然具备丰富的个性化选项，但是stellar主题的内置wiki功能更加强大，能够有助于我高效的进行文档整理，因此在本次更新中我采用了typecho cuteen主题记录生活随想与hexo stellar主题存放学习笔记，分别绑定二级域名的策略进行搭建。因此您可以在这里进行博客专栏的跳转： 个人主页： https://coolchong.cn 生活随想： https://blog.coolchong.cn 学习笔记： https://scholar.coolchong.cn 起航 200天前，翀翀的小站正式诞生在HEXO大陆。 伴随着大二整整一学年的学习时光，我对博客的开发逐渐熟练同时博客也在魔改下变得愈发美丽，从起初的next主题到如今的volantis主题，从起初的一两篇文章到如今400k+的学习笔记内容，从起初的原始裸域到如今绑定自己的特有域名甚至到现在运行在自己的服务器上…我想一年的博客开发经历既充实了我的大学生活，让每一天充满了开发与维护博客的乐趣，同时又见证了我的成长，每每回看自己的博客文章，我总是能够回忆起坚持日更笔记的那些日子，虽然枯燥却充满了意义✒️。 一年的博客生涯，我结交了许多小伙伴，同时见证了许多充满意义的时刻。首先当然就是狂推我的小伙伴–Mr.拆加入了hexo博客大陆🤣（在这里为他打个小广告👉Cheeseburgerim’s blog)。同时加入到了volantis社区大家庭，认识了许多技术大佬，在他们的帮助下得以成功DIY自己的博客并在社区展示🍻。同时还认识了博友–HermitLSR(一个铁憨憨，也为他打个广告👉HermitLSR‘s blog)，和他交流博客开发的技术，学习到了许多新知识。同时还在大佬的友链中发现了自己的同专业校友😆–SuperPung，只能说缘分妙不可言呀！ 结尾语 未来的日子中，我希望自己可以坚持维护更新博客，勤更文章，不忘初心！ 雨中的博客于今日起重生再起航🚢… 最后分享一句话给未来的自己😁每一个优秀的人，都有一段沉默的时光。那一段时光，是付出了很多努力，忍受了很多的孤独和寂寞，不抱怨不诉苦，只有自己知道。而当日后说起时，连自己都能被感动的日子。","tags":["简介"],"categories":["简介"]},{"title":"处理工具","path":"/notes/处理工具/index.html","content":"在线文件处理 ConvertIO文件转换器https://convertio.co/zh/aConvert图片转换https://www.aconvert.com/cn/image/webp-to-gif/RemoveBG抠图https://www.remove.bg/zh?from=thosefree.com改图宝压缩裁剪https://www.gaitubao.com/#图片生成pdfhttps://smallpdf.com/cn/jpg-to-pdftinypnghttps://tinypng.com/ 设计素材模板 Canvas可画https://www.canva.cn/IconFonthttps://www.iconfont.cn/fontAwesomehttps://fontawesomelib.cn/FlatUIColorhttps://flatuicolors.com/ 代码文档共享 代码高亮https://tool.oschina.net/highlight代码生成图片https://carbon.now.sh/代码分享https://paste.org.cn/金山文档https://www.kdocs.cn/latest 有用但没大用 emoji文档https://www.emojiall.com/zh-hans在线画板https://www.suxieban.com/index.html美寄词云https://www.moage.cn/wordartMonkeyTypehttps://monkeytype.com/login键帽设计https://www.zfrontier.com/mykb/editor缩略图设计http://xsdggw.cn/t/tool/wylst/mockuphonehttps://mockuphone.com/device?type=ios#iphone12"},{"path":"/intro/index.html","content":"冬夜读书示子聿陆游古人学问无遗力，少壮工夫老始成。纸上得来终觉浅，绝知此事要躬行。2023年1月1日随想录分类卷标签集归档册言堂序 关于本站关于博主站点说明你好，欢迎参观我的学习博客“学圃堂” ，也许你已经发现了这个博客非常简洁只记录了我科研学习的笔记，这也是我的博客名称由来，因此我建立这个网站的初衷就是存放学习笔记、疑难点以及一些小技巧，这也就意味着这个博客更新面向我自己，文章更多的是用我自己看得懂的方式书写，如果你也对内容感兴趣并且在阅读过程中有任何疑惑欢迎在下方进行留言探讨！当然如果你想更加深入的了解我还请前往我的主站!来自于七里台男子职业技术学院的软件工程专业在读大四学生😆 热爱cg的科研小白，立志于成为冉冉升起的科研新星😂 在逃社恐人员，害怕工作的家里蹲一枚😨 学习能力堪忧，除了八股文啥也不会，未能保研的菜菜🥺 正在为研究生学位焦虑奋斗的考研人(等待来自于2.21的审判版)😳本站使用百度统计记录访问者的ip、浏览页面、浏览时间等信息。 本站部分资源来源网络，如因传播、转载、商用等导致纠纷，与本站无关； 本站文章引用或转载会严格遵循转载协议，尊重原作者的创作成果，如发现侵权等问题，及时联系处理； 本站提供非实名制评论功能，站长有权在未告知用户的前提下，修改、删除任何评论内容，所以请和谐留言； 本站非特别注明，均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。 最终解释权归本站所有。"},{"title":"科研学习","path":"/notes/index.html","content":"技术加油站 W3schoolhttps://www.w3school.com.cn/C语言中文网http://c.biancheng.netcs-Noteshttp://www.cyc2018.xyzRoad2Codinghttps://r2coding.com/OI WIKIhttps://oi-wiki.org/廖雪峰的技术网站https://www.liaoxuefeng.com/Quick Referencehttps://quickref.cn/图形学与混合现实平台https://games-cn.org/git bookhttps://git-scm.com/book/zh/v2leetcode bookhttps://books.halfrost.com/leetcode/GAMES101课件https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html南瓜书https://datawhalechina.github.io/pumpkin-book/ 闭关修炼室 LeetCodehttps://leetcode.cn/?utm_source=LCUS&utm_medium=ip_redirect&utm_campaign=transfer2china拼题Ahttps://pintia.cn/homeCodeForceshttps://codeforces.com/KuangBIN刷题https://vjudge.net/article/371 情报收集处 中国知网https://www.cnki.net/ARXIVhttps://arxiv.org/CHATGPThttps://chat.openai.com/chatStackOverFlowhttps://stackoverflow.com/ 秘传功法阁 搬书匠http://www.banshujiang.cn/鸠摩搜书https://www.jiumodiary.com/谷粉想学术http://chongbuluo.glgooo.top/muchong.html艾思科蓝https://www.ais.cn/ 上古神器室 CNKI学术翻译https://dict.cnki.net/index有道文档翻译https://pdf.youdao.com/?src=fanyiwebHighCharts演示图https://www.hcharts.cn/demo/highchartsLatex公式编辑器https://www.latexlive.com/Slager Latex模板https://www.slager.link/#/home妙写论文排版https://www.miaowrite.com/latex表格生成器https://www.tablesgenerator.com/亿图图示https://www.edrawmax.cn/Latex公式转图片https://latex.vimsky.com/论文查重http://www.papertime.cn/矩阵计算器https://zh.numberempire.com/matrixcalculator.php3D计算器https://www.geogebra.org/calculator"},{"title":"建站必备","path":"/notes/建站必备/index.html","content":"云数据存储 七牛云KODO存储https://www.qiniu.com/products/kodo阿里云ecshttps://www.aliyun.com/product/ecs?spm=5176.19720258.J_3207526240.33.542176f4vcfDVPvercelhttps://vercel.com/leancloudhttps://leancloud.app/ 网站自维护 百度流量统计https://tongji.baidu.com/web5/welcome/login域名解析https://cloud.tencent.com/product/cns网站测速https://tool.chinaz.com/speedtest/github.com"},{"title":"这是分页标题","path":"/wiki/GAMES191笔记/index.html","content":"fff ggg"},{"title":"什么是计算机图形学","path":"/wiki/GAMES191笔记/什么是图形学/index.html","content":"fff ggg"},{"title":"镜像与卷挂载","path":"/wiki/Docker笔记/镜像与卷挂载/index.html","content":"可视化管理工具——portainer 1234567891011121314151617#首先我们需要下载portainer镜像[root@VM-0-7-centos ~]# docker pull portainer/portainerUsing default tag: latestlatest: Pulling from portainer/portainer94cfa856b2b1: Pull complete 49d59ee0881a: Pull complete a2300fd28637: Pull complete Digest: sha256:fb45b43738646048a0a0cc74fcee2865b69efde857e710126084ee5de9be0f3fStatus: Downloaded newer image for portainer/portainer:latestdocker.io/portainer/portainer:latest[root@VM-0-7-centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest ea335eea17ab 3 days ago 141MBcentos latest 5d0da3dc9764 2 months ago 231MBportainer/portainer latest 580c0e4e98b0 8 months ago 79.1MB#创建一个容器运行服务，这里我暴露到了外网的9000端口[root@VM-0-7-centos ~]# docker run -d -p 9000:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --name prtainer01 portainer/portainer 然后我们就可以在http://ip:9000上看到portainer可视化面板了如下图所示，首先我们需要创建账号然后就可以登录了 然后我们选择本地local选项即可，因为一般我们都是单机测试使用的 然后我们就进入到了管理面板，映入眼前的有我们非常熟悉的镜像、容器等展示，我们可以在这里使用UI进行容器、镜像的管理，比如查看日志、进入容器的终端界面、删除创建、运行停止等等。 Docker镜像讲解 镜像是什么 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行换开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。所有应用，直接打包成docker镜像，就可以直接跑起来。那么我们如何获取到打包好的镜像呢？我们可以通过如下几种途径获取： 从远程仓库下载 朋友拷贝给你 自己制作一个镜像DockerFile Dokcer镜像加载原理 联合文件系统 联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。 联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率。 Docker镜像加载原理 docker的镜像实际上是由一层一层的文件系统组成，这种层级的文件系统就是UnionFS。 bootfs(boot file system)：docker镜像的最底层是bootfs，主要包含bootloader（加载器）和kernel（内核)。bootloader主要是引导加载kernel，linux刚启动时会加载bootfs文件系统。这一层与典型的linux/Unix系统一样，包含bootloader和kernel。当boot加载完成后，整个内核就在内存中了，此时内存的使用权已由bootfs转交给了内核，此时系统也会卸载bootfs(减少资源浪费)。这里的加载，可以理解为，我们windows电脑开机时候，从黑屏到进入操作系统的过程。 rootfs(root file system)：在bootfs之上，包含的就是典型linux系统中的/dev、/proc、/bin、/etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu、Centos等等。 图中以一个debian系统为例，从左到右，分为3个过程: 首先下载一个debian系统 让安装了emacs，这是后可以看到在图1基础上加了一层image 然后又安装了Apache,这时候就是在之前的基础上又加了一层image 这正验证了之前的那句话，docker的镜像实际上是由层一层的文件系统组成的。对于不同的的linux发行版本，bootfs基本是一致的，rootfs会有差别，所以不同的发行版可以共用bootfs。 平时我们安装虚拟机的CentOS都是好几个G，但是为什么Docker这里安装CentOS才200M呢？ 123[root@VM-0-7-centos ~]# docker images centosREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 5d0da3dc9764 2 months ago 231MB 这就是因为首先docker安装会优先安装最精简版的OS,同时对于一个精简的OS，rootfs可以非常小，只需要包含最基本的命令、工具和程序库即可。而更底层的bootfs并不需要镜像来携带安装，他可以使用主机的内核，因此没有了最浪费时间的引导加载过程，启动速度也就快了，同时大小也轻巧了许多。 镜像分层理解 知道了镜像的加载原理，不妨再回头看下镜像分层的原理。之前提过，镜像下载的时候是分层下载的，有些层如果已经存在了，就无需再次下载。比如我下载一个redis的镜像。 这种方式最大的好处就在于资源共享。比如有多个镜像都从相同的BASE镜像构建来的，那么宿主机只需要在磁盘上保留1分BASE镜像，同时内存中 也只需要加载一份BASE镜像，这样所有的容器都可以使用。另外，镜像的每一层都是可以共享的。我们可以通过docker image inspect来查看镜像的分层，比如我们现在查看刚才下在的redis镜像 1docker image inspect redis:latest 上面就是redis镜像的所有分层文件，因此所有的docker镜像都起始于一个基础镜像层，当进行修改或者增加新的内容时，就会在当前镜像之层上创建新的镜像层，如下图 假如现在我们要制作一个镜像，这个镜像基于Ubuntu linux 16.04，那么这个也就是镜像的第一层，然后我们还要继续安装python包，那么就会在第一层之上创建第二个镜像层即python层，继续打补丁的话，就会在第二层python镜像层的基础上创建第三个层。 我们一定要注意镜像和镜像层的区别，在添加额外的镜像层时，镜像始终保持是当前所有镜像层的组合。 如上图所示这里有2个镜像层，第一个镜像层包含了3个文件，而镜像则是包含了两个镜像层的6个文件。**同时当需要对某个层文件进行更新操作时，并不是替换，而是使用更高一层的文件去覆盖旧文件。**如下图所示，如果现在我们需要更新第二个镜像层文件5，那么此时生成镜像中的文件会覆盖底层镜像中对应的文件，使得文件里更新版本为一个新镜像层添加到镜像中。 此时这个镜像实际上有7个文件，但是我们从镜像外的角度来看，会认为他有6个文件，这是因为文件7覆盖而不是更换的文件5。即我们从外部的视角有点类似于搭盒子以后的俯视图，即如下图所示 我们从外部看这个三层镜像层组成的镜像会认为没有文件5，但是实际上此时文件5并没有消失，他还存在于第二个镜像层，只是被更高层次的同功能的位置文件7覆盖了而已。 因此我们在下载一个镜像时并不是一次性下载完成的，而是逐层逐层的下载，当发现他需要的某些层已经在下方存在过了，那么他就无需再下载这个镜像层了。 同时我们还要记住docker的一个特点，即docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部，这一层就是我们通常说的容器层，容器层之下的叫做镜像层。 这样当我们这个我们修改过的容器为一个新的镜像时，实际上就是在原基础镜像的基础上又新添加了我们的操作层，但是别人下载我们的这个镜像时如果他之前已经安装了基础镜像层，那么根据分层的理论他就只需要下载我们的操作层即可了，效率大大提升！如下图 commit镜像 1234docker commit 提交容器为一个新的副本#命令和git原理类似docker commit -m=&quot;提交的描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[tag] 我们以tomcat测试为例，首先我们下载tomcat镜像，让创建并运行容器，但是会发现webapps下没有任何东西，这是因为他默认安装的是最精简的阉割版，我们需要把webapps.dist下的所有内容copy到webapps下。 123[root@VM-0-7-centos ~]# docker run -it -p 8080:8080 tomcat[root@VM-0-7-centos ~]# docker exec -it 866a0027304a /bin/bashroot@866a0027304a:/usr/local/tomcat# cp -r webapps.dist/* webapps/ 现在我们已经部署tomcat成功了，可以输入http://ip:8090 查看界面了： 然后刚刚我们已经修改了在tomcat容器上进行了文件移动的操作了，那么我们现在就可以commit提交我们刚刚的修改了 123#我们提交后命名为tomcatwenchong 1.0版本[root@VM-0-7-centos ~]# docker commit -a=&quot;wenchong&quot; -m=&quot;add webapps app&quot; 866a0027304a tomcatwenchon:1.0sha256:dfe08bc422460ad9dddf275c5f45f387fd4f2c6596991eb51da5a4df36975b6f 然后我们就得到了我们自己的一个镜像，我们会发现它比tomcat要大一点点，这是因为我们在tomcat镜像的基础上加上了一个新的操作层。这也间接体现了镜像分层的原理。我们可以多次commit获得多个版本，和git commit类似。 容器数据卷 我们回顾一下之前的mysql容器有没有什么弊端。我们发现这个数据都是存储在mysql容器内部的，那么只要我们不小心删除了容器就会造成数据的永久丢失，这显然是很危险的，因此我们需要保证数据持久化存储在本地，即docker内部产生的数据可以同步到本地，这样删除容器后本地还会保留有数据，这就是容器数据卷的作用。 使用容器卷技术不仅仅可以实现容器和外部主机的数据共享，同时多个容器之间可以通过挂载相同的主机路径实现容器间的数据共享。 使用数据卷 使用-v命令挂载 1234567891011docker run -it -v 主机目录:容器目录#如下我们将centos容器内部的home挂载到主机的/home/ceshi[root@VM-0-7-centos home]# docker run -it -v /home/ceshi:/home centos /bin/bash[root@c384462e385f /]# cd /home[root@c384462e385f home]# ls[root@c384462e385f home]# [root@VM-0-7-centos home]# [root@VM-0-7-centos home]# lsceshi compile demo hexo wenchong[root@VM-0-7-centos home]# docker inspect c384462e385f 接下来我们写一点东西测试一下是否真正实现了数据共享 发现通过数据卷挂载以后确实实现了类似共享文件夹的功能。这样我们就可以保证容器的数据持久化存储了。并且当主机下修改这个目录，容器也会自动同步（即使容器没有运行）。如下图 此时我们修改test.java后再查看容器内的内容 并且此时如果我们删除容器，test.java也并不会丢失，还会存储在主机的/home/ceshi下，如下图所示 要注意虽然删除容器后，主机的文件还会存在。但是如果删除了容器内的这个文件夹，那么主机上也会同步删除所有的数据文件。 实战：数据卷挂载安装mysql 这个实战非常常用，因为我们经常需要容器运行mysql进行数据管理，但是数据又需要本地存储，因此会用到卷技术。这里我们实战演练一下 12345678910111213#首先我们获取镜像，这里下载mysql:5.7[root@VM-0-7-centos home]# docker pull mysql:5.7#然后我们需要创建容器#但是我们知道mysql需要创建账户，这里会用到如下命令#（你可以在docker hub mysql手册中找到这个命令）-d 后台运行-p 端口映射-v 数据卷挂载-e 环境配置，这里配置了mysql的账户密码--name 容器命名[root@VM-0-7-centos home]$ docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7 自此我们就启动了一个mysql容器，并且注册了账号，密码为123456，同时容器向外暴露的端口是3310，那么接下来我们启动navicat工具尝试连接这个数据，填写完账号，密码和地址后我们会发现成功连接了这个容器内的数据库 并且此时卷挂载成功，我们在主机/home/mysql下可以查看到data和conf文件夹 12345[root@VM-0-7-centos home]# lscompile demo hexo mysql wenchong[root@VM-0-7-centos home]# cd mysql[root@VM-0-7-centos mysql]# lsconf data 接下来我们尝试navicat中操作为数据库建一个表test，然后我们进入数据存储目录data下发现确实容器这里确实同步了一个数据库test如下图 这样我们就实现了在本地创建数据库后，容器内自动同步，实现了mysql数据的持久化本地存储，即使这时候删除容器也不会波及到数据。同时当我们再修改配置时，无需在连接服务器进入容器去修改配置了，而是可以直接在本地修改配置，远程服务器的容器将会自动同步这个配置，这样修改配置更加高效了😍。 具名挂载和匿名挂载 之前我们使用-v挂载时总是声明了主机路径和容器路径，即如下图所示 1docker run -d -P --name nginx01 -v /主机路径:/容器路径 nginx 这样我们就实现了把nginx01容器的一个路径挂载到主机的一个路径下，但是有时候我们并不想主动声明要挂载的主机路径，那么此时我们可以如下书写 1docker run -d -P --name nginx02 -v /容器路径 nginx 12docker volume ls 查看所有卷#这种就是匿名挂载，我们在-v时只写了容器内路径，不写主机路径 但是此时他挂载到了哪里呢？实际上未直接声明要挂在主句路径的卷都会默认放到docker下，这里我们为了方便验证，再学习一下具名挂载，具名挂载实际上也没有声明主句路径，但是他为这个新建的卷起了一个名字方便一会我们取寻找到他，格式如下 1docker run -d -P --name nginx03 -v 卷名:/容器路径 nginx 12#然后我们查看juming-nginx这个卷默认存储的位置docker volume inspect juming-nginx 查找juming-nginx卷的默认挂载地址 具名和匿名卷都是没有指定挂载路径的，但是他们会默认挂载到`/var/lib/docker/volumes/xxxxx/_data,`下 然后我们进入这个路径查看一下这个匿名卷是否真的取出了我们需要的conf.d以便后面和主机进行文件同步。 我们通过具名挂载可以方便的找到我们的卷，后面我们就可以动态的挂载这个卷了，因此大多数情况下我们使用的都是具名挂载。 12345678910#总结-v的写法-v /容器内路径 #匿名挂载-v 卷名:容器内路径 #具名挂载-v /宿主机路径:/容器内路径 #指定路径挂载#同时我们还可以为容器内设置权限#当卷容器路径后面加上:ro那么这个文件就只能宿主机修改了，容器只能读此文件了#当卷容器路径后面加上:rw那么容器可以读或者写这个共享文件(默认不写也是这个权限)docker run -d -P --name nginx03 juming-nginx:/etc/nginx:ro nginxdocker run -d -P --name nginx03 juming-nginx:/etc/nginx:rw nginx DockerFile dockerfile就是构建docker镜像的文件，因此是一个命令参数脚本。他的构建步骤如下 编写一个dockerfile文件 docker build构建为一个镜像 docker run运行镜像 docker push发布镜像到远程镜像仓库平台（Docker hub 或者阿里云) 实际上官方的镜像也是用dickerfile构建的，比如docker hub上的centos镜像，我们点击他的标签就会跳转到对应的github仓库里面就是dockerfile文件。 比如这里我们点击最新版本的latest标签，我们会发现他跳转到了如下的dockerfile界面，首先他使用指令from scratch提供最基础的镜像层，然后添加了centos最纯净版本，然后又添加了额外的指令集扩充并打上了标签，最终使用bin/bash完成运行。 很多官方镜像都是基础包，很多功能都没有，我们通常都会搭建自己的镜像。只有自己制作的才是最适合自己的开发环境。因此我们可以构建自己的dockerfile来创建自己的docker镜像。 dockerfile类似于一个自动化执行指令不断创建commit镜像提交并最终打包发布的一个脚本，可以用来构建一个docker镜像。 DockerFile构建过程 基础知识 每一个保留关键字（指令）都必须是大写字母组成 指令是从上到下顺序执行的 #表示注释 每一个指令运行后会创建提交生成一个新的创建层 dockerfile是面向开发，我们以后发布项目，就需要做镜像为我们的项目提供相对应的运行环境，此时我们就需要编写dockerfile文件，这个文件十分简单。项目交付由以前的jar包、war包等代码项目提交逐渐演化为了docker镜像代码项目+环境集成一体的阶段。因此Docker镜像逐渐成为企业交付的标准，必须要掌握。 思考：DockerFile和Docker images的区别？ 正如上文所述，dockerfile是docker images的构建文件，dockerfile定义了创建一个镜像的一切步骤，只要按照dockerfile中的指令执行即可构建生成一个我们最终所需要的docker镜像。而镜像就是最终我们需要发布和运行的产品，他直接包含了要运行的项目以及其需要的运行环境，因此保证了项目打包文件即拆即用，大大简化了运维部署的流程。 思考：docker commit提交也可以完成自定义镜像构建，为什么还需要dockerfile? 我们回顾一下之前的docker commit是我们手动修改了一个容器，在上面进行了一系列的操作然后commit提交打包成一个新的镜像。但是当面临需要添加许多新的依赖，并且添加环境配置，端口暴露等复杂需求时，使用commit就略显麻烦和鸡肋了，因此我们需要一个自动化构建镜像的脚本文件，这就是dockerfile存在的价值。 DockerFile的指令 12345678910111213FROM #引入基础镜像 centos ubuntu等都是基础镜像，一些从这里开始构建MAINTAINER #镜像是谁写的，姓名+邮箱RUN #镜像构建的时候需要运行的命令ADD #在基础镜像基础上添加其他功能WORKDIR #镜像的工作目录VOLUME #卷要挂载的目录位置EXPOSE #指定暴露端口（如果定义了，那么run创建容器时就无需在-p指定暴露端口）RUN #需要运行的指令CMD #指定容器启动时要运行的命令（只有最终一个会生效，且可被替代）ENTRYPOINT\t#指定容器启动时要运行的命令（可以追加命令）ONBUILD #当构建一个被继承的DockerFile就会运行ONBUILD指令COPY #类似于ADD，将指定的文件拷贝到镜像中ENV #构建时设置环境便令 实战测试 假设我们要自己创建一个centos镜像，我们在/home路径下创建/home/dockerfile用来存储我们创建的dockerfile文件。因为官方的centos镜像是最精简版的，许多我们平时需要的命令比如vim,ll等都是没有的，因此我们想基于官方的centos镜像基础上再添加一些指令。 这里我们在centos基础上添加vim，ifconfig等指令，同时希望在启动运行后能够输入语句提示我们镜像已经构建 编写完成后保存退出，然后我们运行这个dockerfile尝试构建我们自己的docker镜像如下图 12345#运行dockerfile构建docker镜像docker build -f dockerfile文件路径 -t 镜像名:[tag]#然后会依次执行我们的指令，最终得到如下输出及说明运行构建镜像成功Successfully built c5f9b92260c5Successfully tagged mycentos:0.1 然后我们进行这个镜像的测试，创建一个对应的容器并查看刚刚我们添加的指令集是否安装成功 要注意，ENV类似于map只是存储了不同的配置变量的具体值，而具体的首次进入路径设置是由WORKDIR完成的。 同时我们还可以使用如下命令轻松查看这个自定义的镜像是如何一步一步构建完成的 1docker history 镜像id CMD和ENTRYPOINT 12CMD #指定容器启动时要运行的命令（只有最终一个会生效，且可被替代）ENTRYPOINT\t#指定容器启动时要运行的命令（只有最终一个会生效，可以追加命令） 刚刚我们也运行了CMD指令，那么他和ENTRYPOINT具体是干什么的？又有什么区别呢？ CMD测试 我们再创建一个新的dockerfile命名为dockerfile-cmd-test，并且在里面添加CMD指令 12FROM centosCMD [&quot;ls&quot;,&quot;-a&quot;] #启动容器后面添加 ls -a打印全部内容 然后现在我们运行这个dockerfile文件生成一个新的镜像，并创建容器启动它，我们可以看到如下结果 123456789101112[root@VM-0-7-centos dockerfile]# docker build -f dockerfile-cmd-test -t cmdtest .Sending build context to Docker daemon 3.072kBStep 1/2 : FROM centos ---&gt; 5d0da3dc9764Step 2/2 : CMD [&quot;ls&quot;,&quot;-a&quot;] ---&gt; Running in d14c7e0b26d5Removing intermediate container d14c7e0b26d5 ---&gt; 48fe3fde9750Successfully built 48fe3fde9750Successfully tagged cmdtest:latest[root@VM-0-7-centos dockerfile]# docker run 48fe3fde9750 因此CMD指令是容器创建成功并启动后会执行的指令。但是此时如果我们在启动时再追加一个-l参数使得启动后打印的操作变为ls -al，但是此时会发现报错了： 12[root@VM-0-7-centos dockerfile]# docker run 48fe3fde9750 -ldocker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &quot;-l&quot;: executable file not found in $PATH: unknown. 这是因为此时-l参数并不是追加到了ls -a后面，而是直接替换了ls -a，因此此时相当于创建容器并启动容器后要运行的指令变成了-l，很显然容器并不知道这是个什么指令，因此报错了。因此如果我们在CMD的情况下向最后运行ls -al指令，需要全部替换，即创建并启动容器的指令应该是 1docker run 48fe3fde9750 ls -al ENTRYPOINT测试 这个指令就是解决了上面的弊端，他是允许直接为要运行的指令追加参数的。比如此时我们再创建一个dockerfile文件命名为dockerfile-cmd-entrypoint。然后在里面添加如下内容 12FROM centosENTRYPOINT [&quot;ls&quot;,&quot;-a&quot;] #这里使用了ENTRYPOINT代替之前的CMD 然后也是运行dockerfile创建镜像，然后创建并启动容器，正常情况下不加新的指令参数也是会正常执行ls -a 指令的，和CMD没有什么区别。但是如果此时我们再后面追加一个-l，那么此时指令并不会被替换为-l而是追加这个参数变成了ls -al，因此此时可以正确执行命令得到如下结果 DockerFile中许多命令都十分类似，我们需要了解他们的区别，CMD和ENTRYPOINT只是其中一组，我们要通过对比测试学习区分两个指令的不同点。 实战：Tomcat镜像构建 这次我们不再是基于已有的tomcat容器或者镜像进行操作构建一个tomcat新镜像了，而是完完全全使用压缩包原文件，引入并使用脚本自动化构建环境创建一个tomcat镜像。因此首先我们需要一个tomcat源文件压缩包，然后由于tomcat基于java运行，因此我们还需要一个jdk压缩包。这里我们可以前往jdk官网下和tomcat官网下载需要的tar.gz压缩包文件。这里博主宝宝贴心的提供我实操用的压缩包文件😁,密码是wssb 实验资源https://pan.baidu.com/s/1a6nOATjckhAOTAlVcrQSew 下载完成以后我们使用xftp上传到服务器上，这里我上传到了/home/dockerfile/tomcat/路径下,在编写之前我们需要先写一个声明文件为readme.txt，在tomcat下创建即可然后我们现在就开始编写dockerfile文件。此时tomcat文件夹文件如下 我们要注意按照官方的规范写法，我们需要将容器构建文件命名为Dockerfile。这样我们之后运行dockerfile取构建镜像时服务器会自动寻找这个Dockerfile文件，前面不再需要添加-f选项了。接下来我们开始编写Dockerfile文件 123456789101112131415161718192021222324252627282930313233343536#引入基本镜像FROM centos#创作者信息MAINTAINER wenchong&lt;1422257646@qq.com&gt;#把之前的说明文档readme.txt放到容器的/usr/local/下COPY readme.txt /usr/local/readme.txt#注意这里使用ADD而不是COPY是因为ADD可以解压缩#同样解压缩后将文件夹放到容器的/usr/local/下ADD jdk-8u311-linux-x64.tar.gz /usr/local/ADD apache-tomcat-9.0.55.tar.gz /usr/local/#安装vim指令集RUN yum -y install vim#pwd后账号的基础工作路径ENV MYPATH /usr/localWORKDIR $MYPATH#这里是核心，他自动的使用之前添加的tomcat和jdk依赖文件#自动搭建环境，这里就是使用脚本指令设置环境变量#注意不同的版本略有区别，需要根据实际情况设置ENV JAVA_HOME /usr/local/jdk1.8.0_311#分号用来区分路径1和路径2ENV CLASS_PATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.55ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.55ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin#希望tomcat运行后在容器内部的8080端口暴露EXPOSE 8080#最后每一次打开都会打印日志#也是为了让他有一个前端进程，从而保证不会让容器自动关闭CMD /usr/local/apache-tomcat-9.0.55/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.55/logs/catalina.out 然后我们就完成了Dockerfile的编写，接下来我们就运行这个dockerfile来创建我们自己的diytomcat镜像，命令如下 123#一定不要忘记最后面有一个.#同时由于我们命名为了Dockerfile因此这里不需要-f选中dockerfile文件了[root@VM-0-7-centos tomcat]# docker build -t diytomcat . 然后他就会逐行 指令去执行，最后我们得到如下图则说明镜像创建完成： 接下来我们运行这个镜像来创建并启动一个diytomcat容器，指令如下 123456#有点长，我们依次解释#首先-d 容器后台运行，由于我们设置了启动后打印日志的前端进程因此容器不会自动关闭# --name 设置容器名称为diytomcat01#然后-p 将容器内部8080端口映射暴露到宿主机的9090端口，这样我们可以在外部访问#然后两个-v分别是挂载路径映射[root@VM-0-7-centos tomcat]# docker run -d -p 9090:8080 --name diytomcat01 -v /home/dockerfile/tomcat/test:/usr/local/apache-tomcat-9.0.55/webapps/test -v /home/dockerfile/tomcat/tomcatlogs/:/usr/local/apache-tomcat-9.0.55/logs diytomcat 我们创建并启动成功以后，发现他确实没有自动关闭，同时我们进入这个容器输入pwd后发现默认的工作目录确实是/usr/local，同时输入ls -ll发现我们需要的tomcat和jdk的文件夹都存在，说明配置成功了 然后我们再去访问https://云服务器ip:9090查看能否访问到tomcat入口页面，结果成功！ 那么接下来我们可以尝试发布项目了，由于我们做了卷挂载，因此我们可以直接在本地将项目放置到/home/dockerfile/tomcat/test文件夹下既可以自动同步到容器内tomcat的test目录下自动发布，也就意味着现在我们通过了卷挂载实现了本地项目编写完成后后远程容器内的tomcat自动部署项目😎! 我们进入本地的test路径创建一个WEB-INF目录，然后里面编写一个web.xml文件内容如下 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://java.sun.com/xml/ns/j2ee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd&quot; version=&quot;2.4&quot;&gt; &lt;/web-app&gt; 然后我们再返回到test文件夹下编写一个入口页面，这里我们使用index.jsp文件实现，内容如下 123456789101112131415&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;Hello World&lt;/title&gt;&lt;/head&gt;&lt;body&gt;Hello World!&lt;br/&gt;&lt;%\tSystem.out.println(&quot;Hello Wenchong&quot;);%&gt;&lt;/body&gt;&lt;/html&gt; 编写完成，此时我们的本地test目录下新添加了一个入口页面indexjsp,由于使用了卷挂载，容器内的tomcat也会自动同步这个文件，因此此时我们输入http:云服务器ip:90980/test就可以立即看到这个页面自动部署成功了，如下图 这就是使用卷挂载实现的项目自动部署，我们的nginx的nginx.conf配置文件也可以和本地的同步，这样每次我们都无需再去容器内部修改配置文件了，大大简化了修改流程。同时我们还可以通过查看本地的tomcatlogs时刻看到容器中tomcat的日志如下图 每次有人访问和这个服务，我们tomcat都会在日志中打印信息，但是我们无需到容器内不去查看日志，而是通过卷挂载后只需通过本地的tomcatlogs下的catalina.out就可以实时查看日志。"},{"title":"常用操作","path":"/wiki/Docker笔记/常用操作/index.html","content":"Docker的基本组成 首先我们可以看到他由客户端、本地服务器、远程仓库三个部分完成。其中我们客户端可以输入指令从远程仓库拉取不同的镜像到本地服务器。本地服务器通过Docker守卫进程首先管理镜像，然后镜像可以实例化出许多相互隔离的容器来进行不同的工作。 镜像（images)：docekr镜像就好比模板，可以通过这个模板来创建容器服务、比如我们可以通过run tomcat镜像创建两个tomcat容器分别是tomcat01和tomcat02，两个容器相互隔离独立的运行服务。也就是说一个镜像可以创建多个容器、最终的服务运行或者项目运行是在容器中的 容器（Container)：Docker利用容器技术可以独立运行一个或者一组容器，通过镜像来创建的。因此容器可以启动、停止、删除等。 仓库（Repository)：仓库就是存放镜像的地方，分为私有仓库和公有仓库，默认的是docker hub(但是也有国内阿里云镜像等)。 我们可以简单的理解为仓库就是类似于github的远程仓库地址，可以pullpush。而镜像和容器的关系类似于java中类和实例的关系，镜像来定义工作的原理和运行的功能。容器就是具体的工作实例，因此由同一个镜像创建的容器工作原理是相同的，但是他们之间相互独立工作。 Docker安装 环境查看 博主使用的是centos8，腾讯云1核2G的服务器，使用xshell远程连接服务器进行学习的 首先查看配置如下 123456789101112131415161718#系统版本[root@VM-0-7-centos ~]# cat /etc/os-releaseNAME=&quot;CentOS Linux&quot;VERSION=&quot;8 (Core)&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;8&quot;PLATFORM_ID=&quot;platform:el8&quot;PRETTY_NAME=&quot;CentOS Linux 8 (Core)&quot;ANSI_COLOR=&quot;0;31&quot;CPE_NAME=&quot;cpe:/o:centos:centos:8&quot;HOME_URL=&quot;https://www.centos.org/&quot;BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;CENTOS_MANTISBT_PROJECT=&quot;CentOS-8&quot;CENTOS_MANTISBT_PROJECT_VERSION=&quot;8&quot;REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;REDHAT_SUPPORT_PRODUCT_VERSION=&quot;8&quot; 安装步骤 首先我们打开帮助文档查看具体的安装步骤 1.卸载旧的版本 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 2.需要的依赖安装包 1sudo yum install -y yum-utils 3.设置镜像仓库 注意这里官方文档给的镜像仓库地址是外网的，我们改为阿里云国内镜像 123sudo yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4.安装docker相关函数 1sudo yum install docker-ce docker-ce-cli containerd.io 5.安装完成启动docker 1sudo systemctl start docker 启动成功以后我们可以运行docker version 查看相关的docker信息 123456789101112131415161718192021222324252627282930[root@VM-0-7-centos ~]# docker versionClient: Docker Engine - Community Version: 20.10.10 API version: 1.41 Go version: go1.16.9 Git commit: b485636 Built: Mon Oct 25 07:42:56 2021 OS/Arch: linux/amd64 Context: default Experimental: trueServer: Docker Engine - Community Engine: Version: 20.10.10 API version: 1.41 (minimum version 1.12) Go version: go1.16.9 Git commit: e2f740d Built: Mon Oct 25 07:41:17 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.11 GitCommit: 5b46e404f6b9f661a205e28d59c982d3634148f8 runc: Version: 1.0.2 GitCommit: v1.0.2-0-g52b36a2 docker-init: Version: 0.19.0 GitCommit: de40ad0 6.运行Hello World 1sudo docker run hello-world 出现上图说明运行成功了，实际上上面图就是一个完整的docker镜像搜索-&gt;docker拉取镜像-&gt;docker运行镜像创建容器-&gt;docker容器启动运行的全流程。 我们可以通过如下指令查看从远程仓库拉取到的镜像 1docker images Docker讲解 我们回顾一下刚刚的hello-world镜像获取，创建容器，运行容器的全流程，可以总结为下图 要注意命令dockerrun name是尝试创建一个新的容器name，如果没有这个镜像会去远程仓库寻找，否则在本地直接使用name镜像创建一个新的容器，因此name是镜像名字，默认如果没有给容器命名会自动创建一个名字，或者我们可以使用容器id。 思考：docker到底是什么？怎么运行的？ Docker是一个C/S结构的系统，Docker的守卫进程运行在主机上，通过socket从客户端访问。DockerServer接收到Docker-Client的指令以后就会执行这个命令。 上图很清晰的描述了docker运行的底层原理。首先最外面的框架就是一个大的Linux服务器即我们的云服务器，而客户端就是不同的账户，比如现在我们正在使用一个账户输入指令，那么这就是一个客户端，但是我们并不是直接操作docker容器的，而是统一将命令交付到守卫进程，守卫进程来根据执行具体的操作不同的容器，因此从docker的视角来看，他和守卫进程通信，而不能直接被我们所操纵，我们只是通过守卫间接的操纵。 同时里面存在许多个相互隔离的容器，他们独立的运行，比如上图中左侧是一个centos容器，右侧是一个mysql容器，但是我们要知道每一个容器都是一个小的完整系统，即他们自己都有一套完整的指令、端口等。比如centos容器正在运行，他自己内部端口是8080，mysql容器也在运行并且使用的端口是3306，两者互不干扰，此时mysql容器也可以运行在8080端口也并不会干扰到centos容器，这是因为两个容器都是独立的系统，有自己的一套完整的构件。而我们外部也可以使用8080端口，他和两个容器的端口也是互不干扰的，但是此时我们并不能直接通过服务器的8080或者3306端口查看到两个容器的运行，因为我们并不能直接访问操控容器，后面我们会学到可以使用-p(port)指令来设置容器的端口向外暴露，这样我们就可以访问了😋。 Docker和虚拟机的区别？为什么Docker更轻量级、运行更快？ 看上图我们可以很明显的看出原因，Docker有更少的抽象层。对于一个虚拟机，他需要现在宿主机上虚拟一套完整的硬件映射系统，然后再在这层虚拟的硬件上搭建一个完整的虚拟操作系统内核Guest OS，然后才能安装真正的项目运行需要的依赖环境。而Docker容器并没有自己的虚拟硬件和操作系统内核，他是直接在宿主机上抽象一层Docker引擎，然后容器直接使用宿主机的硬件和操作系统内核，因此更轻量级、同时运行也更快。一个虚拟机大约是1-2G，而一个docekr容器仅仅10-20M就可以完成和虚拟机一样的工作。因此新建一个容器的时候，docker不需要像虚拟机一样加载一个操作系统内核，无需引导加载，因此启动只需要几秒相较于虚拟机几分钟的启动要快上许多， 一定要注意Docker容器没有自己的虚拟硬件和操作系统内核，他们使用的都是宿主机的，而虚拟机需要先使用宿主机虚拟自己的硬件和操作系统内核GuestOS。 Docker的常用命令 帮助命令 123docker version #查看docker版本信息docker info #详细展示docekr当前的具体信息docker 命令 --help #针对某一命令各种参数的功能 , https://docs.docker.com/reference/https://scholar.coolchong.cn/docker%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3 镜像命令 docker images查看所有本地主机上的镜像 12345678910111213141516[root@VM-0-7-centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest feb5d9fea6a5 8 weeks ago 13.3kBcentos latest 5d0da3dc9764 2 months ago 231MB#解释REPOSITORY\t#镜像仓库源TAG #版本标签IMAGE ID #唯一区分标识符CREATED #创建时间SIZE #代销#可选项-a, --all #列出所有的镜像-q, --quiet #只显示镜像的ID-aq #显示所有镜像的ID docker search搜索镜像 首先我们可以直接在docker hub上进行搜索也是可以得，但是我们也可以在终端中快速搜索并进行筛选。 1234567[root@VM-0-7-centos ~]# docker search mysqlNAME DESCRIPTION STARS OFFICIAL AUTOMATEDmysql MySQL is a widely used, open-source relation… 11707 [OK] mariadb MariaDB Server is a high performing open sou… 4458#可选项--filter=STARTS=3000 #通过star过滤大于3000的镜像仓库 docker pull下载镜像 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#docker pull image默认下载最新版[root@VM-0-7-centos ~]# docker pull mysqlUsing default tag: latest #默认下载最新版latest: Pulling from library/mysqla10c77af2613: Pull complete #分层下载，docker image的核心，联合文件系统b76a7eb51ffd: Pull complete 258223f927e4: Pull complete 2d2c75386df9: Pull complete 63e92e4046c9: Pull complete f5845c731544: Pull complete bd0401123a9b: Pull complete 3ef07ec35f1a: Pull complete c93a31315089: Pull complete 3349ed800d44: Pull complete 6d01857ca4c1: Pull complete 4cc13890eda8: Pull complete Digest: sha256:aeecae58035f3868bf4f00e5fc623630d8b438db9d05f4d8c6538deb14d4c31bStatus: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest #真实地址#也可以使用docker pull image:[tag]下载指定版本#如现在下载mysql5.7版本[root@VM-0-7-centos ~]# docker pull mysql:5.75.7: Pulling from library/mysqla10c77af2613: Already exists #docker联合文件核心亮点，有的就不需重复下载了b76a7eb51ffd: Already exists #直接共用相同的文件258223f927e4: Already exists 2d2c75386df9: Already exists 63e92e4046c9: Already exists f5845c731544: Already exists bd0401123a9b: Already exists 2724b2da64fd: Pull complete d10a7e9e325c: Pull complete #5.7版本特有的1c5fd9c3683d: Pull complete 2e35f83a12e9: Pull complete Digest: sha256:7a3a7b7a29e6fbff433c339fc52245435fa2c308586481f2f92ab1df239d6a29Status: Downloaded newer image for mysql:5.7docker.io/library/mysql:5.7 #真实地址#实际上之前的docker pull mysql等同于docker pull mysql:latest也是有标签的#当前有两个版本，但是两者之间部分文件是相同共用的[root@VM-0-7-centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmysql 5.7 8b43c6af2ad0 3 days ago 448MBmysql latest b05128b000dd 3 days ago 516MB docker rmi删除镜像 12docker rmi 镜像id 删除指定镜像docker rmi 镜像id1 镜像id2 ...删除多个镜像 123#强制删除所有的镜像#-f表示强制，后面的$()是计算式使用了查询所有id的docker指令docker rmi -f $(docker images -aq) 容器命令 只有有了镜像，才能创建容器，我们这里下载一个centos镜像来测试学习容器的命令 新建容器并启动 12345678910111213141516171819202122232425262728293031docker run [可选参数] image#参数说明--name=&quot;Name&quot; 容器名字 tomcat01 tomcat02用来区分容器-d 后台方式运行-it 交互方式运行-p 指定容器端口(用来主机映射80:8080)\t-p ip:主机端口:容器端口\t-p 主机端口:容器端口 (常用，用来端口映射)\t-p 容器端口\t容器端口-P 随机指定端口#测试启动并进入容器#首先现在在容器外部我们的@后面是vm-0-0-centos#然后我们run创建一个容器(未设置名字，没关系可以使用id号)#-it是交互方式进入#/bin/bash是对容器内部操作时使用指令集，一般都是bash[root@VM-0-7-centos /]# docker run -it centos /bin/bash#进入容器内部，@后面跟的是容器id#这个容器就是一个linux系统，所以ls会得到和外部服务器一样的文件结构[root@6ee0cf9db211 /]# lsbin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr vardocker exit 退出容器到主机#输入exit退出容器到主机，并且由于这个容器没有运行任务，因此会默认自动关闭不再运行[root@6ee0cf9db211 /]# exitexit#外部即云服务器也是linux文件结构[root@VM-0-7-centos /]# lsbin boot data dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var 查看容器 1234567891011121314docker ps 查看所有当前正在运行的容器[root@VM-0-7-centos /]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES#由于exit后没有运行任务，刚刚的centos容器已经关闭因此查看不到docker ps -a 查看所有存在的容器(关闭的也可以查看到)[root@VM-0-7-centos /]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES6ee0cf9db211 centos &quot;/bin/bash&quot; 8 minutes ago Exited (0) 6 minutes ago romantic_lehmann#发现创建容器时若没有赋名字会随机生成一个docker -a -n=1 显示最近运行的1个容器docker ps -q 只显示容器的iddocker ps -aq 显示当前所有容器的id 退出容器 12exit #退出容器且如果没有运行任务自动关闭ctrl+p+q #退出容器且不关闭后台运行(即使没有运行任务) 删除容器 123docker rm 容器id 删除指定容器docker rm 容器id1 容器id2 删除多个容器docker rm -f $(docker ps -aq) 强制删除所有容器 之所以要加-f参数是因为正在运行的容器不能删除，因此需要强制删除或者停止后再删除 启动和停止容器 1234docker start 容器id 启动指定容器docker restart 容器id 重启指定容器docker stop 容器id 停止指定当前运行的容器docker kill 容器id 强制停止指定当前运行的容器 其他常用指令 创建并后台启动容器 之前我们学习的是创建容器并直接进入容器，但是我们能不能启动容器后让他直接后台运行，而我们不进入容器呢？我们知道-d是后台运行的参数，那么想当然如下指令就是创建并后台启动容器的指令 12docker run -it image /bin/bash #之前的创建并进入容器docker run -d image #创建并后台启动容器 但是我们发现了一个问题，他并没有维持后台运行待机的状态，这是因为他没有前台进程，也就是说容器他虽然能后台待机，但是没有接收操控他指令的前台，即他不能和操纵者通信，因此自杀了。类似的还有nginx,假设我们启动了一个nginx容器，但是他没有前台呈现页面的任务，即意味着他什么任务也没有，那么也会和centos类似自杀关闭容器减少资源的浪费。并且此时即使我们再输入docker start也无济于事他并不会成功启动，因为他刚启动后又会因为无前台进程自动关闭。我们可以使用如下并不好的策略创建并后台启动容器 12docker run -dit image /bin/bash#此时我们添加了-d属性，并且给他分配了前台进程，因此不会自动关闭了 因此一般我们创建容器时都是首次要进入这个容器并分配任务的，然后再exit或者ctrl+p+q退出容器，此时由于已分配了任务容器不会再自动关闭。如果创建后进入并未分配任务我们为了让他维持运行，需要ctrl+p+q退出。 查看日志 12docker logs -tf 容器id 查看当前容器的全部日志docker logs -tf --tail num 容器id 查看当前容器的最新num条日志(实时刷新) 我们要注意要查看一个容器的日志，首先这个容器必须正在运行，同时他确实运行过任务才能产生日志，由于日志会很多，一般我们需要加上--tail num来限制显示的日志行数。 查看容器中进程的信息 1docker top 容器id 查看当前容器内部的进程信息 同样的，他也需要保证当前查看的容器正在运行。 查看容器的详细信息 1docker inspect 容器id 进入当前正在运行的容器 通常我们的容器都是后台运行任务的，但是有时候我们需要进入这个容器修改一些配置，我们可以使用如下指令 12docker exec -it 容器id /bin/bash 进入容器并进入一个新的指令终端docker attach 进入容器并使用之前的指令终端 我们注意两者是有区别的，假设现在正在运行的容器正在不断的占用之前的终端打印信息，那么此时如果我们使用docker attach会导致我们无法输入命令，因为当前容器的任务正在使用这个终端打印信息。为了以防这种尴尬的情况出现，我们最好使用前者指令创建一个新终端进入容器。 从容器内拷贝文件到主机上 1docker cp 容器id:容器内路径 目的主机路径 我们要注意docker cp是用来将容器内部的文件拷贝到主机上的，并且不受容器是否正在运行的影响。而主机文件到容器一般不使用此命令，而是通过挂载卷完成。同时使用-v卷的技术可以实现文件系统的自动同步，类似于共享文件夹的功能😁。 常用命令总结 上图给出了docker相关的大部分命令，我们刚刚只是学习了最常用的镜像和容器相关的指令，实际上还有许多和git相类似的指令，我们会在后面学习到。docker的命令非常多，我们需要经常使用和复习才能记住哦！ 作业练习 我们这里使用之前学习到的指令尝试完成nginx部署。首先我们需要下载nginx镜像 12345678910111213141516[root@VM-0-7-centos ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginxeff15d958d66: Pull complete 1e5351450a59: Pull complete 2df63e6ce2be: Pull complete 9171c7ae368c: Pull complete 020f975acd28: Pull complete 266f639b35ad: Pull complete Digest: sha256:097c3a0913d7e3a5b01b6c685a60c03632fc7a2b50bc8e35bcaa3691d788226eStatus: Downloaded newer image for nginx:latestdocker.io/library/nginx:latest[root@VM-0-7-centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest ea335eea17ab 3 days ago 141MB 然后我们创建一个nginx容器并命名为nginx01，如下操作进行后台运行和端口配置 此时我们输入http://云服务ip:3344即可看到成功部署后的nginx服务页面(前提是服务器的防火墙已打开)： 并且此时我们进入nginx容器发现其内部也存在一个配置完整的nginx文件夹，我们可以在这里的nginx.conf配置相关的转发。 123456789[root@VM-0-7-centos ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES429fc0ba5ede nginx &quot;/docker-entrypoint.…&quot; 3 minutes ago Up 3 minutes 0.0.0.0:3344-&gt;80/tcp, :::3344-&gt;80/tcp nginx01[root@VM-0-7-centos ~]# docker exec -it nginx01 /bin/bashroot@429fc0ba5ede:/# whereis nginxnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginxroot@429fc0ba5ede:/# cd /etc/nginxroot@429fc0ba5ede:/etc/nginx# lsconf.d\tfastcgi_params\tmime.types modules nginx.conf scgi_params uwsgi_params 这样使用容器配置nginx的好处时，当我们需要动态使用nginx切换部署的项目时，无需再频繁的去修改nginx.conf文件了，而只需要将不同的项目都部署到一个nginx容器内，当需要切换时只需要动态的启动或者关闭对应的nginx容器即可了。"},{"title":"网络与Dockerhub","path":"/wiki/Docker笔记/Docker网络/index.html","content":"发布镜像到Dockerhub等远程仓库 首先我们需要一个DockerHub账户，这样我们就可以在服务器发布我们的镜像到远程仓库了。首先我们查看一下在服务器上登录我们DockerHub账户 12345678910111213141516171819Log in to a Docker registry.If no server is specified, the default is defined by the daemon.Options:\t#密码 -p, --password string Password --password-stdin Take the password from stdin #账号 -u, --username string Username #这里我们登录自己的账号Login with your Docker ID to push and pull images from Docker Hub. If you don&#x27;t have a Docker ID, head over to https://hub.docker.com to create one.Username: langwenchongPassword: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-store#登录成功Login Succeeded 然后我们尝试发布这个镜像，但是在发布之前我们需要先创建一个标签如下图所示 我们使用docker push指令进行发布，如下图所示，但是由于DockerHub在外网，因此我们可能会上传失败或者上传非常慢，请耐心等待，后面我们还会学习如何发布到阿里云镜像仓库。 发布镜像到阿里云镜像远程仓库 我们已经体会到了上传DockerHub有多慢了，因此我们这里学习如何发布到阿里云镜像仓库。首先我们登录阿里云然后搜索寻找容器镜像服务，然后创建一个个人实例用来学习即可如下图 然后我们进入个人镜像实例，这里我们可以创建命名空间，但是要注意一个账号只能创建三个命名空间，但是一个命名空间可以存储许多的镜像仓库，因此个人使用完全足够，如下图： 然后我们再创建一个镜像仓库（就类似于github的远程仓库），一会我们就提交到这个远程仓库中，如下图 然后选择本地仓库创建即可，然后我们就得到了一个远程仓库的地址 接下来我们按照上面的步骤上传即可，首先我们DockerHub的账号，然后登陆阿里云的账号 然后我们按照步骤还需要进行仓库的pull,使用docker tag创建提交版本等， 这里由于我们是首次提交就不需要拉取了 123456#从Registry中拉取镜像docker pull registry.cn-hangzhou.aliyuncs.com/langwenchong/tomcat-test:[镜像版本号]#创建提交版本docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/langwenchong/tomcat-test:[镜像版本号]#然后pushdocker push registry.cn-hangzhou.aliyuncs.com/langwenchong/tomcat-test:[镜像版本号] 一定要注意这里的创建版本，提交必须按照阿里云的要求完成，否则会被拒绝push😯！前面的hangzhou.aliyuncs.com是不能省略的！ 比如我们这里将镜像版本号设置为1.0并提交，那么指令应该如下图这样操作： 理论上来说应该挺快的，一会就能提交完成然而我最终还是提交失败了…如果你提交成功了，应该可以看到阿里云的镜像仓库已经更新了 以后如果我们需要别人使用我们的镜像，只需要docker pull 镜像名称即可了。 Docker所有流程小结 自此我们已经学会了docker的全部基本操作，上图是所有流程的过程图。我们看到上图还有save和load指令，这两个指令实际上也很好理解，我们除了可以让伙伴直接从远程仓库拉取我们推送的镜像以外，也可以使用save指令将我们创建的镜像打包成压缩包，然后发送给伙伴，他再使用load指令解压即可得到我们创建的镜像。如果你已经能看懂上面的图了，那么恭喜你已经入门Docker成功😁！但是我们可以再深入学习进阶Docker知识，偏向集群的运维。 Docker网络 理解Docker0 首先我们清空之前创建的所有镜像和容器，然后输入ip addr查看网络信息 我们可以看到三个网络，分别是三个docker环境。我们思考一个问题：假设现在主机内部有两个容器，其中一个是tomcat容器负责页面的访问，另一个容器时mysql容器用来存储数据，那么我们tomcat容器的项目如何去连接mysql容器获取数据？ 思考：这样连接会不会与容器之间独立的原则相悖？ 答案是不会，因为此时两个容器结构上还是独立运行的，两者配置的更改不会影响到对方，只是两个容器之间有功能上的连接，这种连接是允许的。 这里就会涉及到docker网络的知识。接下来我们就以这个为案例进行docker网络的学习，首先我们创建一个tomcat容器，然后启动并且在后面追加ip addr查看这个容器的内网信息如下图所示，由于我下载的这个最新版tomcat是精简版没有ip addr指令，因此我们选择进入这个容器然后输入如下指令先安装指令集 1apt update &amp;&amp; apt install -y iproute2 安装完成后我们再输入ip addr查看这个容器的内网信息： 如果你已经学过计算及网络了，可以回忆一下这个地址后面的/8、/16代表什么？实际上他是子网掩码，通过前面的ip地址加上子网掩码我们就可以得知子网的划分。 上面的第二个网络是每一个容器都有的，他是docker为其分配的一个地址用来宿主机访问连接的，我们在创建这个容器时使用的是-P随机的端口暴露，但是我们可以通过这个docker为其分配的地址仍然可以ping通这个容器，如下图 现在我们发现主机是可以通过docker为这个容器分配的地址ping到这个容器的，想一想也很合理，既然容器在宿主机上运行，很显然宿主机应该能够ping到这个容器内部。我们前面学习过两个容器之间很难直接建立连接，那么我们此时就可以借用主机可以ping通任何一个容器的特点，让两个容器通过主机来间接连接。实际上我们学习过计网后应该可以知道实际上docke为这些容器分配的就是一个主机的内网ip，因此这些容器处于同一个主机内网下。 我们每启动一个docker容器，docker就会为docker容器分配一个ip,我们只要安装了docker，就会有一个网卡docker0,他使用桥接模式工作，使用的技术是veth-pair技术。此时每添加一个容器，主机的docker0网络就会添加一条网卡即docker容器的veth地址如下图我们对比一下： 创建容器前主机docker0网络创建容器主机后docker0网络tomcat容器内网信息 这就是主机可以ping同创建的容器的原因，由此类推，如果现在再创建一个tomcat02容器，那么主机docker0网络下会再新增一个记录值网卡： 创建tomcat02后主机网络第二个容器内网信息 思考：veth-pair到底是啥？怎么运行的？ 我们仔细观察发现当创建一个容器后，这个容器获得了88，而宿主机就是89，他们永远生成的都是一对连接的数值即网卡，这就是linux的veth-pair技术，他是专门用来连接各种虚拟网络设备的技术类似于“桥梁”，如下图我们很容易就能理解主机是如何通过veth-pair技术提供的网卡实现和容器通信的 OpenStac、Docker容器之间的连接、OVS的连接等都是使用veth-pair技术实现的 思考：此时tomcat01能否直接和tomcat02ping通？ 此时tomcat01是可以ping通tomcat02的，原因就是两个容器可以通过主机间接实现连接，此时他们位于同一个内网网段了（此时主机是172.18.0.1,tomcat01是172.18.0.2，tomcat02是172.18.0.3），因此可以互相连接了。实际上就是基于vrth-pair实现的。 即此时两个容器之间可以间接连通了： 我们要注意首先是通过veth-pair实现了主机和所有的容器连通，然后容器之间又通过和主机的veth-pair通信技术和其他容器处于了同一个网段因此间接也连通了！ 也就是说刚刚我们实现的tomcat01连接tomcat02通信实际上通信的路径应该如下： 我们可以查看到主机的docker0下存储了所有的相关的网卡，因此主机模块优点类似于网络层的路由器他维护了一个路由转发表用来转发信息，因此其他容器间的通信会经过主机。 同时我们要注意，docker0是虚拟的，使用linux桥接直接和物理设备的ip直连映射，即NAT直连。如下图： 由于docker0的地址都是虚拟ip，因此容器间的通信速度，主机的转发速度非常快。 思考：docker0可用的ip数量有多少？ 所有的容器在不指定网络下，都是docker0路由，docker会给我们的容器分配一个默认的可用ip，那么可用的ip数量大概有多少呢？我们查看一下docker0的子网ip是xxx.xxx.xxx.xxx/16，那么也就意味着子网段码占后16位ip，因此是255*255-2≈65535个可分配容器的ip(减去的两个是回环地址0.0.0.0和用来表示子网掩码的255.255.255.255)。 并且当我们删除容器时，docker0网卡会自动回收，假设现在我们将tomcat01容器删除，再查看主机docker0下的网卡信息，会发现之前的88-89网卡被回收了。 容器互联–link 我们回顾一下之前两个容器之间的通信，他们是基于清楚对方ip的情况下才能通过主机转发连通的，但是我们知道ip是很容易变化的，即使是docker0分配，当一个容器崩溃重启后他的ip会被收回可能再次被分配的ip也和之前的不一样了，那么之前和他有联系的容器现在在和他通信难道还需要手动的一个个去更新ip?很显然不现实，因此我们希望可以通过知道对方的容器服名就可以自动连接，而不再是基于ip。这时我们就会用到--link。 首先我们尝试不用--link能够让tomcat02ping到tomcat01，就直接使用容器名tomcat01。 容器默认不配备ping指令，请先输入如下指令为容器安装1apt-get update &amp;&amp; apt install iputils-ping &amp;&amp; apt install net-tools 此时我们在创建一个容器时加上--link 要连接的容器既可以实现他的单向连通，比如此时我们创建一个tomcat03容器命令如下 1docker run -d -P --name tomcat03 --link tomcat02 tomcat 此时我们创建的容器tomcat03就可以使用容器名来连通tomcat02了（别忘了先安装ping指令），证明图如下 思考：此时tomcat02能否使用ping tomcat03 连接到tomcat03容器？ 答案是不能，我们之前说到了–link仅仅是单向连同，因此此时tomcat02并不能使用ping tomcat03连接到tomcat03: 我们探究一下tomcat03为什么可以知道tomcat02的ip，实际上他是使用--link为自己的本地host中添加了一条规则记录值记录着tomcat02的ip，因此我们输入ping tomcat02时他可以从自己的本地host中获知tomcat02的ip，实际上这个场景优点类似于域名和ip的关系。如下图是探究时的一些发现： 一：docker network指令的使用以及docker0信息 1234567891011121314151617181920212223[root@VM-0-7-centos ~]# docker network --helpUsage: docker network COMMANDManage networks#下面是docker network后面可以追加的参数Commands: #连接一个容器加入网络 connect Connect a container to a network #创建网络 create Create a network #容器断开指定网络 disconnect Disconnect a container from a network #查看某一个网络的详细信息 inspect Display detailed information on one or more networks #获取网络信息 ls List networks #删除所有没有被使用的网络 prune Remove all unused networks #删除指定网络 rm Remove one or more networksRun &#x27;docker network COMMAND --help&#x27; for more information on a command. 因此这里我们使用docker network ls查看一下全局的网络配置如下图 123456[root@VM-0-7-centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE#这里的第一个bridge实际上就是使用桥接的docker0网络我们进一步查看010db73bc452 bridge bridge local7bb6e8a7bdb9 host host localb57d61a5e430 none null local 这里我们使用docker network inspect 010db73bc452进一步查看docker0网络的信息 二：容器内部信息 这里我们是将tomcat03使用了--link单向连接了tomcat02，因此此时我们就来查看docker03的信息，这里输入docker inspect docker03的id查看他的详细信息： 除了发现环境配置以外，我们还可以看到他的被分配的docker0ip地址以及默认网关确实就是主机的docker0因此他会经过主机的转发 三：查看tomcat03的本地host记录值 我们知道hosts是一种很早的计网产物，他类似于一个设备的网络备忘录，记录了常用的连接设备要解析的ip地址，因此他再访问这个设备时可以自动根据设备名从host查看到对应的ip。由于使用了--link tomcat02，现在tomcat03确实可以根据tomcat02就自动ping通，因此他肯定是知道tomcat02的ip，那么理论上这个对应关系应该就存储到了tomcat03的本地hosts: 1234567891011121314#打印docker03的hosts[root@VM-0-7-centos ~]# docker exec -it tomcat03 /bin/bashroot@ad49f9ff52b2:/usr/local/tomcat# cat /etc/hosts#localhost对应回环地址127.0.0.1127.0.0.1\tlocalhost::1\tlocalhost ip6-localhost ip6-loopbackfe00::0\tip6-localnetff00::0\tip6-mcastprefixff02::1\tip6-allnodesff02::2\tip6-allrouters#注意这里确实记录了tomcat02的ip172.18.0.3\ttomcat02 560768d4bf97172.18.0.4\tad49f9ff52b2 正式由于tomcat03的hosts记录了tomcat02的ip映射，因此tomcat03可以通过ping tomcat02就可以ping通，因为他会从hotsts获取到tomcat02的ip。 那么现在我们怎么才能让tomcat02也能够通过ping tomcat03甚至ping tomcat01等等就可以实现连通呢？答案很简单了，逐一去修改各容器的hosts后重启就可以了，但是很显然这种操作太麻烦了，即使使用了卷挂载技术共享hosts也很麻烦。因此--link现在并不常用了，甚至docker0都不太常用， 因为他是一个官网的网络，默认不支持容器名连接访问等功能，因此接下来我们会学习自定义网络。 自定义网络 我们输入docker netwoek ls查看一下当前已有的网络： 123456[root@VM-0-7-centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE#注意name为beidge默认就是docker0010db73bc452 bridge bridge local7bb6e8a7bdb9 host host localb57d61a5e430 none null local 会发现有如下几种网络模式（driver)： bridge：桥接模式（默认的网络模式，一会我们创建的自定义网络也是这种类型） none：不配置网络 host：和宿主机共享网络 container：容器网络连通（用得少，局限性大） 接下来我们就来实际操作一下自定义网络，我们在创建自定义网络进行测试之前，先将之前用来演示的tomcat01,tomcat02,tomcat03容器删除。 然后我们来创建一个网络，首先我们看一下``docker network create`的可选参数 123456789101112131415161718192021222324252627 valid_lft forever preferred_lft forever[root@VM-0-7-centos ~]# docker network create --helpUsage: docker network create [OPTIONS] NETWORKCreate a networkOptions: --attachable Enable manual container attachment --aux-address map Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[]) --config-from string The network from which to copy the configuration --config-only Create a configuration only network #核心参数：配置网络模式 -d, --driver string Driver to manage the Network (default &quot;bridge&quot;) #核心参数：配置子网网关 --gateway strings IPv4 or IPv6 Gateway for the master subnet --ingress Create swarm routing-mesh network --internal Restrict external access to the network --ip-range strings Allocate container ip from a sub-range --ipam-driver string IP Address Management Driver (default &quot;default&quot;) --ipam-opt map Set IPAM driver specific options (default map[]) --ipv6 Enable IPv6 networking --label list Set metadata on a network -o, --opt map Set driver specific options (default map[]) --scope string Control the network&#x27;s scope #核心参数：配置子网并且格式为xx.xx.xx.xx/xx，决定了一个子网个数以及子网下可分配ip数 --subnet strings Subnet in CIDR format that represents a network segment 我们创建一个子网命名为mynet并且子网掩码长度是16，这样他就可以支持65535个可分配ip,同时子网段是192.168那么命令如下 1234567891011121314#创建网络，并且mynet的默认网关是192.168.0.1#--drive 设置网络模式为bridge，实际上默认就是bridge#--subnet 设置子网段为192.168，后面随意变化，因此有255个子网并且每一个子网有255个可分配ip#--gateway 设置默认网关，一般就是子网下的第一个可分配ip[root@VM-0-7-centos ~]# docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynetc9bf25797ca395d914d6807e3536e148a464777831b9cc4897d166a88e565f2d#查看所有网络[root@VM-0-7-centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE010db73bc452 bridge bridge local7bb6e8a7bdb9 host host local#添加成功c9bf25797ca3 mynet bridge localb57d61a5e430 none null local 然后接下来我们创建两个容器为tomcat-mynet-01和tomcat-mynet-02并且不再默认加入到docker0网络下，而是我们自己新创建的自定义网络mynet，如下图输入指令 12345[root@VM-0-7-centos ~]# docker run -d -P --name tomcat-mynet-01 --net mynet tomcat8bc67a95591891df5347385f91a36ab8fff46f6fe77a6a1b8ce36a295e98467d[root@VM-0-7-centos ~]# docker run -d -P --name tomcat-mynet-02 --net mynet tomcat14adf5f3a12c4b41ba61eb6886c3f4bfd83799372cee4374936274f2a0821f48 注意-net是设置容器加入的网络，默认情况下不写是加入到名为bridge的网络也就是docker0网络，但是docker0禁止了域名访问，只有使用--link才能打通。 我们为了能够支持域名访问，因此创建了一个新的自定义网络，一个完整的默认的bridge桥接网络模式是支持域名访问的，因此此时我们发现tomcat-mynet-01是可以不用--link既可以使用ping tomcat-mynet-02连接tomcat-mynet-02容器的，即支持了域名访问，这比docker0要方便的多。 同样tomcat-mynet-02肯定也是可以的，这里我们再查看一下tomcat-mynet-01容器的信息会发现他被分配的ip使用的子网确实使我们之前设置的。 自定义的网络都已经自动帮我们维护好了ip和容器名的对应关系，因此推荐平时使用自定义网络而不要使用docker0 同时我们使用自定义网络可以为不同的集群分配不同的自定义网络，保证各个功能模块集群互不干扰的工作，比如现在有一个redis集群和一个mysql集群，为他们分配到不同的自定义网络，那么不同种类的容器就会做到通信隔离，更加安全！ 但是两个集群也不能完全不通信呀😂，还是需要有一些容器有连通的（此时使用--link也做不到，因为他们不再同一个网段），因此接下来我们将学习网络连通。 网络连通 接下来我们以docker0网络下的tomcat01和tomcat02以及mynet下的tomcat01-mynet-01和tomcat-mynet-02进行演示，首先我们创建tomcat01和tomcat02两个容器，然后尝试用tomcat-mynet-01容器去ping容器tomcat01发现无法实现： 因此不同网络下的容器无法通信，但是实际上有时处于不同网络下的两个容器功能上需要进行连接通信，因此我们希望可以允许容器和另一个网络下的某个容器进行连通。首先两个网卡不能直接打通，这样会导致两个子网发生变化，应该是让一个容器和另一个子网的网卡连接即他进入到另一个子网下，也就是类似于一个人加入多个组织，他同时拥有多个网络的分配ip，这样他就可以和另一个子网的容器进行通信了，如下图： 这里我们就会用到一个新指令即docker network connect ,他的可选参数如下 12345678910111213[root@VM-0-7-centos ~]# docker network connect --helpUsage: docker network connect [OPTIONS] NETWORK CONTAINERConnect a container to a networkOptions: --alias strings Add network-scoped alias for the container --driver-opt strings driver options for the network --ip string IPv4 address (e.g., 172.30.100.104) --ip6 string IPv6 address (e.g., 2001:db8::33) --link list Add link to another container --link-local-ip strings Add a link-local address for the container 现在我们就将容器tomcat01打通加入到mynet网络下 1[root@VM-0-7-centos ~]# docker inspect tomcat01 配置成功后我们发现正如之前的那个比喻所说，现在这个tomcat01容器同时属于两个网络了，因此他有两个ip分别对应docker0和mynet网络，因此此时tomcat-mynet-01容器可以ping通tomcat01了 思考：此时tomcat01能否使用ping+容器名的形式ping通其他容器？ 很显然结果应该是tomcat01只能使用ping+容器名的形式连通mynet下的容器，这就好比你假如了A组织和B组织，虽然此时你能与B组织交流了，但是在与A组织下的成员交流时还是要遵循之前A组织的规则，因此tomcat01在和tomcat02连通时还是要遵循docker0网络基于ip的规则，但是在和tomcat-mynet-01和tomcat-mynet-02容器连通时可以基于容器名。 但是如果此时tomcat02也用connect指令加入到了mynet网络下，那么此时tomcat01就可以和tomcat02使用ping+容器名的形式ping通了 实战：部署redis集群 这部分博主还没有学习redis，暂时不写了，您可以参考这里学习 redis集群部署实战https://www.bilibili.com/video/BV1og4y1q7M4?p=38&spm_id_from=pageDriver 如果一个月内博主还没有更新，请@我督促我去学习😂 SingBoot微服务打包Docker镜像 接下来我们学习一下如何将简单的SpringBoot项目打包成Docker镜像然后部署到服务器上，首先我们打开idea创建一个SpringBoot项目，选择Sping Initializer创建项目然后选择最简单web功能即可，这里我们新建一个Controller包进行测试，里面添加一个HelloController.java文件，内容如下 12345678910111213141516171819package com.example.demo.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @Author Lang wenchong * @Date 2021/11/28 20:21 * @Version 1.0 */@RestControllerpublic class HelloController &#123; @RequestMapping(&quot;/hello&quot;) public String hello()&#123; return &quot;hello,wenchong😎&quot;; &#125;&#125; 然后我们本地先测试一下，运行以后前往http://localhost:8080/hello查看能够正确返还字符串 成功以后我们开始进行项目的打包，点击右侧Maven栏demo声明周期下的package选项进行打包 然后我们进行DockerFile的编写，首先我们安装一下Docker的高亮插件直接在设置-&gt;插件中搜索Docker安装即可，安装完成以后我们在demo目录下新建一个Dockerfile文件，命名正确且插件安装成功后这个文件的小图标会有一个小鲸鱼，然后我们开始写Dockerfile脚本文件如下 12345678910#引入项目需要的jdk基础环境FROM java:8#引入项目文件COPY *.jar /app.jar#设置及端口CMD [&quot;--server.port=8080&quot;]#项目在容器内暴露8080端口上运行EXPOSE 8080#启动项目ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 然后我们打开xftp将jar包和Dockerfile上传到服务器的/home/idea下，然后我们在这个目录下进行打包，实际上就是运行Dockerfile创建镜像，如下图 这样我们就打包完成了得到一个springboot-project镜像，然后我们运行镜像创建一个容器查看能否完美部署运行，为了方便测试我们将容器端口暴露映射到主机的8081端口上 然后我们在浏览器中输入http://服务器ip:8081/hello即可查看到入口页面 思考：因此我们最终只需要给别人什么文件用来部署上线呢？ 我们发现实际上还是要将项目打包成jar包，然后我们在编辑Dockerfile是引入了这个jar包来构建镜像，因此我们最终创建容器时这个容器会包含有这个项目并且自动部署运行，并且使用FROM引入了需要的jdk环境。因此我们实际上最终只需要给别人发送这个使用Dockerfile构建的镜像即可了，这个别人只需要pull这个镜像然后run创建并启动容器即可，剩下的环境配置容器会自动完成，非常简单！ 总结 自此， 我们花费了大约1周的时间入门了Docker，剩下的进阶篇我们以后再更。相较于一周前我们对Docker的懵懂到如今基本掌握Docker应用，细细想来，这一路并不是很艰难，学习的过程并不仅仅充满了汗水与枯燥，实际上也伴随着学习新知识后的充实与快乐，希望你我都能坚持学习，不辜负自己的一片野心😊！"},{"title":"远程仓库","path":"/wiki/Git笔记/远程仓库/index.html","content":"什么是远程仓库 实际上我们之前所做的工作都是在本地进行的，即只有这台计算机可以看到进行版本库的修改等。然而实际生活中我们经常需要将这个仓库上传到云端，这样我们可以随时在不同的电脑上进行“克隆”获得之前版本的库文件，在这个版本的基础上继续进行工作，或者从本地提交新的版本至远程的仓库来更新版本，这就是github的最大魅力。那么接下来我们就来学习使用github。 首先我们需要github账号，注册一个即可。然后我们需要进行以下几个步骤 检查是否有SSH Key 首先在任意地方打开git终端，输入以下指令检查是否已为此电脑配置了ssh key： 1ssh -T git@github.com 如果已经配置过sshkey了，那么应该会出现下图的提示： 那么就说明这个电脑可以通过ssh key免密登录上传本地仓库到远端，否则每次提交都需要输入账号和密码。 创建SSH key 如果很不幸你没有设置ssh key，其实也没啥，如果你觉得每次上传输入一次账号和密码也是可以得，那你可以选择不设置SSH Key，但是如果你想上传本地仓库到远端github时不用输入密码，那么就需要配置SSH key,并且你是用的每一个设备都需要配置一个SSH Key（包括你的虚拟机），这样gitHub就可以通过ssh秘钥知道这台设备是你允许免密登录的设备。以后在上传时你就可以免密上传啦！ 所以sshkey的作用一句话概括就是可以让你这台计算机免密上传本地仓库到远端，实际上他是通过rsa密钥对实现了你设置过SSH key的计算机和远端加密传输。 创建ssh key实际上很简单，首先我们需要打开git终端，然后输入以下指令： 1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 上面的邮箱请输入自己的邮箱，然后一路回车就行了。然后我们就可以到用户目录下找到.ssh目录了（不同的系统路径是不同的，这里我给出win的路径：C:\\用户\\user(应该是你的设备名字）.ssh。其它系统的请自己努力查找，大致路径是相同的）。然后这个.ssh路径下应该有三个文件，其中id_rsa就是sshkey的私钥，不能告知他人的，而id_rsa.pub是公钥，可以告诉别人。我们现在要将公钥加入到github上，这样远端就可以通过sshkey公钥找到你的这台设备来验证私钥，如果你的这台计算机可以提供正确的私钥，那么就可以免密登陆了。 所以接下来我们登陆github，打开settings中的ssh栏，如图： 新建ssh Key: 然后我们就可以看到新建sshKey的输入框了，这里我们先介绍一下都是什么意思： 我们想，那么一个git账户ssh key肯定不只是有一个，比如你同事有mac,win两台电脑外加一个ubuntu虚拟机，那么现在这三个设备都要免密登录就需要都设置一个sshkey所以你的这个账号下肯定会有许多个sshKey(当然如果你就是穷，只有一个计算机，那当我没说😝)，但是总的来说每台设备都只对应唯一的一个sshkey，所以title就是用来区分每一个秘钥对应的是你的那台设备，你可千万不要命名为sshkey1,sshkey2…。这样以后你也不好区分这个sshkey对应的是那台电脑，我推荐你将title处填写你的设备名，比如我的是win10联想电脑，那么我就命名为Chong’s Win laptop,相对应的mac就是Chong’s Mac laptop等等。这样我们就可以区分出sshkey对应的设备了，然后我们将刚刚.ssh文件夹下的id_rsa.pub（一定要注意是公钥)复制到下方key处。然后点击add就完成了一个sshkey的添加，从此你的这台设备可以免密登录上传了。此时你在打开终端输入 1ssh -T git@github.com 应该就会出现成功的那句话了，见上面检查sshkey截图。 思考：为什么我的SSHkey是灰色的？ 你会发现你刚刚创建的SSHKey应该和下图的灰色要是一样，写着NeverUsed，这正常，因为你现在只是创建成功了，还未使用过。当使用过这个SSHKey免密登录后就会变成绿色的并且显示上一次使用的时间。 所以如果你创建完成后一定要使用免密登录的方法，否则你创建SSHkey又是为了什么？当然如果你用了很长时间的git后发现某个🔑一直是灰色的或者很久没用了，请仔细想一想是不是你更换了那个设备导致这个SSHkey不会再用到了，那么就可以删除这个🔑了。 添加远程仓库 那么我们现在配置完了sshkey了，接下来我们尝试将之前的learngit仓库推送到github上。首先我们需要在github上创建一个远程仓库： 然后我们就会进入到新建仓库编辑处如下： 这里名字就命名为本地仓库相同的即可，然后选择public即公开仓库，这样别人就可以看到我们的这个仓库，也就可以查看并克隆我们的仓库（所以不要存储敏感信息，比如银行卡密码等），如果是隐私信息请设置为private，然后下方的discription是仓库介绍，一般写2~3句话简单介绍一下即可，以后他会显示在这个地方： 然后同时我们勾选Add a Readme file，他是进入这个仓库后的详细信息，以后这个readme.md中的内容会显示在仓库下方，你可以写一些介绍文档，版本迭代信息，致谢等等，他最后会显示在这个地方： 并且以后我们可以通过点击绿色劝处的钢笔直接在github上对这个readme.md进行编辑。例如现在我们创建完learngit后（create respository后),他会默认在reame.md中填写的是我们之前的discription,现在我们修改这个readme: 编辑完成后我们看下方： 这里会有一个commit表，就是类似于git commit，可以写一些这次修改的注释。这里我们然后点击commit changes。我们会发现learngit下的介绍信息被修改了： 多了一句刚刚我们添加的话，并且上面的红圈处注释了我们commit时修改的注释信息。此时首页的仓库介绍就只有“翀翀学习git的仓库😎”这句话，而仓库具体的介绍即readme的信息就有我们新添加的话。所以我们以后关于仓库的具体介绍信息都可以写到readme文件中。 但是现在我们github上的仓库还是空的，没有和我们本地的learngit仓库关联，所以也就还没有readme.txt文件呢，接下来我们将本地方库提交至github上的远程仓库。这里有两种方法：①将本地仓库与远程仓库关联②克隆这个远程仓库然后本地文件转移 两种方法无好坏都可以，这里我们先教第一种： 方法一：将本地仓库与远程仓库关联 首先我们需要在github上将仓库地址获取，这里点击仓库的绿色code按钮，我们可以看到有5中方法： HTTPS格式的远程仓库地址 SSH格式的远程仓库地址 Github Cli格式的远程仓库地址 在GitHub Desktop打开（需要额外下载github桌面软件） 以压缩包方式下载 前三种方法比较常见，都是获取地址关联，其中HTTPS格式和SSH格式是我们今后会常用的方法，我们需要分辨以下这两者的区别： 思考:HTTPS和SSH的仓库地址区别？ 我们知道HTTPS协议一般安全性很强，所以按照理解，凡事使用https的地址关联的仓库，那么无论你这个设备是否注册过sshkey，push时是都需要输入密码的。而SSH地址就是利用SSH验证私钥，如果你的电脑有SSHkey私钥且验证正确，那么推送时就可以免密啦，当然如果私钥验证不正确那么你是无权免密推送，会报错你无权push。一定要注意ssh只是能够允许你将仓库推送到自己的远程仓库时免密的，否则你是无权将本地仓库推送到别人的远程仓库的。 那么我们之前刚刚设置完SSH，所以尝试使用SSH来免密推送我们的本地仓库到远程仓库github/learngit.git。首先我们复制SSH地址： 注意SSH地址一定是git@github.com开头的，后面的是你的账号名称/仓库名称.git。并且点击右边的小面板按钮就会复制这个地址，然后我们在本地仓库中打开git终端，即在learngit文件夹中右键鼠标选择git-bash-here(这个是win的方法)： 如果是linux的，那么就需要cd 这个文件夹，总之最后你打开的终端最末尾处的应该写的是你的仓库名称learngit，然后我们关联这个仓库输入以下指令： 1git remote add origin git@github.com:Langwenchong/learngit.git 一定要注意后面的地址应该是你自己的地址，即Langwenchong处应该是你自己的账号名称，否则你就会推送到我的远程仓库，当然了你是无权推送到我的远程仓库的（因为密码验证无法通过，最终会报错）。 然后关联完成后，我们就可以push将本地仓库的文件推送到远程仓库了： 1git push -u origin master //注意如果你是新版本的话可能是main 一定要注意请查看github上的默认分枝是master还是main,一般最新版本都是main了，那么代码应该是： 1git push -u origin main 如果顺利的话，你应该不用输入密码就可以直接上传成功了，最后如下图： 现在我们查看一下github上的learngit仓库，应该发生了变化增加了readme.txt文件： 如果你上传成功后发现github上没有变化，请查看是否上传到了master分支上： 所以我们知道了git push origin &quot;branch&quot;是将本地仓库的最新版本关联到远程仓库的branch分支上，如果你选择的是master，那么就关联到了master分支上，如果是main,那么就关联到了main分支上。 这里我们只有第一次关联时使用这个指令： 12git remote add origin git@github.com:Langwenchong/learngit.gitgit push -u origin master 上面的第一句指令是关联仓库，一个远程仓库只能和一个本地仓库关联，而第二句就是将最新的版本上传到github上的哪一个分支上，其中-u参数是不仅把本地master分枝内容推送到远程仓库的目标分支master上，同时还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令了。 即以后我们在push或者pull时不用加上-u直接 12git push origin mastergit pull origin master 就可以完成将本地仓库的最新分支版本上传远端或者从远端获取某个分支的版本了。 注意：第一次使用sshkey进行clone或者push时的报错 当我们刚刚弄完sshkey还从未使用过，这次是第一次使用时那么可能会出现如下询问： 这个是正常的，他需要你确认GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入yes后回车即可。自此我们就学会了将本地仓库关联到远程仓库并且上传文件了。这种方法比较好，建议牢记，当然你也可以学习方法二： 方法二：克隆这个远程仓库然后本地文件转移 这里我们的方法优点不同，但最终的效果是一样的。其实只是思路相反了，这里我们是先将远程仓库克隆下来为本地仓库，这样他就自动完成了两个仓库的关联，然后我们将readme.txt文件移动到这个新的本地仓库在提交，然后以后我们就在这个新的本地仓库进行文件的修改了。 我们还是先复制SSH地址这样可以免密上传，但是接下来我们是在桌面上打开终端克隆这个仓库从而创建一个与远程仓库已经关联了的本地仓库。所以我先克隆这个远程仓库到本地 1git clone git@github.com:Langwenchong/learngit.git 然后我们就可以发现主目录下多了一个本地文件夹仓库就是learngit，我们在这里创建readme.txt文件。然后编辑完成这个readme.txt一定要注意接下来的步骤有略微差异： 我们思考现在这个本地仓库中新建了一个readme.txt文件，但是还未加入到本地仓库中，所以需要先 12git add .git commit -m &quot;create a readme.txt&quot; 然后我们在上传 1git push -u origin main 这样也完成了免密本地上传 思考：两种上传方式的区别？ 我想你现在肯定是看的云里雾里了，确实这里不太好理解尤其对于github小白来说，你现在可以思考这些，随便学一种方法会用即可，反正最终学习的目的就是实用。当然如果你要想弄清楚两种方法需要熟练实用上传的方法再次反复温习就可以很容易辨析两种方法的区别了，这里我总结了以下两种方法的区别： 角度一：指令输入方面 方法一的提交步骤 指令 功能 git remote add origin仓库地址 将本地的仓库与远程仓库关联 git push -u origin main 将这个本地分支提交到远程仓库的main(git commit信息就是git log中最新的注释信息)分支并完成关联 方法二的提交步骤 指令 功能 git clone 仓库地址 将远程仓库克隆到本地即自动生成了一个与远程仓库关联(包括分支)的本地仓库 git add . 将文件提交到新的本地仓库 git commit -m “message” 提交的注释 git push (-u) oigin main -u加不加都行，远程提交完成 角度二：关联方式 方法一是将本地仓库关联到远程仓库从而实现了文件上传，所以需要将本地的分支和远程仓库的分支关联，同时上传的是最新的版本和注释信息，但是之前的版本即gitlog也会上传到远程仓库，所以一次提交后远程仓库的分支可能就已经存储了许多版本了。而方法二是先将新建的远程仓库克隆到本地从而实现创建了一个已经和远程仓库分支关联的新的空本地仓库，修改文件add和commit后加入到本地仓库在上传提交，即第一次提交就是只提交一次版本节点。两种方法都可以在SSHKey的帮助下免密提交。 克隆远程仓库 实际上方法二就是在克隆仓库的基础上完成的，即克隆就是获得一个仓库的地址，然后 1git clone 仓库地址 就可以将自己（当然别人的远程仓库也可以）克隆到自己的本地设备上。当然如果是克隆的别人的远程仓库的文件，那么你修改后是不能将修改文件提交到别人的远程仓库的，只能上传到自己的远程仓库。那么这个仓库就会显示为你在别人的仓库基础上修改后上传到了自己的远程仓库即你们两个都是这个仓库的贡献者，这也就就是我们常在github上看到的多人贡献过的仓库，如下图： 结尾语 那么本次我们就学习到这里，我们要重点掌握SSHkey的创建和两种方式的提交（尤其是免密）的方法。希望你能有所收获😁~"},{"title":"本地仓库","path":"/wiki/Git笔记/本地仓库/index.html","content":"git安装与注册 linux安装 我使用的是ubuntu(linux内核)，所以这里我首先给出linux的安装方法，输入以下指令（需要密码）： 1sudo apt-get install git 如果是老一点的设备或者输入上条指令报错那么请尝试输入 1sudo apt-get install git-core win安装 去git官网下载安装文件然后全部默认安装即可。然后使用git-bash-here来运行，这个就可以完美替代win的cmd窗口了。 本地账户注册 我们需要在本地的仓库中注册一个账户，这样以后的git log中就会以我们的名字和邮箱来记录历史事件了。我们需要在命令行中输入： 12git config --global user.name &quot;Your Name&quot;git config --global user.email &quot;You Email&quot; 这里面的–global选项是全局设定参数，输入这个以后所有的本地仓库都默认使用这个账户了。输入完成后可以通过如下指令检查自己是否注册成功： 12git config user.namegit config user.email 这个是我的步骤仅供参考，当然这个不会有泄密风险，他只是一个自报家门的步骤方便用来记录的，后面真正的提交需要相对应的密码验证才可以提交。 版本库创建 创建新文件 我们按照廖雪峰老师的教学步骤来进行，你可以参考我的过程截图来确认自己是否正在正确进行。我们先创建gitlearn然后输入git init初始化这个仓库，至此这个本地的库就建好了，实际上就是多了一个.git文件并且一般是隐藏的。我们在做nemu时也知道.git文件中有一个叫做git log的功能可以实现记录我们的每一次改动从而做到版本回溯实际上就是在.git中实现的。现在我们检验一下.git文件是否存在。 我们发现果然如廖大大所说，.git是隐藏文件，只有在ls加上-ah才能看到并且同时还有两个文件叫做.和…实际上我们大概也能理解这个是什么，他们是两个隐藏的特殊文件用来表示同级和父级文件的。 特别注意：git不能记录word的改动，且win下的文本文档也有相对应的缺陷，最好使用notepad++代替（实际上这个应用还有排版，高亮，替代查找等高效的功能，值得使用） 接下来我们就是要尝试进行几次修改和提交来查看git如何进行记录修改的。 我这里使用的是linux中的vim编辑器来创建txt文件，使用的是命令行创建，如果你和我一样那么可以尝试使用这种方法创建，修改文件，毕竟我们在实际工作中并不是总能使用带有GUI的编辑器，使用命令行也是一项本领值得学习。在Linux中vi &quot;fileName&quot;就是打开一个文件，这种使用的是linux自带的vim编辑器打开文件，如果没有这个文件，那么输入这个指令后就会创建一个以你输入的名称为文件名的临时文件，你可以在这里进行编辑。但是他默认的是只读模式（也叫指令模式，因为此时只能输入文件指令），只有点击Insert键才可以转换为插入（编辑）模式对这个文件进行编辑，当编辑完成后点击Esc就又回到了只读模式，如果你确实想要创建这个新文件，那么你就需要在只读模式下输入:wq，即保存并退出编辑，否则输入:q！即表示不保存强制退出。此时我们保存这个文件： 此时我们输入ls指令检查learngit文件夹发现确实新建了一个readme.txt文件。此时我们还要将这个文件加入到learngit本地仓库中才可以被git追踪这个文件的修改历史。 将文件加入到仓库 当我们没有把readme.txt加入到仓库中时，那么git还不能追踪这个文件即git log不会显示这个文件的修改历史，我们此时输入git log检查历史日志发现他会报错fetal:您的当前分支’master’尚无任何提交。 master分支是一个仓库默认的分支，所有的提交历史默认在这个分支下进行更新 可能现在我们还无法理解master分支是什么，我们以后在学习，现在知道了当文件提交后才可以被git追踪历史修改，其历史会保存到git日志中。master就是默认的分支（当然，由于git新版本的更新，可能你那里显示的是main，但其实没有什么本质区别）。所以我们需要将readme.txt加入到仓库中去才可以被git追踪，上传到本地仓库指令很简单： 12git add &lt;filename&gt;git commit -m &quot;message&quot; git add 文件名是添加到本地仓库，git commit -m &quot;信息&quot;是在git日志中添加我们对于本次版本提交的一些小注释方便我们了解这次版本的修改特点，从而版本回溯时知道该回溯到何处。这里如果按照廖雪峰大大的教程我们要输入以下指令提交： 12git add readme.txtgit commit -m &quot;wrote a readme file&quot; 这样我们就完成了一次版本库的更新，就是将readme.txt加入到了gitlearn本地仓库中。此时我们在输入git log就可以看到版本库的更新信息了 我们发现git日志中增加了一项信息，其中Author就是我们之前注册的信息，下方记录着提交时间以及这次版本库更新的小提示，这样我们就知道了这次提交都有哪些修改信息了。其中git commit时有显示1 file changed,2 insertions表示的是一个文件修改（就是我们新建的readme.txt），后面的2 insertions就是插入了两个语句。 思考：那么当我们需要一次性提交上百甚至上千个文件时怎么办？ 你肯定会有这种疑虑：当我们上传成百上千的文件时怎么办，难道git add 一百次？其实不用，此时我们使用以下指令即可一次性进行加入： 1git add . 思考：此时就可以在github上查看到我这次提交的文件了吗？ 千万不要以为这个上传是上传到github上，他仅仅是将文件上传到了本地仓库并且日志记录了本次本地仓库中的变化，还没有上传到github上。 文件修改对比 此时我们在本地仓库中添加了一个文件readme.txt，那么以后git将会追踪他的变化。此时我们修改readme.txt文件，然后输入指令 1git status 得到的结果如图： 他会和上一次的提交进行对比并告诉我们两者之间的区别，这样我们就可以了解当前的仓库状态了。上面说到readme.txt被修改了但是还没有保存提交，所以此时我们使用git log查看时并没有记录这次修改。 但是我们发现此时只是知道了某个文件被修改了，却不知道具体的修改之处，此时我们可以输入git diff查看文件具体哪里出现了修改。 红色代表删除，绿色代表添加，我们发现Git is aversion control system.被删除替换为了新添加的Git is a distributed version control system.了。并且下方之前的空行我们删除后他也能够追踪。所以git diff（实际上就是difference的简写）就可以对比本次待提交的文件版本和上一次已经提交的文件版本之间的变化。这样我们确认修改无误后就可以将第二次的版本也提交了。步骤同上，你可以尝试： 我们发现在git add添加以后输入git diff会对比告诉我们要添加到本地仓库的修改文件时readme.txt然后同样输入提示信息后再次输入git status我们可以看出此时readme.txt确实被提交了，此时和版本库中的readme.txt就一样了（请忽视下方的.radme.txt.swo）。此时提交为空，说明被修改过的文件都已经上传到了本地仓库了。此时我们再次输入git lig进行查看： 我们可以看到新的提交已经上传，并且注释为add distributed，且最新的一次版本提交总是位于log中的最上方。 思考：git status和git diff的区别？ git status指令是告诉我们那些文件被修改了需要等待提交，git diff是告诉我们被修改过的待提交的文件（未add之前的文件）和上一次版本的文件对比哪些具体内容被修改了。下面的廖大大的工作区和暂存区一章就不讲了，因为我们是以能够使用为目的的，会用就行了，那一章理论只是探讨实用性不强就不细学了。 版本回退 我们此时再次修改文件readme.txt的内容并且再次上传。 此时readme.txt内容如下： 而之前的几个版本的内容如下： 123456789//版本1：wrote a readme fileGit is a version control system.Git is free software.//版本2：add distributedGit is a distributed version control system.Git is free software.//版本3：append GPLGit is a distributed version control system.Git is free software distributed under the GPL. 那么现在我们可能想回到之前的版本2，如果按照原先的修改，我们需要手动修改至版本2，但是当内容太多时，手动修改肯定不现实。此时我们就可以使用git版本回退的功能，这离不开git log的记录。我们再次打开git log 现在我们具体讨论一下git log的各种信息的用处。首先注释不用说能够提示我们各个版本的修改特点，Author是谁修改的，而注意HEAD-&gt;master，HEAD指的是当前版本所在的分支为master且是版本3，而现在我们想要回退到版本2，那么就需要commit后面的一长串数字了，他是是每一次提交版本特有的数字串用来区分各个版本的，而我们回退就需要使用这个数字串。 这里有两种方法回退，首先就是HEAD表示当前版本，HEAD^表示的是上一个版本，HEAD^就是上上个版本，在后面可以使用HEAD^3,HEAD100等表示回退，例如现在我们要从版本3回退到版本2，可以使用如下指令： 123git reset --hard HEAD^//或者如下(请以自己的commit为准)git reset --hard commitID 此时我们确实回退到了版本2，commit回到了e9ec3的版本2，如果你不信可以查看一下readme.txt文件的内容。 但是我们需要注意此时的回退真的是回退到了版本2的地方，连同git log也回到了版本2，所以此时git log中就只有版本2之前的内容了，就好像从来没有出现过版本3一样。 这样子可是不太妙，如果此时我们后悔了，想在回到版本3，但是Head^只能表示以前的，而版本3的commit又不见了。此时如果你没有关闭中断或者切换中断，你可以选择往上找找到之前的版本3的commit从而实现回退至版本3，但是你总是会关闭中断的，那么此时就不能获得版本3的commit了。例如此时关闭这个中断重新打开，发现任何有关版本3的信息都没有了，此时我们需要获得版本3的commit就需要输入 1git reflog 来获得git中每一条指令的信息，从而间接获得版本3的commit 我们可以看到reflog中有指出版本3的信息，可以根据后面的commit提示知道版本3的commit ID是d915b22（请以自己的ID为准），所以此时我们就可以回退之版本3了。此时在打开git log就回到了版本3时的git log了，所以此时git log中应为: 那么本次我们就完成了版本3-&gt;版本2-&gt;版本3的穿越过程了。 思考：为什么版本回退会如此之快？ 实际上git中的HEAD就是一个指针，每一次的版本提交都会存储，我们的版本回退只是切换指针而已，所以切换速度很快。 删除本地仓库中的文件 我们知道git add是将文件加入到本地仓库，这样git就可以追踪他了，但是假设你现在删除了这个文件，那么git会察觉到你删除了某个文件而这个文件现在在被追踪，那么你就需要告诉他将版本库中的这个文件删除，即使用 12git rm fileNamegit commit -m &quot;message&quot; 假设现在我们删除了raedme.txt。 那么我们发现此时git察觉到了删除操作并且git staus也告诉了我们删除了readme.txt，现在我们想要将这个文件也在本地仓库中删除从此git不在追踪他认为其从来没有存在过。我们输入 123git rm raedme.txt//当然实际上此时使用 git add readme.txt和rm是一个效果，所以都使用add也可以git commit -m &quot;remove readme.txt&quot; 当然此时git也会把这次提交看成一个版本库，所以在git log中也会记录这次修改： 提示：当git log太长无法一页显示时，按↑和↓可以查看更多信息，并且按q退出日志。因为他也会将这次删除看成一次版本所以，我们也可以使用版本回退恢复这个被删除的文件，即 1git reset --hard HEAD^ 我们就又回到了版本3： 当然我们此时的git log中就没有版本4删除文件的提交信息了，就好像版本4不存在过一样： 我们发现一旦在本地仓库中删除了这个文件，那么想要恢复这个文件就只能使用版本回退恢复了。还有一种情况是，你不小心将git追踪的文件删除了，但是本地仓库中还没有删除这个文件，那么就可以使用 1git checkout -- fileName 来恢复文件，但是实际上我们也可以使用回收站恢复来复原这个误删的文件。 git指令速览 指令名称 指令功能 git add fileNamegit add . 将修改过的待提交的文件加入到版本库（实际上是暂存区） git commit -m “message” 将暂存区的文件提交至版本库（此时gitlog中会增加一个commit历史）并且添加提交提示 git reset --hard HEAD^git reset --hard commitID 版本回退至特定的commit处 git log 查看git日志 git reflog 查看git每一条指令 结尾语 一定要记住我所讲的是最简单的git操作指令，许多复杂情况并未讨论，但是也足以应用git实现我们日常的需求了，在这里我们要记住add和commit永远要一起连接着输入（实际上并不用，但是为了避免复杂的bug产生，我们这里add后必须commit）。重点是掌握版本回退就足矣。那么希望你能有所收获😉~"},{"title":"多人协作","path":"/wiki/Git笔记/多人协作/index.html","content":"bug分支 我们这里在讨论一种特殊的情况，这个场景一般发生在实际的业务开发工作中，我们假设现在某个项目已经开发出来一个不稳定的版本readme.txt存在于dev分支上，然后我们现在自己的分支myjob上正在开发自己的业务功能板块，实现一个矩阵相乘的c文件maxtrix-mul.c，但是我们现在还处于中途开发阶段，还没有commit。即此时我们的分支情况下图： 此时我们假设现在matrix-mul.c还没有开发完，即如下图： 那么显然此时我们就还没有将matrix-mul开发完不能commit为一个版本（在实际开发中，一般只有开发完一个阶段形成一个版本后才会commit,而不是随心所欲的提交）。但是此时我们已经修改了matrix-mul.c，此时老板告诉我们开发的dev分支上的新版本中readme.txt有Bug需要修改并且要求我们现在就要修改这个bug。此时我们第一想法就是切换到dev分支，然后新建一个Issue分支来解决这个bug，然后再将这个issue上改完bug的分支合并到dev上从而达到修改bug的目的（注意这种创建新分支修改bug再合并到dev分支的策略，我们一般不能够直接修改dev分支上的文件以防破坏了dev分支）。但是此时我们发现当尝试切换到dev分支再创建issue分支时是不行的，会报错： 我们发现他报错还没有对已被修改的文件matrix-mul.c进行保存，所以切换分支的行为被终止了。我们分析一下发现确实此时我们编辑了matrix-mul.c文件但是此时还没有commit到一个新节点保存。理论上来说我们未尝不可已先将这个文件的修改提交为一个版本然后注释为&quot;不是一个新版本，而是临时需要改bug切换分支而保存的行为&quot;以此来达到在git日志中记录我们这次上传的提示。但是我们想一想平常工作中肯定需要时常进行修改bug的任务，难道每次都要这样暂存一个版本吗？那这样git日志里绘充斥了许多没有意义的切换分支的信息记录，无疑阻碍工作。所以此时我们需要一个办法来暂存这个已被修改的matrix-mul.c文件同时不会记录到git日志上成为一个节点，然后我们可以切换到dev分支上先解决bug，解决完后在切换回来继续工作直至开发成一个阶段了再提交commit。这时我们需要输入以下指令： 1git stash 这样git会将myjob分支上的我们现在开发到一半的matrix-mul.c存到一个特殊的地方并且不会新增commit,此时我们再查看工作区状态 我们发现此时git认为myjob分支是干净的，即假装认为此时所有被修改的文件都已经存储了(实际上此时myjob分支的被修改的matrix-mul.c只是被暂存到了一个地方)。然后此时我们就可以切换到了dev分支上了。此时我们就到达了如下图的情况 然后我们现在查看一下这个有bug的readme.txt文件，他的内容如下： 果然有bug,我们现在修改一下readme.txt的bug，修复成无bug的版本： 然后在issue上提交这个修改好bug的版本，此时分支情况如下图： 所以新的issue分支现在领先dev一个版本是修复好bug的版本，我们采用Fast forward模式的分支合并将dev分支也移到这个无bug版本： 我们发现此时dev分支上的最新版本确实修复了bug: 所以dev分支上的版本已经修改好了bug了，所以我们可以删除issue分支了并切换到myjob分支继续我们的板块开发了。 注意：删除分支时所处分支对命令的影响 一定要注意在上面这种情况下，如果我们处在dev分支上删除issue分支，那么命令就是 1git branch -d issue 即可，但是如果此时我们是先切换到了myjob分支上在删除issue分支时会有一个小报错如下： 此时我们需要输入如下的指令进行强制删除 1git branch -D issue 效果是一样的，但是为了防止出现这种报错，我们最好是在上游分支即dev分支上删除合并的分支issue分支最好。 那么此时我们就回到了issue分支了，分支分布情况如下： 此时我们的myjob分支上的文件还在被暂存处呢，我们输入以下指令： 1git stash list 可以查看暂存处确实还存储这之前的文件： 接下来我们从暂存处取出这个文件版本，这里有两种方式 ①输入git stash apply恢复文件但是暂存处还会保存这个文件，所以还需要在输入git stash drop来删除暂存处的文件。 12git stash apply //从暂存处取出文件恢复我们的myjob分支git stash drop //删除暂存处的文件 ②或者直接一键取出暂存处的文件同时清空暂存处 1git stash pop 此时我们在查看stash list 发现确实清空了暂存处同时恢复了文件工作区有记录了被修改的但是还没有被保存的文件: 我们现在思考一个问题，dev分支上的bug确实是修复好了，但是我们想一下我们的myjob分支的版本肯定是在之前的dev分支上clone来的基础上进行开发的，所以我们的myjob当前版本肯定也存在和dev分支上的bug,所以我们也需要将myjob分支上同样的bug进行修复，但是此时就不需要再重复创建分支-修改bug-合并等过程了，可以直接使用下面的方法一步修改相同的bug： 我们查看一下dev分支的git log: 我们可以找到之前修复bug的提交commit ID是4857ad1c，然后切换回myjob分支： 输入以下指令： 1git cherry-pick 4857ad1c 即可以将dev分支上修复bug的操作（注意仅仅是修复bug的操作，而不是dev上的文件）复制同步到了myjob分支上，这样myjob分支就修复好了和dev相同的bug了，并且一定要注意此时git会自动生成一次新的提交即git日志上新增加了一次提交历史并且commit信息就是dev修复bug的信息。我们此时查看一下myjob分支上的readme.txt文件： 确实修复好了相同的bug。并且此时myjob分支上确实新增加了一个提交&quot;reapai bug&quot;和dev的commit信息相同，但是注意这真的是一个新的提交所以commit ID是不同于dev分支的git日志的commit ID。这样我们就可以继续开发我们的myjob分支了。 思考：有没有另一种修复dev分支的bug? 聪明的你一定想到了另一种修复bug的方法了。即先把myjob上的bug修复了，然后切换到dev分支上，使用git cherry-pick [commitID]同步myjob上的修复bug操作即可。并且此时dev分支还会自动生成一个新提交即为新版本。但是注意即使是这个方法切换分支时也还是需要输入git stash暂时存储那些被修改但是还没有提交的文件。 多人协作 远程仓库 这里我们介绍一下多人协作的指令。首先我们知道当从远程仓库克隆时，git就是把本地的master分支和远程的master分支对应，所以我们克隆下来的都默认克隆master分支。并且要注意远程仓库的默认名称是origin。我们使用指令 1git remote //查看远程仓库信息 可以查看远程仓库的名字： 如果没有更改过一般就是origin，然后我们使用以下指令可以查看远程仓库的地址： 1git romote -v //查看远程仓库详细信息 我们可以查看到远程仓库的地址： 这里会显示两个地址一般是一样的，你可能是https协议的也有可能是我这种git协议的，通过上面我们就可以知道抓取和推送的远程仓库origin的地址。但是要注意如果你没有推送权限，比如你克隆了别人的仓库的git地址，你会发现你没有push的地址。 推送分支 我们现在再来回忆一下推送的指令： 1git push origin master 实际上这条指令的意思是说把本地仓库你现在所处的分支推送到远程仓库oirgin的master分支上。再比如我们要将本地的分支版本推送到dev分支上，那么指令就是： 1git push origin debv 这里我们并不是要将所有的分支都推送到远程仓库，我们规定： master分支时主分支，存储的是项目稳定的版本，因此要时刻保证本地远程同步 dev分支时开发分支，一般存储的是项目不稳定的版本，可能存在Bug，一般团队中所有成员的最终开发分支要合并到这个分支上形成多个版本，所以也要与远程仓库同步 bug分支，比如issue-1,issue-1001,bug-7等你自己本地命名的新分支用来修复bug，修复后就会删掉的分支就没必要上传到远程仓库了 feature分支，一般是开发一些未知的功能板块（可能不会应用到实际项目中）时的分支，可上传也可不上传 chong，yourjob等自己开发时的分支一般不用推送到这个项目的远程分支，你可以推送到自己的git仓库的分支上 抓取分支 在多人写作时，master分支和dev分支无疑经常需要被抓取，比如你要在稳定版本1.0之上开发2.0版本，那么就需要克隆版本1.0作为开发基础版本。现在假设你要克隆这个项目，由于肯定也是开发团队中的一员，所以sshkey肯定已经加到这个团队仓库中了，所以可以直接使用git协议抓取，这样就可以免密上传了。重点是一般可能作为开发人员，你克隆的都是dev分支，然而git默认只会抓取master分支，所以你需要输入如下指令抓取特定分支： 1git clone -b [branchname] [git-addr] // 抓取远程仓库的某一个特定分支 思考：如果两个人都同时推送一个特定分支会怎样？ 我们举一个例子，假如有一个dev分支上的项目版本是1.0，然后你克隆了这个仓库的dev分支到了你的本地开发分支myjon上，那么你开发了一个新版本你将其命名为版本2.0。此时你想将这个新版本推送到dev分支上，但是在你推送之前，已经由另一个开发伙伴也用1.0开发了一小部分功能命名为1.1上传到了dev分支上了，那么此时你就会出现报错： 1234567To github.com:michaelliao/learngit.git ! [rejected] dev -&gt; dev (non-fast-forward)error: failed to push some refs to &#x27;git@github.com:michaelliao/learngit.git&#x27;hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: &#x27;git pull ...&#x27;) before pushing again.hint: See the &#x27;Note about fast-forwards&#x27; in &#x27;git push --help&#x27; for details. 一般如上面这样，我们分析一下为什么会报错，此时分支情况如下图： 此时就是这种情况，你会发现在我们推送2.0版本之前小明已经将1.1推送到了远程仓库dev分支上，那么此时如果我们要将我们的2.0版本推送到远程仓库的2.0分支时git就会出现报错，原因是此时远程仓库已经是1.0-&gt;1.1了，而要推送的是1.0-&gt;2.0，那么就产生了歧义，2.0版本到底是推送到1.0和1.1版本之间还是1.1版本之后？所以我们需要先同步一下远程分支。 因为我们之前clone过远程仓库了，所以我们这条分支已经和远程仓库的dev分支有了联系，所以此时不需要删除仓库重新克隆远程仓库来更新分支，而只需要输入如下指令更新： 1git pull //同步远程仓库分支到本地仓库分支 那么就会变成如下图所示情况： 那么此时我们的本地分支已经同步更新了，此时在git push到远程仓库就可以上传我们的2.0版本了。当然在git pull时由于版本不同可能会产生冲突即版本1.1和版本2.0之间有冲突（毕竟你们两个人个能同时对同一个文件进行了修改），那么我们就需要手动解决一下即可。所以在本地仓库的分支必须领先远程仓库的分支才可以推送。 注意：如果本地仓库分支和远程仓库分支没有建立关联会报错 此时要注意只有clone后我们的这条分支myjob才会和远程仓库的dev分支建立了关联，这样git pull 时git才会知道是将dev分支要同步更新到myjob分支上，但是如果此时你使用的是另一个自己新建的本地分支feature，那么git pull时由于feature和dev分枝没有建立关联，git pill时会报错（因为git不知道feature分支要同步远程仓库的那一条分支）： 1no tracking information 所以此时我们需要手动关联一下本地分支，我们输入 12git branch --set-upstream-to &lt;branch-nameA&gt; origin/&lt;branch-nameB&gt;//将本地仓库的分支A和远程仓库的B分支建立关联 这样我们再git pull时则可以将远程仓库的B分支更新同步到本地仓库的A分支了。 这里还有一小节是变基，不太好看懂，学有余力不妨看一看：《Rebase》 总结 指令名字 指令功能 git stash 将现在分支上的工作区中已被修改但是还没有上传的文件暂存起来 git stash apply 将暂存区的文件恢复，但是不会清空暂存区 git stash drop 清空暂存区 git stash pop 将暂存取文件恢复的同时清空暂存区 git stash list 查看暂存区 git branch -d [branchname] 删除分支 git branch -D [branchname] 强制删除分支 git cherry-pick [commit ID] 同步某一次操作同时自动新生成一次提交，提交的注释和pick的注释相同 git remote 查看远程仓库（显示远程仓库名字） git remote -v 查看远程仓库的具体信息（显示远程仓库地址） git clone -b [branchname] [origin_addr] 克隆远程仓库的某一个特定分支到当前分支同时建立两个分支的关联 git pull 更新同步远程仓库的分支到当前已关联的分支 git branch --set-upstream-to [branch-nameA] origin/[branch-nameB] 将本地仓库的分支A和远程仓库的B分支建立关联 多人协作模式： git clone从远程仓库克隆之前的稳定版本后在本地分支上开发 首先试图push推送自己的分支 如果推送失败，git pull更新本地分支 如果合并有冲突，先手动解决冲突并本地提交 如果没有冲突或者冲突已解决再次尝试push即可 如果git pull时报错无关联，那么需要先将本地分支和远程仓库的远程分支相关联"},{"title":"多人协作","path":"/wiki/Git笔记/标签管理/index.html","content":"标签管理 git还引入了标签的概念，实际上就是对于一个对应着commit ID的版本提交一个简便的称号，这样我们就可以轻松的和他人交流某一个特殊的提交节点了。例如我们将commit ID为6a5819e…打上标签为版本v1.2。这样我们在和别人交流这个提交节点时就不用了说commitID了，而是标签v1.2了。 创建标签 我们使用如下命令为当前分支所在节点打上标签： 1git tag [tagname] 但是我们有时候可能需要将所在分支之前的提交节点打上标签，而非当前的最新版本，此时我们不可能是使用版本回退来回到之前的节点的，因为这样会丢失当前最新版本，只需要使用如下指令: 1git tag [tagname] [commit ID] 我们可以使用如下指令查看标签列表： 1git tag 但是一定要注意tag的排列不是按照时间顺序的，而是按照字母排序的，所以从tag顺序中无法知道版本节点的先后。同时我们想要查看某个标签对应的版本详细信息时只需要输入： 1git show [tagname] 这样可比查看冗长的git log要方便了许多。例如： 123456789$ git show v0.9commit f52c63349bc3c1593499807e5c8e972b82c8f286 (tag: v0.9)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:56:54 2018 +0800 add mergediff --git a/readme.txt b/readme.txt... 同时我们还可以在打标签的时候再次添加说明信息： 1git tag -a [tagname] -m &quot;message&quot; [commit ID] 这样当我们再次使用git show的时候就可以得到两条说明文字，一个是之前git commit时的，一个是git tag时的，例如： 123456789101112131415$ git show v0.1tag v0.1Tagger: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 22:48:43 2018 +0800version 0.1 releasedcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (tag: v0.1)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:06:15 2018 +0800 append GPLdiff --git a/readme.txt b/readme.txt... 注意：当某个节点是合并共享的版本节点，即同时处于master分支和dev分支上，那么无论处于哪个分支的这个节点上，我们都可以查看到这个标签。 操作标签 我们肯定有打错标签的时候，那么可以使用如下指令删除标签： 1git tag -d [tagname] 创建的标签都只会存储在本地，不会自动推送到远程分支，所以删除标签可以再本地安全删除，当我们想要将标签推送到远程仓库时，使用git push即可： 1git push origin [tagname] 既可以将本地的某一个标签推送到远程仓库分支，当然你也可以一次性将这条分支上的所有标签全部推送到远程仓库： 1git push origin --tags 但是如果已经推送到远程仓库的标签要删除，那么我们需要先将本地分支上的标签删除： 1git tag -d [tagname] 然后再推送删除操作将远程仓库的同样的标签也删除： 1git push origin :refs/tags/[tagname] 我们可以在github上查看远程仓库的标签是否添加和删除成功。 项目参与 由于github上的大部分项目开源存储，所以我们可以参与到这个项目中的开发中，但是我们知道对于别人的远程仓库由于我们没有sshkey绑定是不能够给将我们本地的修改推送到别人的远程仓库中的，那么我们如何才能够参与这个开源项目呢？很简单，我们点击一下某个人的开源仓库项目fork按钮 就可以将这个开源项目添加到了我们自己的远程仓库中（其中star按钮表示点赞）。这样我们就可以在自己的远程仓库中查看到这个项目（显示fork from…) 然后我们克隆自己远程仓库中的这个项目到本地就可以参与开发修改了，这样我们自己新建一个分支然后修改这个项目或者在master分支后面新增修改提交，然后我们将自己的修改提交到我们自己的远程仓库（一定要注意是自己的仓库）。那么如果我们想要将自己的一些修改想法分享给原创作者只需要创建一个pull request，然后选择自己的修改即可，同时我们还需要添加一下修改的标题和一些介绍即可，最后将pull request提交给作者，作者审核通过同意后即可将我们的修改添加到他的远程仓库了。 比如现在我们想要向廖雪峰老师发送一份感谢信的pull request，我们首先需要fork他的仓库，这里我已经完成了。然后我们克隆这个仓库到我们的本地，然后我们根据廖雪峰老师的提示，在相应的日期下新建我们的感谢信，我处于2021一月份，所以在202001中添加一个md： 然后我们将这个文件提交并上传到我们的远程仓库 然后我们就可以在自己的远程仓库查看到这个修改了。 这样我们的仓库已经有了我们的修改，接下来我们将自己的修改通过pull request发给廖雪峰老师，只需要点击pull request一栏创建一个新的pull request即可： 这里提示可以将我们的master分支下的修改提交合并到廖雪峰老师的learngit仓库的master分支，然后我们点击创建： 然后我们添加一下标题和一些说明文字就可以提交pull request了。 那么现在我们就可以查看到自己的pull request已经成功提交了，接下来就是等待廖老师的审核啦。 结尾语 那么此次我们历时5天的git学习历程就到此结束啦，回想起来，git学习也不是一件多难的事情，凡事都重在持之以恒，敢于尝试吧😜！"},{"title":"分支管理","path":"/wiki/Git笔记/分支管理/index.html","content":"分支管理 我们先来了解一下分支，其实可以看成许多个平行宇宙，每一个分支就是一个时间线，可以存储不同进度，不同版本的文件。如果你做过我博客中分享的nemu实验，那么你会发现在我的这个NEMU2020仓库存有4个分支，分别是master,pa1,pa2,pa3，他们分别存储着不同阶段的代码。 这就是分支分作用，他可以存储不同版本的完整代码，亦或者是和别人协作开发时为了不影响总体进度，将自己的代码上传到某一分支上最后在合并从而实现高效开发。而Mseter或者是最新版的Main就是默认分支，如果想要切换到其他分支上需要我们自己创建并管理分支，而git完美实现了这一点。 创建、合并分支 我们知道当我们未创建其他分支时，那么所有版本都会在master分支上，每一次更新都会在master分支上增加一个节点（对应着gitlog多一项记录），所以随着版本的不断更新，master分支会越来越长，并且又因为HEAD指针一直指向的是最新版本，所以默认的情况如下图： 也就是说HEAD指针永远指向分支的最新节点，而现在我们可以创建一个新的分支并且将HEAD切换到新分支dev上，如下图： 我们完成这个操作只需输入以下指令 1git branch //我们先查看一下现在本地仓库中的分支 现在只有一个分支main并且HEAD指针现在就指向了main(带*代表当前分支)，现在我们创建一个新分支dev并且切换到新分支上 12git branch dev //创建新分支devgit checkout dev // 切换到新分支dev上 或者你也可以输入以下指令一键执行两个操作 1git checkout -b dev //创建新分支dev并切换 此时我们在输入git branch查看分支情况就会发现成功切换到了dev,此时HEAD就是指向了dev分支的最新版本，但其实看上图我们就知道HEAD还是指向的版本3。 思考：为什么分支切换如此之快？ 我们发现创建分支不过是创建了一个新指针dev指向版本3，切换就是将HEAD指向dev而已，学过c我们都知道指针切换是非常迅速的，所以git可以快速创建和切换分支。 现在我们在dev分支上进行版本更新，更新到版本4（比如在txt中加上一句话：Chong is Handsome)。然后我们提交到本地仓库的dev分支，代码如下： 那么此时我们就来到了下图的情况： 此时我们发现只有dev更新了，也就是说在master分支上最新版本是版本3，而dev分支上最新版本是版本3并且此时HEAD指向的是dev分支，所以现在HEAD指向的也是版本4。我们验证一下发现此时HEAD指向的版本4的readme.txt内容如下： 然后我们切回到master分支，那么在查看此时HEAD指向的master最新版本3的readme.txt发现确实没有新加的那句话： 那么现在我们尝试合并两个分支，即将dev的版本4加到master上，即变成下图的情况： 实际上就是将master指针指向了版本4，接下来我们实际操作以下，就是输入以下指令 1git merge dev //将dev合并到当前分支master 我们可以看到在没有合并之前master分支的gitlog中只记录了版本3的信息，而当合并了dev以后，master分支的gitlog中增加了一条新信息为版本4的提交信息说明master现在也有了版本4即形成了上图的情况，因此此时master分支下的readme.txt应该也是有新加的那句话： 那么现在dev和master实际上就没有区别了，完全相同了。所以我们现在就可以删除dev分支了，所以输入以下指令删除dev分支： 1git branch -d dev // 删除dev分支 那么此时我们就又只有一个默认分支master了并且HEAD指向了新的版本4。 思考：为什么合并时是Fast-forward? 我们注意到合并分支时显示为Faster-forward,实际上就是快速切换的意思，我们可以大概了解到这种指针指向改变的何兵就是Faster-forward的情况，那么也就是说还有其他情况的分支合并，我们后面再学习，现在只需了这些指令的使用就可以了。一定要注意git merge branch是将branch合并到当前的分支上，并且不是只添加最新版本，而是将所有的历时版本都合并到当前分支。即： 如果此时dev更新了版本4和版本5，那么合并后master也将拥有版本4和版本5两个版本的历史版本。即merge时当前的分子master会把对方相对于自己超前的版本节点继承。 补充：切换分支的新指令 我们知道checkout是检查的意思，貌似和切换分支的意思没有关系，那怎么能担当切换分支的作用呢？为了更加形象也为了避免指令歧义，我们现在最好用更新的指令来实现切换分支，如下： 12git branch dev // 创建dev分支git switch dev //切换到新分支dev 或者一键创建并切换到新分支dev 1git switch -c dev //创建并切换到到新分支dev 总结 指令名称 指令功能 git branch 查看现有分支 git branch [branchname] 新建分支 git switch [branchname]git checkout [branchname] 切换到新分支 git switch -c [branchname]git checkout -b [branchname] 一键新建并切换到新分支 git merge [branchname] 将[branchname]分支合并到当前HEAD指向的分支 git branch -d [branchname] 删除分支 解决分支冲突 我们发现之前的合并是master在版本3停住了，然后dev往后更新了一个版本4，所以dev超前了master分支一个版本，所以合并时master就直接继承了dev的新版本4。但是现在考虑另一种情况master此时如果也有自己的版本4时那么合并时会不会出现问题呢？实际上也不一定必定出现冲突，我们先看一种比较好的情况。 假设此时有一个文件里面写了a，并且此时有两个分支都在这个节点且此时HEAD是在feature分支上如下图： 那么此时如果feature往后更新了一个版本为ab，同时master也自己更新了一个版本bc如下图： 那么我们此时要进行合并是把feature合并到master上即同级别合并，我们思考此时会不会出现合并冲突，实际上并不会，因为master分支时在a的前面一行插入了c,而feature分支时在a的后面一行插入了b，此时合并不会出现冲突，而是出现下图的情况： 即此时master会增加一个新版本他是来自于自己之前的版本和feature版本的合并体，新的文本会有三行，就是在master的第二个版本的基础上的末尾添加了来自于feature版本的b。这种就是非常良好的合并情况，即没有冲突的地方。你一会感到疑惑为什么此时不会出现冲突，我们以一个形象的例子来比喻，这就好像两个学生用时写一篇作文，小明改开头c，小红改结尾b，作文中间部分a不做修改，那么合并时就没有冲突只需加上小明的开头c和小红的结尾b。并且一定要注意此时feature是不会影响的，绿色线只是表示为…做了贡献的意思。也就是说此时feature自己还是处于版本2没有发生变化可以自己继续进行发展而master分支此时位于版本3也可以继续自己发展。但是如果两个人都同时修改一个地方就不行了。比如下面这种情况就会出现冲突： 即此时feature是将a这一行改为了ab,而master将a这一行改成了ca，此时就会出现冲突了，此时就相当于两个人同时对文章的主体内容部分进行了修改，我们来实际操作一下这种情况，首先先做到为合并之前的情况，完成这个情况后我们输入下面这个指令以图的形式来展示以下此时的情况是否和上面相一致： 1git log --graph --pretty=oneline --abbrev-commit 我们先查看master分支： 此时master确实是两个版本，a-&gt;ca，然后我们看一下feature分支： 此时feature确实是两个版本，a-&gt;ab,然后我们尝试将feature合并到master： 此时我们发现出现冲突了，我们查看一下readme.txt文件信息： 我们发现git已经用箭头指出来出现冲突的内容的部分了，所以接下来我们需要将有冲突的地方进行重新手动更正合并。其中&lt;&lt;&lt;&lt;到===是HEAD中冲突部分的内容，===到&gt;&gt;&gt;&gt;部分是feature部分的内容。我们删除这些内容将冲突的内容重新更正为hhh再次提交，那么此时就处于了下图的情况。我们可以观察到此时master分支单独出现了一个新版本为hhh，并且此时feature分支还是处于版本2可以继续独立发展，master也是。 这就是解决冲突的办法。此时在输入以图的形式查看 我们发现此时的图和我们上面的图是一样的。 思考：此时如果是二进制或者其他不能直接打开修改合并的冲突文件怎么办？ 实际上只有对于txt,md,cpp等可以直接编辑的冲突文件允许手动更正，而对于更多的exe,二进制等冲突文件一般是二选一选择一个版本来替换。 思考：合并到底是如何合并的？ 我们这里具体讨论一下合并的具体情况以及合并冲突的由来问题。我们对比两种情况可以总结出合并具有以下特点： 合并时将目标分支的版本合并到当前版本 目标分支自身不会受到任何影响 合并的版本是领先于当前分支的所有版本 我们具体来分析一种很极端的情况，加入在上图合并后的基础上，feature有经过了三次版本的迭代，到达了如下图的情况： 那么此时如果要将feature合并到master分支，那么合并后的情况会如下图所示： 即此时master分支上会增加两个版本分别是feature的版本4和版本5因为他们两个都是领先于master分支的。我们发现此时虽然feature版本4和master的版本3有冲突，但是也没有关系，因为冲突永远是在两个最新版本之间产生的，而版本4此时只是一个历史版本，所以不会有冲突，只要feature合并时的最新版本5和master版本3不冲突即可正常合并。因此此时我们查看master的版本会发现他有5个版本，分别是a,ca,hhh,hhhaaa,hhhh换行abcd。这就是分支合并与冲突解决的相关知识点。 分支管理策略 我们之前学习了Fast forwad模式的分支合并，实际上在开发中已经能够完成绝大多数的任务需求了，但是我们现在假设一种实际多人开发一个项目的环境下： 一般master分支主分支上是存储某个项目的迭代稳定版本，所有人是不允许在这个分支上进行开发的。而dev分支一般是所有开发人员开发时定期合并组成的不稳定的迭代版本。底下的两个代表的是不同的开发人员对于这个项目的不同板块进行开发都各自拥有一个自己的分支。在一段开发时间后，完成了一定的功能开发后，工作人员会将所有分支合并到dev分支形成一个不稳定的待检测的版本，如果有bug会在进行相应的修复，然后稳定后无bug后合并到master分支上形成一个稳定版本。所以我们在每次合并时尤其是dev分支的合并时，我们希望可以记录每一次合并分支的信息，知道这次dev上的版本合并了那些开发人员的分支，这样我们就可以看出不同的项目功能版本的贡献者了。但是很明显Faster forward模式下的合并是不会存储合并分支信息的。所以我们学习一种新的模式开发，实际上就是禁用Fast forward模式的分支合并，这样每次合并都会在Fastforward的基础上在向后移动一个节点产生一个commit来记录我们的合并分支信息如下图： 可千万别和分支合并时解决冲突的图混淆了，看上图合并以后master分支的指针并未指向dev分支的最新版本，而是又往后走了一个节点，产生了一个新的节点形成一个新commit,所以我们需要加上一个分支合并的信息。 指令如下： 1git merge --no-ff -m &quot;message&quot; [branchname] 实际上就是在git merge [branchname]之间加上了一个参数 -m &quot;messsage&quot;来填写分支合并的的信息。观察上面那个多人合作开发的图，很明显当都合并到dev分支上时也是采用的禁用Fast forward模式的分支合并。 结尾语 那么本次学习就先到这里了，我们要重点理解和掌握创建、切换分支（尤其是Fast forward模式）和分支合并以及解决合并冲突的方法😃。"},{"title":"函数基础","path":"/wiki/Python学习笔记/函数基础/index.html","content":"Python函数用法详解 函数就是将一个复杂的需要多次调用的步骤进行封装以便后期复用，在Python中除了可以使用内置函数以外，我们还可以自定义函数，将一段有规律的、可重复使用的代码定义成函数，从而达到一次编写、多次调用的目的。 123456789101112#自定义 len() 函数def my_len(str): length = 0 for c in str: length = length + 1 return length#调用自定义的 my_len() 函数length = my_len(&quot;http://c.biancheng.net/python/&quot;)print(length)#再次调用 my_len() 函数length = my_len(&quot;http://c.biancheng.net/shell/&quot;)print(length) 运行结果： 123029 注意，Python中的函数既可以接收多个(&gt;=0)参数，还可以返还多个(&gt;=0)返回值。 Python函数的定义 Python中使用def关键字实现对一个自定义函数的声明，具体格式如下： 123def 函数名(参数列表): //实现特定功能的多行代码 [return [返回值]] 其中，用 [] 括起来的为可选择部分，即可以使用，也可以省略。当不设置返回值时，默认返回None。注意，在创建函数时即使不需要参数，也必须保留一对空的&quot;()&quot;，否则Python解释器将提示&quot;invalid syntax&quot;错误。同时如果想要定义一个没有任何功能的空函数，可以使用pass语句作为占位符。 另外值得一提的是，函数中的 return 语句可以直接返回一个表达式的值： 12def str_max(str1,str2): return str1 if str1 &gt; str2 else str2 Python函数的调用 1[返回值] = 函数名([形参值]) 要注意创建的函数有多少个形参，那么调用时即需要传入多少个值，并且顺序必须和创建函数时一致，即使该函数没有参数，函数名后面的小括号也不能省略。 为函数提供说明文档 我们通过调用Python的help()内置函数或者__doc__属性，就可以查看到某个函数的使用说明文档。无论是Python提供给我们的函数，还是自定义的函数，其说明文档都需要设计该函数的程序猿自己编写。 本质上，函数的说明文档就是一段字符串，只不过作为说明文档。字符串的放置位置是有讲究的，函数的说明文档通常位于函数内部、所有代码的最前面。 123456789#定义一个比较字符串大小的函数def str_max(str1,str2): &#x27;&#x27;&#x27; 比较 2 个字符串的大小 &#x27;&#x27;&#x27; str = str1 if str1 &gt; str2 else str2 return strhelp(str_max)#print(str_max.__doc__) 运行结果： 1234Help on function str_max in module __main__:str_max(str1, str2) 比较 2 个字符串的大小 Python函数值传递和引用传递 在Python中，根据实际参数的类型不同，函数传递的方式有两种，分别为值传递和引用传递(地址传递)。 值传递：适用于实参类型为不可变类型（字符串、数字、元组）； 引用（地址）传递：适用于实参类型为可变类型（列表，字典）； 值传递和应用传递的特点是，函数参数进行值传递以后，如果形参的值发生改变，不会影响实参的值。而函数参数继续使用引用传递以后，改变形参的值，实参的值也会一同发生改变。 12345678910111213def demo(obj) : obj += obj print(&quot;形参值为：&quot;,obj)print(&quot;-------值传递-----&quot;)a = &quot;C语言中文网&quot;print(&quot;a的值为：&quot;,a)demo(a)print(&quot;实参值为：&quot;,a)print(&quot;-----引用传递-----&quot;)a = [1,2,3]print(&quot;a的值为：&quot;,a)demo(a)print(&quot;实参值为：&quot;,a) 运行结果： 12345678-------值传递-----a的值为： C语言中文网形参值为： C语言中文网C语言中文网实参值为： C语言中文网-----引用传递-----a的值为： [1, 2, 3]形参值为： [1, 2, 3, 1, 2, 3]实参值为： [1, 2, 3, 1, 2, 3] Python底层了解函数参数传递机制 Python函数参数的值传递机制 12345678910def swap(a , b) : # 下面代码实现a、b变量的值交换 a, b = b, a print(&quot;swap函数里，a的值是&quot;, \\ a, &quot;；b的值是&quot;, b)a = 6b = 9swap(a , b)print(&quot;交换结束后，变量a的值是&quot;, \\ a , &quot;；变量b的值是&quot;, b) 运行结果： 12swap函数里，a的值是 9 ；b的值是 6交换结束后，变量a的值是 6 ；变量b的值是 9 如上所示，在swap()函数中，a和b的值分别是9,6，交换结果后，变量a和b的值依然是6和9，从这个运行结果可以看出，程序中实际定义的变量a和b，并不是swap()函数中的a和b。因为swap()函数中的a和b只是主程序变量a和b的复制品，如下图所示： 上面程序开始定义了 a、b 两个局部变量，这两个变量在内存中的存储示意图如图 1 所示。 当程序执行swap()函数时，系统进入swap()函数，并且将主程序的a、b变量作为参数传入swap()函数，但是传入swap()函数的只是a、b的副本，而不是a、b本身。进入swap()函数以后，系统中产生了4个变量，这4个变量在内存中的存储示意图如图2所示： 当在主程序中调用swap()函数时，系统分别为主程序和swap()函数分配两块栈区，用于保存他们的局部变量。将主程序中的a、b变量作为参数值传入swap()函数，实际上是在swap()函数栈区中重新生成了两个变量a、b，并且将主程序栈区中a、b变量的值分别赋值给swap()函数栈区中的a、b参数（就是对swap()函数中的a、b两个变量进行初始化）。此时，系统存在两个a变量、两个b变量，只是存在与不同的栈区中而已。 程序在swap()函数中交换a、b两个变量的值，实际上是对图2中灰色区域中的a、b变量进行交换。交换结束以后，输出swap()函数中a、b变量的值，可以看到a的值为9，b的值为6,此时在内存中的存储示意图如图3所示： 对比图3和图1，可以看到两个示意图中主程序栈区中a、b的值并未有任何变化，程序改变的仅仅是swap()函数栈区中a、b的值。这既是值传递的实质，当程序开始执行函数时，系统对形参进行初始化，就是把实参变量的值赋给函数的形参变量，在函数中操作的并不是实际上的实参变量。 Python函数参数的引用传递 如果实际参数的数据类型是可变对象（列表、字典），则函数参数的传递方式将采用引用传递方式，需要注意的是，引用传递方式的底层实现，采用的依然是值传递的方式。 123456789def swap(dw): # 下面代码实现dw的a、b两个元素的值交换 dw[&#x27;a&#x27;], dw[&#x27;b&#x27;] = dw[&#x27;b&#x27;], dw[&#x27;a&#x27;] print(&quot;swap函数里，a元素的值是&quot;,\\ dw[&#x27;a&#x27;], &quot;；b元素的值是&quot;, dw[&#x27;b&#x27;])dw = &#123;&#x27;a&#x27;: 6, &#x27;b&#x27;: 9&#125;swap(dw)print(&quot;交换结束后，a元素的值是&quot;,\\ dw[&#x27;a&#x27;], &quot;；b元素的值是&quot;, dw[&#x27;b&#x27;]) 运行结果： 12swap函数里，a元素的值是 9 ；b元素的值是 6交换结束后，a元素的值是 9 ；b元素的值是 6 如上所示，在swap()函数中，dw字典的a,b两个元素的值被交换成功，不仅如此，当swap()函数执行结束后，主程序中dw字典的a、b两个元素的值被交换了，这很容易造成一种错觉，即在调用swap()函数时，传入swap()函数的就是dw字典本身，而不是它的复制品。但这是一种错觉，下面我们还是结合示意图来说明程序的执行过程。 程序开始创建了一个字典对象，并且定义了一个dw引用变量（其实就是一个指针），指向字典变量，这意味着此时内存中有两个东西，对象本身和指向该对象的引用变量。此时系统内存中的存储示意图如下所示： 接下来当主程序开始调用swap()函数时，dw变量作为参数传入swap()函数，这里依然采用值传递方式，把主程序中dw变量的值赋给swap()函数的dw形参，从而完成swap()函数的dw参数的初始化。值的指出的是，主程序中的dw是一个引用变量（也就是一个指针），他保存了字典对象的地址值，当把dw的值赋给swap()函数的dw参数后，就是让swap()函数也保存这个地址值，即也会引用到同一个字典对象，图5显示了dw字典传入swap()函数后的存储示意图。 从图5来看，这种参数传递方式是不折不扣的值传递方式，系统一样复制了dw的副本到swap()函数，但由于dw只是一个引用变量，因此系统复制的是dw变量，并未复制字典本身。 当程序在swap()函数中操作dw参数时，由于dw只是一个引用变量，故实际操作的还是字典对象。此时，不管是操作主函数中的dw变量，还是操作swap()函数里的dw参数，其实操作的都是他们共同引用的字典对象，他们引用的是同一个字典对象。因此，当在swap()函数中交换dw参数所引用字典对象的a,b两个元素的值后，可以看到在主程序中dw变量所引用字典对象的a、b两个元素的值也被交换了。 为了更好地证明主程序中的dw和swap()函数中的dw是两个变量，在swap()函数的最后一行增加如下代码： 12#把dw 直接赋值为None，让它不再指向任何对象dw = None 运行上面代码，结果是swap()函数中的dw变量不再指向任何对象，程序其他地方没有任何变化。主程序调用swap()函数后，再次访问dw变量的两个元素，依然可以输出9、6。可见，主程序的dw变量并没有受到任何影响。实际上，当在sawp()函数中增加dw=None代码后，在内存中的存储示意图如下所示： 我们可以看出，把swap()函数中的dw赋值为None后，在swap()函数中失去了对字典对象的引用，不可再访问该字典对象，但是主程序中的dw变量不受任何影响，依然可以使用该字典对象，所以依然输出字典对象的a、b元素的值。 我们通过上面的学习，可以得到如下两个结论： 不管什么类型的参数，在 Python 函数中对参数直接使用“=”符号赋值是没用的，直接使用“=”符号赋值并不能改变参数。 如果需要让函数修改某些数据，则可以通过把这些数据包装成列表、字典等可变对象，然后把列表、字典等可变对象作为参数传入函数，在函数中通过列表、字典的方法修改它们，这样才能改变这些数据。 Python位置参数 实参和形参数量必须一致 位置参数，有时也被称为必备参数，指的是必须按照正确的顺序将实际参数传到函数中，换句话说，调用参数时传入实际参数的数量和位置必须和定义函数时保持一致。 在调用函数，指定的实际参数的数量，必须和形式参数的数量一致（传多传少都不行）。否则Python解释器会抛出TypeError异常，并提示缺少必要的位置参数。 1234def girth(width , height): return 2 * (width + height)#调用函数时，必须传递 2 个参数，否则会引发错误print(girth(3)) 运行结果： 1234Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(girth(3))TypeError: girth() missing 1 required positional argument: &#x27;height&#x27; 1234def girth(width , height): return 2 * (width + height)#调用函数时，必须传递 2 个参数，否则会引发错误print(girth(3,2,4)) 运行结果： 1234Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(girth(3,2,4))TypeError: girth() takes 2 positional arguments but 3 were given 实参和形参位置必须一致 在调用函数时，传入实际参数的位置必须和形式参数的位置一一对应，否则就会产生以下2中结果： 抛出 TypeError 异常 当实际参数类型和形式参数类型不一致，并且在函数种，这两种类型之间不能正常转换，此时就会抛出 TypeError 异常。 123def area(height,width): return height*width/2print(area(&quot;hhhh&quot;,3)) 运行结果： 123456Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 3, in &lt;module&gt; print(area(&quot;hhh&quot;,3)) File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 2, in area return height*width/2TypeError: unsupported operand type(s) for /: &#x27;str&#x27; and &#x27;int&#x27; 以上显示的异常信息，就是因为字符串类型和整形数值做除法运算。 产生的结果和预期不符 调用函数时，如果指定的实际参数和形式参数的位置不一致，但是他们的数据类型相同，那么程序并不会抛出异常，只不过导致运行结果和预期不符。 例如，设计一个求梯形面积的函数，并利用此函数求上底为 4cm，下底为 3cm，高为 5cm 的梯形的面积。但如果交互高和下低参数的传入位置，计算结果将导致错误： 1234def area(upper_base,lower_bottom,height): return (upper_base+lower_bottom)*height/2print(&quot;正确结果为：&quot;,area(4,3,5))print(&quot;错误结果为：&quot;,area(4,5,3)) 运行结果： 12正确结果为： 17.5错误结果为： 13.5 Python函数关键字参数及用法 之前我们学习的一直是位置参数，即实参和形参位置要一一对应，顺序不能出现错误。但是当参数过多时，使用位置参数就较为复杂，因此我们可以使用关键字参数。关键字参数是指使用形式参数的名字来确定输入的参数值，通过此方式来指定函数实参时，不再需要与形参的位置完全一致，只需要将参数名写正确即可。 12345678def dis_str(str1,str2): print(&quot;str1:&quot;,str1) print(&quot;str2:&quot;,str2)#位置参数dis_str(&quot;http://c.biancheng.net/python/&quot;,&quot;http://c.biancheng.net/shell/&quot;)#关键字参数dis_str(&quot;http://c.biancheng.net/python/&quot;,str2=&quot;http://c.biancheng.net/shell/&quot;)dis_str(str2=&quot;http://c.biancheng.net/python/&quot;,str1=&quot;http://c.biancheng.net/shell/&quot;) 运行结果： 123456str1: http://c.biancheng.net/python/str2: http://c.biancheng.net/shell/str1: http://c.biancheng.net/python/str2: http://c.biancheng.net/shell/str1: http://c.biancheng.net/shell/str2: http://c.biancheng.net/python/ 我们发现函数在传参时，可以单独使用位置参数，也可以单独使用关键字参数传参，甚至还可以混用传参的参数方法。 但是一定要注意，混用两者时，所有关键字参数必须位于所有的位置参数之后。 如下的写法就是错误的 12# 位置参数必须放在关键字参数之前，下面代码错误dis_str(str1=&quot;http://c.biancheng.net/python/&quot;,&quot;http://c.biancheng.net/shell/&quot;) Python解释器会报如下错误： 1SyntaxError: positional argument follows keyword argument Python函数默认参数设置 我们可以为Python中的函数设置默认值，这样的话，即使调用函数时没有给拥有默认值的形参传递参数，该参数可以直接使用定义函数时设置的默认值。 12def 函数名(...，形参名，形参名=默认值)： 代码块 要注意，在使用此格式定义函数时，指定有默认值的形式参数必须在所有没有默认参数的后面，否则会产生语法错误。同时要注意默认参数必须指向不变对象。 如下写法就是错误的： 123#语法错误def dis_str(str1=&quot;http://c.biancheng.net/python/&quot;,str2,str3): pass 显然，str1 设有默认值，而 str2 和 str3 没有默认值，因此 str1 必须位于 str2 和 str3 之后。 接下来我们看一个正确使用函数默认值的例子： 123456#str1没有默认参数，str2有默认参数def dis_str(str1,str2 = &quot;http://c.biancheng.net/python/&quot;): print(&quot;str1:&quot;,str1) print(&quot;str2:&quot;,str2)dis_str(&quot;http://c.biancheng.net/shell/&quot;)dis_str(&quot;http://c.biancheng.net/java/&quot;,&quot;http://c.biancheng.net/golang/&quot;) 运行结果： 1234str1: http://c.biancheng.net/shell/str2: http://c.biancheng.net/python/str1: http://c.biancheng.net/java/str2: http://c.biancheng.net/golang/ 上面程序中，dis_str() 函数有 2 个参数，其中第 2 个设有默认参数。这意味着，在调用 dis_str() 函数时，我们可以仅传入 1 个参数，此时该参数会传给 str1 参数，而 str2 会使用默认的参数，如程序中第 6 行代码所示。当然在调用 dis_str() 函数时，也可以给所有的参数传值（如第 7 行代码所示），这时即便 str2 有默认值，它也会优先使用传递给它的新值。 同时，结合关键字参数，以下 3 种调用 dis_str() 函数的方式也是可以的： 123dis_str(str1 = &quot;http://c.biancheng.net/shell/&quot;)dis_str(&quot;http://c.biancheng.net/java/&quot;,str2 = &quot;http://c.biancheng.net/golang/&quot;)dis_str(str1 = &quot;http://c.biancheng.net/java/&quot;,str2 = &quot;http://c.biancheng.net/golang/&quot;) 你可能会疑惑，对于自己自定义的函数，我们可以轻易知道那个参数有默认值，但是如果使用Python提供的内置函数，又或者其他第三方提供的函数，我们怎么知道那些参数有默认值呢？ 在Python中，我们可以使用函数名.__defaults__查看函数的默认参数的当前值，其返回值是一个元组，以本节中的 dis_str() 函数为例，在其基础上，执行如下代码： 1print(dis_str.__defaults__) 程序执行结果为 1(&#x27;http://c.biancheng.net/python/&#x27;,) Python函数传入任意个参数(进阶) *args接收任意个位置参数 *args是可变参数，args接收的是一个元组tuple,可变参数允许传入0个或者任意个参数，这些可变参数在函数调用时被组装为一个元组，如下所示： 123456def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 例如我们要传入0个或者多个不可变参数 12345calc（）可传入0到多个参数值&gt;&gt;&gt; calc(1, 2)5&gt;&gt;&gt; calc()0 但是如果此时我们要传递一个列表中的所有元素或者元组中的所有元组又该怎么写呢？我们可以如下书写： 123&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(nums[0], nums[1], nums[2])14 但是如果列表或者元组的元素过多时，操作就会过于繁琐，此时Python允许我们在list或者tuple前面加一个*号，把list或者tuple传入： 123&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(*nums)14 **kw接收任意个关键字参数 **kw是关键字参数，kw接收的是一个字典，关键字参数允许你传入0个或者任意个含参数名的参数，这些关键字参数会在函数内部自动组装成一个字典。 12def person(name, age, **kw): print(&#x27;name:&#x27;, name, &#x27;age:&#x27;, age, &#x27;other:&#x27;, kw) 假设现在我们传入任意个关键字参数 123456&gt;&gt;&gt; person(&#x27;Michael&#x27;, 30)name: Michael age: 30 other: &#123;&#125;&gt;&gt;&gt; person(&#x27;Bob&#x27;, 35, city=&#x27;Beijing&#x27;)name: Bob age: 35 other: &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;&#125;&gt;&gt;&gt; person(&#x27;Adam&#x27;, 45, gender=&#x27;M&#x27;, job=&#x27;Engineer&#x27;)name: Adam age: 45 other: &#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125; 但是如果此时需要传递许多个关键字参数，操作也会很繁琐，因此Python允许我们传递一个字典，只需要在字典dict前加上**符号，如下所示： 123&gt;&gt;&gt; dict=&#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125;&gt;&gt;&gt; person(&#x27;Adam&#x27;, 45, **dict)name Adam age 45 other &#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125; 我们要注意由于*args和**kw都是可以吸收任意个参数，因此一般置于后面，同时根据关键字参数总是要位于位置参数后面，如果同时有*args和**kw存在，**kw要置于后面。 命名关键字参数 我们还可以进一步限制传入的关键字参数的名字，并且一旦声明了命名关键字参数，那么就必须出现否则会报错。 如下所示，如果我们使用**kw来接收任意个关键字参数，那么传入的参数名字可以是任意的，我们可以在函数内部对kw进行校验寻找我们要求出现的关键字参数，但是这样的话仍然会造成传入了许多不需要的关键字参数如下所示： 12345678910111213def person(name, age, **kw): if &#x27;city&#x27; in kw: # 有city参数 pass if &#x27;job&#x27; in kw: # 有job参数 pass print(&#x27;name:&#x27;, name, &#x27;age:&#x27;, age, &#x27;other:&#x27;, kw)但是调用者仍可以传入不受限制的关键字参数：# addr,zipcode完全不需要，但是也传进来了&gt;&gt;&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;Beijing&#x27;, addr=&#x27;Chaoyang&#x27;, zipcode=123456)name: Jack age: 24 other: &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;, &#x27;addr&#x27;: &#x27;Chaoyang&#x27;, &#x27;zipcode&#x27;: 123456&#125; 我们发现上面的代码中我们只是需要两个关键字参数即city和job，但是此时使用kw却接收了许多没用的关键字参数。那么我们如何实现只接收指定的关键字参数呢？这时就要使用命名关键字参数，他的写法如下： 12def person(name, age, *, city, job): print(name, age, city, job) 此时我们指定接收4个参数，name和age都是位置参数，而特殊分隔符*表示后面的所有参数都是指定命名关键字参数（注意此时city和job不再是位置参数了）。那么我们在为person函数传递参数时就必须传递两个关键字参数city和job了。此时指定了两个必须传进的指定名称的关键字参数，多了或者少了都不行 1234567891011121314151617181920&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;)Jack 24 chengdu auditor# 少job报错&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;)TypeError: person() missing 1 required keyword-only argument: &#x27;job&#x27;# 多sex也报错&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;,sex=&quot;male&quot;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;,sex=&quot;male&quot;)TypeError: person() got an unexpected keyword argument &#x27;sex&#x27;# 使用位置参数来传递city和job肯定也是不行的&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, &#x27;chengdu&#x27;,&#x27;auditor&#x27;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, &#x27;chengdu&#x27;,&#x27;auditor&#x27;)TypeError: person() takes 2 positional arguments but 4 were given 命名关键字参数可以简单地理解为必须使用关键字参数的形式传进来的键名必须一致的参数。 但是如果我们已经为命名关键字参数设置了默认值，那么此时可以选择不传： 123456def person(name, age, *, city=&#x27;chengdu&#x27;, job): print(name, age, city, job)由于命名关键字参数city具有默认值，调用时，可不传入city参数：&gt;&gt;&gt; person(&#x27;Jack&#x27;, 24, job=&#x27;tester&#x27;)Jack 24 chengdu tester 思考：下面这样的写法错在了哪里？ 12def person(name, age, **kw, *，city, job): print(name, age,kw, city, job) 我们发现此时**kw这个可以接收任意个关键字参数的形参写在了city和job这两个命名关键字参数前面，那么很显然无论我们传入多少个关键字参数都会被kw吸收，甚至是city换入job命名关键字参数也会被kw吸收，因此形参city和job永远不可能被赋值，因此上面的写法错误，我们可以如下改写即为正确： 1234def person(name, age, *, city, job, **kw,): print(name, age, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&quot;beijing&quot;, job=&quot;auditor&quot;, sex=&#x27;male&#x27;, addr=&#x27;big house&#x27;)Jack 24 beijing auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;, &#x27;addr&#x27;: &#x27;big house&#x27;&#125; 也就是说**kw永远不能写到命名关键字形参前面 思考：如果可变位置参数*args写在关键字命名参数前面会怎样？ 虽然**kw不能写到命名关键字参数前面，但是*args是可以写到前面的，并且此时命名关键字参数前面就无需在加上特殊分隔符*了，如下所示： 1234def person(name, age, *args, city, job, **kw,): print(name, age,args, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,&quot;a cool boy&quot;,&quot;500&quot;,city=&quot;beijing&quot;, job=&quot;auditor&quot;, sex=&#x27;male&#x27;, addr=&#x27;big house&#x27;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) beijing auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;, &#x27;addr&#x27;: &#x27;big house&#x27;&#125; 此时person函数先通过位置参数的方法获取了name和age变量，然后又通过args获取了2个位置参数，紧接着就是两个命名关键字参数city和job，然后最后面又使用了kw接收剩余的关键字参数sex和addr。因此总体上来看，函数接收参数的顺序总是先接收所有的位置参数，然后再接收所有的关键字参数。 思考：为什么*args在命名关键字前面时就无需再使用*特殊分隔符号了？ 原因很简单，之前我们之所要在命名关键字参数前加上特殊分隔符*是为了区分位置参数和命名关键字参数，但是当我们使用了*args那么所有的位置参数都已经吸收了，后面紧跟着的形参很明显一定是关键字参数了，因此此时我们就无需再使用*进行区分了。 思考：下面这样的写法错在了哪里？ 12def person(*, city, job,name, age, *args, **kw,): print(name, age,args, city, job, kw) 我们发现此时city和name命名关键字反而写到了位置关键字的前面，很明显违背了所有关键字参数要位于所有位置参数后面的原则，那么为什么此时命名关键字参数不能写到前面呢？原因很简单，此时name和age语义就不明确了，我们无法区分他们到底是位置参数还是命名关键字参数了。 因此一定要记住再复杂的函数传参也一定要保证所有的位置参数在所有关键字参数的前面，顺序可以总结为：1def func(位置参数，默认参数，*args，命名关键字参数，默认参数，**kw) 例如如下就是一些包含了所有传参形式的例子，如果你可以理解那么恭喜你进阶成功！ 1234567def person(name, age=18, *args, city=&quot;chengdu&quot;, job, **kw,): print(name, age,args, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,&quot;a cool boy&quot;,&quot;500&quot;, job=&quot;auditor&quot;, sex=&quot;male&quot;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) chengdu auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;&#125;&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,*(&quot;a cool boy&quot;,&quot;500&quot;), job=&quot;auditor&quot;, **&#123;&quot;sex&quot;:&quot;male&quot;&#125;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) chengdu auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;&#125; Python None(空值) 在Python中，有一个特殊的常量None(N必须大写)。他和False,0,[],(),{},&quot;&quot;等都不同，None有自己的数据类型，我们可以在IDLE中使用type()函数查看它的类型： 12&gt;&gt;&gt; type(None)&lt;class &#x27;NoneType&#x27;&gt; 可以看到，它属于NoneType类型，None是NoneType数据类型的唯一值（其他变成语言可能将这个值称为null,nll或者undifined）。也就是说None表示为初始化赋值的一个状态。对于任何函数，如果没有return返回值，或者return关键字后面不带任何值，那么Python默认函数都返回None，比如print()函数 1234&gt;&gt;&gt; spam = print(&#x27;Hello!&#x27;)Hello!&gt;&gt;&gt; None == spamTrue Python函数返回多个值 实际上Python就是只能反会有一个值，只不过我们可以使用列表，元组，字典甚至对象将多个返回值进行封装，然后一次性返回封装结果即可实现返回多个值的效果。 使用对象返回 123456789101112class Test: def __init__(self): self.str = &quot;hello world!&quot; self.x = 20 # 返回一个对象def fun(): return Test()t = fun() print(t.str)print(t.x) 运行结果： 12hello world!20 使用列表返回 123456789# 返回一个列表def fun(): str = &quot;hello&quot; x = 20 return [str, x]; list = fun() print(list) 运行结果： 1[&#x27;hello&#x27;, 20] 使用元组返回 123456789# 返回一个元组def fun(): str = &quot;你好！&quot; x = 2022 return str, x;str, x = fun() # Assign returned tupleprint(str)print(x) 运行结果： 12你好！2022 使用字典返回 123456789# 返回一个字典def fun(): d = dict(); d[&#x27;name&#x27;] = &quot;欧阳克&quot; d[&#x27;age&#x27;] = 25 return dd = fun() print(d) 运行结果： 1&#123;&#x27;name&#x27;: &#x27;欧阳克&#x27;, &#x27;age&#x27;: 25&#125;"},{"title":"元组、字典与集合","path":"/wiki/Python学习笔记/元组、字典与集合/index.html","content":"Python tuple元组详解 元组（tuple)是Python中另一个重要的序列结构，和列表类似，元组也是由一系列按特定顺序排列的元组组成。但是他和list列表又有所区别如下： 列表的元素是可以更改的，包括修改元素值，删除和插入元素，所以列表是可变序列； 而元组一旦被创建，它的元素就不可更改了，所以元组是不可变序列。 元组可以看成是不可变的列表，因此他不提供append()，remove()等方法同时也不支持del tuple[idx]删除元组的方法。 1234&gt;&gt;&gt; tup=(1,2,3)&gt;&gt;&gt; del tup(0) File &quot;&lt;stdin&gt;&quot;, line 1SyntaxError: cannot delete function call 通常情况下，元组用于保存无需修改的内容。从形式上看，元组的所有元素都放在一对小括号()中，相邻元素之间用逗号,分隔，如下所示： 1(element1, element2, ... , elementn) 其中 element1~elementn 表示元组中的各个元素，个数没有限制，只要是 Python 支持的数据类型就可以。因此元组中也可以存储若干个类型不同的数据，但是为了提高可读性，一般也存储相同类型的数据。 1(&quot;c.biancheng.net&quot;, 1, [2,&#x27;a&#x27;], (&quot;abc&quot;,3.0)) 要注意元组tuple和列表list是两种不同的数据结构，他们的type类型并不相同！ 12&gt;&gt;&gt; type( (&quot;c.biancheng.net&quot;,1,[2,&#x27;a&#x27;],(&quot;abc&quot;,3.0)) )&lt;class &#x27;tuple&#x27;&gt; Python创建元组 Python中元组的创建和list类似也有两种创建方法 1）使用()创建 通过()创建元组以后，一般使用=将它赋值给某个变量，具体格式为： 1tuplename = (element1, element2, ..., elementn) 其中，tuplename表示变量名，element1~elementn表示元组存储的元素。如下所示： 123num = (7, 14, 21, 28, 35)course = (&quot;Python教程&quot;, &quot;http://coolchong.cn&quot;)abc = ( &quot;Python&quot;, 19, [1,2], (&#x27;c&#x27;,2.0) ) 在Python中，元组通常都是使用一对小括号将所有元素包围起来的，但是小括号不是必须的，只要将各元素用逗号分隔，Python就会将其视为元组，如下也是元组： 12course = &quot;Python教程&quot;, &quot;http://coolchong.cn&quot;print(course) 运行结果： 1(&#x27;Python教程&#x27;, &#x27;http://coolchong.cn&#x27;) 要特别注意，当创建的元组中只有一个字符串类型的元素时，该元素后面必须要加一个逗号,，否则Python解释器会将它视为字符串，如下所示： 123456&gt;&gt;&gt; a=(&quot;https://coolchong.cn/&quot;,)&gt;&gt;&gt; print(type(a))&lt;class &#x27;tuple&#x27;&gt;&gt;&gt;&gt; b=(&quot;https://coolchong.cn/&quot;)&gt;&gt;&gt; print(type(b))&lt;class &#x27;str&#x27;&gt; 2)使用tuple()函数创建元组 除了使用()创建元组外，Python还提供了一个内置的函数tuple()，可以用来将其他数据类型转换为元组类型。tuple()的语法格式如下： 1tuple(data) 其中data表示可以转换为元组的数据，包含字符串、元组、range()对象等。 1234567891011121314151617#将字符串转换成元组tup1 = tuple(&quot;hello&quot;)print(tup1)#将列表转换成元组list1 = [&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;]tup2 = tuple(list1)print(tup2)#将字典转换成元组dict1 = &#123;&#x27;a&#x27;:100, &#x27;b&#x27;:42, &#x27;c&#x27;:9&#125;tup3 = tuple(dict1)print(tup3)#将区间转换成元组range1 = range(1, 6)tup4 = tuple(range1)print(tup4)#创建空元组print(tuple()) 运行结果： 12345(&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;)(&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;)(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;)(1, 2, 3, 4, 5)() Python访问元组元素 和列表一样，我们也可以使用索引(Index)访问元组的某个元素（得到的是一个元素的值），也可以使用切片访问元组的一组元素(得到的是一个新的子元组)。 1234#访问单个元素tuplename[i]#访问一组元素tuplename[start : end : step] 12345678url = tuple(&quot;http://c.biancheng.net/shell/&quot;)#使用索引访问元组中的某个元素print(url[3]) #使用正数索引print(url[-4]) #使用负数索引#使用切片访问元组中的一组元素print(url[9: 18]) #使用正数切片print(url[9: 18: 3]) #指定步长print(url[-6: -1]) #使用负数切片 运行结果： 12345pe(&#x27;b&#x27;, &#x27;i&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;c&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;n&#x27;, &#x27;g&#x27;)(&#x27;b&#x27;, &#x27;n&#x27;, &#x27;e&#x27;)(&#x27;s&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;) Python修改元组 前面我们已经介绍过元组是无法修改的，因此我们只能是为变量赋值一个新元素来改变变量的元组值如下所示： 12345tup = (100, 0.5, -36, 73)print(tup)#对元组进行重新赋值tup = (&#x27;Shell脚本&#x27;,&quot;https://coolchong.cn/&quot;)print(tup) 运行结果： 12(100, 0.5, -36, 73)(&#x27;Shell脚本&#x27;, &#x27;https://coolchong.cn/&#x27;) 同时我们也可以使用+拼接元组生成一个新的元组，但是也不会改变原元组： 12345tup1 = (100, 0.5, -36, 73)tup2 = (3+12j, -54.6, 99)print(tup1+tup2)print(tup1)print(tup2) 运行结果： 123100, 0.5, -36, 73, (3+12j), -54.6, 99)(100, 0.5, -36, 73)((3+12j), -54.6, 99) Python删除元组 我们并不能删除元组中的某一个元素，但是我们可以删除不再使用的整个元组，如下： 1234tup = (&#x27;Java教程&#x27;,&quot;http://coolchong.cn/&quot;)print(tup)del tupprint(tup) 运行结果： 12345(&#x27;Java教程&#x27;, &#x27;http://coolchong.cn&#x27;)Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(tup)NameError: name &#x27;tup&#x27; is not defined Python 自带垃圾回收功能，会自动销毁不用的元组，所以一般不需要通过 del 来手动删除。 Python中元素和列表的区别 看完前面对元组和列表的介绍以后，我们可以发现两者有很多共同点，但是列表中的元素可以任意修改，就好比是用铅笔在纸上写的字，写错了还可以擦除重写，而元组中的元素无法修改，除非将元组整体替换掉，就好比是用圆珠笔写的字，写了就擦不掉除非换一张纸。 可以将元组tuple理解为一个只读版本的列表list即可 由于两者的存储特性不同，因此存储方式也是不同的： 123456&gt;&gt;&gt; listdemo = []&gt;&gt;&gt; listdemo.__sizeof__()40&gt;&gt;&gt; tupleDemo = ()&gt;&gt;&gt; tupleDemo.__sizeof__()24 可以看出虽然列表和元组都是空的，但是元组却比列表少占用了16个字节，这是因为列表是动态的，需要存储指针指向对应的元素（占用8个字节），另外，由于列表是可变的，所以需要额外存储已经分配的长度大小（占用8个字节）。但是对于元组，他由于不可变，长度固定 ，因此存储空间也是固定的，不需要指针和额外的空间因此相较于列表更加轻量级，性能也要略优于列表。 但是既然列表就可以实现元组的功能，我们为什么还要保留使用元组这个数据类型呢？这要从Python的垃圾回收机制讲起，在Python中如果一些变量不再使用，Python就会回收他们所占用的内存，返还给操作系统，以便其他变量或其他应用使用。但是对于一些静态变量，（比如元组），如果他占用的空间不大，那么Python会暂时缓存这些内存，这样的话，下一次再创建同样大小的元组时，Python就可以不用再向操作系统发出请求取寻找内存了，而是直接分配之前缓存的内存空间，大大提升程序的运行速度（大约快了5倍）。因此元组具有不可替代性。同时，元组还可以在映射（和集合的成员）中当做键使用，而列表是不行的。 Python dict字典 Python中字典(dict)是一种无序的、可变的序列，他的元组以键值对(key-value)的形式存储因此元素在底层并不是挨着存放的。相对地，列表和元组都是有序的序列，他们的元素在底层是挨着存放的。 字典类型是Python中唯一的映射类型，”映射“是数学中的术语，简单理解，他指的是元素之间相互对应的关系，即用过一个元素就可以唯一的找到另一个元素如下所示： 字典类型的特点就是： 主要特征 解释 通过键而不是通过索引来读取元素 字典类型有时也称为关联数组或者散列表（hash）。它是通过键将一系列的值联系起来的，这样就可以通过键从字典中获取指定项，但不能通过索引来获取。 字典是任意数据类型的无序集合 和列表、元组不同，通常会将索引值 0 对应的元素称为第一个元素，而字典中的元素是无序的。 字典是可变的，并且可以任意嵌套 字典可以在原处增长或者缩短（无需生成一个副本），并且它支持任意深度的嵌套，即字典存储的值也可以是列表或其它的字典。 字典中的键必须唯一 字典中，不支持同一个键出现多次，否则只会保留最后一个键值对。 字典中的键必须不可变 字典中每个键值对的键是不可变的，只能使用数字、字符串或者元组，不能使用列表。 Python中的字典类型相当于Java或者C中的Map对象，但是它比Map对象更加灵活，因为字典的键类型可以是任意的，而不像Java或者C中需要提前声明键的数据类型保证所有的键类型统一。 123&gt;&gt;&gt; a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125; #a是一个字典类型&gt;&gt;&gt; type(a)&lt;class &#x27;dict&#x27;&gt; Python创建字典 1）使用{}创建字典 由于字典中每一个元素都包含两个部分，分别是键（key）和值（value），因此创建字典时、键和值之间使用冒号:分隔，相邻元素之间使用逗号,分隔，所有元素放在大括号&#123;&#125;中。 1dictname = &#123;&#x27;key&#x27;:&#x27;value1&#x27;, &#x27;key2&#x27;:&#x27;value2&#x27;, ..., &#x27;keyn&#x27;:valuen&#125; 其中 dictname 表示字典变量名，keyn : valuen 表示各个元素的键值对。需要注意的是，同一字典中的各个键必须唯一，不能重复。当为已有键再次设定值的时候会将之前的值覆盖掉。 123456789#使用字符串作为keyscores = &#123;&#x27;数学&#x27;: 95, &#x27;英语&#x27;: 92, &#x27;语文&#x27;: 84&#125;print(scores)#使用元组和数字作为keydict1 = &#123;(20, 30): &#x27;great&#x27;, 30: [1,2,3]&#125;print(dict1)#创建空元组dict2 = &#123;&#125;print(dict2) 运行结果： 123&#123;&#x27;数学&#x27;: 95, &#x27;英语&#x27;: 92, &#x27;语文&#x27;: 84&#125;&#123;(20, 30): &#x27;great&#x27;, 30: [1, 2, 3]&#125;&#123;&#125; 可以看到，字典的键可以是整数、字符串或者元组，只要符合唯一和不可变的特性就行；字典的值可以是 Python 支持的任意数据类型。 2）通过fromkeys()方法创建字典 在Python中我们还可以使用dict字典类型提供的fromkeys()方法创建带有默认值的字典，具体格式如下： 1dictname = dict.fromkeys(list，value=None) 其中list参数表示字典中所有键的列表（因此必须各不相同），value参数表示所有值的默认值，如果不写，就会设置为空值None。 123knowledge = [&#x27;语文&#x27;, &#x27;数学&#x27;, &#x27;英语&#x27;]scores = dict.fromkeys(knowledge, 60)print(scores) 运行结果： 1&#123;&#x27;语文&#x27;: 60, &#x27;英语&#x27;: 60, &#x27;数学&#x27;: 60&#125; 3）通过dict()映射函数创建字典 通过dict()函数创建字典的写法有多种，如下所示几种写法都是等价的创建了同一个字典a 创建格式 注意事项 a = dict(str1=value1, str2=value2, str3=value3) str 表示字符串类型的键，value 表示键对应的值。使用此方式创建字典时，字符串不能带引号。这种方式创建会导致键都是统一的字符串类型 #方式1demo = [(‘two’,2), (‘one’,1), (‘three’,3)]#方式2demo = [[‘two’,2], [‘one’,1], [‘three’,3]]#方式3demo = ((‘two’,2), (‘one’,1), (‘three’,3))#方式4demo = ([‘two’,2], [‘one’,1], [‘three’,3])a = dict(demo) 向 dict() 函数传入列表或元组，而它们中的元素又各自是包含 2 个元素的列表或元组，其中第一个元素作为键，第二个元素作为值。 eys = [‘one’, ‘two’, ‘three’] #还可以是字符串或元组values = [1, 2, 3] #还可以是字符串或元组a = dict( zip(keys, values) ) 通过应用 dict() 函数和 zip() 函数，可将前两个列表转换为对应的字典。 注意，无论采用以上哪种方式创建字典，字典中各元素的键都只能是字符串、元组或者数字，不能是列表，因为列表是可变的，不能作为键。 123456789101112&gt;&gt;&gt; a=dict(name=&quot;langwenchong&quot;,height=190,age=20)&gt;&gt;&gt; pring(a)&#123;&#x27;name&#x27;: &#x27;langwenchong&#x27;, &#x27;height&#x27;: 190, &#x27;age&#x27;: 20&#125;&gt;&gt;&gt; demo=([1,&#x27;one&#x27;],[&#x27;two&#x27;,2])&gt;&gt;&gt; b=dict(demo)&gt;&gt;&gt; print(b)&#123;1: &#x27;one&#x27;, &#x27;two&#x27;: 2&#125;&gt;&gt;&gt; keys=((&#x27;name&#x27;,&#x27;age&#x27;),&#x27;height&#x27;)&gt;&gt;&gt; values=[&quot;langwenchong+20&quot;,190]&gt;&gt;&gt; c=dict(zip(keys,values))&gt;&gt;&gt; print(c)&#123;(&#x27;name&#x27;, &#x27;age&#x27;): &#x27;langwenchong+20&#x27;, &#x27;height&#x27;: 190&#125; 如果不为dict()函数传入任何参数，那么代表创建一个空的字典，如下： 123# 创建空的字典d = dict()print(d) 运行结果为： 1&#123;&#125; Python访问字典 列表和元组都是通过下表索引来访问元素的，而字典不同，他可以通过键来访问对应的值。因为字典中的元素都是无序的，每一个元素的位置都是不固定的，因此字典也不能像列表和元组那样，采用切片的方式一次性访问多个元素。 1234tup = ([&#x27;two&#x27;,26], [&#x27;one&#x27;,88], [&#x27;three&#x27;,100], [&#x27;four&#x27;,-59])dic = dict(tup)print(dic[&#x27;one&#x27;]) #键存在print(dic[&#x27;five&#x27;]) #键不存在 运行结果： 1234588Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(dic[&#x27;five&#x27;]) #键不存在KeyError: &#x27;five&#x27; 除了上面这种方式访问字典，Python更推荐使用get()方法来获取指定键对应的值，当指定的键不存在时，get()方法不会抛出异常。 1dictname.get(key[,default]) 其中，dictname 表示字典变量的名字；key 表示指定的键；default 用于指定要查询的键不存在时，此方法返回的默认值，如果不手动指定，会返回 None。 1234a = dict(two=0.65, one=88, three=100, four=-59)print( a.get(&#x27;one&#x27;) )print( a.get(&#x27;five&#x27;) )print( a.get(&#x27;five&#x27;, &#x27;该键不存在&#x27;) ) 运行结果： 12388None该键不存在 Python删除字典 1234a = dict(two=0.65, one=88, three=100, four=-59)print(a)del aprint(a) 运行结果： 12345&#123;&#x27;two&#x27;: 0.65, &#x27;one&#x27;: 88, &#x27;three&#x27;: 100, &#x27;four&#x27;: -59&#125;Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(a)NameError: name &#x27;a&#x27; is not defined Python字典基本操作 字典是一个可变序列，因此我们可以添加、修改、删除字典中的键值对，常见的字典操作有以下几种： 向现有字典中添加新的键值对。 修改现有字典中的键值对。 从现有字典中删除指定的键值对。 判断现有字典中是否存在指定的键值对。 Python字典添加键值对 1dictname[key] = value 12345678a = &#123;&#x27;数学&#x27;:95&#125;print(a)#添加新键值对a[&#x27;语文&#x27;] = 89print(a)#再次添加新键值对a[&#x27;英语&#x27;] = 90print(a) 运行结果： 123&#123;&#x27;数学&#x27;: 95&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125; Python字典修改键值对 Python字典中的键的名字是不能被修改的，但是我们可以修改键对应的值。由于字典中各元素的键是唯一的，因此，如果新添加元素的键与已存在的元素的键相同，那么键所对应的值就会被新的值替换掉，以此达到修改元素值的目的： 1234a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(a)a[&#x27;语文&#x27;] = 100print(a) 运行结果： 12&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 100, &#x27;英语&#x27;: 90&#125; Python字典删除键值对 如果要删除字典中的键值对，还是可以使用del语句 12345# 使用del语句删除键值对a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;del a[&#x27;语文&#x27;]del a[&#x27;数学&#x27;]print(a) 运行结果： 1&#123;&#x27;英语&#x27;: 90&#125; 判断字典中是否存在指定键值对 我们只能通过in和noe in运算符对键进行判断，而无法判断值是否在字典中即只能判断是否为字典的键而不能判断是否为字典的值，如下都是基于键key的判断 1234567a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;# 判断 a 中是否包含名为&#x27;数学&#x27;的keyprint(&#x27;数学&#x27; in a) # True# 判断 a 是否包含名为&#x27;物理&#x27;的keyprint(&#x27;物理&#x27; in a) # False# 这个判断是判断95是否为字典的键print(95 in a) #False 运行结果： 123TrueTrueFalse 思考：怎样判断字典是否包含某个值？ 我们可以通过dict.keys()和dict.values()获取所有的键和所有的值，这样我们可以使用in和dict.values()来实现值的查找 123&gt;&gt;&gt; d = &#123;&#x27;1&#x27;: &#x27;one&#x27;, &#x27;3&#x27;: &#x27;three&#x27;, &#x27;2&#x27;: &#x27;two&#x27;, &#x27;5&#x27;: &#x27;five&#x27;, &#x27;4&#x27;: &#x27;four&#x27;&#125;&gt;&gt;&gt; &#x27;one&#x27; in d.values()&gt;&gt;&gt; True 思考：能够根据值找到字典中的键？ 可以代码实现如下： 123&gt;&gt;&gt; d = &#123;&#x27;1&#x27;: &#x27;one&#x27;, &#x27;3&#x27;: &#x27;three&#x27;, &#x27;2&#x27;: &#x27;two&#x27;, &#x27;5&#x27;: &#x27;five&#x27;, &#x27;4&#x27;: &#x27;four&#x27;&#125;&gt;&gt;&gt; list(d.keys())[list(d.values()).index(&#x27;one&#x27;)] #根据字典值 返回对应的key&gt;&gt;&gt; &#x27;1&#x27; 根据上面的代码我们可以得出一个结论，即dict的键中的第k个键与值中的第k个值正好可以组成字典中的第k个键值对，即键和值的相对位置是对应的。 Python dict字典其他方法详解 前面我们学习了fromkeys()和get()，这里再介绍剩余的函数。 keys()、values()和items()方法 将这三个放在一起介绍，是因为他们都用来获取字典中特定数据： eys() 方法用于返回字典中的所有键（key）； values() 方法用于返回字典中所有键对应的值（value）； items() 用于返回字典中所有的键值对（key-value）。 1234scores = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(scores.keys())print(scores.values())print(scores.items()) 运行结果： 123dict_keys([&#x27;数学&#x27;, &#x27;语文&#x27;, &#x27;英语&#x27;])dict_values([95, 89, 90])dict_items([(&#x27;数学&#x27;, 95), (&#x27;语文&#x27;, 89), (&#x27;英语&#x27;, 90)]) 要注意，keys()、values()和items()返回值类型分别为dic_keys、dict_values、dict_items而并不是列表list或元组tuple或集合set。这是因为Python并不希望我们用户能直接操作这几个方法的返回值。 为了能够使用这三个方法返回的数据进行操作，我们有以下几种方案，但是无一例外都是使用的新数据，而并没有操作原字典 数据，即操作并不会影响改变字典 1）使用list()函数，将他们返回的数据转换成列表 12345a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;b = list(a.keys())print(b)a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;b = list(a.keys())print(b) 运行结果： 1[&#x27;数学&#x27;, &#x27;语文&#x27;, &#x27;英语&#x27;] 2）使用for in 循环遍历他们的返回值 123456789a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;for k in a.keys(): print(k,end=&#x27; &#x27;)print(&quot; ---------------&quot;)for v in a.values(): print(v,end=&#x27; &#x27;)print(&quot; ---------------&quot;)for k,v in a.items(): print(&quot;key:&quot;,k,&quot; value:&quot;,v) 运行结果： 1234567数学 语文 英语---------------95 89 90---------------key: 数学 value: 95key: 语文 value: 89key: 英语 value: 90 copy()方法 copy()方法返回一个字典的拷贝，也即返回一个具有相同键值对的新字典 123a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1,2,3]&#125;b = a.copy()print(b) 运行结果： 1&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3]&#125; 但是我们要注意此时copy()方法只是浅拷贝，即只是对最表层的键值对进行了深拷贝，也就是说它会再申请一块内存用来存放&#123;'one':1,'two':2,'three':[]&#125;,而对于某些列表类型的值来说，此方法对其做的是浅拷贝，也就是说，b中的[1,2,3]的值不是自己独有的， 而是和a共有指向的统一内存单元。 12345678910a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1,2,3]&#125;b = a.copy()#向 a 中添加新键值对，由于b已经提前将 a 所有键值对都深拷贝过来，因此 a 添加新键值对，不会影响 b。a[&#x27;four&#x27;]=100print(a)print(b)#由于 b 和 a 共享[1,2,3]（浅拷贝），因此移除 a 中列表中的元素，也会影响 b。a[&#x27;three&#x27;].remove(1)print(a)print(b) 运行结果： 1234&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3], &#x27;four&#x27;: 100&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3]&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [2, 3], &#x27;four&#x27;: 100&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [2, 3]&#125; 从运行结果不难看出，对a增加新键值对，b不变；而修改a某键值对中列表内的元素，b也会相应改变。 update()方法 update()方法可以使用一个字典所包含的键值对来更新已有的字典。在执行update()方法时，如果被更新的字典已包含对应的键值对，那么value会被覆盖，如果被更新的字典中不包含对应的键值对，那么键值对被添加进去。 123a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125;a.update(&#123;&#x27;one&#x27;:4.5, &#x27;four&#x27;: 9.3&#125;)print(a) 运行结果： 1&#123;&#x27;one&#x27;: 4.5, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3, &#x27;four&#x27;: 9.3&#125; 从运行结果可以看出，由于被更新的字典已经包含key为&quot;one&quot;的键值对，因此更改时键值对的value被改写，而被更新的字典中不包含key为“four&quot;的键值对，所以更新时会为原字典增加一个新的键值对。 pop()和popitem(）方法 pop和popitem()都用来删除字典中的键值对，不同的是，pop()用来删除指定的键值对，而popitem()用来随机删除一个键值对，他们得语法格式如下： 12dictname.pop(key)dictname.popitem() 123456a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;化学&#x27;: 83, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;print(a)a.pop(&#x27;化学&#x27;)print(a)a.popitem()print(a) 运行结果： 123&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;化学&#x27;: 83, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;生物&#x27;: 98&#125; 思考：popitem()的底层原理？ 其实，说popitem()随机删除字典中的一个键值对是不准确的，虽然字典时一种无序的列表，但是键值对在底层也是有存储顺序的，popitem()总是弹出底层的最后一个key-value，这和列表的pop()方法类似，都实现了数据结构中的“出栈”的操作。 setdefault()方法 setdefault()方法用来返回字典中某个key对应的value值，但是他在返回前会进行以下操作： 如果该 key 存在，那么直接返回该 key 对应的 value； 如果该 key 不存在，那么先为该 key 设置默认的 defaultvalue（可以理解为插入了一个新的键值对，key-defaultvalue），然后再返回该 key 对应的 defaultvalue。 1234567891011a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(a)#key不存在，指定默认值a.setdefault(&#x27;物理&#x27;, 94)print(a)#key不存在，不指定默认值a.setdefault(&#x27;化学&#x27;)print(a)#key存在，指定默认值a.setdefault(&#x27;数学&#x27;, 100)print(a) 运行结果： 1234&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94, &#x27;化学&#x27;: None&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94, &#x27;化学&#x27;: None&#125; 我们发现由于前两次调用setdefault()时传入的键都是在字典中不存在的，因此会在字典中加入这个新的键值对，值就是defaultvalue可以自定义或者默认为None，但是如果穿入的键存在，那么后面的defaultvalue将没有任何作用，直接返还字典key对应的value值。 Python使用字典格式化字符串 之前我们学习过使用转换说明符来格式化输出字符串，比如： 123name=&quot;小明&quot;age = 8print(&quot;%s已经%d岁了！&quot; % (name,age)) 运行结果： 1小明已经8岁了！ 但是这是变量比较少的情况，如果变量非常多，那么此时我们再使用这种形式格式化字符串就变得异常麻烦，因此我们接下来学习使用字典来格式化字符串： 12345678 字符串模板中使用keytemp = &#x27;教程是:%(name)s, 价格是:%(price)010.2f, 出版社是:%(publish)s&#x27;book = &#123;&#x27;name&#x27;:&#x27;Python基础教程&#x27;, &#x27;price&#x27;: 99, &#x27;publish&#x27;: &#x27;C语言中文网&#x27;&#125;# 使用字典为字符串模板中的key传入值print(temp % book)book = &#123;&#x27;name&#x27;:&#x27;C语言小白变怪兽&#x27;, &#x27;price&#x27;:159, &#x27;publish&#x27;: &#x27;C语言中文网&#x27;&#125;# 使用字典为字符串模板中的key传入值print(temp % book) 运行结果： 12教程是:Python基础教程, 价格是:0000099.00, 出版社是:C语言中文网教程是:C语言小白变怪兽, 价格是:0000159.00, 出版社是:C语言中文网 要注意对应的键是写在百分号%和转换符字母之间的，比如%(price)010.2f表示的是此处输出的字典中price键对应的值价钱应为一个小数，并且最小宽度为10（不足就前面补0），同时保留两位小数。 Python set集合详解 Python中的集合，与数学中的和概念一致，用来保存不重复的元素，即集合中的元素都是唯一的，互不相同。从形式上看，和字典类似，Python集合会将所有元素放在一对大括号&#123;&#125;中，相邻元素使用逗号,分开 1&#123;element1,element2,...,elementn&#125; 集合可以存储无限多个元素。**从内容上看，集合只能存储不可变的数据类型，包括整型、浮点型、字符型、元组。但是无法存储列表、字典、集合这些可变的数据类型，否则Python解释器就会抛出TypeError错误。**比如说： 123456789101112131415&gt;&gt;&gt; &#123;&#123;&#x27;a&#x27;:1&#125;&#125;Traceback (most recent call last): File &quot;&lt;pyshell#8&gt;&quot;, line 1, in &lt;module&gt; &#123;&#123;&#x27;a&#x27;:1&#125;&#125;TypeError: unhashable type: &#x27;dict&#x27;&gt;&gt;&gt; &#123;[1,2,3]&#125;Traceback (most recent call last): File &quot;&lt;pyshell#9&gt;&quot;, line 1, in &lt;module&gt; &#123;[1,2,3]&#125;TypeError: unhashable type: &#x27;list&#x27;&gt;&gt;&gt; &#123;&#123;1,2,3&#125;&#125;Traceback (most recent call last): File &quot;&lt;pyshell#10&gt;&quot;, line 1, in &lt;module&gt; &#123;&#123;1,2,3&#125;&#125;TypeError: unhashable type: &#x27;set&#x27; 要注意集合中的元素是唯一的，对于重复出现的数据元素，只会保留一份 12&gt;&gt;&gt; &#123;1,2,1,(1,2,3),&#x27;c&#x27;,&#x27;c&#x27;&#125;&#123;1, 2, &#x27;c&#x27;, (1, 2, 3)&#125; 由于Python中的set集合是无序的，因此每一次输出元素的排列顺序都是不同的。 其实Python中有两种集合类型，一种是set类型的集合，另一种是frozenset类型的集合，他们的唯一区别就是set类型集合可以做添加、删除元素的操作，而frozenset类型集合不行。 Python创建set集合 Python提供了2种创建set集合的方法，分别是使用{}创建和使用set()函数将列表、元组等类型数据转换为集合。 1）使用{}创建集合 在Python中，创建set集合可以像列表、元素和字典一样，直接将集合赋值给变量，从而实现创建集合的目的，其语法格式如下： 1setname = &#123;element1,element2,...,elementn&#125; 其中，setname 表示集合的名称，起名时既要符合 Python 命名规范，也要避免与 Python 内置函数重名。 12a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;print(a) 运行结果： 1&#123;1, &#x27;c&#x27;, (1, 2, 3)&#125; 2）set()函数创建集合 set()函数为Python的内置函数，其功能是将字符串、列表、元组、range()对象等可迭代对象转换成集合，该函数的语法如下： 1setname = set(iteration) 其中，iteration 就表示字符串、列表、元组、range 对象等数据。 123456set1 = set(&quot;c.biancheng.net&quot;)set2 = set([1,2,3,4,5])set3 = set((1,2,3,4,5))print(&quot;set1:&quot;,set1)print(&quot;set2:&quot;,set2)print(&quot;set3:&quot;,set3) 运行结果： 123set1: &#123;&#x27;a&#x27;, &#x27;g&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;n&#x27;, &#x27;h&#x27;, &#x27;.&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;e&#x27;&#125;set2: &#123;1, 2, 3, 4, 5&#125;set3: &#123;1, 2, 3, 4, 5&#125; 注意如果要创建空集合，只能使用set()函数实现，因为直接使用一对{}，Python解释器会将其视为一个空字典。 Python访问set集合元素 由于集合中的元素是无序的，因此无法像列表那样使用下表索引来访问元素，Python中，访问集合元素最常用的方法就是使用循环结构，将集合的数据逐一读取出来。 123a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;for ele in a: print(ele,end=&#x27; &#x27;) 运行结果： 11 c (1, 2, 3) Python删除set集合 1234a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;print(a)del(a)print(a) 运行结果： 12345&#123;1, &#x27;c&#x27;, (1, 2, 3)&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(a)NameError: name &#x27;a&#x27; is not defined Python set集合基础操作 向set集合中添加元素 我们要注意，使用add()方法向set集合添加元素时，只能是数字，字符串，元组或者布尔类型，不能添加列表、元组或者集合这些可变的数据，否则Python解释器会报TypeError错误。 12345a = &#123;1,2,3&#125;a.add((1,2))print(a)a.add([1,2])print(a) 运行结果： 12345&#123;(1, 2), 1, 2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.add([1,2])TypeError: unhashable type: &#x27;list&#x27; 从set集合中删除元素 使用remove()可以删除集合中的元素，但是我们要注意如果被删除的元素不包含在集合中，那么这个方法会抛出KeyError错误，例如： 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.remove(1)print(a) 运行结果： 12345&#123;2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.remove(1)KeyError: 1 如果使用此方法删除集合中元素，需要注意的是，如果被删除的元素就不包含在集合中，那么此方法就会抛出KeyError异常，例如： 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.remove(1)print(a) 运行结果为： 12345&#123;2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.remove(1)KeyError: 1 为了避免这种报错，我们可以哈斯用discard()方法，此方法和remove()方法的用法完全相同，唯一的区别就是当删除集合中元素失败时，此方法不会抛出任何错误。 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.discard(1)print(a) 运行结果： 12&#123;2, 3&#125;&#123;2, 3&#125; Python set集合做交集、并集、差集运算 集合最常用的操作就是交集、并集、差集以及对称差集运算，如下所示： 我们可以使用如下代码实现不同的集合运算： 运算操作 Python运算符 含义 例子 交集 &amp; 取两集合公共的元素 &gt;&gt;&gt; set1 &amp; set2 {3} 并集 丨 取两集合全部的元素 &gt;&gt;&gt; set1 丨 set2 {1,2,3,4,5} 差集 - 取一个集合中另一集合没有的元素 &gt;&gt;&gt; set1 - set2 {1,2} &gt;&gt;&gt; set2 - set1 {4,5} 对称差集 ^ 取集合 A 和 B 中不属于 A&amp;B 的元素 &gt;&gt;&gt; set1 ^ set2 {1,2,4,5} Python set集合方法大全 这里我们给出C语言编程网的Python中集合函数大全方便查阅： set集合操作大全http://c.biancheng.net/view/4402.html Python frozenset set是一个可变序列，程序可以改变序列中的元素，而frozenset集合是不可变序列，程序是不能改变不可变序列中的元素的。set结合所支持的add()、remove()、discard()等方法frozenset一概不支持，而set中不改变集合本身的方法frozenset也支持。 我们在以下两种场景下会使用到frozenset，也正是这两个场景确立了frozenset的不可替代性： 当集合的元素不需要改变时，我们可以使用 fronzenset 替代 set，这样更加安全。 有时候程序要求必须是不可变对象，这个时候也要使用 fronzenset 替代 set。比如，字典（dict）的键（key）就要求是不可变对象。 一定要注意字典的键是不允许发生改变的，因此他不支持list,set这些可变序列数据类型的。 123456789s = &#123;&#x27;Python&#x27;, &#x27;C&#x27;, &#x27;C++&#x27;&#125;fs = frozenset([&#x27;Java&#x27;, &#x27;Shell&#x27;])s_sub = &#123;&#x27;PHP&#x27;, &#x27;C#&#x27;&#125;#向set集合中添加frozensets.add(fs)print(&#x27;s =&#x27;, s)#向为set集合添加子set集合s.add(s_sub)print(&#x27;s =&#x27;, s) 运行结果： 12345s = &#123;&#x27;Python&#x27;, frozenset(&#123;&#x27;Java&#x27;, &#x27;Shell&#x27;&#125;), &#x27;C&#x27;, &#x27;C++&#x27;&#125;Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 11, in &lt;module&gt; s.add(s_sub)TypeError: unhashable type: &#x27;set&#x27; 要注意，set集合本身的元素要求是不可变的，因此set的元素是不能为set的，即set集合不支持嵌套的，但是我们可以向set中加入frozenset的，因为他是不可变的集合类型。 深入底层了解Python字典和集合 在Python中字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作。我们首先拿列表介绍一下复杂度： 假设现在有一个存储产品信息（产品ID、名称和价格）的列表，现在的需求是，借助某件产品的ID找出其价格，则实现代码如下： 1234567891011def find_product_price(products, product_id): for id, price in products: if id == product_id: return price return Noneproducts = [ (111, 100), (222, 30), (333, 150)]print(&#x27;The price of product 222 is &#123;&#125;&#x27;.format(find_product_price(products, 222))) 运行结果： 1The price of product 222 is 30 如上查找列表时，如果列表有n个元素，因为查找的过程需要遍历列表，那么最坏的情况时间复杂度是O(n)。即使对列表进行了排序，再使用二分查找算法，也需要O(logn)的时间复杂度，更何况列表的排序还需要O(nlogn)的时间。 当如果用字典来存储这些数据，那么查找就会非常便捷高效，只需要O(1)的时间复杂度就可以完成，因为可以通过键的哈希值，找到对应的值，而不需要对字典做遍历操作，实现代码如下： 123456products = &#123; 111: 100, 222: 30, 333: 150&#125;print(&#x27;The price of product 222 is &#123;&#125;&#x27;.format(products[222])) 运行结果为： 1The price of product 222 is 30 如下是一个简单的列表查找和字典查找的速度对比，我们可以看到仅仅十万的数据量，两者的速度差异就如此之大： 123456789101112131415161718192021222324252627#统计时间需要用到 time 模块中的函数，了解即可import timedef find_unique_price_using_list(products): unique_price_list = [] for _, price in products: # A if price not in unique_price_list: #B unique_price_list.append(price) return len(unique_price_list)id = [x for x in range(0, 100000)]price = [x for x in range(200000, 300000)]products = list(zip(id, price))# 计算列表版本的时间start_using_list = time.perf_counter()find_unique_price_using_list(products)end_using_list = time.perf_counter()print(&quot;time elapse using list: &#123;&#125;&quot;.format(end_using_list - start_using_list))#使用集合完成同样的工作def find_unique_price_using_set(products): unique_price_set = set() for _, price in products: unique_price_set.add(price) return len(unique_price_set)# 计算集合版本的时间start_using_set = time.perf_counter()find_unique_price_using_set(products)end_using_set = time.perf_counter()print(&quot;time elapse using set: &#123;&#125;&quot;.format(end_using_set - start_using_set)) 运行结果： 12time elapse using list: 68.78650900000001time elapse using set: 0.010747099999989018 而往往企业的后台数据都有上亿乃至十亿数量级，因此如果使用了不合适的数据结构，很容易造成服务器的崩溃。因此字典和集合O(1)的复杂度可谓是相当快速了，加下来我们就了解一下他们的底层实现原理。 字典和集合的工作原理 字典和集合能如此高效，和他们的数据结构密不可分，不同于其他数据结构，字典和集合内部结构都是一张哈希表： 对于字典而言，这张表存储了哈希值（hash）、键和值这 3 个元素。 而对集合来说，哈希表内只存储单一的元素。 对于之前版本的Python，他的哈希结构如下： 12345678 | 哈希值 (hash) 键 (key) 值 (value). | ...0 | hash0 key0 value0. | ...1 | hash1 key1 value1. | ...2 | hash2 key2 value2. | ... 但是我们发现这种结构的弊端，是随着哈希表的扩张，他会变得越来越稀疏，比如有这样一个字典： 1&#123;&#x27;name&#x27;: &#x27;mike&#x27;, &#x27;dob&#x27;: &#x27;1999-01-01&#x27;, &#x27;gender&#x27;: &#x27;male&#x27;&#125; 那么他会存储为如下结构： 123456789entries = [[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;][-230273521, &#x27;dob&#x27;, &#x27;1999-01-01&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[1231236123, &#x27;name&#x27;, &#x27;mike&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[9371539127, &#x27;gender&#x27;, &#x27;male&#x27;]] 三个键值对数据却需要哈希表开辟7个空间，显然非常浪费存储空间，为了提高存储空间的利用率，现在的哈希表除了字典本身的结构，会把索引和哈希值、键、值单独分开，也就是采用如下这种结构： 12345678910111213141516Indices----------------------------------------------------None | index | None | None | index | None | index ...----------------------------------------------------Entries--------------------hash0 key0 value0---------------------hash1 key1 value1---------------------hash2 key2 value2--------------------- ...--------------------- 这和数据结构中的索引表建立类似，此时哈希表内键哈希值不同的键值对存储到了相邻的存储单元，而我们使用indices来表示哈希表内的关系，这样就节省了大量的空间。因此此时上面的字典在新哈希表结构下的存储形式为： 123456indices = [None, 1, None, None, 0, None, 2]entries = [[1231236123, &#x27;name&#x27;, &#x27;mike&#x27;],[-230273521, &#x27;dob&#x27;, &#x27;1999-01-01&#x27;],[9371539127, &#x27;gender&#x27;, &#x27;male&#x27;]] 哈希表插入数据 当我们向字典中插入数据时，Python会首先根据键(key)计算出对应的哈希值（通过hash(key)函数计算)，而向集合中插入数据时，Python会根据元素本身计算对应的哈希值（通过hash(values)函数计算)。 1234dic = &#123;&quot;name&quot;:1&#125;print(hash(&quot;name&quot;))setDemo = &#123;1&#125;print(hash(1)) 运行结果： 1282301150420083146831 得到哈希值（例如hash)之后，再结合字典或集合要存储数据的个数（例如n),就可以得到该元素应该插入到哈希表中的位置（比如,可以用hash%n的方式) 如果哈希表中此位置是空的，那么此元素可以直接插入其中，反之如果此位置已经被其他元素占用，那么Python会比较这两个元素的哈希值和键是否相等： 如果相等，则表明该元素已经存在，再比较他们的值，不相等就进行更新； 如果不相等，这种情况称为哈希冲突（即两个元素的键不同，但求得的哈希值相同）。这种情况下，Python 会使用开放定址法、再哈希法等继续寻找哈希表中空余的位置，直到找到位置。 哈希表查找数据 在哈希表中查找数据，和插入操作类似，Python 会根据哈希值，找到该元素应该存储到哈希表中的位置，然后和该位置的元素比较其哈希值和键（集合直接比较元素值）： 如果相等，则证明找到； 反之，则证明当初存储该元素时，遇到了哈希冲突，需要继续使用当初解决哈希冲突的方法进行查找，直到找到该元素或者找到空位为止。 这里的空位，表示哈希表没有存储目标元素 哈希表删除元素 对于删除操作，Python会暂时对这个位置的元素赋予一个特殊的值，等到重新调整哈希表的大小时，再将其删除。 需要注意的是，哈希冲突的发生往往会降低字典和集合操作的速度。因此，为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有 1/3 的剩余空间。随着元素的不停插入，当剩余空间小于 1/3 时，Python 会重新获取更大的内存空间，扩充哈希表，与此同时，表内所有的元素位置都会被重新排放。 虽然哈希冲突和哈希表大小的调整，都会导致速度减缓，但是这种情况发生的次数极少。所以，平均情况下，仍能保证插入、查找和删除的时间复杂度为 O(1)。 Python深拷贝和浅拷贝详解 Python浅拷贝 常见的浅拷贝方法，是使用数据类型本身的构造器，比如下面两个例子： 12345678910list1 = [1, 2, 3]list2 = list(list1)print(list2)print(&quot;list1==list2 ?&quot;,list1==list2)print(&quot;list1 is list2 ?&quot;,list1 is list2)set1= set([1, 2, 3])set2 = set(set1)print(set2)print(&quot;set1==set2 ?&quot;,set1==set2)print(&quot;set1 is set2 ?&quot;,set1 is set2) 运行结果： 123456[1, 2, 3]list1==list2 ? Truelist1 is list2 ? False&#123;1, 2, 3&#125;set1==set2 ? Trueset1 is set2 ? False 在上面程序中，list2就是list1的浅拷贝，同理set2是set1的浅拷贝。当然，对于可变的序列，还可以通过切片操作符:来完成浅拷贝，例如： 12345list1 = [1, 2, 3]list2 = list1[:]print(list2)print(&quot;list1 == list2 ?&quot;,list1 == list2)print(&quot;list1 is list2 ?&quot;,list1 is list2) 运行结果： 123[1, 2, 3]list1 == list2 ? Truelist1 is list2 ? False 除此之外，Python 还提供了对应的函数 copy.copy() 函数，适用于任何数据类型。其用法如下： 123456import copylist1 = [1, 2, 3]list2 = copy.copy(list1)print(list2)print(&quot;list1 == list2 ?&quot;,list1 == list2)print(&quot;list1 is list2 ?&quot;,list1 is list2) 运行结果： 123[1, 2, 3]list1 == list2 ? Truelist1 is list2 ? False 不过要注意的是，对于元组，使用tuple()或者切片操作符:不会创建一个浅拷贝，相反他会创建一个指向相同元组的引用： 12345tuple1 = (1, 2, 3)tuple2 = tuple(tuple1)print(tuple2)print(&quot;tuple1 == tuple2 ?&quot;,tuple1 == tuple2)print(&quot;tuple1 is tuple2 ?&quot;,tuple1 is tuple2) 运行结果： 1231, 2, 3)tuple1 == tuple2 ? Truetuple1 is tuple2 ? True 此程序中，元组 (1, 2, 3) 只被创建一次，t1 和 t2 同时指向这个元组。 思考：什么时候构造器和切片返还的是引用？什么时候是新数据？ 这里有一个规律，就是凡是可变数据类型，那么构造器或者切片返还的就是一个新的浅拷贝数据；凡是不可变数据类型，那么构造器或者切片返还的就是一个指向原内存单元的引用 以下是验证，我们发现对于string还是frozenset最终返还的都是引用，而dict就是一个新的拷贝数据 12345678910111213&gt;&gt;&gt; s1=&quot;hello&quot;&gt;&gt;&gt; s2=s1[:]&gt;&gt;&gt; print(s2 is s1)True# frozenset不能切片，因此使用构造器&gt;&gt;&gt; fs1=frozenset([1,2,3])&gt;&gt;&gt; fs2=frozenset(fs1)&gt;&gt;&gt; print(fs2 is fs1)True# 字典不能切片，因此也使用构造器&gt;&gt;&gt; d1=&#123;&#x27;name&#x27;:&#x27;langwenchong&#x27;,&#x27;age&#x27;:20&#125;&gt;&gt;&gt; d2=dict(d1)&gt;&gt;&gt; print(d2 is d1) 思考：那么怎样才能让到d2和d1指向同一地址呢？ 很简单使用赋值即可，毕竟d1本身就是一个指向内存单元的指针： 123&gt;&gt;&gt; d2=d1&gt;&gt;&gt; print(d2 is d1)True 看到这里，也许你可能对浅拷贝有了初步的认识。浅拷贝，指的是重新分配一块内存，创建一个新的对象，但里面的元素是原对象中各个子对象的引用。 对数据采用浅拷贝的方式时，如果原对象中的元素不可变，那倒无所谓；但如果元素可变，浅拷贝通常会出现一些问题，例如： 1234567891011list1 = [[1, 2], (30, 40)]list2 = list(list1)list1.append(100)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[0].append(3)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[1] += (50, 60)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2) 运行结果为： 123456list1: [[1, 2], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40), 100]list2: [[1, 2, 3], (30, 40)]list1: [[1, 2, 3], (30, 40, 50, 60), 100]list2: [[1, 2, 3], (30, 40)] 再来看，list1[0].append(3) 表示对 list1 中的第一个列表新增元素 3。因为 list2 是 list1 的浅拷贝，list2 中的第一个元素和 list1 中的第一个元素，共同指向同一个列表，因此 list2 中的第一个列表也会相对应的新增元素 3。 最后是 list1[1] += (50, 60)，因为元组是不可变的，这里表示对 list1 中的第二个元组拼接，然后重新创建了一个新元组作为 list1 中的第二个元素，而 list2 中没有引用新元组，因此 list2 并不受影响。 通过这个例子，你可以很清楚地看到使用浅拷贝可能带来的副作用。如果想避免这种副作用，完整地拷贝一个对象，就需要使用深拷贝。所谓深拷贝，是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。 Python深拷贝 Python 中以 copy.deepcopy() 来实现对象的深度拷贝。比如上述例子写成下面的形式，就是深度拷贝： 123456789101112import copylist1 = [[1, 2], (30, 40)]list2 = copy.deepcopy(list1)list1.append(100)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[0].append(3)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[1] += (50, 60)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2) 运行结果： 123456list1: [[1, 2], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40, 50, 60), 100]list2: [[1, 2], (30, 40)] 不过，深度拷贝也不是完美的，往往也会带来一系列问题。如果被拷贝对象中存在指向自身的引用，那么程序很容易陷入无限循环，例如： 123456import copylist1 = [1]list1.append(list1)print(list1)list2 = copy.deepcopy(list1)print(list2) 运行结果为： 12[1, [...]][1, [...]] 此例子中，列表 x 中有指向自身的引用，因此 x 是一个无限嵌套的列表。但是当深度拷贝 x 到 y 后，程序并没有出现栈溢出的现象。这是为什么呢？ 其实，这是因为深度拷贝函数 deepcopy 中会维护一个字典，记录已经拷贝的对象与其 ID。拷贝过程中，如果字典里已经存储了将要拷贝的对象，则会从字典直接返回。通过查看 deepcopy 函数实现的源码就会明白： 12345678910111213def deepcopy(x, memo=None, _nil=[]): &quot;&quot;&quot;Deep copy operation on arbitrary Python objects. See the module&#x27;s __doc__ string for more info. &quot;&quot;&quot; if memo is None: memo = &#123;&#125; d = id(x) # 查询被拷贝对象 x 的 id y = memo.get(d, _nil) # 查询字典里是否已经存储了该对象 if y is not _nil: return y # 如果字典里已经存储了将要拷贝的对象，则直接返回 ..."},{"title":"变量类型和运算符","path":"/wiki/Python学习笔记/变量类型和运算符/index.html","content":"Python整数类型(int)详解 数值范围 对于弱类型语言python，整数的范围是无限大，他不会区分byte,int,long等等，只要是整数统一使用int来表示，当使用的数值超过计算机自身的计算能力时，python就会自动转用高精度进行计算（大数计算） 1234567891011121314#将 78 赋值给变量 nn = 78print(n)print( type(n) )#给x赋值一个很大的整数x = 8888888888888888888888print(x)print( type(x) )#给y赋值一个很小的整数y = -7777777777777777777777print(y)print( type(y) ) 以上的所有数字最终的type打印出来的类型都是int，即python不会发生数值溢出，具有非常强大的整数处理能力，但是要注意python2.x是会区分int、long的类型的。 整数的不同进制 十进制形式：0~9组成，开头不能是0 二进制形式：书写时以0b或者0B作为开头，同时数字只能由0和1组成，比如0B101对应的就是十进制的5 八进制形式：首先是0o或者0O开头，数字范围为0~7,同时要注意在Python2.x中八进制数字还可以以0开头表示 十六进制形式：以0x或者0X开头，后面数字0~9，同时还可以使用字母A-F或者a-f表示 1234567891011121314151617#十六进制hex1 = 0x45hex2 = 0x4Afprint(&quot;hex1Value: &quot;, hex1)print(&quot;hex2Value: &quot;, hex2)#二进制bin1 = 0b101print(&#x27;bin1Value: &#x27;, bin1)bin2 = 0B110print(&#x27;bin2Value: &#x27;, bin2)#八进制oct1 = 0o26print(&#x27;oct1Value: &#x27;, oct1)oct2 = 0O41print(&#x27;oct2Value: &#x27;, oct2) 运行结果： 123456hex1Value: 69hex2Value: 1199bin1Value: 5bin2Value: 6oct1Value: 22oct2Value: 33 同时Python中为了提高数字的可读性，允许对数字使用_进行分割，比如348000000可以表示为348_000_000，一般是隔三个数字进行一次划分。 Python小数/浮点数(float)类型详解 Python浮点数就是float类型，没有double双精度类型，他有如下两种写法 十进制形式 这个就是我们平常总是使用的形式，比如34.6、34.60等等，书写时必须包含一个小数点从而和整数进行区分 指数形式 Python中指数形式的写法就和科学计数法类似，形式为: 1aEn或者aen a是尾数部分，是一个十进制数（可以是整数或者小数），n是指数部分，必须是一个十进制整数，E或者e是固定的字符，用于分割尾数部分和指数部分，整个表达式计算公式为 a×10na×10^n a×10n 例如以下形式： 2.1E5 = 2.1×105，其中 2.1 是尾数，5 是指数。 3.7E-2 = 3.7×10-2，其中 3.7 是尾数，-2 是指数。 0.5E7 = 0.5×107，其中 0.5 是尾数，7 是指数。 要注意只要写成了指数形式就一定是小数，即使此时他的值看起来像一个整数，比如14E3等价于14000，但是实际上此时14E3也是小数而非整数 Python复数类型(complex)类型详解 在Python中还内置了复数类型，直接书写即可，复数由实部和虚部两部分组成，因此在python中写法如下： 1a+bj a表示实部，b表示虚部 12345678910c1 = 12 + 0.2jprint(&quot;c1Value: &quot;, c1)print(&quot;c1Type&quot;, type(c1))c2 = 6 - 1.2jprint(&quot;c2Value: &quot;, c2)#对复数进行简单计算print(&quot;c1+c2: &quot;, c1+c2)print(&quot;c1*c2: &quot;, c1*c2) 运行结果： 12345c1Value: (12+0.2j)c1Type &lt;class &#x27;complex&#x27;&gt;c2Value: (6-1.2j)c1+c2: (18-1j)c1*c2: (72.24-13.2j) Python字符串(string)详解 首先我们要知道在Python中字符串可以看成是若干个字符组成的列表，因此他支持len()统计长度，使用索引进行获取指定位置字符等方法。Python中字符串必须使用双引号&quot;&quot;或者单引号''包裹。 处理字符串中的引号 对于本身就包含双引号&quot;或者单引号'的字符串，此时我们需要对其进行处理，我们这里以I'm a great coder为例，此时我们需要使用如下两种方法正确表示这个字符串： 对引号进行转义 如果此时我们就要使用单引号对这个字符串进行包裹，那么我们需要对字符串内部的单引号进行转义，使用符号\\对其进行转义即可 12str1 = &#x27;I\\&#x27;m a great coder!&#x27;str2 = &quot;引文双引号是\\&quot;，中文双引号是“&quot; 使用不同的引号包围字符串 也可以此时外部使用不同的双引号包裹即可： 12str1 = &quot;I&#x27;m a great coder!&quot; #使用双引号包围含有单引号的字符串str2 = &#x27;引文双引号是&quot;，中文双引号是“&#x27; #使用单引号包围含有双引号的字符串 但是假设此时这个字符串内部同时包含有单引号和双引号，那么没有办法只能使用\\对特殊的符号进行转义了 字符串的换行 我们只需要在需要换行处末尾添加一个反斜杠\\既可以换行继续书写字符串如下，同时也可以对过长的表达式进行换行： 1234567#长字符串进行换行书写s2 = &#x27;It took me six months to write this Python tutorial. \\ Please give me more support. \\ I will keep it updated.&#x27;#长表达式进行换行书写num = 20 + 3 / 4 + \\ 2 * 3 长字符串 我们之前也了解过在Python有两种书写代码注释的方法： 12345678#单行注释&quot;&quot;&quot;多行注释&quot;&quot;&quot;&#x27;&#x27;&#x27;多行注释&#x27;&#x27;&#x27; 但是实际上三个单引号或者三个双引号自身就是长字符串，也就是说三个单引号或者三个双引号包围的字符串会默认支持换行书写，同时在其内部在放置单引号或者双引号也是不会出现解析错误的，因此无需对其进行转义，当这个长字符串没有赋值给任何一个变量时，那么这个长字符串就是一个不会对代码程序本身起到任何影响的事物，因此他可以用来书写注释，那么换句话说也就是它本身实际上是可以被当成字符串赋值给一个变量进行存储的如下： 123456longstr = &#x27;&#x27;&#x27; It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.&#x27;&#x27;&#x27;print(longstr) 运行结果： 12345#注意这里是有一个空行的It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.#这里也会有一个空行 但是我们会发现对于长字符串，他会自动存储换行、空格、缩进等内容，因此对于上面的代码我们如果想去掉空行需要写为： 1234longstr = &#x27;&#x27;&#x27;It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.&#x27;&#x27;&#x27;print(longstr) Python原始字符串 由于反斜杠\\本身具有转义的意义，那么假如我们希望写一些包含反斜杠的字符串（最常见的即使文件路径）时就需要特别注意需要对反斜杠进行转义从而取消其自身本身的转义功能，那么写起来就会非常麻烦如下： 假设此时我们要写一个Windows路径D:\\Program Files\\Python 3.8\\python.exe,那么为了避免反斜杠转义对路径的影响，我们需要对路径中的每一个反斜杠进行转义因此应该写为:D:\\\\Program Files\\\\Python 3.8\\\\python.exe。 但是这样写太麻烦了，因此Python支持原始字符串，即默认字符串中的每一个反斜杠\\都是会原封不动的保留(即使此时他发挥转义的作用），所有内容都保持原汁原味的样子，写法只需要在开头加上r即可： 123str1 = r&#x27;原始字符串内容&#x27;str2 = r&quot;&quot;&quot;原始字符串内容&quot;&quot;&quot;rstr = r&#x27;D:\\Program Files\\Python 3.8\\python.exe&#x27; 一定要注意原始字符串中的反斜杠还是会起到转义的作用，但是不同的是此时反斜杠也会被保留显示出来 假设此时我们对单引号包裹的原始字符串I'm a great coder进行转义，很明显需要在'前加上反斜杠，但是这个反斜杠也会保留显示如下： 12str1 = r&#x27;I\\&#x27;m a great coder!&#x27;print(str1) 运行结果： 1I\\&#x27;m a great coder! 正是由于斜杆转义这个特性，我们一定要注意字符串的结尾处不能是反斜杠，否则字符串结尾处的引号将会被转义，导致字符串不能正常结束。 思考：D:\\Program Files\\Python 3.8\\怎么表示？ 那么此时上面的这种以反斜杠结尾的路径我们该怎么样表示呢？有两种方法： 方法一：直接使用\\\\进行结尾即可 很简单我们对结尾的\\进行转义即可，如下所示： 1print(&#x27;D:\\\\Program Files\\\\Python 3.8\\\\&#x27;) 方法二：拼接字符串 但是上面的写法中我们需要对每一个反斜杠都进行一次转义太麻烦了，为了方便我们肯定是会用到原始字符串来写的，但是此时如果结尾是\\\\就会保留显示出两个反斜杠，但是又不能只写一个反斜杠，此时我们就可以使用字符串拼接的方法： 123str1 = r&#x27;D:\\Program Files\\Python 3.8&#x27; &#x27;\\\\&#x27;str1 = r&#x27;D:\\Program Files\\Python 3.8&#x27; + &#x27;\\\\&#x27;print(str1) 前半部分使用原始字符串书写，结尾的反斜杠再使用字符串双反斜杠书写，这样即可简便的完成需求，同时我们注意到了python会自动将相邻的字符串进行拼接，即中间的+写不写都可以。 Python bytes Python中bytes用来表示一个字节串，他和字符串很类似，但是又有区别： 字符串是由若干个字符组成的，以字符为单位进行操作，但是字节串是由若干个字节组成的，以字节为单位进行操作 字节串和字符串除了操作的数据单元不同之外，它们支持的所有方法基本相同 字节串和字符串都是不可变序列，不能随意增加和删除数据，一般的操作都仅仅是生成一个新的字节串或者字符串，并不会修改其自身 bytes的最大特点就是他只负责以字节序列的形式（二进制形式）存储数据，这些数据到底表示什么完全由程序的解析方式决定，如果采用合适的字符编码方式（字符集），字节串可以恢复成字符串，反之亦然，字符串也可以转换成字节串。 说白了，bytes 只是简单地记录内存中的原始数据，至于如何使用这些数据，bytes 并不在意，你想怎么使用就怎么使用，bytes 并不约束你的行为。 字符串和 bytes 存在着千丝万缕的联系，我们可以通过字符串来创建 bytes 对象，或者说将字符串转换成 bytes 对象。有以下三种方法可以达到这个目的： 如果字符串的内容都是 ASCII 字符，那么直接在字符串前面添加b前缀就可以转换成 bytes。 bytes 是一个类，调用它的构造方法，也就是 bytes()，可以将字符串按照指定的字符集转换成 bytes；如果不指定字符集，那么默认采用 UTF-8。 字符串本身有一个 encode() 方法，该方法专门用来将字符串按照指定的字符集转换成对应的字节串；如果不指定字符集，那么默认采用 UTF-8。 123456789101112131415161718#通过构造函数创建空 bytesb1 = bytes()#通过空字符串创建空 bytesb2 = b&#x27;&#x27;#通过b前缀将字符串转换成 bytesb3 = b&#x27;http://c.biancheng.net/python/&#x27;print(&quot;b3: &quot;, b3)print(b3[3])print(b3[7:22])#为 bytes() 方法指定字符集b4 = bytes(&#x27;C语言中文网8岁了&#x27;, encoding=&#x27;UTF-8&#x27;)print(&quot;b4: &quot;, b4)#通过 encode() 方法将字符串转换成 bytesb5 = &quot;C语言中文网8岁了&quot;.encode(&#x27;UTF-8&#x27;)print(&quot;b5: &quot;, b5) 运行结果： 12345b3: b&#x27;http://c.biancheng.net/python/&#x27;112b&#x27;c.biancheng.net&#x27;b4: b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x918\\xe5\\xb2\\x81\\xe4\\xba\\x86&#x27;b5: b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x918\\xe5\\xb2\\x81\\xe4\\xba\\x86&#x27; 我们仔细观察b3的三个输出结果，可以发现字节串和字符串的区别，对于字符串获取的是返还的字符，**但是对于字节串，获取的是指定数据的ASCII，这个特性可以帮助我们获取任意一个字符的ASCII。**假设此时我们需要知道B的ASCII，我们不需要查询ASCII表，只需要在Python终端中输入print(b'B'[0])即可获知： 12&gt;&gt;&gt; print(b&#x27;B&#x27;[0])66 Python布尔(bool)类型详解 Python中使用True和False来表示真假，同时True相当于整数值1，False相当于整数值0，因此下面运算是可以的： 1234&gt;&gt;&gt; False+11&gt;&gt;&gt; True+12 Python input()函数 input()是Python的内置函数，用来从控制天获取用户输入的内容。Input()函数总是以字符串的形式来处理用户输入的内容，所以用户输入的内容可以包含任意字符串。 1str=input(tipmsg) str表示一个字符串类型的变量，input会将读取到的字符串放入str中 tipmsg表示提示信息，他会显示在控制台上，告诉用户应该输入什么样的内容，如果不写tipmsg那么就不会有任何的提示信息 123456789a = input(&quot;Enter a number: &quot;)b = input(&quot;Enter another number: &quot;)print(&quot;aType: &quot;, type(a))print(&quot;bType: &quot;, type(b))result = a + bprint(&quot;resultValue: &quot;, result)print(&quot;resultType: &quot;, type(result)) 运行结果： 123456Enter a number: 100↙Enter another number: 45↙aType: &lt;class &#x27;str&#x27;&gt;bType: &lt;class &#x27;str&#x27;&gt;resultValue: 10045resultType: &lt;class &#x27;str&#x27;&gt; ↙表示按下回车键，按下回车键后 input() 读取就结束了。但是我们发现上面的代码我们是想计算输入的a和b的和，但是由于输入的内容会被当做字符串类型，因此最终变成了字符串的拼接，为了解决这个问题，我们首先需要将a和b输入内容转成整数类型，此时我们会使用如下一些类似的强转类型函数： int(string) 将字符串转换成 int 类型； float(string) 将字符串转换成 float 类型； bool(string) 将字符串转换成 bool 类型。 Python print()函数高级用法 之前我们使用print()函数都只是输出显示单个内容变量，但是实际上print()函数完全可以同时输出多个变量，而且他具有更复杂丰富的功能。 1print (value,...,sep=&#x27;&#x27;,end=&#x27; &#x27;,file=sys.stdout,flush=False) value参数可以接收任意多个变量的值，不同的变量之间使用,进行分割，因此print()可以输出多个值： 1234user_name ＝ &#x27;Charlie&#x27;user_age = 8#同时输出多个变量和字符串print(&quot;读者名：&quot;,user_name,&quot;年龄：&quot;,user_age) 运行结果： 1读者名： Charlie 年龄： 8 从上面的输出结果我们不难看出print()输出多个变量时，会默认使用空格进行分隔，如果希望手动设定分隔符，需要修改sep参数： 12#同时输出多个变量和字符串，指定分隔符print(&quot;读者名：&quot; ,user_name,&quot;年龄：&quot;,user_age,sep=&#x27;|&#x27;) 运行结果： 1读者名：|Charlie|年龄：|8 同时我们还发现print()默认输出结束会进行换行，这是因为print()的end参数的默认值是 因此他总是会在输出结果后面加上一个换行符，如果我们要手动设定，只需要修改end参数即可： 1234#设置end 参数，指定输出之后不再换行print(40,&#x27;\\t&#x27;,end＝&quot;&quot;)print(5O,&#x27;\\t&#x27;,end＝&quot;&quot;)print(60,&#x27;\\t&#x27;,end＝&quot;&quot;) 运行结果： 140 50 60 同时file指定了输入的地方，默认是sys.stdout即控制台因此会将变量的内容打印在控制台上，我们也可以修改它为指定文件，这样内容将会打印到文件中： 1234f = open(&quot;demo.txt&quot;,&quot;w&quot;)#打开文件以便写入print(&#x27;沧海月明珠有泪&#x27;,file=f)print(&#x27;蓝回日暖玉生烟&#x27;,file=f)f.close() 上面的代码中，open()函数用于打开demo.txt文件，同时权限为w写入权限，此时即使没有这个文件也会自动创建，然后写入两句话再关闭这个文件输入流，这样我们就将这句诗输出到了demo.txt文件中了 print()的flush参数用于控制输出缓存，改参数一般设置为False，这样可以获得更好的性能。 Python格式化输出字符串 转换说明符 和C类似，Python也可以对要输出的变量的内容进行格式化，在print()中使用%开头的转换说明符对各种类型的数据进行格式化输出，具体参考下表：、 转换说明符 解释 %d,%i 转换为带符号的十进制整数 %o 转换为带符号的八进制整数 %x,%X 转换为带符号的十六进制正式 %e 转换为科学计数法表示的浮点数（e小写） %E 转换为科学计数法表示的浮点数（E大写） %f,%F 转换为十进制浮点数 %g 智能选择使用%f或者%e格式 %G 智能选择使用%F或者%E格式 %c 格式化字符及其ASCII码 %r 使用repr()函数将表达式转换为字符串 %s 使用str()函数将表达式转换为字符串 要注意转换说明符只是一个占位符，他会被后面表达式（变量，常量，数字，字符串，加减乘除等各种形式）的值代替。 123name=&quot;小明&quot;age = 8print(&quot;%s已经%d岁了！&quot; % (name,age)) 运行结果： 1小明已经8岁了！ 指定最小输出宽度 有时候我们需要指定格式化的输出内容占用的最少宽度即最小输出宽度（至少占用多少个字符的位置）： %10d 表示输出的整数宽度至少为 10； %20s 表示输出的字符串宽度至少为 20。 123n = 1234567print(&quot;n(10):%10d.&quot; % n)print(&quot;n(5):%5d.&quot; % n) 运行结果： 12n(10): 1234567.n(5):1234567. 可以看出对于整数和字符串，当数据的实际宽度小于指定宽度时，会在左侧以空格填充补齐，当数据的实际宽度大于指定宽度时，会按照数据的实际宽度输出，因此他只会限制最小宽度，当数据的实际宽度够宽时指定宽度就没有任何意义了。 指定对齐方式 也就是说默认情况下，print()的数据对齐方式是右对齐的，当数据宽度不够宽时，数据总是靠右侧，左侧不足的地方用空格进行填充，但是我们有时候需要指定的对齐方式，此时我们就可以使用如下标志进行指定： 标志 说明 - 指定左对齐 + 表示输出的数字要带着符号，正式带+，负数带- 0 表示宽度不足时补充0，而不是补充空格 几点说明： 对于整数，指定左对齐时，在右边补 0 是没有效果的，因为这样会改变整数的值。 对于小数，以上三个标志可以同时存在。 对于字符串，只能使用-标志，因为符号对于字符串没有意义，而补 0 会改变字符串的值。 12345678910111213n = 123456# %09d 表示最小宽度为9，左边补0print(&quot;n(09):%09d&quot; % n)# %+9d 表示最小宽度为9，带上符号print(&quot;n(+9):%+9d&quot; % n)f = 140.5# %-+010f 表示最小宽度为10，左对齐，带上符号print(&quot;f(-+0):%-+010f&quot; % f)s = &quot;Hello&quot;# %-10s 表示最小宽度为10，左对齐print(&quot;s(-10):%-10s.&quot; % s) 运行结果： 1234n(09):000123456n(+9): +123456f(-+0):+140.500000s(-10):Hello . 指定小数精度 对于小数（浮点数），print()还允许指定小数点的数字位数，也即指定小数的输出精度。精度值需要放在最小宽度以后，中间用.隔开，也可以不写最小宽度，只写精度，具体格式如下： 12%m.nf%.nf m表示最小宽度，n表示输出精度，.是必须存在的。 1234567f = 3.141592653# 最小宽度为8，小数点后保留3位print(&quot;%8.3f&quot; % f)# 最小宽度为8，小数点后保留3位，左边补0print(&quot;%08.3f&quot; % f)# 最小宽度为8，小数点后保留3位，左边补0，带符号print(&quot;%+08.3f&quot; % f) 运行结果： 123 3.1420003.142+003.142 Python转义字符 ASCII编码为每一个字符都分配了唯一的编号，称为编码值。在Python中，一个ASCII字符除了可以使用它的实体（也就是真正的字符）表示，还可以使用它的编码表示值。这种使用编码值来间接的表示字符的方式称为转义字符。 转义字符以\\0或者\\x开头，当转义字符以\\0开头表示后面跟的是八进制形式的编码值，以\\x开头表示后面跟十六进制形式的编码值，Python中转义字符只能使用八进制或者十六进制。 ASCII编码共收录了128个字符，而\\0和\\x后面最多只能跟两位数字，所以八进制形式\\0并不能表示所有ASCII字符，只有十六进制\\x可以表示所有ASCII字符。 字符 1、2、3、x、y、z 对应的 ASCII 码的八进制形式分别是 61、62、63、170、171、172，十六进制形式分别是 31、32、33、78、79、7A。下面的例子演示了转义字符的用法： 1234str1 = &quot;Oct: \\061\\062\\063&quot;str2 = &quot;Hex: \\x31\\x32\\x33\\x78\\x79\\x7A&quot;print(str1)print(str2) 运行结果： 12Oct: 123Hex: 123xyz 要注意使用八进制的转义字符是不能表示xyz的，因为他们的编码值都转换成八进制以后有三位。 对于ASCII编码，0~31（十进制）范围内的字符是控制字符，他们都是看不见的，不能在显示器上显示，甚至无法从键盘输入，只能使用转义字符的形式来表示，不过，直接使用ASCII编码记忆不方便，也不容易理解，因此针对常用的控制字符，我们有简写方式如下： 转义字符 说明 换行符，将光标位置移到下一行开头 \\r 回车符，将光标位置移到本行开头 \\t 水平制表符，也即Tab键，一般相当于四个空格 \\ 在字符串行尾的续行符，即一行未完，转到下一行继续写。 \\b 退格（Backspace），将光标位置移到前一列。 \\\\ 反斜线 \\’ 单引号 \\\\&quot; 双引号 虽然转义字符书写形式上由多个字符组成，但是Python将他们看成是一个整体，表示一个字符。 1234567#使用\\t排版str1 = &#x27;网站\\t\\t域名\\t\\t\\t年龄\\t\\t价值&#x27;str2 = &#x27;C语言中文网\\tc.biancheng.net\\t\\t8\\t\\t500W&#x27;str3 = &#x27;百度\\t\\twww.baidu.com\\t\\t20\\t\\t500000W&#x27;print(str1)print(str2)print(str3) 运行结果： 123网站 域名 年龄 价值C语言中文网 c.biancheng.net 8 500W百度 www.baidu.com 20 500000W Python数据类型转换 假设我们现在要输入一句话是“您的身高+身高值”，此时身高值是小数类型，那么如下写法是错误的： 123456&gt;&gt;&gt; height = 70.0&gt;&gt;&gt; print(&quot;您的身高&quot;+height)Traceback (most recent call last): File &quot;&lt;pyshell#1&gt;&quot;, line 1, in &lt;module&gt; print(&quot;您的身高&quot;+height)TypeError: must be str, not float 解释器提示我们字符串和浮点数类型变量不能直接相连，需要将浮点数类型变量height转换为字符串类型才可以。此时我们就需要使用类型转换函数了如下所示： 函 数 作 用 int(x) 将 x 转换成整数类型 float(x) 将 x 转换成浮点数类型 complex(real，[,imag]) 创建一个复数 str(x) 将 x 转换为字符串 repr(x) 将 x 转换为表达式字符串 eval(str) 计算在字符串中的有效 Python 表达式，并返回一个对象 chr(x) 将整数 x 转换为一个字符 ord(x) 将一个字符 x 转换为它对应的整数值 hex(x) 将一个整数 x 转换为一个十六进制字符串 oct(x) 将一个整数 x 转换为一个八进制的字符串 思考：除了使用类型转换还能怎样输出？ 其实很简单，使用我们之前提到的格式化输出即可，如下所示： 1234567&gt;&gt;&gt; height=185.0&gt;&gt;&gt; print(&#x27;你的身高是%g&#x27; % height)你的身高是185&gt;&gt;&gt; print(&#x27;你的身高是%f&#x27; % height)你的身高是185.000000&gt;&gt;&gt; print(&#x27;你的身高是%.1f&#x27; % height)你的身高是185.0 Python算术运算符 这里就简单介绍了，因为无论是运算符号还是运算优先级都是差不多的，但是我们要注意在python中指数不是^表示，这个是按位异或的意思，我们需要使用**来表示指数，同时/就是除法并且不是整除而是直接输出具体的值，//才是整除。如下所示： 123456789101112&gt;&gt;&gt; 2**38&gt;&gt;&gt; 4**01&gt;&gt;&gt; 2/30.6666666666666666&gt;&gt;&gt; 2//30&gt;&gt;&gt; 3/31.0&gt;&gt;&gt; 3//31 一定要注意python中/输出的一定是浮点数，如果要输出整数必须使用//。 Python比较运算符 这里我们主要区分理解一下==和is的区别： 比较运算符 说明 == 等于，如果==两边的值相等，则返回 True，否则返回 False。 is 判断两个变量所引用的对象是否相同，如果相同则返回 True，否则返回 False。 实际上很好区分，==就是单纯比较数值是否相同，而is就是比较引用是否相同，即存储地址是否相同。因此一下代码如下输出： 123456import time #引入time模块t1 = time.gmtime() # gmtime()用来获取当前时间t2 = time.gmtime()print(t1 == t2) #输出Trueprint(t1 is t2) #输出False 运行结果： 12TrueFalse 由于time模块的gettime()方法用来获取当前的系统时间，精确到秒级，因为程序运行非常快，所以t1和t2得到的时间是一样的。==用来判断t1和t2的是否相等，因此返还True。而is是判断两者是否为一个对象，但是gettime()每次都是返还一个新对象，因此两者的存储地址并不相同，因此is判断返还False。 Python逻辑运算符 逻辑运算符 含义 基本格式 说明 and 逻辑与运算，等价于数学中的“且” a and b 当 a 和 b 两个表达式都为真时，a and b 的结果才为真，否则为假。 or 逻辑或运算，等价于数学中的“或” a or b 当 a 和 b 两个表达式都为假时，a or b 的结果才是假，否则为真。 not 逻辑非运算，等价于数学中的“非” not a 如果 a 为真，那么 not a 的结果为假；如果 a 为假，那么 not a 的结果为真。相当于对 a 取反。 123456age = int(input(&quot;请输入年龄：&quot;))height = int(input(&quot;请输入身高：&quot;))if age&gt;=18 and age&lt;=30 and height &gt;=170 and height &lt;= 185 : print(&quot;恭喜，你符合报考飞行员的条件&quot;)else: print(&quot;抱歉，你不符合报考飞行员的条件&quot;) 一种运行结果： 123请输入年龄：23↙请输入身高：178↙恭喜，你符合报考飞行员的条件 但是我们要注意逻辑表达式最终返还的结果并不一定是布尔类型，即不一定是True或者False。他可以是任意类型。 1234print(100 and 200)print(45 and 0)print(&quot;&quot; or &quot;http://c.biancheng.net/python/&quot;)print(18.5 or &quot;http://c.biancheng.net/python/&quot;) 运行结果： 12342000http://c.biancheng.net/python/18.5 那么为什么上面的输出结果不是布尔类型呢，这就要求我们要去理解逻辑运算的本质原理。 逻辑运算符的本质 在Python中，and和or并不一定会计算右边表达式的值，有时候仅仅计算左边的值就能得到最终的结果。同时and和or运算会将其中一个表达式的值作为最终结果，而不一定是True或者False。 对于and运算，两边的都为真时，最终结果才为真，但是只要其中有一个值为假，那么最终结果就是假，所以Python按照下面的规则执行and运算： 如果左边表达式的值为假，那么就不用计算右边表达式的值了，因为不管右边表达式的值是什么，都不会影响最终结果，最终结果都是假，此时 and 会把左边表达式的值作为最终结果。 如果左边表达式的值为真，那么最终值是不能确定的，and 会继续计算右边表达式的值，并将右边表达式的值作为最终结果。 对于 or 运算符，情况是类似的，两边的值都为假时最终结果才为假，只要其中有一个值为真，那么最终结果就是真，所以 Python 按照下面的规则执行 or 运算： 如果左边表达式的值为真，那么就不用计算右边表达式的值了，因为不管右边表达式的值是什么，都不会影响最终结果，最终结果都是真，此时 or 会把左边表达式的值作为最终结果。 如果左边表达式的值为假，那么最终值是不能确定的，or 会继续计算右边表达式的值，并将右边表达式的值作为最终结果。 了解了上面的原理以后我们就可以很容易理解下面的代码的输出结果了： 123456789url = &quot;http://c.biancheng.net/cplus/&quot;print(&quot;----False and xxx-----&quot;)print( False and print(url) )print(&quot;----True and xxx-----&quot;)print( True and print(url) )print(&quot;----False or xxx-----&quot;)print( False or print(url) )print(&quot;----True or xxx-----&quot;)print( True or print(url) ) 运行结果: 12345678910----False and xxx-----False----True and xxx-----http://c.biancheng.net/cplus/None----False or xxx-----http://c.biancheng.net/cplus/None----True or xxx-----True Python三元运算符 我们在C中和Java中都可以使用一种非常简便的比较赋值操作即三元比较符，他们的格式为： 1234567a=(exp?trueVal:falseVal)//等价于if(exp==true)&#123; a=trueVal&#125;else&#123; a=falseVal&#125; 那么python中有没有三元比较符呢？是有的，但是形式略有区别，他直接使用if和else来表示如下： 123456max = a if a&gt;b else b#等价于if(a&gt;b): max=aelse: max=b 也就是说形式为： 1a=trueVal if exp else falseVal 更复杂的嵌套如下： 123a = int( input(&quot;Input a: &quot;) )b = int( input(&quot;Input b: &quot;) )print(&quot;a大于b&quot;) if a&gt;b else ( print(&quot;a小于b&quot;) if a&lt;b else print(&quot;a等于b&quot;) ) 运行结果： 123Input a: 45↙Input b: 100↙a小于b 两个变量值得大小关系有三种，很明显我们需要嵌套使用三元比较复杂，此时由于嵌套后逻辑关系较为难以理解我们最好使用()包裹表达式以便提高代码可读性"},{"title":"字符串","path":"/wiki/Python学习笔记/字符串/index.html","content":"Python字符串拼接 在Python中拼接字符串很简单，可以直接将两个字符串紧挨着写在一起即可： 1strname = &quot;str1&quot; &quot;str2&quot; strname 表示拼接以后的字符串变量名，str1 和 str2 是要拼接的字符串内容。使用这种写法，Python 会自动将两个字符串拼接在一起。要注意拼接并不会改变原先的字符串，仅仅是生成一个新的字符串而已。 1234str1 = &quot;Python教程&quot; &quot;http://c.biancheng.net/python/&quot;print(str1)str2 = &quot;Java&quot; &quot;Python&quot; &quot;C++&quot; &quot;PHP&quot;print(str2) 运行结果： 12Python教程http://c.biancheng.net/python/JavaPythonC++PHP 这种直接罗列紧挨着的字符串拼接仅限于拼接字符串常量，如果需要使用到变量，那么需要使用+进行拼接 1234name = &quot;C++教程&quot;url = &quot;http://c.biancheng.net/cplus/&quot;info = name + &quot;的网址是：&quot; + urlprint(info) 运行结果： 1C++教程的网址是：http://c.biancheng.net/cplus/ Python字符串和数字的拼接 在很多应用场景中，我们都需要将字符串和数字进行拼接，而Python是不允许直接拼接数字和字符串的，所以我们必须先将数字转换成字符串。可以借助str()和repr()函数将数字转换为字符串，他们的使用格式如下： 12str(obj)repr(obj) obj表示要转换的对象，他可以是数字、列表、元组、字典等多种类型的数据。 12345name = &quot;C语言中文网&quot;age = 8course = 30info = name + &quot;已经&quot; + str(age) + &quot;岁了，共发布了&quot; + repr(course) + &quot;套教程。&quot;print(info) 运行结果： 1C语言中文网已经8岁了，共发布了30套教程。 思考：str()和repr()的区别？ str() 用于将数据转换成适合人类阅读的字符串形式。 repr() 用于将数据转换成适合解释器阅读的字符串形式（Python 表达式的形式），适合在开发和调试阶段使用；如果没有等价的语法，则会发生 SyntaxError 异常。 1234567s = &quot;http://c.biancheng.net/shell/&quot;s_str = str(s)s_repr = repr(s)print( type(s_str) )print (s_str)print( type(s_repr) )print (s_repr) 运行结果: 1234&lt;class &#x27;str&#x27;&gt;http://c.biancheng.net/shell/&lt;class &#x27;str&#x27;&gt;&#x27;http://c.biancheng.net/shell/&#x27; 从上面的演示中，我们可以看到，s本身就是一个字符串，但是我们依然使用了str()和repr()来对他进行转换。从运行结果中我们可以看出，str()保留了字符串最原始的样子，而repr()使用引号将字符串包围起来，这就是Python字符串的表达形式。 另外，在Python交互变成环境中，输入一个字符串（变量、加减乘除、逻辑运算等）时，Python会自动使用repr()函数处理该表达式。 Python截取字符串（字符串切片） 本质上来看，字符串是由多个字符构成的，字符之间是有顺序的，这个顺序就是索引（index)。Python允许通过索引来操作字符串中的单个字符或者多个字符，比如获取指定索引处的字符，返回指定字符的索引值等。 获取单个字符 知道字符名以后，我们可以通过方括号[]中使用索引即可访问对应的字符，具体语法格式如下： 1strname[index] strname表示字符串名字，index表示索引值。 Python允许从字符串的两端使用索引： 当以字符串的左端（字符串的开头）为起点时，索引是从 0 开始计数的；字符串的第一个字符的索引为 0，第二个字符的索引为 1，第三个字符串的索引为 2 …… 当以字符串的右端（字符串的末尾）为起点时，索引是从 -1 开始计数的；字符串的倒数第一个字符的索引为 -1，倒数第二个字符的索引为 -2，倒数第三个字符的索引为 -3 …… 12345url = &#x27;http://c.biancheng.net/python/&#x27;#获取索引为10的字符print(url[10])#获取索引为 6 的字符print(url[-6]) 运行结果： 12iy 获取多个字符（字符串切片） 使用[]除了可以获取单个字符之外，我们还可以指定一个范围获取多个字符，也就是一个子串或者片段，具体格式如下： 1strname[start : end : step] strname：要截取的字符串； start：表示要截取的第一个字符所在的索引（截取时包含该字符）。如果不指定，默认为 0，也就是从字符串的开头截取； end：表示要截取的最后一个字符所在的索引（截取时不包含该字符）。如果不指定，默认为字符串的长度； step：指的是从 start 索引处的字符开始，每 step 个距离获取一个字符，直至 end 索引出的字符。step 默认值为 1，当省略该值时，最后一个冒号也可以省略。 123456789url = &#x27;http://c.biancheng.net/java/&#x27;#获取从索引5开始，直到末尾的子串print(url[7: ])#获取从索引-21开始，直到末尾的子串print(url[-21: ])#从开头截取字符串，直到索引22为止print(url[: 22])#每隔3个字符取出一个字符print(url[:: 3]) 运行结果： 1234c.biancheng.net/java/c.biancheng.net/java/http://c.biancheng.nethp/bne.ta/ Python len()函数详解 Python中，要想知道一个字符串有多少个字符（获取字符串长度），或者一字符串占用多少个字节，我们可以使用len()方法。 1len（string） 123&gt;&gt;&gt; a=&#x27;http://c.biancheng.net&#x27;&gt;&gt;&gt; len(a)22 在实际开发中，除了常常获取字符串的长度外，有时候我们还需要获取字符串的字节数。在Python中，不同的字符所占的字节数不同，数字、英文字母、小数点、下划线以及空格各占一个字节，而一个汉字可能占2~4个字节，具体占多少个，取决于采用的编码方式。例如，汉字在GBK/GB2312编码中占用2个字节，而在UTF-8编码中一般占用3个字节。 我们可以通过使用encode()方法，将字符串进行编码后再获取它的字节数。例如，采用UTF-8编码方式，计算”人生苦短，我用Python“的字节数，可以执行如下代码： 123&gt;&gt;&gt; str1 = &quot;人生苦短，我用Python&quot;&gt;&gt;&gt; len(str1.encode())27 因为汉字加中文标点符号共7个，占21个字节，而英文字母和英文的标点符号占6个字节，一共占用27个字节。同理，如果要获取采用GBK编码的字符串的长度，可以执行如下代码： 123&gt;&gt;&gt; str1 = &quot;人生苦短，我用Python&quot;&gt;&gt;&gt; len(str1.encode(&#x27;gbk&#x27;))20 Python split()方法切割字符串 Python中，除了提供了一些内置函数获取字符串的相关信息外（例如len()),字符串类型本身也提供了一些方法供我们使用，这些方法都是字符串类型特有的。 split()方法可以实现将一个字符串按照指定的分隔符切分成多个子串，这些子串会被保存到列表中（不包括分隔符），作为方法的返回值。 1str.split(sep,maxsplit) 此方法中各部分参数的含义分别是： str：表示要进行分割的字符串； sep：用于指定分隔符，可以包含多个字符。此参数默认为 None，表示所有空字符，包括空格、换行符“ ”、制表符“\\t”等。 maxsplit：可选参数，用于指定分割的次数，最后列表中子串的个数最多为 maxsplit+1。如果不指定或者指定为 -1，则表示分割次数没有限制。 在split()方法中，如果不指定sep参数，那么也不能指定maxsplit参数。 要注意，当未指定sep参数时，split(）方法默认采用空字符进行分割，但是当字符串中有连续的空格或其他空字符时，都会被视为一个分割符归字符串进行分割 1234&gt;&gt;&gt; str = &quot;C语言中文网 &gt;&gt;&gt; c.biancheng.net&quot; #包含 3 个连续的空格&gt;&gt;&gt; list6 = str.split()&gt;&gt;&gt; list6[&#x27;C语言中文网&#x27;, &#x27;&gt;&gt;&gt;&#x27;, &#x27;c.biancheng.net&#x27;] Python join()方法合并字符串 join()方法就是split()方法的逆方法，用来将列表（或者元组）中包含的多个字符串连接成一个字符串。 使用join()方法合并字符串时，他会将列表（或者元组）中多个字符串采用固定的分隔符连接在一起。例如，字符串&quot;c.biancheng.net&quot;就可以看做是通过分隔符“.”将[‘c’,‘biancheng’,‘net’] 列表合并为一个字符串的结果。 1newstr = str.join(iterable) 此方法中各参数的含义如下： newstr：表示合并后生成的新字符串； str：用于指定合并时的分隔符； iterable：做合并操作的源字符串数据，允许以列表、元组等形式提供。 12345&gt;&gt;&gt; dir = &#x27;&#x27;,&#x27;usr&#x27;,&#x27;bin&#x27;,&#x27;env&#x27;&gt;&gt;&gt; type(dir)&lt;class &#x27;tuple&#x27;&gt;&gt;&gt;&gt; &#x27;/&#x27;.join(dir)&#x27;/usr/bin/env&#x27; Python count()方法统计字符串出现的次数 count()方法用于检索指定字符串在另一字符串中出现的次数，如果检索的字符串不存在，则返回0，否则返回出现的次数。 1str.count(sub[,start[,end]]) 此方法中，各参数的具体含义如下： str：表示原字符串； sub：表示要检索的字符串； start：指定检索的起始位置，也就是从什么位置开始检测。如果不指定，默认从头开始检索； end：指定检索的终止位置，如果不指定，则表示一直检索到结尾。 12345&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.count(&#x27;.&#x27;,2,-3)1&gt;&gt;&gt; str.count(&#x27;.&#x27;,2,-4)0 要注意搜索范围是[start,end)即末尾是开区间。 Python find()方法检测字符串中是否包含某子串 find()方法用于检索字符串中是否包含目标字符串，如果包含，则返回第一次出现该字符串的索引，反之则返回-1。 1str.find(sub[,start[,end]]) 此格式中各参数的含义如下： str：表示原字符串； sub：表示要检索的目标字符串； start：表示开始检索的起始位置。如果不指定，则默认从头开始检索； end：表示结束检索的结束位置。如果不指定，则默认一直检索到结尾。 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.find(&#x27;.&#x27;,2,-4)-1 同时Python还提供了rfind()方法，他可以从字符串右边开始检索，因此返回的是最靠近右侧的首次出现的字符串 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.rfind(&#x27;.&#x27;)11 Python index()方法检测字符串中是否包含某子串 和find()方法类似，index()方法也可以用来检索是否包含指定的字符串，不同之处在于，当指定的字符串不存在时，idnex()方法会抛出异常。 1str.index(sub[,start[,end]]) 此格式中各参数的含义分别是： str：表示原字符串； sub：表示要检索的子字符串； start：表示检索开始的起始位置，如果不指定，默认从头开始检索； end：表示检索的结束位置，如果不指定，默认一直检索到结尾。 123456789&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.index(&#x27;.&#x27;)1&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.index(&#x27;z&#x27;)Traceback (most recent call last): File &quot;&lt;pyshell#49&gt;&quot;, line 1, in &lt;module&gt; str.index(&#x27;z&#x27;)ValueError: substring not found 类似的，Python也提供了rindex()方法，从右边开始检索： 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.rindex(&#x27;.&#x27;)11 Python字符串对齐方法 Python str还提供了3种可以用来进行文本对齐的方法，分别是ljust()、rjust()和center()方法。 Python ljust()方法 ljust()方法的功能是向指定字符串的右侧填充指定字符，从而达到左对齐文本的目的。 1S.ljust(width[, fillchar]) 其中各个参数的含义如下： S：表示要进行填充的字符串； width：表示包括 S 本身长度在内，字符串要占的总长度； fillchar：作为可选参数，用来指定填充字符串时所用的字符，默认情况使用空格。 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.ljust(35,&#x27;-&#x27;))print(addr.ljust(35,&#x27;-&#x27;)) 运行结果： 12http://c.biancheng.net/python/-----http://c.biancheng.net------------- Python rjust()方法 rjust()和ljust()方法类似，唯一的不同之处在于，rjust()方法是向字符串的左侧填充指定字符串，从而达到右对齐文本的目的。 1S.rjust(width[, fillchar]) 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.rjust(35,&#x27;-&#x27;))print(addr.rjust(35,&#x27;-&#x27;)) 运行结果： 12-----http://c.biancheng.net/python/-------------http://c.biancheng.net Python center()方法 1S.center(width[, fillchar]) 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.center(35,&#x27;-&#x27;))print(addr.center(35,&#x27;-&#x27;)) 运行结果： 12---http://c.biancheng.net/python/---------http://c.biancheng.net------ Python startswith()和endswith()方法 startswith()方法 startswith()方法用来检索字符串是否以指定字符串开头，如果是返回True,反之返回False。 1str.startswith(sub[,start[,end]]) 此格式中各个参数的具体含义如下： str：表示原字符串； sub：要检索的子串； start：指定检索开始的起始位置索引，如果不指定，则默认从头开始检索； end：指定检索的结束位置索引，如果不指定，则默认一直检索在结束。 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.startswith(&quot;b&quot;,2)True endswith()方法 endswith() 方法用于检索字符串是否以指定字符串结尾，如果是则返回 True；反之则返回 False。该方法的语法格式如下： 1str.endswith(sub[,start[,end]]) 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.endswith(&quot;net&quot;)True Python字符串大小写转换 Python title()方法 titile()方法用于将字符串中的每一个单词的首字母转为大写，其他字母全部转为小写，转换完成后，此方法会返回转换得到的字符串。如果字符串中没有需要被转换的字符，那么字符串将会被原封不动的返回 1str.title() 123456&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.title()&#x27;C.Biancheng.Net&#x27;&gt;&gt;&gt; str = &quot;I LIKE C&quot;&gt;&gt;&gt; str.title()&#x27;I Like C&#x27; Python lower()方法 用于将字符串中的所有大写字母转换为小写字母，转换完成以后，该方法会返回新得到的字符串。如果字符串中原本就都是小写字母，那么这个方法返回原字符串。 1str.lower() 123&gt;&gt;&gt; str = &quot;I LIKE C&quot;&gt;&gt;&gt; str.lower()&#x27;i like c&#x27; Python upper()方法 upper()方法和lower()方法功能相反，他用来将字符串中的所有小写字母转换为大写字母。 1str.upper() 123&gt;&gt;&gt; str = &quot;i like C&quot;&gt;&gt;&gt; str.upper()&#x27;I LIKE C&#x27; { % note color:yellow 要注意，以上三个方法都仅限于将转换后的新字符串返回，而不会修改原字符串。 %} Python去除字符串中空格 用户输入数据时，很有可能无疑中输入了多余的空格，或者在一些场景中，字符串前后不允许出现空格或者特殊字符，此时就需要去除字符串中的空格或者特殊字符了。 这里的特殊字符，指的是制表符\\t，回车符\\r,换行符 等。 在Python中，字符串变量提供了3种方法来删除字符串中多于的空格或者特殊字符，他们分别是： strip()：删除字符串前后（左右两侧）的空格或特殊字符。 lstrip()：删除字符串前面（左边）的空格或特殊字符。 rstrip()：删除字符串后面（右边）的空格或特殊字符。 我们要注意Python中字符串类型是不可变的，因此这三个方法仅仅是返回字符串前面或后面空白被删除以后的副本，并不会改变原字符串本身。 Python strip()方法 1str.strip([chars]) 其中，str 表示原字符串，[chars] 用来指定要删除的字符，可以同时指定多个，如果不手动指定，则默认会删除空格以及制表符、回车符、换行符等特殊字符。 1234567&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.strip()&#x27;c.biancheng.net&#x27;&gt;&gt;&gt; str.strip(&quot; ,\\r&quot;)&#x27;c.biancheng.net \\t &#x27;&gt;&gt;&gt; str&#x27; c.biancheng.net \\t \\r&#x27; Python lstrip()方法 123&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.lstrip()&#x27;c.biancheng.net \\t \\r&#x27; Python rstrip()方法 123&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.rstrip()&#x27; c.biancheng.net&#x27; Python format()格式化输出方法 之前我们学习了使用%操作符来对各种类型的数据进行格式化输出，这是早期Python提供的方法。自从Python2.6版本之后，字符串类型提供了format()方法对字符串进行格式化。 1str.format(args) 此方法中，str 用于指定字符串的显示样式；args 用于指定要进行格式转换的项，如果有多项，之间有逗号进行分割。 学习 format() 方法的难点，在于搞清楚 str 显示样式的书写格式。在创建显示样式模板时，需要使用&#123;&#125;和：来指定占位符，其完整的语法格式为： 1&#123; [index][ : [ [fill] align] [sign] [#] [width] [.precision] [type] ] &#125; 注意，格式中用 [] 括起来的参数都是可选参数，即可以使用，也可以不使用。各个参数的含义如下： index：指定：后边设置的格式要作用到 args 中第几个数据，数据的索引值从 0 开始。如果省略此选项，则会根据 args 中数据的先后顺序自动分配。 fill：指定空白处填充的字符。注意，当填充字符为逗号(,)且作用于整数或浮点数时，该整数（或浮点数）会以逗号分隔的形式输出，例如（1000000会输出 1,000,000）。 align：指定数据的对齐方式，具体的对齐方式如下表所示 align参数 含义 &lt; 数据左对齐。 &gt; 数据右对齐。 = 数据右对齐，同时将符号放置在填充内容的最左侧，该选项只对数字类型有效。 ^ 数据居中，此选项需和 width 参数一起使用。 sign：指定有五符号数，此参数的值以及对应的含义如下表所示 sign参数 含义 + 正数前加正号，负数前加负号。 - 正数前不加正号，负数前加负号。 空格 正数前加空格，负数前加负号。 # 对于二进制数、八进制数和十六进制数，使用此参数，各进制数前会分别显示 0b、0o、0x前缀；反之则不显示前缀。 width：指定输出数据时所占的宽度。 .precision：指定保留的小数位数。 type：指定输出数据的具体类型，如下表所示 type类型值 含义 s 对字符串类型格式化。 d 十进制整数。 c 将十进制整数自动转换成对应的 Unicode 字符。 e 或者 E 转换成科学计数法后，再格式化输出。 g 或 G 自动在 e 和 f（或 E 和 F）中切换。 b 将十进制数自动转换成二进制表示，再格式化输出。 o 将十进制数自动转换成八进制表示，再格式化输出。 x 或者 X 将十进制数自动转换成十六进制表示，再格式化输出。 f 或者 F 转换为浮点数（默认小数点后保留 6 位），再格式化输出。 % 显示百分比（默认显示小数点后 6 位）。 12345678#以货币形式显示print(&quot;货币形式：&#123;:,d&#125;&quot;.format(1000000))#科学计数法表示print(&quot;科学计数法：&#123;:E&#125;&quot;.format(1200.12))#以十六进制表示print(&quot;100的十六进制：&#123;:#x&#125;&quot;.format(100))#输出百分比形式print(&quot;0.01的百分比表示：&#123;:.0%&#125;&quot;.format(0.01)) 运行结果： 1234货币形式：1,000,000科学计数法：1.200120E+03100的十六进制：0x640.01的百分比表示：1% Python字符串编码转换 我们知道，最早的字符串编码是ASCII编码，它仅仅对10个数字、26个大小写英文字母以及一些特殊字符进行了编码。ASCII码最多只能表示256个字符，每一个字符只需要占用一个字节。但是伴随着信息技术的发展，各国的文字都需要进行编码，于是相继出现了GBK,GB2312,UTF-8编码等。其中GBK和GB2312是我国制定的中文编码标准，规定英文字符占用1个字节，中文字符占2个字节。而UTF-8是国际通过的编码格式，它包含了全世界所有国家需要用到的字符，其规定是英文字符占1个字节，中文字符占3个字节。 Python3.x默认采用UTF-8编码格式，有效的解决了中文乱码的问题。 我们之前学习过在Python中有两种字符串类型，分别是str和bytes类型，其中str用来表示Unicode字符，bytes用来表示二进制数据。str类型和bytes类型之间就需要使用encode()和decode()方法进行转换。 Python encode()方法 encode()方法为字符串类型str提供的方法，用于将str转换为bytes类型，这个过程也称为编码。 1str.encode([encoding=&quot;utf-8&quot;][,errors=&quot;strict&quot;]) 注意，格式中用 [] 括起来的参数为可选参数，也就是说，在使用此方法时，可以使用 [] 中的参数，也可以不使用。 参数 含义 str 表示要进行转换的字符串。 encoding = “utf-8” 指定进行编码时采用的字符编码，该选项默认采用 utf-8 编码。例如，如果想使用简体中文，可以设置 gb2312。 当方法中只使用这一个参数时，可以省略前边的“encoding=”，直接写编码格式，例如 str.encode(“UTF-8”)。 errors = “strict” 指定错误处理方式，其可选择值可以是：strict：遇到非法字符就抛出异常。ignore：忽略非法字符。replace：用“？”替换非法字符。xmlcharrefreplace：使用 xml 的字符引用。该参数的默认值为 strict。 注意，使用 encode() 方法对原字符串进行编码，不会直接修改原字符串，如果想修改原字符串，需要重新赋值。 123456&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; str.encode()b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x91&#x27;&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; str.encode(&#x27;GBK&#x27;)b&#x27;C\\xd3\\xef\\xd1\\xd4\\xd6\\xd0\\xce\\xc4\\xcd\\xf8&#x27; Python decode()方法 和encode()方法相反，decode()方法用于将bytes类型的二进制数据转换为str类型，这个过程又称为阶解码。 1bytes.decode([encoding=&quot;utf-8&quot;][,errors=&quot;strict&quot;]) 参数 含义 bytes 表示要进行转换的二进制数据。 encoding=“utf-8” 指定解码时采用的字符编码，默认采用 utf-8 格式。当方法中只使用这一个参数时，可以省略“encoding=”，直接写编码方式即可。 注意，对 bytes 类型数据解码，要选择和当初编码时一样的格式。 errors = “strict” 指定错误处理方式，其可选择值可以是：strict：遇到非法字符就抛出异常。ignore：忽略非法字符。replace：用“？”替换非法字符。xmlcharrefreplace：使用 xml 的字符引用。该参数的默认值为 strict。 1234&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; bytes=str.encode()&gt;&gt;&gt; bytes.decode()&#x27;C语言中文网&#x27; 注意，如果编码时采用的不是默认的 UTF-8 编码，则解码时要选择和编码时一样的格式，否则会抛出异常，例如： 123456789&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; bytes = str.encode(&quot;GBK&quot;)&gt;&gt;&gt; bytes.decode() #默认使用 UTF-8 编码，会抛出以下异常Traceback (most recent call last): File &quot;&lt;pyshell#10&gt;&quot;, line 1, in &lt;module&gt; bytes.decode()UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xd3 in position 1: invalid continuation byte&gt;&gt;&gt; bytes.decode(&quot;GBK&quot;)&#x27;C语言中文网&#x27; Python dir()和help()帮助函数 前面我们仅仅是学习了Python字符串中提供的常用的方法，但是这远远不是他的全部方法。我们还可以通过dir()或者help()方法查看更多方法。 Python dir()函数用来列出某个类或者某个模块中的全部内容，包括变量、方法、函数和类等。他的用法： 1dir(obj) obj 表示要查看的对象。obj 可以不写，此时 dir() 会列出当前范围内的变量、方法和定义的类型。 Python help() 函数用来查看某个函数或者模块的帮助文档，它的用法为： 1help(obj) obj表示要查看的对象，obj可以不写，此时help()会进入帮助子程序。 假设现在我们要使用dir()查看str类型支持的所有方法： 12&gt;&gt;&gt; dir(str)[&#x27;__add__&#x27;, &#x27;__class__&#x27;, &#x27;__contains__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dir__&#x27;, &#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;, &#x27;__getattribute__&#x27;, &#x27;__getitem__&#x27;, &#x27;__getnewargs__&#x27;, &#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__init_subclass__&#x27;, &#x27;__iter__&#x27;, &#x27;__le__&#x27;, &#x27;__len__&#x27;, &#x27;__lt__&#x27;, &#x27;__mod__&#x27;, &#x27;__mul__&#x27;, &#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__rmod__&#x27;, &#x27;__rmul__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;, &#x27;capitalize&#x27;, &#x27;casefold&#x27;, &#x27;center&#x27;, &#x27;count&#x27;, &#x27;encode&#x27;, &#x27;endswith&#x27;, &#x27;expandtabs&#x27;, &#x27;find&#x27;, &#x27;format&#x27;, &#x27;format_map&#x27;, &#x27;index&#x27;, &#x27;isalnum&#x27;, &#x27;isalpha&#x27;, &#x27;isascii&#x27;, &#x27;isdecimal&#x27;, &#x27;isdigit&#x27;, &#x27;isidentifier&#x27;, &#x27;islower&#x27;, &#x27;isnumeric&#x27;, &#x27;isprintable&#x27;, &#x27;isspace&#x27;, &#x27;istitle&#x27;, &#x27;isupper&#x27;, &#x27;join&#x27;, &#x27;ljust&#x27;, &#x27;lower&#x27;, &#x27;lstrip&#x27;, &#x27;maketrans&#x27;, &#x27;partition&#x27;, &#x27;replace&#x27;, &#x27;rfind&#x27;, &#x27;rindex&#x27;, &#x27;rjust&#x27;, &#x27;rpartition&#x27;, &#x27;rsplit&#x27;, &#x27;rstrip&#x27;, &#x27;split&#x27;, &#x27;splitlines&#x27;, &#x27;startswith&#x27;, &#x27;strip&#x27;, &#x27;swapcase&#x27;, &#x27;title&#x27;, &#x27;translate&#x27;, &#x27;upper&#x27;, &#x27;zfill&#x27;] 我们已经找到了它支持的所有方法，接下来我们可以通过help()方法去详细了解每一个方法的具体功能。如下所示我们使用help()方法查看str中lower()方法的用法： 12345&gt;&gt;&gt; help(str.lower)Help on method_descriptor:lower(self, /) Return a copy of the string converted to lowercase. 注意，使用help() 查看某个函数的用法时，函数名后边不能带括号，例如将上面的命令写作help(str.lower())就是错误的。"},{"title":"函数进阶","path":"/wiki/Python学习笔记/函数进阶/index.html","content":"Python partial偏函数 简单的理解偏函数，他是对原始函数的二次封装，是将现有函数的部分参数预先绑定为指定值，从而得到一个新的函数，这个函数就成为偏函数。相比原函数，偏函数具有较少的可变参数，从而降低了函数调用的难度。 偏函数的定义需要使用关键字partial（位于模块functools中）。他的语法格式如下： 1偏函数名 = partial(func, *args, **kwargs) 我们在学习了函数的各种接收方法以后，很容易就可以理解后两个参数的意思。*args用来接收所有的位置参数，而**kwargs用来接收所有的关键字参数，如下是一个偏函数的应用例子： 1234567from functools import partial#定义个原函数def display(name,age): print(&quot;name:&quot;,name,&quot;age:&quot;,age)#定义偏函数，其封装了 display() 函数，并为 name 参数设置了默认参数GaryFun = partial(display,name = &#x27;Gary&#x27;)#由于 name 参数已经有默 运行结果： 1name: Gary age: 13 我们要注意，对于第8行代码，必须采用关键字参数的形式给age形参传值，因为如果以无关键字参数的方式，该实参将试图传递给name形参，Python编辑器会报TypeError错误。 为了方便正确设置默认值，一般情况下我们最好在对偏函数定义设置默认值时使用关键字参数形式，然后调用再使用位置参数的形式。 当然如果你对参数的传递非常熟悉，那么可以使用位置参数传递，如下是一个使用位置参数为偏函数设置参数默认值的例子： 1234567from functools import partialdef mod( n, m ): return n % m#定义偏函数，并设置参数 n 对应的实参值为 100mod_by_100 = partial( mod, 100 )print(mod( 100, 7 ))print(mod_by_100( 7 )) 运行结果: 1222 注意此时mod_by_100相当于只需要再接收一个m参数了，n并不需要在接收了，因此此时如果像下面这样调用会出错： 12345&gt;&gt;&gt;print(mod_by_100( 100,7 ))Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 8, in &lt;module&gt; print(mod_by_100( 100,7 ))TypeError: mod() takes 2 positional arguments but 3 were given 因此我们可以理解为此时mod_by_100是一个新函数，他只需要接收一个参数，然后就会计算出100%n的值，只不过他的具体实现是基于mod实现的。因此它实现了函数的参数截取。 结合上面的例子，我们不难看出实际上偏函数的运行本质上还是调用了原始函数，只不过是对，原始函数进行了封装，将原函数的一些不需要改变的形参设置了默认值，然后对外部用户只暴露剩下的参数。这种通过将任意数量（顺序）的参数，转化为另一个带有剩余参数的函数对象，从而实现了截取函数功能（偏向）的效果。在实际应用中，可以使用一个原函数，然后将其封装多个偏函数，在调用函数时全部调用偏函数，一定程度上可以提高程序的可读性。 Python函数递归 函数递归 函数递归就是一个函数不断的调用自身的过程，他往往需要一个终止条件以便能够跳出递归继续向下执行代码。但是有时候我们会由于代码逻辑的缺陷问题，导致函数递归缺失终止条件，那么此时程序并不会真的一直向下递归调用执行，而是在递归调用997次以后停止并报错RecursionError。这是因为在Python中，默认的最大递归次数是997次。 12345678count=0def func(): global count count+=1 print(count) func()func()#最大打印出997，最后报错 如果我们需要修改默认的最大递归次数，方法如下： 12import syssys.setrecursionlimit(修改后的值) 递归实例 我们以二分法查找列表l中数字num的索引熟悉一下函数的递归 123456789101112131415def search(l, num, start=None, end=None): start = start if start else 0 end = end if end else len(l)-1 mid = (end-start)//2+start if l[mid] &gt; num: return search(l, num, start, mid-1) elif l[mid] &lt; num: return search(l, num, mid+1, end) elif l[mid] == num: return mid# 默认要寻找的数存在，否则会报错l = [2, 3, 5, 10, 15, 16, 18, 22, 26, 30, 32, 35, 41, 42, 43, 55, 56, 66, 67, 69, 72, 76, 82, 83, 88]print(search(l, 67)) 我们只需要记住，递归需要一个终止条件同时还要注意最大递归次数即可。 Python变量作用域 Python局部变量 在函数内部定义的变量，他的作用域也仅限于函数内部，出了函数就不能使用了，我们将这样的变量称为局部变量。 当函数被执行时，Python会为其分配一块临时的存储空间，所有在函数内部定义的变量，都会存储在这块空间中。而在函数执行完毕后，这块临时存储空间随即会被释放并回收，该空间中存储的变量自然也就无法再被使用。 12345def demo(): add = &quot;hello&quot; print(&quot;函数内部 add =&quot;,add)demo()print(&quot;函数外部 add =&quot;,add) 运行结果： 12345函数内部 add = helloTraceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 6, in &lt;module&gt; print(&quot;函数外部 add =&quot;,add)NameError: name &#x27;add&#x27; is not defined 我们可以看到，如果试图在函数外部访问其内部定义的变量，那么Python解释器会报NameError错误，并且提示我们没有定义要访问的变量，这也证实了当函数执行完毕后，其内部定义的变量会被销毁并回收。 我们还要注意，函数接收的参数也属于局部变量，只能在函数内部使用： 123456def demo(name,add): print(&quot;函数内部 name =&quot;,name) print(&quot;函数内部 add =&quot;,add)demo(&quot;Python教程&quot;,&quot;http://c.biancheng.net/python/&quot;)print(&quot;函数外部 name =&quot;,name)print(&quot;函数外部 add =&quot;,add) 运行结果： 123456函数内部 name = Python教程函数内部 add = http://c.biancheng.net/python/Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 7, in &lt;module&gt; print(&quot;函数外部 name =&quot;,name)NameError: name &#x27;name&#x27; is not defined 我们可以看到name变量和add变量形参只能在函数内部使用，外部也是无法使用的。因为函数执行完成以后会立即销毁存储这些函数相关变量的存储空间。 Python全局变量 除了在函数内部定义变量，Python还允许我们在所有函数的我外部定义变量，这样的变量我们成为全局变量。和局部变量不同，全局变量的默认作用域是整个程序，即全局变量既可以在各个函数的外部使用，也可以在各函数内部使用。 定义全局变量的方式有以下两种： 一、在函数体外部定义的变量 12345add = &quot;http://coolchong.cn&quot;def text(): print(&quot;函数体内访问：&quot;,add)text()print(&#x27;函数体外访问：&#x27;,add) 运行结果： 12函数体内访问： http://coolchong.cn函数体外访问： http://coolchong.cn 二、 在函数体内定义全局变量 我们可以使用global关键字对变量进行修饰，这样这个变量就变成了全局变量，即使此时他是在函数内部定义的： 123456ef text(): global add add= &quot;http://coolchong.cn/&quot; print(&quot;函数体内访问：&quot;,add)text()print(&#x27;函数体外访问：&#x27;,add) 运行结果： 12函数体内访问： http://coolchong.cn/函数体外访问： http://coolchong.cn/ 我们要注意使用global关键字修饰变量时，不能直接给变量赋初值，否则会引发语法错误。 获取指定作用域范围中的变量 在一些特定场景中，我们可能需要某个作用域内（全局范围内或者局部范围内）所有的变量，Python中提供了一下3种方式： 1）globals()函数 globals()函数为Python的内置函数，他可以返还一个包含全局范围内所有的变量的字典，该字典中的每个键值对，键为变量名，值为该变量的值。 12345678#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot;print(globals()) 运行结果： 1&#123; ...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ......&#125; 注意globals()函数返还的字典中，不仅仅包含我们定义的全局变量，还有许多默认包含的变量，他们是Python主程序内置的，我们可以不用理会。 可以看到，通过调用globals()函数我们可以得到一个包含所有全局变量的字典，并且通过字典，我们可以访问指定的全局变量，如果需要，我们还可以修改它的值： 123print(globals()[&#x27;Pyname&#x27;])globals()[&#x27;Pyname&#x27;] = &quot;Python入门教程&quot;print(Pyname) 运行结果： 12Python教程Python入门教程 2）locals()函数 locals()函数也是Python内置函数之一，通过调用这个函数，我们可以得到一个包含当前作用域内所有变量的字典。当在函数内部调用locals()函数，会得到包含所有局部变量的字典，而在全局范围内调用locals()函数，其功能就和globals()函数功能完全相同。 123456789101112#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot; print(&quot;函数内部的 locals:&quot;) print(locals())text()print(&quot;函数外部的 locals:&quot;)print(locals()) 运行结果： 1234函数内部的 locals:&#123;&#x27;Sheadd&#x27;: &#x27;http://c.biancheng.net/shell/&#x27;, &#x27;Shename&#x27;: &#x27;shell教程&#x27;&#125;函数外部的 locals:&#123;...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ...... &#125; 但是我们要注意，当使用locals()函数获得所有局部变量组成的字典时，可以像globals()函数那样，通过指定键访问对应的变量值，但是我们无法对变量值进行修改 1234567891011#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot; print(locals()[&#x27;Shename&#x27;]) locals()[&#x27;Shename&#x27;] = &quot;shell入门教程&quot; print(Shename)text() 运行结果： 12shell教程shell教程 3）vars(object) vars()函数也是Python内置函数之一，其功能是返回一个指定object对象范围内所有变量组成的字典，如果不传入object参数，vars()和globals()的作用完全相同。 12345678910 #全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;class Demo: name = &quot;Python 教程&quot; add = &quot;http://c.biancheng.net/python/&quot;print(&quot;有 object：&quot;)print(vars(Demo))print(&quot;无 object：&quot;)print(vars()) 运行结果： 1234有 object：&#123;...... , &#x27;name&#x27;: &#x27;Python 教程&#x27;, &#x27;add&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ......&#125;无 object：&#123;...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ...... &#125; Python在函数内部使用同名的全局变量 首先我们要明确，函数可以直接不接收参数就直接使用全局变量如下所示： 123456name = &#x27;Charlie&#x27;def test (): # 直接访问name全局变量 print(name) # Charlietest()print(name) 运行结果： 12CharlieCharlie 此时写法是正确的，相当于test()函数直接打印了全局变量name，同时在函数外部主程序内又打印了一遍全局变量name，因此两个输出结果均为Charlie。 同时当函数内部出现了同名的局部变量，那么局部变量会覆盖之前的全局变量的值，即函数默认将同名变量视为局部变量进行使用，因此如下所示 123456name = &#x27;Charlie&#x27;def test (): name=&quot;wenchong&quot; print(name) # wenchongtest()print(name) 运行结果： 12wenchongCharlie 此时test()函数内部声明了一个name局部变量并且将值设置为了wenchong，因此此时输出结果如下所示，即在test()函数内部局部变量name覆盖掉了全局变量name。但是我们假如将name=&quot;wenchong&quot;放到print(name)下方会怎样？ 123456name = &#x27;Charlie&#x27;def test (): print(name) name=&quot;wenchong&quot;test()print(name) 运行结果： 1UnboundLocalError : local variable ‘name’ referenced before assignment 我们发现此时报错了！原因是此时test()会将namne视为局部变量，那么很显然print(name)代码打印的是局部变量的值，但是此时局部变量name还未进行赋值，因此报错了。 实际上此时上面的代码本意是打印全局变量name的值，然后再声明一个全局变量name并且赋值为字符串wenchong,那么此时怎么实现呢？很显然我们并不能直接在函数内部将name声明为global全局变量类型，因为这样会导致函数执行结束以后全局变量name也发生了改变导致输出的结果为 12Charliewenchong 但是实际上我们希望输出的结果为 12CharlieCharlie 即在test()函数内部定义了局部变量name赋值为wenchong，同时两次打印使用的都是全局变量name，那么此时我们就会用到之前我们学习的globals()函数了，代码改为： 1234567name = &#x27;Charlie&#x27;def test (): print(globals()[&#x27;name&#x27;]) # Charlie #也可以写为 print(globals.getr(&#x27;name&#x27;)) name=&quot;wenchong&quot;test()print(name) #Charlie 为了验证此时函数内部的name确实为局部变量，我们可以使用如下代码测试： 1234567name = &#x27;Charlie&#x27;def test (): print(globals().get(&#x27;name&#x27;)) # wenchong name=&quot;wenchong&quot; print(name)test()print(name) 运行结果： 123CharliewenchongCharlie Python局部函数详解 通过前面的学习我们已经知道Python支持局部变量了，那么Python是否支持局部函数呢？即Python函数内部可以在定义函数吗？答案是可以得。Python支持在函数内部定义函数，此类函数就被成为局部函数。 123456789#全局函数def outdef (): #局部函数 def indef(): print(&quot;hello world&quot;) #调用局部函数 indef()#调用全局函数outdef() 运行结果： 1hello world 和全局函数返回其局部变量从而扩大这个变量的作用域一样，通过将局部函数函数作为函数的返回值，也可以扩大局部函数的使用范围，比如： 1234567891011#全局函数def outdef (): #局部函数 def indef(): print(&quot;调用局部函数&quot;) #调用局部函数 return indef#调用全局函数new_indef = outdef()调用全局函数中的局部函数new_indef() 运行结果： 1调用局部函数 此时这个局部函数作用域就扩大了，他可以脱离父函数作用而在全局内使用。因此我们可以总结出以下规律： 如果所在函数并没有返还局部函数，那么这个局部函数的可用范围仅限于所在函数内部 反之，如果所在函数将局部函数作为返回值，那么局部函数的作用域就会扩大，既可以在函数内部使用，也可以在所在函数的作用域中使用。 同时我们要注意一个问题，局部函数内部是一个新的作用域，因此如果局部函数中定义了和所在函数中变量同名的变量，也会发生遮蔽问题。 12345678910#全局函数def outdef (): name = &quot;所在函数中定义的 name 变量&quot; #局部函数 def indef(): print(name) name = &quot;局部函数中定义的 name 变量&quot; indef()#调用全局函数outdef() 此时indef()函数内是一个新的作用域，并且此时在内部又定义了一个新的局部变量name，因此此时很明显会报错，Python解释器会报如下错误： 1UnboundLocalError: local variable &#x27;name&#x27; referenced before assignment 那么为了解决这个问题，我们应该怎么样修改代码呢？ 很明显此时无论是使用global关键字还是内置函数globals()、locals()都无法解决错误。此时我们需要使用Python提供的关键字nonlocal，顾名思义不是局部变量，那么此时他就会取消遮蔽效果获取到局部函数所在父函数作用域的变量name的值： 123456789101112#全局函数def outdef (): name = &quot;所在函数中定义的 name 变量&quot; #局部函数 def indef(): nonlocal name print(name) #修改name变量的值 name = &quot;局部函数中定义的 name 变量&quot; indef()#调用全局函数outdef() 运行结果： 1所在函数中定义的 name 变量 Python函数高级使用方法 前面我们已经学习函数的基础用法，接下来我们再学习一些高级用法。首先Python允许直接将函数赋值给变量，这样做的效果是，程序也可以用其他变量来调用函数，更加灵活。 123456def my_def (): print(&quot;正在执行 my_def 函数&quot;)#将函数赋值给其他变量 other = my_def#间接调用 my_def() 函数other() 运行结果： 1正在执行 my_def 函数 不仅如此，Python还支持将函数以参数的形式传入其他函数，例如： 1234567891011def add (a,b): return a+bdef multi(a,b): return a*bdef my_def(a,b,dis): return dis(a,b) #求 2 个数的和print(my_def(3,4,add))#求 2 个数的乘积print(my_def(3,4,multi)) 运行结果： 12712 我们可以看到上面的代码中my_def接收的第三个参数是一个函数，然后将前两个接收的参数传给第三个函数参数去执行，因此函数可以作为参数传递。 Python闭包函数 闭包，又称为闭包函数或闭合函数，其实和前面我们学习的嵌套函数类似，不同之处在于，闭包中外部函数返回的不是一个具体的值，而是一个函数。一般情况下， 返回的函数会赋值给一个变量，这个变量可以在后面被继续执行调用。 例如，现在我们要实现一个计算数的n次幂的函数，那么用闭包可以如下实现： 123456789#闭包函数，其中 exponent 称为自由变量def nth_power(exponent): def exponent_of(base): return base ** exponent return exponent_of # 返回值是 exponent_of 函数square = nth_power(2) # 计算一个数的平方cube = nth_power(3) # 计算一个数的立方print(square(2)) # 计算 2 的平方print(cube(2)) # 计算 2 的立方 运行结果： 1248 在上面的程序中，外部函数nth_power()的返回值是函数exponent__of()，而不是一个具体的数值。这个返还的exponent_of函数还需要接收一个base变量，nth_power()只是将exponent_of内部的exponent变量进行了赋值。 因此，在执行完square=nth_power(2)和cube=nth_power(3)后，外部函数nth_power()的参数exponent会和内部函数exponent_of一起赋值给square和cube，这样在之后调用square(2）和cube(2)时，程序就能顺利的输出结果，而不会报错exponent变量没有定义 但是你可能会疑惑我们为什么非要使用闭包来实现上面的功能呢？完全可以下面这种简单的形式： 12def nth_power_rewrite(base, exponent): return base ** exponent 上面的程序确实也可以实现相同的功能，不过使用闭包，可以让程序变得更加简洁易读。设想一下，比如我们现在需要计算很多个数的平方，那么闭包函数的写法明显更好： 123456789# 不使用闭包res1 = nth_power_rewrite(base1, 2)res2 = nth_power_rewrite(base2, 2)res3 = nth_power_rewrite(base3, 2)# 使用闭包square = nth_power(2)res1 = square(base1)res2 = square(base2)res3 = square(base3) 采用闭包的第二个形式，表达更为简单，每次调用函数时，我们都可以少输入一个参数。 思考：闭包还有什么优势？ 如果仅仅是减少输入参数，貌似闭包优点大材小用了，毕竟闭包很难构思，难道优势仅仅是降低操作的难度吗？当然不是，闭包的优点和缩减嵌套函数的优点类似，我们知道每一个函数开头都需要做一些额外工作，那么当多次调用该函数时，每次都需要重复初始化工作，但是如果我们将这些额外工作统一放置到外部函数中，用闭包返还内部函数，就可以减少多次调用导致的不必要的开销，提高程序的运行效率。 Python闭包的__closure__属性 闭包函数比普通的函数多了一个__closure__属性，这个属性记录着自由变量的地址。当闭包被调用时，系统就会根据该地址找到对应的自由变量，完成整体的函数调用。 以nth_power()为例，当其被调用时，可以通过__closure__属性获取自由变量（也就是程序中的exponent参数）存储的地址，例如： 1234567def nth_power(exponent): def exponent_of(base): return base ** exponent return exponent_ofsquare = nth_power(2)#查看 __closure__ 的值print(square.__closure__) 运行结果： 1(&lt;cell at 0x0000014454DFA948: int object at 0x00000000513CC6D0&gt;,) 可以看到，显示的内容是一个int整数类型，这就是square中自由变量exponent的初始值，还可以看到，__closure__属性的类型是一个元组，这表明闭包可以支持多个自由变量的形式。 Python lambda表达式(匿名函数） 对于一个简单的函数，Python还提供了另外一种方法，即lambda表达式。lambda表达式，又称为匿名函数，常用来表示内部仅包含一行表达式的函数。如果一个函数的函数体仅有一行表达式，那么这个函数就可以使用lambda表达式来代替。 lambda表达式的语法格式如下： 1name = lambda [list] : 表达式 其中，定义lambda表达式时，必须使用lambda关键字，[list]作为可选参数，等同于定义函数时指定的参数列表或者元组用来接收参数，name为表达式的名称。 如果将lambda表达式转换为普通函数的形式就如下方所示： 123def name(list): return 表达式name(list) 接下来我们尝试使用一个lambda表达式解决求两个数之和的问题： 12add = lambda x,y:x+yprint(add(3,4)) 运行结果： 17 使用lambda表达式的优势有： 对于单行函数，使用lambda表达式可以省去定义函数的过程，让代码更加简洁 对于不需要多次复用的函数，使用lambda表达式可以在用完之后立即释放，提高程序执行的性能 Python eval()和exec()函数 eval()和exec()函数都属于Python内置函数，两个函数的功能是类似的，都可以执行一个字符串形式的Python代码（代码以字符串的形式提供），相当于一个Python的解释器。而这不同之处在于，eval()执行完要返回结果，而exec()执行完不返回结果。 eval()和exec()的用法 eval()函数的语法格式如下： 1eval(source, globals=None, locals=None, /) 而exec()函数的语法格式如下： 1exec(source, globals=None, locals=None, /) 两者除了函数名不同，其他都相同，各个参数的具体含义为： expression：这个参数是一个字符串，代表要执行的语句。该语句受后面两个字典类型参数globals和locals的限制，只有在globals字典和locals字典作用域内的变量和函数才能被执行。 globals：这个参数管控的是一个全局的命名空间，即expression可以使用全局命名空间中的函数。如果只是提供了globals参数，而没有提供自定义的 __builtins__，则系统会将当前环境中的__builtins__复制到自己提供的globals中，然后才会进行计算。如果连globals这个参数都没有被提供，那么使用Python的全局命名空间。 locals：这个参数管控的是一个局部命名空间，和globals类似，当它和globals中有重复或冲突时，以locals为准。如果locals没有被提供，那么默认为globals。 注意，\\_\\_builtins\\_\\_是 Python 的内建模块，平时使用的 int、str、abs 都在这个模块中。通过 print(dic[__builtins__]) 语句可以查看 __builtins__ 所对应的 value。 123456dic=&#123;&#125; #定义一个字dic[&#x27;b&#x27;] = 3 #在 dic 中加一条元素，key 为 bprint (dic.keys()) #先将 dic 的 key 打印出来，有一个元素 bexec(&quot;a = 4&quot;, dic) #在 exec 执行的语句后面跟一个作用域 dic#全局域字典dic很明显会增加一个新的全局变量aprint(dic.keys()) #exec 后，dic 的 key 多了一个 运行结果： 12dict_keys([&#x27;b&#x27;])dict_keys([&#x27;b&#x27;, &#x27;__builtins__&#x27;, &#x27;a&#x27;]) 上面的代码是在作用域 dic 下执行了一句 a = 4 的代码。可以看出，exec() 之前 dic 中的 key 只有一个 b。执行完 exec() 之后，系统在 dic 中生成了两个新的 key，分别是 a 和__builtins__。其中，a 为执行语句生成的变量，系统将其放到指定的作用域字典里；__builtins__是系统加入的内置 key。 我们再看一个例子： 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;, g, t)) #定义一个字典 116 运行结果： 1116 为什么结果为116呢？首先我们设置了eval()函数的全局域为&#123;'a':6, 'b':8&#125;，然后又设置了局部域为&#123;'b':100, 'c':10&#125;。但是根据之前的讲解，当globals和locals有冲突时，会产生局部域遮蔽全局域冲突变量的情况，因此此时实际上a+b+c执行的时候，a用全局域中的6，b和c都是使用局部域中的100和10，因此最终结果为116。 我们会发现eval函数中执行代码时变量的值与eval所处的域中变量值并不同，这是因为我们重新为其传入了globals和locals，假设此时我们不设置globals如下所示，那么此时eval()的globals将会继承当前的全局域，因此a为10，代码执行结果为120 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;, None, t)) #定义一个字典 120 以此类推，假设此时我们globals和locals都不设置，那么运行结果将是60 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;)) #定义一个字典 60 exec()和eval()的区别 前面我们讲过，eval()执行完结果会返还，而exec()执行完并不会返还结果，举个例子： 1234567a = 1exec(&quot;a = 2&quot;) #相当于直接执行 a=2print(a)a = exec(&quot;2+3&quot;) #相当于直接执行 2+3，但是并没有返回值，a 应为 Noneprint(a)a = eval(&#x27;2+3&#x27;) #执行 2+3，并把结果返回给 aprint(a) 运行结果： 1232None5 当我们为eval()里放置一个没有结果返回的语句时，Python解释器将会报SyntaxError错误 12345678&gt;&gt;&gt;a= eval(&quot;a = 2&quot;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 1, in &lt;module&gt; a= eval(&quot;a = 2&quot;) File &quot;&lt;string&gt;&quot;, line 1 a = 2 ^SyntaxError: invalid syntax eval()和exec()函数的应用场景 在使用Python开发服务端程序时，两个函数应用的非常广泛，例如客户端向服务端发送一段字符串代码，服务端无需关心具体的内容，直接通过 eval() 或 exec() 来执行，这样的设计会使服务端与客户端的耦合度更低，系统更易扩展。 另外，如果以后接触 TensorFlow 框架，就会发现该框架中的静态图就是类似这个原理实现的： TensorFlow 中先将张量定义在一个静态图里，这就相当将键值对添加到字典里一样； TensorFlow 中通过 session 和张量的 eval() 函数来进行具体值的运算，就当于使用 eval() 函数进行具体值的运算一样。 需要注意的是，在使用 eval() 或是 exec() 来处理请求代码时，函数 eval() 和 exec() 常常会被黑客利用，成为可以执行系统级命令的入口点，进而来攻击网站。解决方法是：通过设置其命名空间里的可执行函数，来限制 eval() 和 exec() 的执行范围。 Python函数式编程 所谓函数式编程，就是指代码中每一块都是不可变的，都由纯函数的形式组成。这里的纯函数，是指函数本身相互独立、互相影响，对于相同的输入，总会有相同的输出。 函数式编程的一大特点，就是允许把函数本身作为参数传入另一个函数，还允许返回一个函数。 假设现在我们想让列表中的元素值都变为原来的两倍，可以使用如下函数实现： 1234def multiply_2(list): for index in range(0, len(list)): list[index] *= 2 return list 要注意，这段代码并不是一个纯函数的形式，因为列表中的元素的值都被改变了，如果多次调用multiply_2()函数，那么每次得到的结果都是不一样的。 而如果想让multiply_2()成为一个纯函数的形式，就得重新创建一个新的列表并返回，也就是写成下面这种形式： 12345def multiply_2_pure(list): new_list = [] for item in list: new_list.append(item * 2) return new_list 对比上面两种写法，我们可以发现第一种写法中是直接修改了输入列表的元素，而第二种写法是返回了一个新的列表，新的列表存储了操作后的结果元素，并未修改原列表。**第二种写法无论传入多少次list，返回的结果都是一样的。**函数式编程的优点，就是其纯函数和不可变的特性使程序更加健壮，易于调试和测试，但是缺点是限制多，难写。 纯粹的函数式编程语言（比如Scala)，其编写的函数中是没有变量的，因此可以保证，只要输入是确定的，输出就是确定的。而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，因此同样的输入，可能也会得到不同的输出。 Python允许使用变量，所以他并不是一门纯函数式编程语言。Python仅对函数式编程提供了部分支持，主要包括map()，filter()和reduce()这3个函数。他们通常都和lambda匿名函数一起使用。 Python map()函数 1map(function, iterable) 其中，fucntion参数表示要传入一个函数，其可以是内置函数、自定义函数或者lambda匿名函数，iterable表示一个或者多个可迭代对象，可以是列表、字符串等。 map()函数的功能是对每一个可迭代对象中的每个元素，都调用指定的函数，并且返回一个map()对象。由于返回的是一个map()对象，因此不能直接输出，可以通过for循环或者list()函数来显示。 我们还是实现对列表中的每一个元素都乘2的功能： 123listDemo = [1, 2, 3, 4, 5]new_list = map(lambda x: x * 2, listDemo)print(list(new_list)) 运行结果： 1[2， 4， 6， 8， 10] 并且map()支持传入多个可迭代对象作为参数 1234listDemo1 = [1, 2, 3, 4, 5]listDemo2 = [3, 4, 5, 6, 7]new_list = map(lambda x,y: x + y, listDemo1,listDemo2)print(list(new_list)) 运行结果： 1[4, 6, 8, 10, 12] 由于map()函数是直接使用C语言写的，运行时不需要通过Python解释器间接调用，并且内部做了诸多优化，所以相比其他方法，此方法的运行效率更高。 Python filter()函数 1filter(function, iterable) 此格式中，fucntion参数要传入一个函数，iterable表示一个可迭代对象。 filter()函数的功能是对iterable中的每一个元素，都使用function函数判断，并返回True或者False，最后将True的元素组成一个新的可遍历的集合。即元素筛选。 123listDemo = [1, 2, 3, 4, 5]new_list = filter(lambda x: x % 2 == 0, listDemo)print(list(new_list)) 运行结果： 1[2, 4] Python reduce()函数 reduce() 函数通常用来对一个集合做一些累积操作，其基本语法格式为： 1reduce(function, iterable) function参数必须是一个包含两个参数的函数，iterable表示可迭代对象。 注意，由于reduce() 函数在 Python 3.x 中已经被移除，放入了 functools 模块，因此在使用该函数之前，需先导入 functools 模块。 假设我们要计算某个列表所有元素的乘积 1234import functoolslistDemo = [1, 2, 3, 4, 5]product = functools.reduce(lambda x, y: x * y, listDemo)print(product) 运行结果: 1120 总结 通常来说，当对集合中的元素进行一系列操作时，如果操作非常简单，比如累加、累积这种，那么优先考虑使用map()，filter()，reduce()等实现，另外，在数据量非常多的情况下（比如机器学习的应用），一般更倾向于使用函数式编程的表示，因为效率更高。 当然，在数据量不多的情况下，使用for循环等方式也是可以的，不过，如果要对集合中的元素做一些比较复杂的操作，考虑到代码的可读性，通常会使用for循环。"},{"title":"列表","path":"/wiki/Python学习笔记/列表/index.html","content":"Python序列 所谓序列，就是一块可以存放多个值的连续内存空间，这些值按照一定的顺序排列，可以通过每一个值所在位置的编号（称为索引）访问他们。 在Python中，序列类型包括字符串、列表（也称为数组）、元组、集合与字典（也称为映射），这些序列支持以下几种通用的操作。但是特殊地是集合和字典不支持索引、切片、相加和相乘操作。 序列索引 这个很好理解，从左到右索引值从0开始递增，我们使用A[index]的形式就可以获取指定位置的序列元素： 除此之外，Python还支持索引值是负数，此时索引是从又向左计数，换句话说，从最后一个元素开始计数，从索引值-1开始向左递减，如下所示： 要注意，使用负值作为序列中各元素的索引值时，是从-1开始，而不是从0开始，因为-0就是0就是开头元素。 123str=&quot;你好呀大帅哥&quot;print(str[0],&quot;==&quot;,str[-6])print(str[5],&quot;==&quot;,str[-1]) 运行结果： 12你 == 你哥 == 哥 序列切片 切片操作是访问序列中元素的另一种方法啊，他可以访问一定范围内的元素，通过切片操作，可以生成一个新的序列。一定要注意切片并不是操作原序列，而是生成一个新序列。 1sname[start : end : step] 其中，各个参数的含义分别是： sname：表示序列的名称； start：表示切片的开始索引位置（包括该位置），此参数也可以不指定，会默认为 0，也就是从序列的开头进行切片； end：表示切片的结束索引位置（不包括该位置），如果不指定，则默认为序列的长度； step：表示在切片过程中，隔几个存储位置（包含当前位置）取一次元素，也就是说，如果 step 的值大于 1，则在进行切片去序列元素时，会“跳跃式”的取元素。如果省略设置 step 的值，则最后一个冒号就可以省略。 要注意切片的范围是左闭右开[start,end），同时step默认是1，想要隔k个元素取一个元素，那么step要设置为step+1 1234567str=&quot;你好呀大帅哥&quot;#取索引区间为[0,2]之间（不包括索引2处的字符）的字符串print(str[:2])#隔 1 个字符取一个字符，区间是整个字符串print(str[::2])#取整个字符串，此时 [] 中只需一个冒号即可print(str[:]) 运行结果： 123你好你呀帅你好呀大帅哥 序列相加 Python中支持两种类型相同的序列使用+运算符进行相加操作，他会将两个序列进行连接，但是并不会取出重复的元素，而是仅仅简单的拼接。同时要注意这里的类型相同指的是两侧序列要么都是列表类型，要么都是元组类型，要么都是字符串。 序列相乘 在Python中，使用数字乘以一个序列会生成新的序列，其内容为原来序列被重复n次的结果。例如： 12str=&quot;你好呀大帅哥&quot;print(str*3) 运行结果： 1&#x27;你好呀大帅哥你好呀大帅哥你好呀大帅哥&#x27; 同时比较特殊的，列表类型在进行乘法运算时，还可以实现初始化指定长度列表的功能。例如如下的代码，将创建一个长度为5的列表，列表中的每一个元素都是None，表示什么都没有。 123#列表的创建用 []，后续讲解列表时会详细介绍list = [None]*5print(list) 运行结果： 1[None, None, None, None, None] 检查元素是否包含在序列中 在Python中，可以使用in关键字检查某元素是否为序列的成员，其语法格式为： 1value in sequence 其中value表示要检查的元素，sequence表示指定的序列。如下代码所示： 12str=&quot;coolchong.cn&quot;print(&#x27;c&#x27; in str) 运行结果： 1True 同时还有一个not in 关键字，他可以用来检查元素是否不包含在指定的序列中，比如： 12str=&quot;coolchong.cn&quot;print(&#x27;c&#x27; not in str) 运行结果： 1False 和序列相关的内置函数 同时Python还提供了一些有关序列的内置函数，其功能如下,注意这些函数都不会直接操作原序列而是生成一个新的值： 函数 功能 len() 计算序列的长度，即返回序列中包含多少个元素。 max() 找出序列中的最大元素。 min() 找出序列中的最小元素。 list() 将序列转换为列表。 str() 将序列转换为字符串。 sum() 计算元素和。注意，对序列使用 sum() 函数时，做加和操作的必须都是数字，不能是字符或字符串，否则该函数将抛出异常，因为解释器无法判定是要做连接操作（+ 运算符可以连接两个序列），还是做加和操作。 sorted() 对元素进行排序。（类型不变） reversed() 反向序列中的元素。（类型会变成reversed，需要再使用list()、或者tuple()转换回去） enumerate() 将序列组合为一个索引序列，多用在 for 循环中。 思考：enumerate()方法的应用？ 1enumerate(sequence, [start=0]) sequence是一个输入序列，start是下标起始位置，方法返回的是一个枚举对象。 12345&gt;&gt;&gt; seasons = [&#x27;Spring&#x27;, &#x27;Summer&#x27;, &#x27;Fall&#x27;, &#x27;Winter&#x27;]&gt;&gt;&gt; list(enumerate(seasons))[(0, &#x27;Spring&#x27;), (1, &#x27;Summer&#x27;), (2, &#x27;Fall&#x27;), (3, &#x27;Winter&#x27;)]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, &#x27;Spring&#x27;), (2, &#x27;Summer&#x27;), (3, &#x27;Fall&#x27;), (4, &#x27;Winter&#x27;)] 在遍历一个序列（列表或者元组）时，我们可以如下遍历，这样就同时可以使用索引和元素值了： 1234567&gt;&gt;&gt; seq = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]&gt;&gt;&gt; for i, element in enumerate(seq):... print i, element...0 one1 two2 three 思考：sorted(list)与list.sort()的区别？ 首先两种写法都是正确的，可以对列表进行排序，但是两个方法略有不同。首先就是返还值不同，sorted()是返还一个新的列表并不会操作原序列，而list.sort()则是直接操作原序列进行排序并且返还一个值None 1234567&gt;&gt;&gt; lst=[1,3,2,4]&gt;&gt;&gt; a=sorted(lst)&gt;&gt;&gt; print(lst,a,sep=&#x27;\\t&#x27;)[1, 3, 2, 4] [1, 2, 3, 4]&gt;&gt;&gt; b=lst.sort()&gt;&gt;&gt; print(lst,b,sep=&#x27;\\t&#x27;)[1, 2, 3, 4] None 同时sorted()和list.sort()还都可以通过使用key参数指定排序规则，并且是稳定排序，也就是说对于指定规则不能涵盖的元素，本来谁在前面，排好以后谁还是在前面。如下所示我们对列表重新制定排序规则，通过使用lambd重新定义排序规则为按照元素转换成字符串以后的长度排序： 12345678&gt;&gt;&gt; lst=[1,2,3,13,7,11]&gt;&gt;&gt; c=sorted(lst,key=lambda x:len(str(x)))&gt;&gt;&gt; print(lst,c,sep=&#x27;\\t&#x27;)[1, 2, 3, 13, 7, 11] [1, 2, 3, 7, 13, 11]&gt;&gt;&gt; d=lst.sort(key=lambda x:len(str(x)))&gt;&gt;&gt; print(lst,d,sep=&#x27;\\t&#x27;)[1, 2, 3, 7, 13, 11] None&gt;&gt;&gt; 实际上sorted()和list.sort()都是在通过key的值比较进行递增排序，默认key=None的但是我们也可以重定义key，一般使用lambda进行重定义（后面会讲到lambda，这里了解即可） 思考：如何实现降序排序？ 实际上排序函数语法如下： 12sorted(iterable,key=None,reverse=False)list.sort(iterable,key=None,reverse=False) 因此降序我们只需要将reverse设置为True即可啦： 1234567&gt;&gt;&gt; lst=[1,2,3,4,45,6]&gt;&gt;&gt; e=sorted(lst,reverse=True)&gt;&gt;&gt; print(lst,e,sep=&#x27;\\t&#x27;)[1, 2, 3, 4, 45, 6] [45, 6, 4, 3, 2, 1]&gt;&gt;&gt; f=lst.sort(reverse=True)&gt;&gt;&gt; print(lst,f,sep=&#x27;\\t&#x27;)[45, 6, 4, 3, 2, 1] None Python列表(list) 在C和Java中我们通常是使用数组Array来存储多个相邻连接的数据，但是在Python中是没有数组的，而是提供了一个更加强大的列表类型，他可以按成数组的所有操作同时还具有一些更加强大的函数。从形似上看，列表就是将所有元素放到一个中括号[]中，相邻元素之间使用,分隔，如下： 1[element1,element2,element3,...,elementn] Python的列表没有个数限制，存储范围为无限大，同时内容可以是任何类型如下所示一个列表可以存储许多不同类型的元素： 1[&quot;http://coolchong.cn/&quot;, 1, [2,3,4] , 3.0] 但是为了提高代码可读性，我们通常默认推荐使用列表存放一些数据类型相同的元素 Python创建列表 在Python中有两种创建列表的方法： 1）使用[]直接创建列表 使用[]创建列表，同时使用=将列表赋值给一个变量： 123um = [1, 2, 3, 4, 5, 6, 7]name = [&quot;C语言中文网&quot;, &quot;coolchong.cn&quot;]program = [&quot;C语言&quot;, &quot;Python&quot;, &quot;Java&quot;] 创建一个空列表只需要用[]表示即可 1emptylist=[] 2）使用list()函数创建列表 使用内置函数lis()创建一个列表，使用它可以将其他数据数据类型转换为列表类型： 1234567891011121314151617#将字符串转换成列表list1 = list(&quot;hello&quot;)print(list1)#将元组转换成列表tuple1 = (&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;)list2 = list(tuple1)print(list2)#将字典转换成列表dict1 = &#123;&#x27;a&#x27;:100, &#x27;b&#x27;:42, &#x27;c&#x27;:9&#125;list3 = list(dict1)print(list3)#将区间转换成列表range1 = range(1, 6)list4 = list(range1)print(list4)#创建空列表print(list()) 运行结果： 12345[&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;][&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;][&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;][1, 2, 3, 4, 5][] 注意对于字典转换为列表以后，只会存储key键，而映射值会丢失并不能存储到列表中 访问列表元素 列表是Python中序列的一种形式，因此我们可以使用索引来获取元素，同时也可以使用切片访问列表中的一组元素（得到的是一个新的子列表） 12345678url = list(&quot;http://c.biancheng.net/shell/&quot;)#使用索引访问列表中的某个元素print(url[3]) #使用正数索引print(url[-4]) #使用负数索引#使用切片访问列表中的一组元素print(url[9: 18]) #使用正数切片print(url[9: 18: 3]) #指定步长print(url[-6: -1]) #使用负数切片 运行结果： 12345pe[&#x27;b&#x27;, &#x27;i&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;c&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;n&#x27;, &#x27;g&#x27;][&#x27;b&#x27;, &#x27;n&#x27;, &#x27;e&#x27;][&#x27;s&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;] 一定要注意取元素一定是从左向右取，可以正/负索引搭配使用来划定要切片的范围，但是要保证范围是合法的 Python删除列表 对于不再使用的数据，我们统一使用del关键字进行删除，因此如果我们需要手动删除某个列表时使用del lst即可，如下： 1234intlist = [1, 45, 8, 34]print(intlist)del intlistprint(intlist) 运行结果： 12345[1, 45, 8, 34]Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(intlist)NameError: name &#x27;intlist&#x27; is not defined 思考：我们需要删除每一个不会再使用的变量吗？ 不需要，Python有自带的垃圾回收机制，当发现某个数据没有再被引用以后就会自动销毁，即使开发者不手动删除，Python也会自动将其回收。 Python list列表添加元素 我们直接尝试使用过+来拼接列表添加元素，如下所示： 123456language = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;]birthday = [1991, 1998, 1995]info = language + birthdayprint(&quot;language =&quot;, language)print(&quot;birthday =&quot;, birthday)print(&quot;info =&quot;, info) 运行结果： 123language = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]birthday = [1991, 1998, 1995]info = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, 1991, 1998, 1995] 但是我们会发现此时两个原列表并没有发生变化，拼接操作仅仅是将两个列表拼接生成一个新列表，但是我们如何修改原列表给他添加元素呢？ Python append()方法添加元素 append()方法就是用于在列表的末尾追加元素，该方法的语法格式如下： 1listname.append(obj) 其中listname就是要添加元素的列表，obj表示添加到列表末尾的数据，他可以是单个元素，也可以是列表、元组等。 1234567891011l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#追加元素l.append(&#x27;PHP&#x27;)print(l)#追加元组，整个元组被当成一个元素t = (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)l.append(t)print(l)#追加列表，整个列表也被当成一个元素l.append([&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l) 运行结果： 123[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;, (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;, (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;]] 我们会发现使用append()方法添加列表或者元组时得到的结果和我们预期略有不同，它仅仅是将列表或者元组整体追加到了后面，但是我们更希望把其内部的元素逐一取出添加到末尾。 Python extend()方法添加元素 extend()和append()的不同之处：extend()不会把列表或者元组视为一个整体，而是把它们包括的元素逐个添加到列表末尾。 1234567891011l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#追加元素l.extend(&#x27;C&#x27;)print(l)#追加元组，元祖被拆分成多个元素t = (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)l.extend(t)print(l)#追加列表，列表也被拆分成多个元素l.extend([&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l) 运行结果： 123[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;, &#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;, &#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;, &#x27;Ruby&#x27;, &#x27;SQL&#x27;] Python insert()方法插入元素 append()和extend()都只能在列表的末尾追加元素，但是如果我们希望在列表中间插入元素，那么次是就会使用到insert()方法，格式如下： 1listname.insert(index , obj) 其中，index表示指定位置的索引值，insert()会将obj插入到listname列表第index个元素的位置，更好理解的说就是新插入的元素在新标中的索引位置为index。同时我们要注意insert()也是将要插入的列表或者元组视为一个整体插入到列表中，这一点和append()一样。 1234567891011121314l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#插入元素l.insert(1, &#x27;C&#x27;)print(l)#插入元组，整个元祖被当成一个元素t = (&#x27;C#&#x27;, &#x27;Go&#x27;)l.insert(2, t)print(l)#插入列表，整个列表被当成一个元素l.insert(3, [&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l)#插入字符串，整个字符串被当成一个元素l.insert(0, &quot;http://coolchong.cn&quot;)print(l) 运行结果： 1234[&#x27;Python&#x27;, &#x27;C&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;], &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;coolchong.cn&#x27;, &#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;], &#x27;C++&#x27;, &#x27;Java&#x27;] Python list列表删除元素 在Python列表中想要删除元素主要有以下三种场景： 根据目标元素所在位置的索引进行删除，可以使用 del 关键字或者 pop() 方法； 根据元素本身的值进行删除，可使用列表（list类型）提供的 remove() 方法； 将列表中所有元素全部删除，可使用列表（list类型）提供的 clear() 方法。 del:根据索引值删除元素 del是Python中的关键字，专门用来执行数据删除操作，他不仅可以删除列表整体，也可以删除列表中指定位置的元素。格式为： 1234#删除一个指定元素del listname[index]#删除[star,end)范围的元素del listname[start : end] 12345678910111213lang = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;, &quot;PHP&quot;, &quot;Ruby&quot;, &quot;MATLAB&quot;]#使用正数索引del lang[2]print(lang)#使用负数索引del lang[-2]print(lang)lang = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;, &quot;PHP&quot;, &quot;Ruby&quot;, &quot;MATLAB&quot;]del lang[1: 4]print(lang)lang.extend([&quot;SQL&quot;, &quot;C#&quot;, &quot;Go&quot;])del lang[-5: -2]print(lang) 运行结果： 1234[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;PHP&#x27;, &#x27;Ruby&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;PHP&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;Ruby&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;] 要注意dellistname[start,end]此时表示的就是删除原列表！ 思考：什么时候切片是新列表?什么时候是引用原列表？ 这个地方非常容易混淆，我们要注意：可以使用切片来截取列表中的任何部分，得到一个新列表，也可以通过切片来修改和删除列表中部分元素，甚至可以通过切片操作为列表对象增加元素。 只有在删除和=赋值的时候切片表示原引用列表，其他情况下都是一个新列表对象，如下所示： 12345678910111213&gt;&gt;&gt; lst=[1,2,3]#此时不是赋值，因此是为新列表添加元素，原列表不会发生变化&gt;&gt;&gt; lst[:].append(4)&gt;&gt;&gt; print(lst)[1, 2, 3]#此时是赋值修改，因此是原列表发生变化&gt;&gt;&gt; lst[:]=[1,2,3,4]&gt;&gt;&gt; print(lst)[1, 2, 3, 4]#删除操作直接删除原列表部分元素&gt;&gt;&gt; del lst[2:]&gt;&gt;&gt; print(lst)[1, 2] Pop():根据索引值删除元素 使用listname.pop(index)可以删除指定索引出的元素，如果不指定index那么默认删除的是列表的最后一个元素类似于数据结构中的出栈操作，此种方法不支持范围删除。 12345nums = [40, 36, 89, 2, 36, 100, 7]nums.pop(3)print(nums)nums.pop()print(nums) 运行结果： 12[40, 36, 89, 36, 100, 7][40, 36, 89, 36, 100] 要注意虽然Python中列表由pop()表示删除元素，但是插入元素可不是push()而是append() remove():根据元素值进行删除 除了使用del和pop()删除指定索引值的元素，我们还可以使用remove()来删除指定元素值，但是要注意他每一次只会删除第一个值匹配的元素，并且必须保证要删除的元素存在，否则会报异常 12345678910nums = [40, 36, 89, 2, 36, 100, 7]#第一次删除36nums.remove(36)print(nums)#第二次删除36nums.remove(36)print(nums)#删除78nums.remove(78)print(nums) 运行结果： 123456[40, 89, 2, 36, 100, 7][40, 89, 2, 100, 7]Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 9, in &lt;module&gt; nums.remove(78)ValueError: list.remove(x): x not in list clear():删除所有元素 Python可以使用clear()删除列表的所有元素，即清空列表但是此时列表自身还是存在的只是变成了一个空列表： 123url = list(&quot;http://c.biancheng.net/python/&quot;)url.clear()print(url) 运行结果： 1[] 思考：搜索并逐一删除元素的写法？ 假设现在有一个场景，是当列表中存在元素为1时，那我们就要将这个元素删除，此时你会怎么写？我猜测你的第一想法一定是： 1234lst=[1,1,1,2,1,1,1]for i in range(len(lst)): if(lst[i]==1): del lst[i] 我们会发现报错了，此时他报的错是列表访问越界： 1234Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 9, in &lt;module&gt; if(lst[i]==1):IndexError: list index out of range 这是为什么呢？原因是列表在删除过程中会逐渐变短，而i使用是在原列表长度的范围内进行递增，因此只要删除了一个或者多个元素，那么后面就一定会出现越界。我们以一个例子为例体会一下这个过程： 1234lst=[1,2,2,3,1,1,4]for i in range(len(lst)): print(i,lst[i],sep=&quot;|&quot;) del lst[i] 假设现在我们要遍历一个列表，每次都打印此次访问到的元素索引值和元素值，然后再删除这个元素，那么我们最终得到的结果如下： 123456789PS D:\\Pythoncode&gt; &amp; D:/Python/anaconda3/python.exe d:/Pythoncode/Algrithm/test.py 0|11|22|13|4Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 3, in &lt;module&gt; print(i,lst[i],sep=&quot;|&quot;)IndexError: list index out of range 这个过程如上所示，因此我们发现这种方法删除元素是不可行的，为了解决这个问题，我们只需要让i倒着遍历列表并删除即可了： 12345lst=[1,2,2,3,1,1,4]#i的范围为[len(lst)-1,-1)，每一次i都减一for i in range(len(lst)-1,-1,-1): print(i,lst[i],sep=&quot;|&quot;) del lst[i] 运行结果： 12345678PS D:\\Pythoncode&gt; &amp; D:/Python/anaconda3/python.exe d:/Pythoncode/Algrithm/test.py6|45|14|13|32|21|20|1 我们可以使用remove()方法来实现类似的删除元素值的功能，他的写法如下： 123456lst=[1,2,2,3,1,1,4]#思考：这里为什么是lst的全范围切片？for el in lst[:]: if(el==1): lst.remove(el)print(lst) 运行结果： 1[2, 2, 3, 4] 这里我们要注意必须是遍历全范围切片，原因很简单和上面类似，如果我们直接在lst中遍历并删除也会造成数组越界的问题，为了解决这个问题，我们使用的策略是遍历一个lst的全范围切片子列表（可以看成是复制了一个列表），在里面寻找是否还有要删除的元素，如果有就调用一次lst.remove()删除，这样我们就保证了每一次调用lst.remove()时保证了一定还有可以删除的元素。同时由于遍历查找和删除的是两个不同的列表，因此就不会造成访问越界了，毕竟el遍历的切片子列表一直就没有变化。 Python list列表修改元素 修改单个元素 1234nums = [40, 36, 89, 2, 36, 100, 7]nums[2] = -26 #使用正数索引nums[-3] = -66.2 #使用负数索引print(nums) 运行结果： 1[40, 36, -26, 2, -66.2, 100, 7] 修改一组元素 Python 支持通过切片语法给一组元素赋值。在进行这种操作时，如果不指定步长（step 参数），Python 就不要求新赋值的元素个数与原来的元素个数相同；这意味，该操作既可以为列表添加元素，也可以为列表删除元素。 1234nums = [40, 36, 89, 2, 36, 100, 7]#修改第 1~4 个元素的值（不包括第4个元素）nums[1: 4] = [45.25, -77, -52.5]print(nums) 运行结果： 1[40, 45.25, -77, -52.5, 36, 100, 7] 如果对空切片（slice）赋值，就相当于插入一组新的元素： 1234nums = [40, 36, 89, 2, 36, 100, 7]#在4个位置插入元素nums[4: 4] = [-77, -52.5, 999]print(nums) 运行结果： 1[40, 36, 89, 2, -77, -52.5, 999, 36, 100, 7] 但是我们要注意使用切片语法赋值时，Python 不支持单个值（必须是一个列表才行），例如下面的写法就是错误的： 1234nums[4: 4] = -77File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 3, in &lt;module&gt; nums[4: 4] = -77TypeError: can only assign an iterable 只需要修改为 1nums[4: 4] = [-77] 但是如果使用字符串赋值，Python会自动把字符串转换成序列，其中的每个字符都是一个元素： 1234nums = [40, 36, 89, 2, 36, 100, 7]#在4个位置插入元素nums[4: 4] = &quot;xyz&quot;print(nums) 运行结果： 1[40, 36, 89, 2, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;, 36, 100, 7] Python list列表查找元素 index()方法 1istname.index(obj, start, end) listname表示列表名称，obj表示要查找的元素，start表示查找起始位置，end表示结束位置。index方法用来查找某个元素在[start,end)列表中首次出现的位置。 start 和 end 可以都不写，此时会检索整个列表； 如果只写 start 不写 end，那么表示检索从 start 到末尾的元素； 如果 start 和 end 都写，那么表示检索 start 和 end 之间的元素。 123456789nums = [40, 36, 89, 2, 36, 100, 7, -20.5, -999]#检索列表中的所有元素print( nums.index(2) )#检索3~7之间的元素print( nums.index(100, 3, 7) )#检索4之后的元素print( nums.index(7, 4) )#检索一个不存在的元素print( nums.index(55) ) 运行结果： 1234567356Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 9, in &lt;module&gt; print( nums.index(55) )ValueError: 55 is not in list 要注意当要查找的元素不存在时，则会导致ValueError错误，因此在使用index()之前最好使用count()方法判断一下 count()方法 1listname.count(obj) 其中listname是列表名称，obj是要统计的元素。count()方法用来统计某个元素在列表中出现的次数，我们可以使用这个方法来判断哪一个列表是否包含某个元素。如果count()返还0则说明列表中不存在这个元素。 12345678nums = [40, 36, 89, 2, 36, 100, 7, -20.5, 36]#统计元素出现的次数print(&quot;36出现了%d次&quot; % nums.count(36))#判断一个元素是否存在if nums.count(100): print(&quot;列表中存在100这个元素&quot;)else: print(&quot;列表中不存在100这个元素&quot;) 运行结果： 1236出现了3次列表中存在100这个元素 Python range()快速初始化数字列表 range()语法格式和切片很像，也有三个参数： 1range(start, stop[, step]) start是起始位置，stop是结束位置，step是步长，同时也是左闭右开[start,stop)，且当只填写一个数字时默认从0开始，但是我们要注意range()生成的元素组成的并不是列表list类型： 12print(type(range(5)))&lt;class &#x27;range&#x27;&gt; 因此如果我们想要视同range()快速初始化列表需要在最外侧转换成list类型，同时我们使用step步长可以初始化一些特殊列表： 比如1~10内的偶数组成的列表： 12even_numbers = list(range(2,11,2))print(even_numbers) 运行结果： 1[2, 4, 6, 8, 10] 思考：还有没有其他高级写法？ 列表推导(List Comprehension) 是一种数学家用来实现众所周知标记集合的Python方式。它由方括号组成，包含一个表达式，后跟一个for子句，后面跟一个可选的if子句。 表达式可以是我们想要放入列表中的任何类型的对象；由于我们用零初始化列表，因此我们的表达式将只为0。 1arr = [0 for i in range(1000)] 当然也可以用等价的写法： 1arr=[0]*1000 使用列表推导也可以写1-10以内的偶数组成的列表： 1even_numbers = [i for i in range(2,11,2)] Python 使用list模拟栈和队列 list模拟栈 栈stack的特点就是后进先出，因此我们必须保证pop()时弹出的是最后进来的元素，因此只需要插入元素使用append()即可模拟： 123456789 #定义一个空 list 当做栈stack = []stack.append(1)stack.append(2)stack.append(&quot;hello&quot;)print(stack)print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop()) 运行结果： 1234[1, 2, &#x27;hello&#x27;]取一个元素： hello取一个元素： 2取一个元素： 1 list模拟队列 队列queue特点是先进先出，因此我们必须保证pop()时弹出的是最先进来的元素，因此只需要保证插入元素使用insert(0,obj)即可模拟： 12345678910 #定义一个空列表，当做队列queue = []#向列表中插入元素queue.insert(0,1)queue.insert(0,2)queue.insert(0,&quot;hello&quot;)print(queue)print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop()) 运行结果： 1234[&#x27;hello&#x27;, 2, 1]取一个元素： 1取一个元素： 2取一个元素： hello"},{"title":"流程控制","path":"/wiki/Python学习笔记/流程控制/index.html","content":"Python if else条件语句详解 123456789101112131415height = float(input(&quot;输入身高（米）：&quot;))weight = float(input(&quot;输入体重（千克）：&quot;))bmi = weight / (height * height) #计算BMI指数if bmi&lt;18.5: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;体重过轻&quot;)elif bmi&gt;=18.5 and bmi&lt;24.9: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;正常范围，注意保持&quot;)elif bmi&gt;=24.9 and bmi&lt;29.9: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;体重过重&quot;)else: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;肥胖&quot;) 运行结果： 1234输入身高（米）：1.7↙输入体重（千克）：70↙BMI指数为：24.221453287197235正常范围，注意保持 要注意Python的判断条件语句后面要加上冒号:，同时他是通过缩进来识别代码块的，不支持大括号包裹，具有相同缩进量的若干行代码属于同一个代码块，因此我们要注意Python中的代码缩进量。 要注意Python中的elseif可以使用更简洁的elif来代替书写。 如何判断表达式是否成立 在Python中if和elif后面的“表达式”的形式是很自由的，只要表达式有一个结果，不管这个结果是什么类型，Python都能判断他是“真”还是“假”。布尔类型有两个值分别是True和False，Python会把True当做真，False当做假。但是对于数字，Python会把0和0.0当做假，其他值都当做真。而对于对象或者序列，当他们为空或者None时，Python会把他们当做假，其他情况当做真，比如下面的表达式都是不成立(假)的： 12345&quot;&quot; #空字符串[ ] #空列表( ) #空元组&#123; &#125; #空字典None #空值 123456789101112131415161718192021222324252627282930313233b = Falseif b: print(&#x27;b是True&#x27;)else: print(&#x27;b是False&#x27;)n = 0if n: print(&#x27;n不是零值&#x27;)else: print(&#x27;n是零值&#x27;)s = &quot;&quot;if s: print(&#x27;s不是空字符串&#x27;)else: print(&#x27;s是空字符串&#x27;)l = []if l: print(&#x27;l不是空列表&#x27;)else: print(&#x27;l是空列表&#x27;)d = &#123;&#125;if d: print(&#x27;d不是空字典&#x27;)else: print(&#x27;d是空字典&#x27;) #不规定时默认函数返还Nonedef func(): print(&quot;函数被调用&quot;)if func(): print(&#x27;func()返回值不是空&#x27;)else: print(&#x27;func()返回值为空&#x27;) 运行结果： 1234567b是Falsen是零值s是空字符串l是空列表d是空字典函数被调用func()返回值为空 对于没有return语句的函数，返回值即为空，也即None Python pass语句及其作用 在实际开发中，有时候我们先搭建起程序的整体逻辑框架，但是暂时不去实现某些细节，而是在这些地方加一些注释，方便以后添加代码，如下所示： 1234567891011age = int( input(&quot;请输入你的年龄：&quot;) )if age &lt; 12 : print(&quot;婴幼儿&quot;)elif age &gt;= 12 and age &lt; 18: print(&quot;青少年&quot;)elif age &gt;= 18 and age &lt; 30: print(&quot;成年人&quot;)elif age &gt;= 30 and age &lt; 50: #TODO: 成年人else: print(&quot;老年人&quot;) 当年龄大于等于30并且小于50时，我们没有使用print()语句，而是使用了一个注释，希望以后再处理成年人的情况，当Python执行到这个elif分支时，会跳过注释，什么都不执行。但是Python系统了一个更加专业的做法，就是空语句pass,pass是Pytohn中的关键字，用来让解释器跳过此处，什么都不做。 就像上面的情况，有时候程序需要占用一个位置，后者放一条语句，但是又不希望这条语句做任何事情，此时就可以通过pass语句来实现，使用pass语句比使用注释更加优雅。 1234567891011age = int( input(&quot;请输入你的年龄：&quot;) )if age &lt; 12 : print(&quot;婴幼儿&quot;)elif age &gt;= 12 and age &lt; 18: print(&quot;青少年&quot;)elif age &gt;= 18 and age &lt; 30: print(&quot;成年人&quot;)elif age &gt;= 30 and age &lt; 50: passelse: print(&quot;老年人&quot;) 运行结果： 1请输入你的年龄：40↙ 从运行结果可以看出，程序虽然执行到第10行代码，但是并没有进行什么操作、 Python assert断言函数及其用法 assert语句又称为断言语句，可以看成是功能缩小版的if语句，他用来判断某个表达式的值，如果值为真，则程序可以继续往下执行，反之如果值为假，那么Python解释器就会报AssertionError错误，程序退出执行。 12345mathmark = int(input())#断言数学考试分数是否位于正常范围内assert 0 &lt;= mathmark &lt;= 100#只有当 mathmark 位于 [0,100]范围内，程序才会继续执行print(&quot;数学考试分数为：&quot;,mathmark) 如果输入的分数为90那么程序可以正常执行： 1290数学考试分数为： 90 但是如果输入的值为159此时表达式为假，程序就会报错： 12345159Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 3, in &lt;module&gt; assert 0 &lt;= mathmark &lt;= 100AssertionError 你可能会疑惑，命名assert会令程序崩溃，为什么还要使用它呢？这是因为，预期让程序在晚些时候崩溃，不如再错误条件出现时，就直接让程序崩溃，这样有利于我们对程序排错，提高程序的健壮性。 因此assert语句通常用于检查用户的输入是否符合规定，还经常用作程序初期测试和调试过程中的辅助工具。 Python while循环语句 12345my_char=&quot;http://c.biancheng.net/python/&quot;i = 0;while i&lt;len(my_char): print(my_char[i],end=&quot;&quot;) i = i + 1 运行结果： 1http://c.biancheng.net/python/ 只需要保证while在有限次循环以后能够退出就行，同时循环体内部的代码缩进要相同。 Python for循环及用法详解 1234for 迭代变量 in 字符串|列表|元组|字典|集合： 代码块for 索引值,元素 in 枚举: 代码块 12345my_dic = &#123;&#x27;python教程&#x27;:&quot;http://c.biancheng.net/python/&quot;,\\ &#x27;shell教程&#x27;:&quot;http://c.biancheng.net/shell/&quot;,\\ &#x27;java教程&#x27;:&quot;http://c.biancheng.net/java/&quot;&#125;for ele in my_dic: print(&#x27;ele =&#x27;, ele) 运行结果： 123ele = python教程ele = shell教程ele = java教程 要注意对于字典的遍历，默认取出来的是键，因此如果想要获取相应的值还需要使用get()方法。 Python循环结构else用法 在Pytohn中，无论是while循环还是for循环，其实都可以紧跟一个else代码块，他们的作用是当循环条件为False跳出循环时，程序会最先执行else代码块中的代码。 1234567add = &quot;http://c.biancheng.net/python/&quot;i = 0while i &lt; len(add): print(add[i],end=&quot;&quot;) i = i + 1#原本位于 else 代码块中的代码print(&quot; 执行 else 代码块&quot;) 运行结果: 12http://c.biancheng.net/python/执行 else 代码块 12345add = &quot;http://c.biancheng.net/python/&quot;for i in add: print(i,end=&quot;&quot;)else: print(&quot; 执行 else 代码块&quot;) 运行结果： 12http://c.biancheng.net/python/执行 else 代码块 我们发现一个问题，就是上面的代码完全不可不添加else也可以实现相同的效果，那也就是说else语句没有用处吗？并不是的，else代码块经常和break结合使用实现一些特殊用处。 Python嵌套循环实现冒泡排序 冒泡排序是数据结构中的经典算法，他的时间复杂度为O(n^2)，就是两个循环的简单嵌套，因此接下来我们尝试使用Python来实现这个冒泡排序。 冒泡排序算法的实现思想遵循以下几步： 比较相邻的元素，如果第一个比第二个大，就交换它们两个。 从最开始的第一对到结尾的最后一对，对每一对相邻元素做步骤 1 所描述的比较工作，并将最大的元素放在后面。这样，当从最开始的第一对到结尾的最后一对都执行完后，整个序列中的最后一个元素便是最大的数。 将循环缩短，除去最后一个数（因为最后一个已经是最大的了），再重复步骤 2 的操作，得到倒数第二大的数。 持续做步骤 3 的操作，每次将循环缩短一位，并得到本次循环中的最大数。直到循环个数缩短为 1，即没有任何一对数字需要比较，此时便得到了一个从小到大排序的序列。 例如，使用 for 循环实现用冒泡排序算法对 [5,8,4,1] 进行排序： 1234567data = [5,8,4,1]#实现冒泡排序for i in range(len(data)-1): for j in range(len(data)-i-1): if(data[j]&gt;data[j+1]): data[j],data[j+1] = data[j+1],data[j]print(&quot;排序后：&quot;,data) 运行结果： 1排序后： [1, 4, 5, 8] 可以看到，实现冒泡排序使用了 2 层循环，其中外层循环负责冒泡排序进行的次数，而内层循环负责将列表中相邻的两个元素进行比较，并调整顺序，即将较小的放在前面，较大的放在后面。 Python break用法详解 在while和for循环中，只要循环条件满足，程序就会一直执行循环体，不停地转圈。但是在某些场景下，我们可能希望程序在循环结束前就能强制退出循环，此时我们就需要使用Python提供的两种强制离开的办法了： 使用 continue 语句，可以跳过执行本次循环体中剩余的代码，转而执行下一次的循环。 只用 break 语句，可以完全终止当前循环。 在上一节我们学习到for可以配备一个else语句，那么在这种情况下，如果使用break语句跳出循环，就不会执行else包含的代码，如下所示： 123456789add = &quot;http://c.biancheng.net/python/,http://c.biancheng.net/shell/&quot;for i in add: if i == &#x27;,&#x27; : #终止循环 break print(i,end=&quot;&quot;)else: print(&quot;执行 else 语句中的代码&quot;)print(&quot; 执行循环体外的代码&quot;) 从输出结果可以看出，使用 break 跳出当前循环体之后，该循环后的 else 代码块也不会被执行。但是，如果将 else 代码块中的代码直接放在循环体的后面，则该部分代码将会被执行。 Python推导式初始化序列 列表推导式 12[表达式 for item in 可迭代对象][表达式 for item in 可迭代对象 if 条件判断] 之前我们实际上已经简单的学习了使用推导式进行序列的初始化，比如： 12y = [x for x in range(1, 5)]print(y) 运行结果： 1[1, 2, 3, 4] 进一步，我们可以在for后面添加一个if条件语句进行元素的筛选，比如： 12y = [x for x in range(1, 50) if x % 5 == 0]print(y) 运行结果： 1[5, 10, 15, 20, 25, 30, 35, 40, 45] 如山所示，我们使用if条件句和for循环推导式初始化了一个50以内所有5的倍数组成的列表。 我们甚至可以使用多个for初始化一个元素为元组的列表如下所示： 12y = [(row, col) for row in range(1, 7) if row % 2 != 0 for col in range(1, 7) if col % 2 == 0]print(y) 运行结果： 1[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)] 字典推导式 1&#123;key表达式: value表达式 for item in 可迭代对象&#125; 比如我们统计一个字符串中各字符出现的次数： 123text = &#x27;you could not see my tears cause I am in the water&#x27;char_count = &#123;c: text.count(c) for c in text&#125;print(char_count) 运行结果： 1&#123;&#x27;y&#x27;: 2, &#x27;o&#x27;: 3, &#x27;u&#x27;: 3, &#x27; &#x27;: 11, &#x27;c&#x27;: 2, &#x27;l&#x27;: 1, &#x27;d&#x27;: 1, &#x27;n&#x27;: 2, &#x27;t&#x27;: 4, &#x27;s&#x27;: 3, &#x27;e&#x27;: 6, &#x27;m&#x27;: 2, &#x27;a&#x27;: 4, &#x27;r&#x27;: 2, &#x27;I&#x27;: 1, &#x27;i&#x27;: 1, &#x27;h&#x27;: 1, &#x27;w&#x27;: 1&#125; 集合推导式 12&#123;表达式 for item in 可迭代对象&#125;&#123;表达式 for item in 可迭代对象 if 条件判断&#125; 12y = &#123;x for x in range(1, 50) if x % 5 == 0&#125;print(y) 运行结果： 1&#123;35, 5, 40, 10, 45, 15, 20, 25, 30&#125; 生成器推导式（生成元组） 12(表达式 for item in 可迭代对象)(表达式 for item in 可迭代对象 if 条件判断) 这样会返还一个生成器对象，一个生成器只能使用一次。 12y = (x for x in range(1, 50) if x % 5 == 0)print(y) 1&lt;generator object &lt;genexpr&gt; at 0x0000025228C64518&gt; 接下来我们遍历这个y 123456789101112131415&gt;&gt;&gt; y = (x for x in range(1, 50) if x % 5 == 0)&gt;&gt;&gt; for i in y: print(i)...51015202530354045&gt;&gt;&gt; for i in y: print(i)...&gt;&gt;&gt; 我们发现第二次遍历时y的元素不见了。因此一定要注意这种表达式初始化的生成器对象（元组）只能使用一次。 Python zip函数 zip()函数时Python内置函数之一，他可以将多个序列(列表、元组、字典、集合、字符串以及range()区间构成的列表)“压缩”成一个zip对象，所谓压缩，就是将这些列表中对应位置的元素重新组合，生成一个新的元组。 1zip(iterable, ...) 其中 iterable,… 表示多个列表、元组、字典、集合、字符串，甚至还可以为 range() 区间。 123456789my_list = [11,12,13]my_tuple = (21,22,23)print([x for x in zip(my_list,my_tuple)])my_dic = &#123;31:2,32:4,33:5&#125;my_set = &#123;41,42,43,44&#125;print([x for x in zip(my_dic)])my_pychar = &quot;python&quot;my_shechar = &quot;shell&quot;print([x for x in zip(my_pychar,my_shechar)]) 运行结果： 123[(11, 21), (12, 22), (13, 23)][(31,), (32,), (33,)][(&#x27;p&#x27;, &#x27;s&#x27;), (&#x27;y&#x27;, &#x27;h&#x27;), (&#x27;t&#x27;, &#x27;e&#x27;), (&#x27;h&#x27;, &#x27;l&#x27;), (&#x27;o&#x27;, &#x27;l&#x27;)] 注意在使用zip()函数“压缩”多个序列时，他会分别读取各序列中第1个元素，第2个元素、…、第n个元素，各自组成一个新的元组。特别注意，当多个序列中元素个数不一致时，会以最短的序列为准进行压缩。 另外，对于 zip() 函数返回的 zip 对象，既可以像上面程序那样，通过遍历提取其存储的元组，也可以向下面程序这样，通过调用 list() 函数将 zip() 对象强制转换成列表： 123my_list = [11,12,13]my_tuple = (21,22,23)print(list(zip(my_list,my_tuple))) 运行结果： 1[(11, 21), (12, 22), (13, 23)] Python reversed()函数及用法 reversed()函数时Python内置函数之一，其功能是对于给定的序列（包括列表、元组、字符串以及range(n)区间)，该函数可以返回一个逆序序列的迭代器（注意是一个新的迭代器类型，没有len())方法，如果必要需要使用list()，tuple()等函数进行转换)用于遍历该逆序序列。 1reversed(seq) 其中，seq 可以是列表，元素，字符串以及 range() 生成的区间列表。 12345678#将列表进行逆序print([x for x in reversed([1,2,3,4,5])])#将元组进行逆序print([x for x in reversed((1,2,3,4,5))])#将字符串进行逆序print([x for x in reversed(&quot;abcdefg&quot;)])#将 range() 生成的区间列表进行逆序print([x for x in reversed(range(10))]) 运行结果： 1234[5, 4, 3, 2, 1][5, 4, 3, 2, 1][&#x27;g&#x27;, &#x27;f&#x27;, &#x27;e&#x27;, &#x27;d&#x27;, &#x27;c&#x27;, &#x27;b&#x27;, &#x27;a&#x27;][9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 同样的我们也可以使用list()函数将reversed()函数逆序返还的迭代器直接转换成列表进行打印： 12#将列表进行逆序print(list(reversed([1,2,3,4,5]))) 运行结果： 1[5, 4, 3, 2, 1] 再次强调，使用 reversed() 函数进行逆序操作，并不会修改原来序列中元素的顺序，例如： 1234a = [1,2,3,4,5]#将列表进行逆序print(list(reversed(a)))print(&quot;a=&quot;,a) 运行结果： 12[5, 4, 3, 2, 1]a= [1, 2, 3, 4, 5]"},{"title":"分治思想","path":"/wiki/手撕算法笔记/分治思想/index.html","content":"什么是分治 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。即一种分目标完成程序算法，简单问题可用二分法完成。 根据度娘讲解我们知道其本质就是化繁为简，将复杂问题拆分成若干简单问题在进行合并得到复杂问题的最优解。归并排序、快速排序、dp算法等都是分治思想的应用，运用分治思想求解问题，可以大大降低时间复杂度，将其变为O(nlogn)型减少计算。 使用条件 该问题的规模缩小到一定的程度就可以容易地解决； 该问题可以分解为若干个规模较小的相同问题； 利用该问题分解出的子问题的解可以合并为该问题的解； 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子问题。 最后一条特征涉及到分治法的效率，如果各子问题是不独立的，则分治法会做许多重复的不必要的计算工作，重复地解公共的子问题，此时虽然可以使用分治法，但是却并未达到降低时间复杂度的预期效果，所以一般用动态规划更好。 伪代码 123456789divide-and-conquer(P)&#123;　if ( | P | &lt;= n0) adhoc(P); //解决小规模的问题　divide P into smaller subinstances P1,P2,...,Pk；//分解问题　for (i=1,i&lt;=k,i++)　yi=divide-and-conquer(Pi); //递归的解各子问题　return merge(y1,...,yk); //将各子问题的解合并为原问题的解&#125; 从大量实验发现，在使用分治法设计算法时，最好尽量使子问题的规模大致相同，即将一个问题分成大小相等的k个子问题进行处理，这种时子问题规模大致相等的做法是出自一种平衡子问题的思想，他几乎总是比子问题规模不等的做法要好。 典型例题精讲 找出伪币 现有16个硬币，其中有一个是伪币，并且伪币重量比真币轻。试用一台天平找出这枚伪币。 直接求解：两两比较，最坏情况需要8次找出伪币。 分治法：先分成两堆（各堆8个硬币）称重，然后轻的一堆在分成堆…仅需4次即可找出伪币。 计算a^n的值 直接求解：暴力相乘，时间复杂度为O(n)。 分治法： k={n/2,n=evenn−1/2,n=oddk= \\begin{cases} n/2,n=even\\\\ n-1/2,n=odd \\end{cases} k={n/2,n=evenn−1/2,n=odd​ an=ak∗ak//分治法思想a^n=a^k*a^k//分治法思想 an=ak∗ak//分治法思想 所以递归式为T(n)=T(n/2)+O(1)，根据Master定理我们得到logba=0,k=0,所以T(n)=O(logn),时间复杂度降低。 金块问题 有若干金块试用一台天平找出其中最轻和最重的金块,n个数中找出最大和最小的数 直接求解：先找出最大值，然后在剩下的n-1个数中再找出最小值，需要比较2n-3次比较。 直接求解改进：一个数要么是最大值，要么是最小值，所以一个数只需要比较一次即可，这样优化后伪代码如下： 1234567min←a[0];max←a[0];For i←1 to n-1 do if a[i]&lt;min min←a[i] else if a[i]&gt;max max←a[i] 当输入的数组伪排好序时，算法需要2*(n-1)次比较，当输入为逆序时，算法要做n-1次比较，虽然有所较少比较次数，但是时间复杂度认为O(n)，并未改变时间复杂度。 分治法：我们这里使用分治的思想，即将max和min值都设置为arr[0]，然后以2位单位不断拆分直至全部拆分为2个数为一组，然后这两个数中选最大值和最小值，如果恰巧不能完整分组，那么就一个数时既是最大值，也是最小值，然后合并merge时只需要比较每组的最大值和最小值，来选取总数组的最大值和最小值。伪代码如下： 1234567891011Max-min(A[0,n-1],max,min) if n=1 max←min←a[0],return; if n=2 &#123;if a[0]≥a[1] max←a[0],min←a[1] else max←a[1],min←a[0];&#125; else m←n/2 Max-min(A[0,m-1],max1,min1), Max-min(A[m,n-1],max2,min2), max←max(max1,max2), min←min(min1,min2), return. 分析时间复杂度，c(1)=0,c(2)=1,c(n)=2c(n/2)+2,迭代可得c(n)=(3n/2)-2。分治法比直接求解法少用了25%次比较。 上面的伪代码中我们使用了递归调用，但是仔细分析，最终分组的情况无非就是拆成两个相邻的数为一组一个为最大值，一个为最小值，然后从这些最大值和最小值里面寻找最终的最大值解和最小值解，所以我们可以解递归，使用非递归的伪代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445template&lt;class T&gt;bool Max-min(T w[],int n,T&amp; Min,T&amp; Max)&#123;\t//寻找w[0:n-1]中的最小和最大值\t//如果少于一个元素，直接退出程序，一个元素就同时为最大值和最小值\t//特殊情况讨论\tif(n&lt;1)return false;\tif(n==1)&#123;Min=Max=w[0];return;&#125;\t//多于一个时，先对Min和Max初始化，我们可以初始化为\tMin=0xffff,Max=0;\tint s;//循环起点\t//讨论第一组\tif(n%2)&#123;\t//n为奇数\t//先单独把第一个数拿出来当第一组，这样后面就是偶数个了 Min=Max=w[0]; s=1;\t&#125;\telse&#123;\t//n为偶数 if(w[0]&gt;w[1])&#123; Min=w[1]; Max=w[0]; &#125; else&#123; Min=w[0]; Max=w[1]; &#125; s=2;\t&#125;\t//剩下的数对分别比大小\tfor(int i=s;i&lt;n;i+=2)&#123; //寻找w[i]和w[i+1]的较大者 //较大者和Max比较 //较小者和Min比较 if(w[i]&gt;w[i+1])&#123; if(w[i]&gt;Max)Max=w[i]; if(w[i+1]&lt;Min)Min=w[i+1]; &#125; else&#123; if(w[i+1]&gt;Max)Max=w[i+1]; if(w[i]&lt;Min)Min=w[i]; &#125;\t&#125;\treturn true;&#125; 当n为奇数时，n=2*k+1,比较k对相邻元素，比较次数为3*k=3*(k-1)/2=[3n/2]-2([]表示向上取整) 当n为偶数时，n=2*k，比较k-1对相邻元素，比较次数为1+3*(k-1)=[3n/2]-2(]表示向上取整) 非递归的时间复杂度和递归写分治法的比较次数相同。 大整数的乘法 设计一个有效的算法，可以进行两个n位大整数的乘法运算。 直接求解：第一个数的每一位分别和第二个数的每一位进行相乘然后进位得结果后在相加，时间复杂度较高为O(n^2)。 分治法： X=A*2^(n/2)+B，Y=C*2^(n/2)+D，所以X*Y=A*C*2^n+(A*D+B*C)*2^(n/2)+B*D 这样时间复杂度为 T(n)={O(1),n=14∗T(n/2)+O(n),n&gt;1T(n)=\\begin{cases} O(1),n=1\\\\ 4*T(n/2)+O(n),n&gt;1 \\end{cases} T(n)={O(1),n=14∗T(n/2)+O(n),n&gt;1​ 根据Master定理知道T(n)=O(n^2)，虽然使用了分支思想，但是时间复杂度无改进效果，说明分支拆分思路不正确。分析式子知道我们需要减小b值，既减少乘法次数，上式中我们可以看到每次都需要求解AC,AD,BD,BD进行四次乘法计算，所以减少乘法次数，我们对公式进行变形，改为 XY=ac2n+((a−c)(b−d)+ac+bd)2n/2+bdXY=ac2^n+((a-c)(b-d)+ac+bd)2^{n/2}+bd XY=ac2n+((a−c)(b−d)+ac+bd)2n/2+bd 或者 XY=ac2n+((a+c)(b+d)−ac−bd)2n/2+bdXY=ac2^n+((a+c)(b+d)-ac-bd)2^{n/2}+bd XY=ac2n+((a+c)(b+d)−ac−bd)2n/2+bd 虽然式子看起来较为复杂，但是他们每次只需要进行3次乘法，即ac,bd,(a+c)*(b+d)或者ac,bd,(a-c)*(b-d)，所以时间复杂度为 T(n)={O(1),n=13T(n/2)+O(n),n&gt;1T(n)=\\begin{cases} O(1),n=1\\\\ 3T(n/2)+O(n),n&gt;1 \\end{cases} T(n)={O(1),n=13T(n/2)+O(n),n&gt;1​ 根据Master定理知道时间复杂度为O*(n^1.59)，有较大的的优化改进，但是考虑到a+c,b+d可能会得到m+1位的结果有进位问题，所以优先使用(a-c)*(b-d)。 矩阵乘法 两个n×n阶的矩阵A和B的乘积是另一个n×n阶矩阵C，C的元素为 C（i,j)=∑k=1nA(i,k)B(k,j)C（i,j)=\\sum_{k=1}^{n}{A(i,k)B(k,j)} C（i,j)=k=1∑n​A(i,k)B(k,j) 那么如果按照直接三重包里循环的话，需要n^3次乘法和n^3-n次加法。代码如下： 123456789101112template&lt;class T&gt;void MatrixMulti(T** A,T** B,T** C,int n)&#123; for(int i=0;i&lt;n;i++)&#123; for(int j=0;j&lt;n;j++)&#123; T sum=0; for(int k=0;k&lt;n;k++)&#123; sum+=A[i][k]*B[k][j] &#125; C[i][j]=sum; &#125; &#125;&#125; 如果我们对矩阵进行分块合并，即进行分治法思想，每个矩阵分为均匀的四个小得子矩阵，如下图 a,b,c,d是A的四个子矩阵，e,f,g,h是B的四个子矩阵。按照乘法公式计算： 可以得到 T（n)=8T(n/2)+O(n2)T（n)=8T(n/2)+O(n^2) T（n)=8T(n/2)+O(n2) 根据master定理得时间复杂度为O(n^3)，我们发现时间复杂度没有减小，难道是分治法出问题了吗😕？实际上并没有，只是我们分的快太多啦，开销太大啦，经过天才的推理，我们得知分成7块时时间复杂度明显降低（证明就不证了）具体操作如下： 我们将abcdefgh重新按一定规则进行整合，即A，B两个矩阵总共分为7块，此时C的四个子矩阵rstu可以用如下公式计算求解： 例如：r=P5+P4-P2+P6=ae+ah+de+dh+dg-de-ah-bh+bg+bh-dg-dh=ae+bg,经过上面的这种分治拆分，可以得： T（n)=3T(n/2)+O(n2)T（n)=3T(n/2)+O(n^2) T（n)=3T(n/2)+O(n2) 根据Master定理得时间复杂度为O(n^2.81)明显缩短了。 残缺的棋盘 有一个棋盘，他有一处坏掉了（即下图蓝色方块），你拥有4四个小版块，要用这四个小版块拼成残缺棋盘的样子，坏掉的地方要空出来，即蓝色方块要空出来。 不同情况的残缺棋盘 你拥有的四种小版块 毋庸置疑，残缺的棋盘肯定有某种特定的规律，既然残缺的棋盘总是由这四种小版块拼出，所以我们总是要想方设法将剩余的白色部分拆成许多个小版块，即三个成直角的小白块为一组划分残缺的前，我们不难看出规律。 对于下面这三个复杂的棋盘，每次我们都先填充黄色区域，使得将棋盘分成4个部分后，有残缺块的那个小部分永远没有黄色板块的小方格，这样我们就达到了将白块分割成多个成直角的三个小白块组合了，其实多想一想，有残缺块的部分不能少一个小白格，自然而然拼凑的时候，第一个小版块要避免放在含有残缺块的部分，这样四个部分拥有的小白块才能均匀分布。所以扩展至无限大的棋盘时，思路是一样的，如下： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566void TileBoard(int tr, int tc, int dr, int dc, int size)&#123;//覆盖残缺棋盘\tif(size==1)return;//形成不了棋盘\tint t=tile++//所使用的三格板数目\ts=size/2;//象限大小（每个象限长宽为原棋盘的一半）\t//覆盖左上象限\tif(dr&lt;tr+s&amp;&amp;dc&lt;tc+s)&#123; //残缺方格位于本象限 //则将三格板t放在右下角 Board[tr + s - 1][tc + s - 1] = t; 然后填充剩余部分，即再次划分为4个小版块进行递归调用 TileBoard(tr,tc,dr+s-1,dc+s-1,s);\t&#125;\telse&#123; //如果本象限没有残缺方格 则直接填充 TileBoard(tr,tc,dr,dc,s);\t&#125;\t//覆盖右上象限\tif(dr&lt;tr+s&amp;&amp;dc&gt;=tc+s)&#123; //残缺方格位于本象限 //则将三格板t放在左下角 Board[tr + s - 1][tc + s ] = t; 然后填充剩余部分，即再次划分为4个小版块进行递归调用 TileBoard(tr,tc+s,tr+s-1,tc+s,s);\t&#125;\telse&#123; //如果本象限没有残缺方格 则直接填充 TileBoard(tr,tc+s,dr,dc,s);\t&#125;\t//覆盖左下象限\tif(dr&gt;=tr+s&amp;&amp;dc&lt;tc+s)&#123; //残缺方格位于本象限 //则将三格板t放在右上角 Board[tr + s ][tc + s -1] = t; 然后填充剩余部分，即再次划分为4个小版块进行递归调用 TileBoard(tr+s,tc,tr+s,tc+s-1,s);\t&#125;\telse&#123; //如果本象限没有残缺方格 则直接填充 TileBoard(tr+s,tc,dr,dc,s);\t&#125;\t//覆盖右下象限\tif(dr&gt;=tr+s&amp;&amp;dc&gt;=tc+s)&#123; //残缺方格位于本象限 //则将三格板t放在右上角 Board[tr + s ][tc + s ] = t; 然后填充剩余部分，即再次划分为4个小版块进行递归调用 TileBoard(tr+s,tc+S,tr+s,tc+s,s);\t&#125;\telse&#123; //如果本象限没有残缺方格 则直接填充 TileBoard(tr+s,tc+s,dr,dc,s);\t&#125;&#125;void OutputBoard(int size)&#123; for(int i=0;i&lt;size;i++)&#123; for(int j=0;j&lt;size;j++) cout&lt;&lt;setw(5)&lt;&lt;Board[i][j]; &#125; cout&lt;&lt;endl;&#125; n=4^k,需要(n-1)/3个三格板填满棋盘，算法复杂度 T（n)=4T(n/4)+cT（n)=4T(n/4)+c T（n)=4T(n/4)+c 根据Master定理可得时间复杂度为O(n)，时间开销很小。 归并排序 采用平衡分割法分割n个元素，即将n个元素分为A和B两个集合，其中A集合中含有n/k个元素，B中包含剩余的元素，即使拆分尽量均匀，这样效果最好（前面有提到过），然后递归使用分治法对A和B在进行排序，当A和B内元素数少于K时开始进行插入排序，然后在采用一种称为归并(merge)的过程，将已经排序好的A和B合并成一个集合。 知识点补充：插入排序就是最符合人类思维的简单排序方法，第一个元素放进一个空数组后，后面的元素大于最大值，就放后面，小于最小值就放前面。时间复杂度很高，但是当元素很少时，时间开销还是很小的。 例题：考虑8个元素，值分别为[10,4,6,3,8,2,5,7]，我们按k=2进行分治拆分： 1代表拆分后取左半部分，2代表拆分后取右半部分。 A1=[10,4,6,3],A2=[8,2,5,7] A11=[10,4],A12=[6,3],A21=[8,2],A22=[5,7] A111=[10],A112=[4],A121=[6],A122=[3],A211=[8],A212=[2],A[221]=[5],A222=[8] merge1:A11=[4,10],A12=[3,6],A21=[2,8],A22=[5,8] merge2:A1=[3,4,6,10],A2=[2,5,7,8] merge3:A=[2,3,4,5,6,7,8,10] 同样可以以k=4进行拆分。 伪代码： 123456789101112131415161718template&lt;class T&gt; void sort(T E,int n)&#123; //对E中的n个元素进行排序，k为全局变量 if(n&gt;=k)&#123; //如果传进来的数组数大于k,说明还要继续拆分 i=n/k;//左半部分 j=n-i;//剩余部分，因为未必刚好平均分，所以这样取j值 //令A包含E中的前i个元素 //令B包含E中余下的j个元素 sort(A,i); sort(B,j); merge(A,B,E,I,J);//merge合并 &#125; else&#123; //否则就该进行插入排序了 //使用插入排序对E进行排序 &#125;&#125; 递推公式如下： T(n)={d,n&lt;kT(n/k)+T(n−n/k)+cn,n&gt;=kT(n)=\\begin{cases} d,n&lt;k\\\\ T(n/k)+T(n-n/k)+cn,n&gt;=k \\end{cases} T(n)={d,n&lt;kT(n/k)+T(n−n/k)+cn,n&gt;=k​ 当n/k与n-(n/k)近似相等时，T(n)值最小(Balance原理),所以特别的，当k=2时，分治法具有最佳性能，此时时间复杂度为logn， T(n)={d,n&lt;=1T(n/2)+T(n−n/2)+cn=2T(n/2)+cn,n&gt;1T(n)=\\begin{cases} d,n&lt;=1\\\\ T(n/2)+T(n-n/2)+cn=2T(n/2)+cn,n&gt;1 \\end{cases} T(n)={d,n&lt;=1T(n/2)+T(n−n/2)+cn=2T(n/2)+cn,n&gt;1​ 当k&gt;2时递归展开的深度logaN,a=k/(k-1)，超过了logn。 快速排序 分治法同时还可以勇于实现另一种不同的排序方法：快速排序，这也是c库函数里常用的sort()函数所使用的方法，在这种方法中，n个元素被分为了3段，左段left,右段right,和中段middle，中段仅包含一个元素，左段中各元素都小于等于中段元素，右段中各元素都大于等于中段元素，因此,left和right中的元素可以独立排序，并且不必对left和right的排序结果进行合并，Middle中的元素又被称为支点(pivot)。 伪代码： 12345678910111213141516171819void quicksort()&#123; //从A[0:n-1]中选择一个元素作为middl，该元素就是支点 T *left,*right//两个指针，指向left段大于支点和right指向小于支点的元素 //交换两个元素，并更改指针 //直至left中的元素都小于等于支点&amp;&amp;right中的元素都大于支点 while(true)&#123; do&#123; left=left+1;//寻找左段大于支点的元素 &#125;while(A[left]&lt;pivot) do&#123; right=right-1;//寻找右段小于支点的元素 &#125;while(A[right]&gt;pivot) if(i&gt;=j)break;//未发现交换对象就退出了 swap(A[left],A[right]);//交换元素 &#125; quicksort(left);//递归调用对left段进行排序 quicksort(right);//递归调用对right进行排序 最终结果为left+middle+right&#125; 需要的递归栈空间为O(n)，如果使用堆栈将递归转化为迭代并每次划分后将长度较大的段压入栈中，则栈空间长度为O(logn)。在最坏的情况，left总是空的，则快速排序所需要的计算时间为O(n^2)，在最好的情况，left和right元素数目大致相同，快速排序的复杂性为O（nlongn)。平均复杂度也为O(nlogn)。 思考:为什么最坏情况时间复杂度为O(n^2)? 递归式为 T(n)=T(0)+T(n−1)+O(n)=O(1)+T(N−1)+O(n)=T(n−1)+O(n)=O(n2)T(n)=T(0)+T(n-1)+O(n)\\\\ =O(1)+T(N-1)+O(n)\\\\ =T(n-1)+O(n) =O(n^2) T(n)=T(0)+T(n−1)+O(n)=O(1)+T(N−1)+O(n)=T(n−1)+O(n)=O(n2) Master定理可以知道就是O(n^2)。当然我们也可以使用迭代展开思考，如下图： 迭代深度为n，每次的值为单调递减数列，求和即得。 思考:为什么最好情况时间复杂度为O(nlogn)? 如果恰巧每次支点都在中间点，那么递归式为 T（n)=2T(n/2)+O(n)=O(nlogn)T（n)=2T(n/2)+O(n)=O(nlogn) T（n)=2T(n/2)+O(n)=O(nlogn) 但是我们发现如果支点落在(1/10n,9/10n)时，也有时间复杂度为O(nlogn)： 即快速排序中支点总是大概率容易落在好情况的位置上，所以平均情形也是好情况为o(nlogn)。 各种排序的算法复杂性比较 方法 最坏复杂性 平均复杂性 冒泡排序 n^2 n^2 计数排序 n^2 n^2 插入排序 n^2 n^2 选择排序 n^2 n^2 堆排序 nlogn nlogn 归并排序 nlogn nlogn 快速排序 n^2 nlogn 各排序算法平均时间的曲线图 选择问题 对于给定的n个元素的数组A[0:n-1]，要求从中找出第k小的元素。这种问题解决时间可以限制在O(nlogn)内，就是先对n个元素进行排序，然后取出A[k-1]就好了，若使用快速排序，可以获得更好的平均性能，尽管该算法在最坏情况下有一个比较差的渐进复杂性O(n^2)。伪代码就不写了，就是快排+取元素。 中间的中间规则优化快排最坏情况 如果仔细选择支点元素，则最坏情况是可以控制在O(n)的，其规则如下，首先将A中的n个元素分成n/r个组，r为某一整型常数，除了最后一组(毕竟有时候剩下的没有r个元素)，对每组中的r个元素进行排序来寻找每组中的中间元素，最后将这些中间元素排序，求得中间之中间支点元素。 例题：n考察如下情形：r=5, n=27, 并且a=[2，6，8，1，4，10，20，6，22，11，9，8，4，3，7，8，16，11，10，8，2，14，15，1，12，5，4 ]。这27个元素可以被分为6组，每组的中间元素分别为4 , 11 , 7 , 1 0 , 1 2和4，这些中间元素的中间元素为7，将其取为支点元素。 距离最近的点对 给定平面上的n个点，找其中的一对典，使得在n个点所组成的所有点对中，该点对间的距离最小。因为最接近点对可能不止一对，为了方便起见，我们只找其中的一对作为问题的解。一个最简单暴力的方法就是将每一个点都和其他的n-1个点相连，然后找出最小距离的点对即可。该方法的时间复杂性是T(n)=n(n-1)/2+n=O(n^2),效率低。 我们先考虑一维的情况，即平面S中的n个点退化为一条直线x轴上的n个实数x1,x2,…,xn，最接近点对就是这n个实数中相差最小的2个实数(所以也必定是相邻的两实数)，简单的方法就是排序这n各数，然后一次性扫描就可以找到最接近点对，时间复杂度为T(n)=O(nlogn)，如下图： 将S分为S1和S2，那么最接近点对就是在S1中最接近点对{p1,p2}和S2中最接近点对{q1,q2}或者某个{p3,q3}（p3在S1,q3在S2）。其中如果最接近点对好巧不巧是{p3,q3}，那么即|p3-q3|&lt;d(d是min{(p1,q1),(p2,q2)})。则p3和q3两者与m的距离都不超过d,所以(m-d,m]中至多包含S中的一个点，同理(m,m+d]也是，所以p3,q3就找到了。 可是这种面中点映射到实数轴上的实数方法无法推广到二维情形。 小作业 Questions 给定自然数1, … , n的一个排列，例如，(1, 3, 4, 2, 5)，如果 j&gt;i,但j 排在i 的前面则称(j, i)为该排列的一个逆序。在上 例中 (3, 2)，(4, 2) 为该排列的逆序。该排列总共有2 个逆序。试用分治法 设计一个计算给定排列的逆序总数的算法，要求算法的时 间复杂度为Θ(nlog2n)。 Answers 有手就行吧，就不给了，上网就能找到答案。 总结 本次分治思想我们对排序有了更进一步的了解，其中快排，归并都是时间复杂度较为理想的排序，残缺棋盘，矩阵相乘，找最小值或最近距离可以尝试使用分治思想解决，那么本次分享就高于段落啦，希望你有所收获😘！"},{"title":"并查集","path":"/wiki/手撕算法笔记/并查集/index.html","content":"什么是并查集? 并查集是一种树型的数据结构，用来处理一些不交集的合并以及查询问题的。有union-find算法定义了两个用于对并查集寻找和合并的操作。即为find函数和union函数（一般我称之为merge函数）。并查集主要是快速对某些关系进行记录，选取一个节点作为一个组合的代表，从而实现快速分组，当然oj题中常涉及到的关系网问题也是一种分组问题，可以通过并查集来实现。 union-find函数的实现 首先我们来学习一下两个函数的用途： Find函数：确定元素属X于哪一个子集，这个确定的方法就是不断向上查找找到它的根节点Y（当然了这个根节点Y肯定是和X就同属于一个共同集合了并且这个集合就是以X为代表的），所以我们称这个集合为Y集合。 Union函数（或者叫Merge函数）：顾名思义，肯定是用来将两个集合合并成为一个集合。 并查集分类思想 其实我们前面提到了，在并查集中，会选择一个节点Y作为一个集合的代表，那么对于任意一个元素X，如果它属于集合Y，那么通过Find(X)就会返还这个集合的代表根节点Y。因此虽然集合中的元素应该都是同级的，但是实际上在并查集中根节点代表元素会是根节点因此处于最高级。而Union函数若想将两个集合合并最简单的思想，就是将两个集合的代表元素放到一个集合建立关系，那么也就是集合A的代表元素A成为集合B的代表元素B的父节点（即将集合B并入到A集合中）或者也可以将集合B的代表元素成为集合A的父节点（即将集合A并入到B集合中）。如下图： 此时A,C,D在一个集合中，且A是集合的代表元素，所以A是根节点，他是C,D的父节点。B,E,F,G在一个集合中并且B是集合的代表元素，所以B是根节点，同时每一个节点一直向上查找最终都会找到B。所以我们就可以写出Find函数的伪代码了： 1234567int Find(int x)&#123; //如果到达了根节点，那么就返还自身\tif(x.parent==x) return x; //如果不是根节点，那么就继续向上查找\telse return Find(x);&#125; 那么现在我们来尝试合并，其实就是将不同集合的代表元素即两个元素的根节点合并，其中一个根节点成为另一个根节点的父元素。因为传入的参数节点未必是根节点，所以我们首先需要用到Find函数来找到两个代表元素根节点，所以伪代码如下： 1234void Union(int x,int y)&#123; //Y的根节点成为X的根节点的父元素\tFind(x).parent=Find(y);&#125; 优化一：按秩合并 所以上面函数的功能是将x的集合并入y的集合，因此y的根节点仍会是新的合并集合的代表元素。比如我们现在要使用Union(C,F),那么最终树的结构如下： 那么最终F的集合的代表元素B会成为C的集合代表元素A的父节点，因此最终所有元素都会纳入B集合。因此Union函数会用到Find函数，同时Union函数的后一个参数是会成为根节点。 现在如果我们写的是Union(G,D)，那么最终树的结构会如下： 实际上从功能上来，这两个貌似没有什么区别，最终都是实现了两个集合的合并。但是我们对比一下上面两个结果图，发现第一种方法最终实现后树的深度不变还是3，但是对于第二种方法最终树的深度会变为4，如果每一次深度大的树总是合并到右子树，那么最终整体树会变得很不平衡，且深度很大。所以我们在合并时可以要求每一次都是深度小的子树合并到深度大的子树上，这样就不会影响合并后的树深度变大了。但是如果刚好两个树深度相同，那么就随意了，深度肯定是会加一的。因此Union函数伪代码优化为： 1234567891011121314151617void Union(int x,int y)&#123; //记录x的根节点\tint xRoot=Find(x);\t//记录y的根节点 int yRoot=Find(y); //如果x集合深度更小，那么将x合并到y中即y是根节点 if(xRoot.rank&lt;yRoot.rank) xRoot.parent=yRoot; //如果y集合深度更小，那么将y合并到x中即x是根节点 else if(xRoot.rank&gt;yRoot.rank) yRoot.parent=xRoot; else //两个集合深度刚好相等 xRoot.parent=yRoot; //合并以后集合y的深度增加一 yRoot.rank+=1;&#125; 又因为在并查集中我们一般称集合树的深度为秩，每次都是将深度小的合并到深度大的集合树中，也就是将秩小的树合并到秩大的树上，因此称为按秩（小）合并。 优化二：路径压缩 这是一种在执行查找时扁平化树结构的方法。关键点就是在路径上的每一个节点都直接连在根上，他们有同样的表示方法，都只需至多查找一次即可到达根节点。这样操作速度就会加快了同时树的深度一直会是2，即根节点以及许许多多的叶子节点。 Find函数的伪代码如下： 123456789int Find(int x)&#123; //如果x不是根节点 if(x.parent!=x) //那么继续Find向上查找，同时x的父节点更新为根节点 x.parent=Find(x.parent); else //否则是根节点直接返还自身 return x;&#125; 比如现在知道B是E的父节点，同时E是F和G的父节点，那么也就下图： 现在我们Find(E)后，会返还B，又因为此时B就是E的父节点，那么树结构不变，但是现在要Find(F)后，会一直向上查找到根节点B同时更新F直接连接根节点B，所以变成下图： 一定要注意Find函数是将查找路径上的所有节点都连接到根节点上，这是由于递归先执行内递归层，再返还执行外递归层导致的。比如现在知道了H是G的子节点，即如下图： 那么我们触发了Find(H)后会return Find(G)所以在Find(H)还没有返还根节点之前又触发了Find(G)，所以又会执行Find(G),因此G会连接到根节点。Find(G)执行完以后且Find(H)未return前的树结构图如下： 然后Find(H)执行完以后即return B以后也连接到了B上，因此树结构会变成： 因此这种Find函数保证了树的结构扁平化，永远保持秩为2，因此操作更快。同时由于Union函数中也有Find函数，因此Union后也会变成上图这样的深度为2的数。比如 此时我们触发Union(D,F)以后，最终结果会变成 因此我们现在知道了树与节点的Find和Union方法了。 用数组模拟并查集 但是我们知道在做oj题时不可能写一个树，所以一般是使用更简单的数组来模拟，我们只需要一个fa数组，来存储每一个节点的父节点键值即可。所以假设2的父节点是6，那么fa[2]=6。所以fa数组值相同的键值节点是同一个集合的。初始化时所有值都等于自身键值即可，所以也就初始化成了每一个数各是一个集合的情况，当两者建立关系时会出现相同的值。我们先给出板子： 123456789101112131415161718void initFa(int n)&#123; for(int i=1;i&lt;=n;i++) fa[i]=i;&#125;int Find(int x)&#123;int find(int x)&#123; //路径压缩的查找 //寻找最深层祖先，同时压缩更新x的祖先为最深层祖先 return (fa[x] == x ? x : fa[x] = find(fa[x]));&#125;void merge(int x, int y)&#123; //x的最深层祖先的祖先更新为y，这样x和y就有关系了，同时y会成为更深层的根本祖先 if (find(x) != find(y)) fa[find(x)] = find(y);&#125; 比如现在有5个数1,2,3,4,5，那么初始化以后fa[1=1],fa[2]=2…fa[5]=5。如果现在合并1和2且是merge(1,2),那么就会出现fa[1]=2,fa[2]=2,fa[3]=3,fa[4]=4,fa[5]=5。假设现在由触发merge(5,1)，那么最终fa[1]=2,fa[2]=2,fa[3]=3,fa[4]=4,fa[5]=2。 一定要注意一般板子都是路径压缩，所以最终根节点都是直接和其他节点相连的 并查集解决分组问题 实际上刚刚上面我们举例的1,2,3,4,5就是分组问题，最终实现的就是1,2,5同一组，3自己一组，4自己一组。类似的题还有给出10个树，根据不同的题意进行分组，最终判断有几个森林，实际上最终就是统计fa数组中有几种不同的数就是有几个森林。 并查集解决关系网问题 一般给出的关系网会规定如果a和b有关系，b和c有关系，那么a和c也会有关系，我们仔细思考一下，实际上就可以使用并查集来模拟，只要x,y都同属于同一个根节点就说明两个及节点x,y有关系，只是在并查集中各个节点并不是同级的，而会有父子节点的关系，但是这并不影响关系网的建立。"},{"title":"二分思想","path":"/wiki/手撕算法笔记/二分思想/index.html","content":"本文参考了pengpenglang友人的《二分与三分查找》，非常感谢精彩的讲解😎。 由于翀翀在学习Python算法题，因此以下模板均是Python所写，如果要参考c++板子请前往pengpenglang 博客获取。 整数二分查找 首先我们学习一个最简单的二分查找，即在一个有序递增的数组中寻找一个特定值的索引值。我们第一想法就是遍历整个数组中的元素然后逐一对比，没有就返还-1，找到了就返还索引值。这种方法时间复杂度为O(n)，耗时太长，因此产生了二分搜索，他的思路很简单，就是每一次都折半查找，我们需要设置记录left,right以及mid来进行折半的操作。如果你对二分查找的基础思路还不太熟悉请看下方的视频讲解： 二分查找讲解https://www.bilibili.com/video/BV1d54y1q7k7?from=search&seid=2027361541815860198&spm_id_from=333.337.0.0 我们发现无论是多么复杂的二分查找，不同的二分板子中大体框架都如下所示： 123456789101112131415int binarySearch(int[] nums, int target) &#123; int left = 0, right = ...; //查找左边界、右边界 while (...) &#123; //判断何时查找终止 int mid = (right + left) / 2; //去中点 if (nums[mid] == target) &#123; //相等时的操作 ... &#125; else if (nums[mid] &lt; target) &#123; //小于时的操作 left = ... &#125; else if (nums[mid] &gt; target) &#123; //大于时的操作 right = ... &#125; &#125; return ...;&#125; 在二分查找中，我们不要出现else，最好使用elif将每种情况都写出来，这样可以清楚的展示所有细节。本文中都会使用elif罗列出每一种情况的操作即使有些情况的操作相同。其中标记的...部分是可能出现的细节问题的地方，需要着重注意。 一、基本二分查找 使用场合就是最简单的情况，一个有序递增的序列中，使用二分查找搜索一个数，找到了就返回的索引下表，不存在就输出-1。板子如下 123456789101112# 找到首次出现的targetdef binarySearch(nums, target): l, r = 0, len(nums)-1 # 注意r的起始位置 while l &lt;= r: # 注意l和r的关系 mid = (l+r)//2 if nums[mid] == target: # 找到了就返回索引并退出 return mid elif nums[mid] &gt; target: r = mid-1 elif nums[mid] &lt; target: l = mid+1 return -1 实际上上面的思路就是和视频中的讲解一样，但是我们发现有几个细节判断条件我们要注意。 思考：为什么while循环的条件是l&lt;=r而不是l&lt;r? 我们注意观察l和r的起始取值，可以看出要查找的是一个闭区间[left,right]，因此每次的查找区间都是全闭区间，如果中途找到了target就直接返回索引下表即可，否则一直寻找下去直至搜索完整个元组，也就是要查找的区间为空的时候，很明显此时也是while(left&lt;=right)终止的条件，那么只有当left==right+1时查找的全闭空间才是空的，因此循环的条件是l&lt;=r。 当然如果你非要用while(left&lt;right)也可以，我们只需要针对错误原因出现的地方打一个补丁即可： 1234# ...while l &lt; r : # ...return l if nums[left] == target else -1; //再额外判断区间为1的时候 思考：如上的补丁是什么意思？ while(left &lt; right)的终止条件是 left == right，写成区间的形式就是 [right, right]，或者带个具体的数字进去 [2, 2]，这时候搜索区间非空，还有一个数 2，但此时 while 循环终止了。也就是说这区间 [2, 2] 被漏掉了，索引2没有被搜索，如果这时候直接返回 -1 就可能出现错误。 思考：为什么下次要查找的区间边界取值是l=mid+1,r=mid-1，而有的写法却是l=mid+1,r=mid，如何理解区分？ 理解的问题一种的查找区间这个概念就好及理解，因为本算法的查找区间的全闭区间，那么当我们发现索引mid不是要找的target时当然从中去除该判断过的点，所以下次查找区间取 [left,mid-1] 或者 [mid+1,right] 中的一个即可。 思考：上面的算法有什么缺陷？ 算法缺陷是很明显的，如果存在重复的数那么我们找到的那个值可能数值上和target相同但是位置是随机的，如果题目想要和target数值相同的最左侧的值或者和target数值相同的最右侧的值的索引又如何解决呢？这需要下面的左侧边界和右侧边界的二分查找了。 二、查找左侧边界的二分查找 我们更改一下使用情景，现在要求找到最靠左侧的数值相同的元素的索引下表，如果不存在就返回-1，比如对于[2,2,3]数组，要找2元素的索引，那么此时应该返回0而不能是1。板子如下所示 123456789101112131415161718# 找到最左边界或者最靠近左侧的满足条件的targetdef binarySearch(nums, target): if len(nums) == 0: # 列表长度为0直接退出搜索 return -1 l, r = 0, len(nums) #注意r的起始条件 while l &lt; r: #注意二分查找的终止条件是l==r mid = (l+r)//2 # 找到某个target时不返回而是缩小右边界 if nums[mid] == target: r = mid elif nums[mid] &gt; target: r = mid elif nums[mid] &lt; target: l = mid+1 if l == len(nums): #target比所有的值都大 return -1 # 打补丁额外再检验一下l对应的值是否满足条件 return l if nums[l] == target else -1 思考：为什么while循环条件是l&lt;r，而不是&lt;=? 我们要注意此时r的起始索引值为len(nums)，但是我们知道这个索引实际上已经越界了，因此很明显此时我们需要使用[l,r)左闭右开的区间去查找。那么此时当l==r时要查找的区间就是[l,l)或者[r,r)了，很明显此时这个搜索区间已经是空了，因此只需要l&lt;r进行循环即可，当l&gt;=r时都是搜索区间为空了，退出循环即可。 思考：为什么退出循环以后出现了对l的额外判断条件来返还-1? 我们发现如果不添加这个条件，我们没有了返回-1的代码操作。我们首先理解一下最左侧边界的含义： 对于这个数组，算法会返回1。这个1的含义可以这样理解：nums中小于2的元素有1个。比如对于有序数组nums=[2,3,5,7],target=1，算法会返回0，及说明nums中小于1的元素有0个。如果target为8，那么算法返回4，即说明nums中小于8的元素有4个。 综上我们可以看出，函数的返回值（即l变量的值）取值区间是[0,len(nums)]，当l==len(nums)时很显然l索引下标对应的元素不存在，访问越界了，另一层含义即数组中所有的元组都小于target，那么此时这个判断式表达的意思就是没有找到target。因此此时返回-1。 思考：为什么l=mid+1,r=mid和之前的操作不一样了？ 这个很好解释，因为我们的搜索区间是[l,r)左闭右开，所以当nums[mid]被检测之后，下一步的搜索区间应该去掉mid分成两个区间，即[l,mid)或者[mid+1,r)，因此对应的操作就是l=mid+1和r=mid。 思考：为什么这个算法可以搜索左侧边界？ 关键就在于nums[mid]==target这种情况的处理是r=mid，也就是说，当我们找到target时不要立即返回，而是缩小搜索区间的上界r，在区间[l,r)中继续搜索，即不断向左收缩，达到锁定左侧边界的目的。 思考：为什么返回l而不是r? 实际上此时返回l和r都是一样的，因为while终止的条件就是l==r。 三、查找右侧边界的二分查找 寻找最右侧边界和寻找左侧边界的代码差不多，只有两处不同，已标注： 12345678910111213141516# 找到最右边界或者最靠近右侧的满足条件的targetdef binarySearch(nums, target): if len(nums) == 0: return -1 l, r = 0, len(nums) while l &lt; r: mid = (l+r)//2 if nums[mid] == target: l = mid+1 # 注意 elif nums[mid] &gt; target: r = mid elif nums[mid] &lt; target: l = mid+1 if l == 0: # 注意 return -1 return l-1 if nums[l-1] == target else -1 # 注意 思考：为什么这个算法能够找到右侧边界？ 类似的，找到关键点还是这里： 12if nums[mid] == target: l = mid+1 # 注意 当nums[mid]==target时，不要立即返回，而是增大搜索区间的下界l，使得区间不断向右收缩，达到锁定右侧边界的目的。 思考：为什么最后返回的是l-1，而不是像左侧边界查找一样返回l？而且我觉得这里应该是返回r就行了？ 首先while循环的终止条件是l==r,因此返回l-1或者r-1都是一样的， 但是返回r肯定是错误的。那么为什么要减一呢？这是因为右侧边界的一个特殊点： 12if nums[mid] == target: l = mid+1 # 这样想：mid=l-1 因为我们对l的更新时l=mid+1,因此while循环结束的时候，nums[l]一定不等于target了（一定是第一个大于target的元素的索引下标值），而nums[l-1]可能是target。至于为什么l的更新时l=mid+1就不再赘述了。 思考：为什么返回的-1的判断条件变成了l==0? 很显然此时l的搜索范围是[0,len(nums)]，那么当l==0时对应要返还的索引是-1很明显越界了，同时此时的另一个含义是数组中所有的元素都大于target明显此时没有找到target因此返回-1。 最后总结 先来梳理一下这些细节差异的因果逻辑： 第一个，最基本的二分查找算法： 1234567因为我们初始化 right = nums.length - 1所以决定了我们的「搜索区间」是 [left, right]所以决定了 while (left &lt;= right)同时也决定了 left = mid+1 和 right = mid-1因为我们只需找到一个 target 的索引即可所以当 nums[mid] == target 时可以立即返回 第二个，寻找左侧边界的二分查找： 12345678因为我们初始化 right = nums.length所以决定了我们的「搜索区间」是 [left, right)所以决定了 while (left &lt; right)同时也决定了 left = mid+1 和 right = mid因为我们需找到 target 的最左侧索引所以当 nums[mid] == target 时不要立即返回而要收紧右侧边界以锁定左侧边界 第三个，寻找右侧边界的二分查找： 1234567891011因为我们初始化 right = nums.length所以决定了我们的「搜索区间」是 [left, right)所以决定了 while (left &lt; right)同时也决定了 left = mid+1 和 right = mid因为我们需找到 target 的最右侧索引所以当 nums[mid] == target 时不要立即返回而要收紧左侧边界以锁定右侧边界又因为收紧左侧边界时必须 left = mid + 1所以最后无论返回 left 还是 right，必须减一 如果以上内容你都能理解，那么恭喜你，二分查找算法的细节不过如此。 思考：C++中stl库中的lowerbound和upperbound如何在python中实现？ 很明显python中肯定也是有对应的库的，但是我们知道对于一般的算法比赛中，Python是不让引入第三方库的，因此我们需要自己来手动实现一下lowerbound和upperbound函数。 lowerbound()实现 lowerbound()方法的功能是找到第一个不小于target的值的索引值，而我们的二分查找寻找最左侧边界就是找到最左侧的target值的索引下标。因此略微修改一下就可以实现和lowerbound相似的功能： 123456789101112131415# 找到第一个不小于target的的索引下标def lowerbound(nums, target): if len(nums) == 0: # 列表长度为0直接退出搜索 return -1 l, r = 0, len(nums) #注意r的起始条件 while l &lt; r: #注意二分查找的终止条件是l==r mid = (l+r)//2 # 找到某个target时不返回而是缩小右边界 if nums[mid] == target: r = mid elif nums[mid] &gt; target: r = mid elif nums[mid] &lt; target: l = mid+1 return l #这里直接返还l就是最靠左的不小于target值的索引下标 upperbound()实现 我们知道在二分查找寻找最右侧边界找到的就是最靠右侧的和target值相同的元素的下标，当时我们是返还的l-1，原因是因为l对应的一定是第一个大于target的值，l-1索引对应的元素才有可能是和target相同的。那么现在我们只需要再返还l即可实现upperbound()方法的功能。 1234567891011121314# 找到第一个大于target的值对应的下标def upperbound(nums, target): if len(nums) == 0: return -1 l, r = 0, len(nums) while l &lt; r: mid = (l+r)//2 if nums[mid] == target: l = mid+1 # 注意 elif nums[mid] &gt; target: r = mid elif nums[mid] &lt; target: l = mid+1 return l #直接返还l索引即可 浮点数二分查找 这里我们再额外学习一下浮点数的二分查找，它相比于整数的二分查找要简单，由于在计算机中浮点数不能准确表示，而是在一个精度差范围内表示，因此我们通常在浮点数中使用二分查找并不是要找到准确数值对应的下标，而是找到第一个满足精度要求的浮点数，比如我们要在[1,10]范围内找到5的平方根的值，要求这个值和准确值精度差在1e-18内。那么此时我们就可以使用二分查找。 12345678910# 浮点数的二分查找# 遍历六十次精度为1e-18,一百次精度为1e-30def binarySearch(l,r,target): for i in range(100): mid=(l+r)/2 if(mid&gt;=target): r=mid else: l=mid return (l+r)/2 通过控制循环的次数来取得要求精度，60次循环达到 1e-18 。100 次的循环则可以达到 1e-30 的精度范围，基本上足以解决所有问题 算法练习 学习完二分查找以后，我们再通过以下两个题来练习一下二分查找算法的应用。 1）完全平方数 题目链接 完全平方数https://ac.nowcoder.com/acm/problem/14733 题目描述 多次查询[l,r]范围内的完全平方数个数 ，定义整数x为完全平方数当且仅当可以找到整数y使得y*y=x。 输入描述 12第一行一个数n表示查询次数之后n行每行两个数l,r 输出描述 1对于每个查询，输出一个数表示答案 示例 输入 12345651 31 42 44 41 1000000000 输出 123421131622 备注 12n &lt;= 1000000&lt;= l &lt;= r &lt;= 1000000000 解题思路 首先我们知道实际上就是找到[l,r]中所有的平方数，即可以开平方后得到整数根的数值，那么最简单的思路就是暴搜注意检验，但是这样很明显会超时，因此我们可以使用另一个思路，即找到边界值，首先找到大于等于l的最小的平方数minn和小于等于r的最大的平方数maxx，然后maxx-minn就是答案。那么我们如何找到maxx和minn呢？有以下两种策略： 假设对于l就是直接使用sqrt(l)并向上取整，同时对于r使用sqrt®向下取整即可得到minn和maxx 使用二分查找中的左侧边界和右侧边界分别找到minn和maxx 很明显第一种更简单，但是这里我们为了练习二分查找使用第二个策略，代码如下 解题代码 123456789101112131415161718192021222324252627282930313233def binarySearchLeft(l, r, target): while l &lt; r: mid = (l+r)//2 if mid**2 == target: r = mid if mid**2 &gt; target: r = mid elif mid**2 &lt; target: l = mid+1 return ldef binarySearchRight(l, r, target): while l &lt; r: mid = (l+r)//2 if mid**2 == target: l = mid+1 elif mid**2 &gt; target: r = mid elif mid**2 &lt; target: l = mid+1 return l-1n = int(input())for i in range(n): # 使用map映射更快获取输入 left, right = list(map(int, input().split())) # 要注意1e10的表现形式在Python中默认为浮点数，需要转换为整数 minn = binarySearchLeft(0, int(1e10), left) maxx = binarySearchRight(0, int(1e10), right) print(maxx-minn+1) 2）Carry爱木头 题目描述 CarryNotKarry 最近迷上了砍木头，已知他需要砍 n 个木头，他有一把神奇但又有束缚的斧头，这个斧头每一次只能砍若干个长度一样的木头，但是**却又只能砍恰好 **m−1 次，也就是将木头分成 m 组。当然，不同组木头的长度当然可以一样的，毕竟若干个同一长度的木头可以分好几次来砍。但是，CarryNotKarry 不希望任何一组的木头个数过多，否则他会觉得分配很不均匀，也就是说，他希望木头中最多个数的组的个数尽量小。他想问问你，最多个数的那个组最小个数是多少，如果无法顺利完成，请告诉他输出 -1 输入描述 第一行两个正整数 n,m(1≤m≤n≤1×105)，其中 n 表示一共需要砍 n 个木头，m 表示需要恰好砍 m 组。第二行有 n 个数，ai(1≤ai≤n)代表第i个木头的长度。 输出描述 输出一个数，表示 m 个组中，个数最多的组的最小值是多少。 样例1 输入 126 42 2 2 3 3 3 输出 12 样例2 输入 126 32 2 2 3 3 3 输出 13 样例3 输入 126 12 2 2 3 3 3 输出 1-1 样例解释 对于样例一，我们可以将 [2,2,2,3,3,3] 分成 [2],[2,2],[3],[3,3] 四组，这时候组数最多的那个数是 2，这时候 2 是最优解。 对于样例二，一种方案是将 [2,2,2,3,3,3] 分成 [2],[2,2],[3,3,3] 三组，这时候组数最多的那个数是3，同理也可以分成 [2,2,2],[3],[3,3]，这时候也是 3，注意，你不能分为 [2,3] ，因为同一组木头要长度一样。 对于样例三，你不能将他们只分成一组。 解题思路 乍一看，感觉并不能使用二分。实际上对于这种寻找最大的最小值或者最小的最大值都是二分题，例如这里我们可以直接枚举答案的取值，然后检验这个答案取值能不能满足条件，那么显然此时使用暴力枚举可能的答案（范围为[0,1e5 ]）是不现实的，会超时，因此枚举可能的答案需要使用到二分法。但是此时我们并不需要使用二分来查找某一个元素，而是仅仅使用二分来进行折半的切割范围即可，因此判断条件很显然不是nums[mid]和target的关系，而是能否满足条件，此时这个条件判断就需要我们自己去实现一个check()函数了，仅仅是是否满足条件判断的后的处理操作和二分很相似而已。又因为我们要找到的是最多个数的那个组的最小个数很明显是最小的最大值，因此使用左侧边界查找。 解题代码 1234567891011121314151617181920212223242526272829303132333435363738n, m = [int(x) for x in input().split()]trees = list(map(int, input().split()))def check(x): l = [] num = 0 idx = 0 while idx &lt; len(trees): if (len(l) == 0 or l[len(l)-1] == trees[idx]) and len(l) != x: l.append(trees[idx]) idx += 1 else: l.clear() num += 1 return False if num &gt; m-1 else Truedef binarySearch(l, r): while(l &lt; r): mid = (l+r)//2 # 枚举可能的答案，然后检测check是否满足条件 # 满足，那么可能可以进一步缩小 if check(mid) == True: r = mid # 不满足，l右移 elif check(mid) == False: l = mid+1 if l == n: print(-1, end=&quot;&quot;) return print(l, end=&quot;&quot;) if check(l) else print(-1, end=&quot;&quot;) return#要注意我们需要先对数目进行排序trees.sort()binarySearch(1, n) 也即是说二分查找仅仅是一种折半的思想，我们要熟悉这种折半的思想，同时理解左界和有界的查找原理，真正解题时可能还需要自己进行变化例如上题中重新构建判断条件。"},{"title":"回溯算法","path":"/wiki/手撕算法笔记/回溯算法/index.html","content":"什么是回溯 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 根据度娘的解读，我们不难理解回溯法就是与人类正常思维相契合的枚举搜索方法，对于每一个交叉十字路口都是尝试所有可能的理想情况，当都尝试完后再回到上一个交叉口进行试，所以回溯法也常常与深度优先搜索dfs相关，但是我们要注意并不是要尝试所有情况，而是可能产生更好结果的情况，对于已知不理想的情况则直接避开，所以这也是回溯法相较于直接暴力枚举有所优化时间复杂度的不同之处。 典型例题精讲 8皇后问题 在8×8的棋盘上放置8个皇后，使得这8个皇后不在同一行、同一列以及同一斜角线上，如下图 这是一道典型的dfs题，这里我们主要是讨论对齐优化，即回溯减少时间开销。在解题之前我们先看几个概念： 什么是解空间？ 8皇后问题的解可以表示为一个8-(x1,x2,…x8)的元组，其中xi是放在第i行的皇后所在的列号，则8皇后为题就可以形式化为在8^8个8元组解中找到满足题干条件的解，这8^8个8元组解构成的集合就成为8皇后问题的解空间即搜索范围。如果我们将约数条件之一即任意两个皇后不能再同一列上时，则解空间大幅缩小到8!个元组。不同的算法设计会产生不同的解空间，但是我们的目的永远是用尽可能少的约束条件来大幅缩减解空间从而加快搜索，这里我们使用xi时就已经限制了皇后不可能在同一行或同一列了，所以唯一可能不符合的情况只会是由于出现了同一斜角线产生，这样我们就大幅缩小了解空间。 什么是状态空间树？ 任何算法都可以用建立在解空间上的状态空间树加以描述。状态空间树是我们尝试选择元组的各个分量时产生的结构，及每一个从根节点出发直至叶子节点的树枝都代表一种情况，每一个中间节点都会对应几个选择即代表对于不同情况的选择。搜索算法并不是事先将状态空间树存储在计算机内在进行遍历，而是通过不断的尝试来展开状态空间树找到所求的解，而回溯法，分支-限界法等就是利用一种启发式的限界条件剪掉状态空间树上的某些没必要的分枝即不用走就知道不可能得到更好解的情况，使得搜索算法在展开时只展开空间树的一部分，从而降低了搜索算法的时间和空间复杂度。 接下来我们就来分析一下8皇后问题，这里为了普适性，我们推广为n皇后问题，所以解空间为n元组啦，并且有n!个情况，状态空间互有两种，一种是每次只讨论本节点是否选取的二叉树结构（即0-1结构），还有一种就是符合人类思维，每次分叉点代表写一个可以选取的节点，即m叉树。如下： 第一种： 第二种： 其中无好坏之分，只是后者空间复杂度会略小，但是同时也不好构建代码逻辑，树上节点的数字代表执行的顺序。下面我们在定义一下不同节点的术语： 什么是状态空间树术语？ 状态空间树的每个节点代表问题求解过程中达到的一个状态，根节点到他的路径代表对一些分量已作出的选择，状态空间树的所有节点构成的集合称为求解该问题的状态空间。 每一个中间节点X都代表一个面临选择的问题，所以称为问题节点 对于叶子节点S，若从根节点出发到节点S可以确定为解空间的一个元组解，则S节点称为解节点 如果解节点S(实际上代表的是一个从根节点到S的元组解)满足约束条件，则为答案节点 若已展开了空间树部分子节点，但是还没有将子节点完全展开，即中间节点，则称为活结点 被限界无法在展开或者已全部展开的子节点称为死节点 当前正在展开子节点的活结点称为E-节点 举例来看，上图中的2节点，他有三个选择可选(即3,8,13），所以2节点是一个问题节点，1-&gt;2-&gt;3已经走完了，所以3就是一个解节点，如果还刚好满足条件约束则3就是一个答案节点，在看如果此时2只是展开了3，接下来该展开8了，所以2是一个活结点因为他还可以继续展开，再看此时正在展开8(即8有两个选择)，所以此时8既是问题节点又是E-节点，当8节点走完9,11两种情况后发现没有可展开的了，则8就成为了死节点。接下来返回到2,2继续展开13，所以此时13又变成了E-节点，此时2变成了死节点。 仔细回想我们发现上面这种展开方法其实就是深度优先搜索，即: 一个E-结点展开自己的一个子结点后, 就让该子结点成为E-结点的展开方法(相当于对状态空间树做深度优先搜索), 称为深度优先展开方法。而回溯法也通常就是在深度优先搜索方法上加上限制条件来加快搜索速度，那么分支-限界则刚好相反，他是经常伴随广度优先搜索出现，即一个结点一旦成为E-结点则它将展开其全部子节点, 之后自己变成死结点. 这样的展开状态空间树的方法成为广度优先搜索，而分支-限界就是加上了限制条件从而加快搜索速度。 什么是限制条件（限界）？ 综上所述，我们无论是回溯还是分支限界都是要在dfs或者bfs上加以限界，这个限界函数就是在每次展开这个子节点之前先进行预估计算判断是否可以得到一个比已知答案解更好的答案节点，当不能得到是就返回true，此时就会停止展开这个子节点(即限界或者&quot;kill子节点&quot;)。从而加快了搜索，此时面对限界函数返还的true信息两种不同的放法进行不同的策略，回溯法就是一直回退到还可以进行展开的父节点处，而分支-限界就是回退到已知可能还会得到更好解的节点进行展开（本章不细讲此方法）。 解题思路 对于n皇后问题我们采用此种策略，即每次先对第i行的皇后分配列数然后将不可能的取值点进行标记，然后在选下一行的皇后i+1的列数，入过此时发现无法放置，则说明上一个皇后放置的位置不妥当，此时我们回退到第i个皇后放置的问题上，选择放置其他列数位置，如果没有可选的了，则继续回退到第i-1个皇后更改，按照此方法即可快速搜索。具体实现参考本视频：N皇后问题 子集和数的问题 给定n个正数w(i)和另一个正数M，找出{w(i)，i=1,2,3…,n}中所有使得和数等于M的子集。 这里我们可以思考每次展开这个子节点前先思考对于这个节点K是否有前面所有已选择的数的和+k节点后面所有数的总和值是否能够&gt;=M，如果不能，则Kill掉次子节点不再展开，因为已知最大和值都已经不可能等于M了，则就没有必要展开了，限界函数表达如下:其中X(i)表示取1表示选择，取0表示不选择 if∑i=1kW(i)X(i)+∑i=k+1nW(i)&lt;Mif\\sum_{i=1}^{k}{W(i)X(i)}+\\sum_{i=k+1}^{n}{W(i)}&lt;M ifi=1∑k​W(i)X(i)+i=k+1∑n​W(i)&lt;M 后面一项没有乘X(i)是因为默认就是全部选择所以全部乘1，就没必要写了，然后表达式设置为小于是因为只有满足次条件是才应该返还true值从而Kill子节点。符合限界函数的定义要求。 最大子集和数的问题 找到不超过M的和数最大的子集。 最大子集和数的问题其实可以看做是效益值等于质量的特殊0/1背包问题，这里我们讨论一种更特殊的情况，即如果已知数是以一种非降序的方式排列给出的，那么我们进一步可以限界条件强化为当已选数的和值小于M且再加上下面一个数就超过了M值，则就不用了展开次子节点了，限界条件如下： if(∑i=1kW(i)X(i)&lt;M&amp;&amp;∑i=1kW(i)X(i)+W(i+1)&gt;M)if(\\sum_{i=1}^{k}{W(i)X(i)}&lt;M\\&amp;\\&amp;\\sum_{i=1}^{k}{W(i)X(i)}+W(i+1)&gt;M) if(i=1∑k​W(i)X(i)&lt;M&amp;&amp;i=1∑k​W(i)X(i)+W(i+1)&gt;M) 此时如果返回true就限界kill此子节点，因为W(i+1)必定是后面的数中最小的了，加上都大于M了，则此时后面无论再选什么数W，都一定超过M了。 0/1背包问题 0/1背包问题此时我们也需要找到一个限界条件，此时我们先对背包的物品和效益值计算效益密度，按照效益密度重新排列，然后注意，此时我们这里要做的不是逐一尝试，而是将其看成连续背包问题来计算最大效益值，即即使装不下我们也要拿效益密度最大的进行填充来计算出最理想效益密度值bestp，而限界条件就是拿每次的最大贪心解bound来和bestp相比较，如果bound&lt;=bestp,就不展开，一句话就是每次我都尽量多拿，如果大了我们在回退考虑不拿某个物体的情况，所以回溯虽然可以省略某些不必要的情况，但是我们还是计算出来了所有可能取得答案解的情况。 下面我们举一道例题来进行对比：考察一个背包例子，n=4,c=7,p=[9,10,7,4],w=[3,5,2,1]，按密度排列为(4,3,1,2)，w=[1,2,3,5],p=[4,7,9,10] 我们用回溯法求解，首先先进行效益密度重排列，题干已完成，然后我们直接求解最理想效益值bound=4+7+9+2*(7-1-2-3)=22,所以最理想效益值为22。接下来开始展开空间树，其中节点序号代表执行顺序，则回溯法展开时如下：(bound为可能取得的最大贪心效益值，bestp为已知取得的最大贪心效益值)，图中的判断式去掉等于号 我们仔细观察上图，发现对于第一个效益密度值最大的物体(即物体4)（来到了节点1），我们假设拿，则此时在已经拿了物体4以后的最大贪心效益值为bestp=4+7+9+2*(7-1-2-3)还是22，所以没有大于bound继续展开左子树，即继续假设拿（来到了节点2），此时第二大效益密度值得物体3，我们发现可以拿，则拿此时再重新计算最大贪心效益值，还是22，所以继续展开左子树，来到节点3讨论是否拿第三大效益密度值得物体1，发现可以拿，则继续拿，此时最大贪心效益密度还是22，所以继续展开左子树，来到了节点4，此时讨论是否拿第四大效益密度值物体2（其实就是最好一个拿不拿），按照bound和bestp的计算，我们都是假设拿不了了就尽量填充，但是实际上只能选择拿或者不拿，所以此时不足以放下物体2，所以就不拿了，此时就来到了5节点（因为4左子树不能展开，所以就只能展开右子树），此时bestp=20，更新bestp=20，所以我们回溯到上一个父节点4，发现也展开完了，继续回溯至节点3，发现此时可以展开右子树，即讨论拿不拿物体1，此时我们假设不拿，则最大贪心效益值bound为4+7+0+2*（7-1-2)=19发现不拿物体1时，最大贪心效益值为bound=19&lt;bestp=20，所以不再展开子节点6（因为已知不拿物品1的话最大效益值都已经到不了已知最大效益值20了,触发限界函数），而是继续回溯到了节点2，发现可以尝试展开右子树，即不拿物品3，此时做大贪心效益值bound=4+0+9+2*(7-1-3)=19&lt;bestp=20,所以不再展开节点7（因为已知不可能得到比已知最大效益值20更好的结果了,触发限界函数），在回溯至节点1展开右子树，发现bound=0+7+9+2*(7-2-3)=20（来到了节点8)。 哎嘿😆，此时发现出现了两个情况最大贪心解都是20： 你说巧不巧，难不成这两种情况都可以吗？有这种可能，但是记住一般做题是不可能滴，仔细想一想这两个20的意义一样吗？其实我们发现这两个20可是意义不一样滴！左下角的20仔细回想一下是用bound=22推出来的，最后推出来具体的元组解效益值为20，也就是具体可以理解为这个bound的意思是可能取得的最最最好的情况也，但是可能具体解出来后会小于这个值，而现在左下角的20就是根据最好的情况为22最终推出来了效益值为20的解，那么现在右上角的那个bound=20就说明元组解的效益值一定为20吗？那可不一定，只是代表不拿物品4，最最好的情况是20，此时bestp不大于bound=20所以可以展开，我们要接着展开节点8继续讨论最终的具体元组解效益值能不能得20，我们再回想一下，这个bound=20是怎么得来的，是bound=0+7+9+2*(7-2-3)=20，也就是不拿物品4，拿了物品3,1，最后的物品2没有全拿，而是只拿了一部分来尽量填充背包才取得的20，但是物品2具体看要么不拿要么拿，所以c=2的情况下不能容纳下物体2，所以最终展开节点8的结果就是具体解的效益值根本就取不到20，而是16，所以最终的解只有一个，就是左下角这种情况了，即取物品4,3,1,不区物品2，最大效益值就是20，元组解为[1,0,1,1]。那么仔细回想一下：我们到底在哪里省略了展开从而加快了搜索呢？ 反思：具体加快搜索怎样实现的？ 我们对比一下dfs的步骤，你就会发现在节点6,7处我们都没有再次展开，这里可是省略了许多步骤呢😲！而我们付出的代价仅仅是每次计算一下最大贪心解执行一下限界判断而已，为此我们可是少进行了以下8个节点（即8中情况）的讨论呢！这就是加快搜索的原理。 反思：能否进一步再优化 其实看一下我们发现我们只是先得到了一种最优效益值解bestp，然后拿着这个解又与其他的情况bound逐一判断来寻找可能更好的解，将其他情况bound全部比较认定为不是比已知刚好的情况后pass掉了其他可能情况最后间接的就证明了bestp这个是最好的解了，那么我们有没有一种不用讨论其他最好情况bound，就只求出一组解就直接可以断定他是最优解的方法呢？当然有，那就是分支-限界的核心所在，具体参考：《手撕算法日记–分枝-限界法》 反思：注意讨论bound=bestp的情况 一定要注意上面讨论的这种5和8相同的情况，千万不要默认5就一定是最好情况了，可能会出现这种8和5的具体解最终效益值相同的情况（即存在两组最优解的罕见情况)甚至更多组相同最优解亦或者是甚至存在比5更好的情况，一定要记得讨论😒！ 总结 就是拿bestp和bound进行比较，bestp&gt;bound时就触发限界函数，bestp&lt;=bound就继续展开。如在结点5处得到bestp=20，结点6处bound=19,故限界掉,类似,结点7,8也被限界掉。 最大集团问题 就是寻找一个图的也叫最大集团，所以重在理解概念。所以首先我们要理解子图，最大集团等概念： 概念 完全图：如果无向图中的任何一对顶点之间都有一条边，这种无向图称为完全图。 完全子图：给定无向图G=（V,E），如果点集U⊆V，且对任意U中的两个点u,v都有（u,v)⊆E,则成U是G的完全子图。 团（最大完全子图）：U是G的团当且仅当U不包含在G的更大的完全子图中。 最大团：G的最大团是指G中所含顶点数最多的团。 独立集：对于给定无向图G=（V,E），如果顶点集合V*⊆V，若V*中任何两个顶点均不相连，则称V*为G的独立集。 最大独立集：G中所含顶点数最多的独立集。 例如： 对于图 有 a,b都是完全子图，因为点和边都是图的子集，且任意点之间都相连，但是c,d是团，a,b都不是团，团就是最大完全子图，a,b都可以被更大的完全子图包含，所以a,b不是最大完全子图，所以也就不是最大团，d是最大团，所以c,d都是最大完全子图，但是只有d是最大团。 所以对于 a是一个无向图，b,c,d都是a的最大团。 补图：完全图中未相连的边和无向图的所有点所构成的图就成为补图 b就是a的一个补图，因为（1,3）（2,4）没有在无向图中存在，所以他是补图的边，而且有如下关系：无向图G的团和G补图的独立集之间存在一一对应的关系，特别地，U是G的最大团当且仅当U是G补图的最大独立集。如{1,2,5}是G的最大团，同时{1,2,5}也是G补图的最大独立集。 无向图G的最大子团和最大独立子集问题实际上是一种题型，两者之间可以互相转换，并且使用回溯法可以将时间复杂度控制在O(n*2^n)以内解决。因为最大团和最大独立子集问题都可以看做是图G顶点集V的子集选取问题，因此，都可以选择使用状态空间树展开求解，解空间就是n元组。解决思想是，设当前的E-节点（又称为扩展节点)Z处于解空间的第i层，在进入左子树，即代表1状态，加入Z之前，我们需要先进行判断他是否和已选择的所有团节点都连接，如果没有，则不能进入，在进入右子树即0状态不选取Z选取除Z以外的其他点之前判断是否还有足够多个点可以供我们选择来使得有可能在右子树（即选择Z以外剩余点）形成比已知最大团更大的团。再具体实现时，使用邻接矩阵表示图G，以一个整数型数组向量返回找到最大团的解，v[i]=1表示顶点i属于最大团的顶点。 所以接下来我们的任务是首先判断这个点能否加入，若不能加入则kill掉左子树，然后在判断能否进入右子树，即还有没有足够多个点来使得右子树产生比已知最大团更大团，如果可以进入左子树，则还需要考虑加入该顶点和舍弃两种情况。这样执行剪枝策略可以有效提高搜索速度。那么我们怎么解决判断是否能够还有足够多个点使得右子树产生比已知最大团更大团？ 思考：右子树限界函数怎么实现？ 这里我们可以考虑执行一种特殊的扩展方式，我们先假设所有节点都是相连的，所以每次扩展时不是挑选节点，而是枚举节点，按照从小到大的顺序枚举节点，然后在判断是否相连，即从i=1开始，然后2,3,4，…,n这样对每一个节点进行判断，这样还有一个好处是相同情况的点会在数的同一层，这样我们就可以轻松知道假设节点Z在t层，总结点数为n个，已选的节点数为cn，那么剩余的除Z以外的节点数就是n-t个，若 (已选节点数)cn+(所有除Z以外剩余的节点数)n−t&lt;已知最大团的节点数bestn(已选节点数)cn+(所有除Z以外剩余的节点数)n-t&lt;已知最大团的节点数bestn (已选节点数)cn+(所有除Z以外剩余的节点数)n−t&lt;已知最大团的节点数bestn 那么就出发限界函数不进入此右子树，那么已选节点数可以通过每次选中某个节点时参数cn++来进行统计，自此核心判断公式就写完了，我们可以写出伪代码了。 伪代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556void AdjacencyGraph::maxClique(int i)&#123; //计算最大团的回溯代码 if(i&gt;n)&#123;//到到达了叶子节点 //找到了一个最大团的元组解，更新 for(int j=1;j&lt;=n;j++)&#123; //记录这组解 bextx[j]=x[j]; //最大团的节点数就是此时解的节点数 bextn=cn; return;//退出 &#125; &#125; //如果没到叶子节点则还是中间节点，首先判断能否进入左子树 //即顶点i是否与其他所有的已选顶点相连 int ok=1//默认是相连的 for(int j=1;j&lt;i;j+=)&#123; //j节点在已选最大团组里&amp;&amp;i和j不相连，找到一组即可 if(x[j]&amp;&amp;a[i][j]==NoEdge)&#123; ok=0;//不相连 break; &#125; &#125; if(ok)//符合全部相连 &#123; //将i加入最大团组中 x[i]=1; //已选顶点数加一 cn++; //检验i+1能否进入，递归调用 //并计算bestn maxClique(i+1); //很重要！！！ //还要回溯到i进入右子树检验不放回的情况 x[i]=0; cn--; &#125; //检验有没有必要进入右子树 //即除i节点以外选取全部剩余节点后能否形成更大团 if(cn+n-i&gt;bextn)&#123; //有必要进入&amp;&amp;不选i节点 x[i]=0; //检验i+1能否进入，递归调用 //并计算bestn maxClique(i+1) &#125;&#125;//初始化和返还bestnint AdjacencyGraph::MaxClique(int v[])&#123; x=new int [n+1]//存元组解 cn=0;//已选顶点数为0 bestn=0;// bestx=v; //从1开始注意检验顶点 maxClique(1); return bestn;&#125; 状态空间树展开过程 上图是对无向图G寻找最大团时状态空间树展开过程的图解，我们从R开始，逐一对顶点进行检验，首先R节点处相当于初始化，此时没有选点，cn=0,bestn=0。我们首先选节点1（因为默认单调递增检验顶点），然后进入1的左子树，检验2发现和1相连，可以加入，所以此时cn=2,bestn=0（记得吗，此时是a情况，虽然是一个完全子图，但是不是团，因为不是最大完全子图),然后检验节点3，发现3虽然和2相连，但是和1不相连，所以2不能展开左子树即不能选择3，此时判断能否进入右子树，此时已选节点数为2，剩余节点数为5-3=2（这里的图是显示3节点在第4层，但是代码由于默认从节点1位根节点出发，所以与这里的图略有出入，在代码里此时节点3就是在第三层），所以cn+n-i=4&gt;bestn=0,即如果将4,5默认全选上还是有可能产生更大的团的，由于此时还没有形成团，所以bestn=0，所以可以对2进行右子树展开即放弃3，然后判断顶点4，发现4和2不相连，所以无法展开3的左子树即不能选择节点4，判断3能否右子树扩展，发现是可以的，所以判断5，发现5和1,2都相连，所以可以选5，此时对于4来说进行了左展开，此时到达了叶子节点，最大团产生了一个为{1,2,5},并且bestn=cn=3，然后注意对于可以加入的顶点，不要忘记还要回溯判断不选的情况，即回溯到了节点4，判断能够右子树扩展，发现此时cn=2(因为此时只选了1,2),出来5剩余的顶点数为5-5=0，所以cn+n-i=2&lt;bestn=3，即展开右子树也不可能得到比已知最大团{1,2,5}更大的团了，所以不展开右子树，继续回溯到了1节点，然后如图，虽然1节点可以右展开到黄色的2节点，但是黄色的2节点无法左右展开，继续回溯到了R节点进行右展开的判断，此时cn+n-i=5&gt;bestn所以右展开，以此类推即完成了空间树的展开。 货箱装船问题 给定载重量c的货船，找一种装船的办法，使得装载的货箱数目最多(0-1背包问题，没有效益值，直接贪心就行)，现在对问题进行了改动，有两艘船和n个货箱，第一艘船的载重量为c1,第二艘船的载重量为c2,w(i)是货箱i的重量，且w(1)+…+w(n)&lt;=c1+c2,问是否有一种可以将n个货箱全部装走的办法（可行解）？ 思路就是极大化第一只船的装箱重量，如果剩余的货箱能够被第二只船装载，则有可行解，否则就没有。我们不要枚举所有情况，太过复杂，可以用某些限界方法进行剪枝，如设cw为船1已装的重量，则如果cw+w(i)&gt;c1,就杀死左子树，不再展开，如果已知的最优装箱重量为bestw，如果r为剩余的未装货的重量，如果cw+r&lt;=bestw，则不用在展开此节点。两种限界方法同时使用即可加快搜索速度。 所以展开左子节点： 如果cw+w(i)&gt;c1，停止展开左子节点，r=r-w[i]，并展开右子树即不放入i物品的情况 如果cw+w(i)&lt;=c1,x[i]=1,cw=cw+w[i],r=r-w[i]并继续检验w[i+1]同时回溯讨论不要i物品的情况即展开右子树的情况 展开右子节点： 如果cw+r&lt;=bestw，停止展开右子树，并回溯到最近的活父节点 如果cw+r&gt;bestw，x[i]=0，展开右子树即讨论不要物品i的情况。 回溯时如果x[i]=1说明只讨论了展开左子树的情况，还可以尝试展开右子树，如果x[i]=0，说明已经节点I已经是个死节点了，继续向上回溯。 旅行商问题 售货员要到若干城市去推销商品，已知各个城市之间的路程，他要选定一条从驻地出发，经过每个城市一次，最后回到驻地的路线，使得总的路程（或者总旅行费）最小。 我们假设城市之间的图如下： 我们发现某些城市之间是没有直接相连接的路径的，且每条路的开销各不相同，我们的目的就是寻找一个使线段权值之和最小的连接所有城市的路。并且不能逐一枚举尝试，复杂度过高，这里可以加上某些限界函数来进行剪枝加快搜索。我们构建一个元组解{x1,…xn}，分量xi表示第i个要去的城市编号，因为只有去一次，所以前面走过的城市{x1,x2,…,xk-1}，后面的取值为S-{x1,x2,…,xk-1}，我们仍然可以使用状态空间树进行展开，这里也要加上限界条件，其中展开左子树需要满足两个节点即两座城市是相连的且从起点到这个检验节点即选择的要去的城市的路径长度（即已经走过的城市所用的路径长度之和）要小于已知的最短路径长度，对于右子树其实我们也可以加上限界条件： 已经选中的城市路径长度之和+未走过的所有城市的最短到达路径长度&lt;已知的走遍全部城市的最短路径长度已经选中的城市路径长度之和+未走过的所有城市的最短到达路径长度&lt;已知的走遍全部城市的最短路径长度 已经选中的城市路径长度之和+未走过的所有城市的最短到达路径长度&lt;已知的走遍全部城市的最短路径长度 但是由于未走过的所有城市最短距离之和不好计算，所以对于右子树展开不加限界条件了，但是只有左子树限界方法也已经大幅加快了搜索速度了。 伪代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960template&lt;class T&gt;T AdjacencyWDigraph&lt;T&gt;::Tsp(int v[])&#123; //回溯算法解决旅行商问题 //预处理程序函数，用来返还最优旅游路径的耗费 //最优路径存入v[1:n] //初始化 x= new int [n+1] //x是排列 //初始化为第i次走城市i for(int i=1;i&lt;=n;i+=)&#123; x[i]=i; &#125; //两城市最短路径默认为正无穷 bestc=NoEdge; //最优可行元组解 bestx=v; cc=0;//已经走过的城市路径长度 tsp(2); delete x; return bestc;&#125;void AdjacencyWDigraph&lt;T&gt;::tsp(int i)&#123; //旅行商回溯算法 if(i==n)&#123; //位于一个叶子节点的父节点 //找到了一个最优路径可行解 //a二维数组是城市无向图G的邻接矩阵 //如果n-1和n有路且1和城市有路（注意他还得回去） //之所以这样比较是因为回去的路长度会影响总长度 if(a[x[n-1][x[n]]]!=NoEdge&amp;&amp;a[x[n][1]]!=NoEdge &amp;&amp;(cc+a[x[n-1]x[n]]+a[x[n][1]]&lt;bestc||bestc==NoEdge) )&#123; //找到了更优的旅行路径 for(int j=1;j&lt;=n;j++)&#123; bestx[j]=x[j];//记录这组解 &#125; bestc=cc+a[x[n-1][x[n]]]+a[x[n][1]];//记录最优路径长度 &#125; &#125; else&#123; //还没走完所有城市 //尝试展开子树 for(int j=i;j&lt;=n;j++)&#123; //判断是否相连即能否展开左子树 //以及是否此时是比已知对短路径更短的情况 if(a[x[i-1]x[j]]!=Noedge&amp;&amp;(cc+a[x[i-1]x[i]]&lt;bestc||bestc==NoEdge))&#123; //能走 //搜索该子树 Swap(x[i],x[j]); cc+=a[x[i-1]x[i]]; //递归调用检验下一个城市 tsp(i+1) //同时千万不要忘记回溯检验不走这个城市的情况 cc-=a[x[i-1]x[i]]; Swap(x[i],x[j]); &#125; &#125; &#125;&#125; 小测验 Questions 对以下最小罚款额调度问题的实例：(10,3,2),(3,4,2),(8,2,1),(6,3,1)利用回溯法求解，要求：写出限界条件，划出展开的部分状态空间树 对以下0/1背包问题的实例：n=4,c=7,w=[3,5,2,1],p=[9,10,7,4]利用回溯法求解，要求：写出限界条件，划出展开的部分状态空间树 Answers 总结 通过这次回溯法的学习，我们了解到回溯法实际上就是在dfs基础上加以限界函数来加快搜索速度，其中无论是哪种题型，其核心思想都是一样的，设置元组解，对利用限界条件对状态空间树展开加以剪枝，其中，我们都是在能否展开，能够左子树展开，能否右子树展开这三处关键点进行限界条件添加，当然如果特别复杂的限界判断可以适当不加，一定要注意对于这种dfs回溯永远都是能左子树展开，优先一直展开左子树，即E-节点优先一直向下延伸，同时对于左子树展开的同时也要回溯进行右子树展开，这样问题才能讨论完全，直至每次到达叶子节点得到一组可行解，记住要更新限界条件等，然后在所有可行接中最终得到最优解，那么这次分享就告于段落啦，有兴趣的小伙伴可以提前思考一下分支-限界和回溯又有什么本质区别呢，我们下次再见😋~"},{"title":"分枝限界","path":"/wiki/手撕算法笔记/分枝限界/index.html","content":"什么是分枝-限界 分枝限界法是一个用途十分广泛的算法，运用这种算法的技巧性很强，不同类型的问题解法也各不相同。分枝限界法的基本思想是对有约束条件的最优化问题的所有可行解（数目有限）空间进行搜索。该算法在具体执行时，把全部可行的解空间不断分割为越来越小的子集（称为分支），并为每个子集内的解的值计算一个下界或上界（称为限界）。对凡是界限超出已知可行解值那些子集不再做进一步分支。 看完度娘的介绍，我们发现其实分枝-限界和回溯法很相似，都是加上限界条件进行剪枝从而加快搜索速度，但是仔细观察，发现分枝-限界对于子问题的求解与回溯法又有所差异，他是每次对一个子节点进行全部打开并分别对每次进行一个限界值得计算，然后每次都选择而最理想的值进行展开，这是与回溯法最大的区别，所以分支-限界一般是与bfs相关的题进行联系。 概念介绍 分枝 顾名思义，就是在一个节点称为E-节点以后（又叫做展开节点），要一次性展开他的所有子节点，并将这些子节点放在一个称为活结点表的数据结构中，从活结点表中的节点可以展开所有状态空间树的节点（说白了就是存储某一层的节点，然后在进行展开），即为广度优先搜索状态空间树。每次我们都是从这个活结点表中取出一个节点作为E节点进行展开，活结点表可以使用FIFO(First Input First Output，先进先出队列），LIFO（Last Input First Output,后进先出队列）或者优先级队列（设计权重的队列）进行表示。当使用优先级队列时必须对活结点表中的节点赋以一个权值。本次结合求解问题介绍使用优先级队列我分支-限界法。 任意节点的成本函数 定义状态空间树上任一节点x的成本函数c(x):如果x是可行的叶子节点，那么c(x)=cost(x)，如果x是中间可行节点，那么c(x)=从x展开状态空间树能得到的最小成本值（即以x为根节点的状态空间树展开后所能得到的最理想值，跟回溯法背包问题中的bound,回溯法最大团cn+n-i,回溯法旅行商中未走过的城市最短路径长度之和bestn的定义其实一样）。如果其子树无可行解，即没有解能满足条件，那么c(x)=∞。 LC-检索 LC-检索其实就是分支-限界法中具体实现每次选择最优节点进行展开的实现方法。即如果活结点表中每个节点都以c(x)为权值，则每次都从活结点表中取最小权值节点（即优先级最高的节点或者情况最理想的节点）作为E-节点，则算法就能够很快找到最优解。虽然可能展开x前我们不知道c(x)的值，但是有可能从历史信息中获得c(x)的某一个下界c*(x)，即c(x)随着具体的展开是会变化的，逐渐趋近于真实值，从回溯法背包问题中bound逐渐变小趋近于具体解所对应的效益值情况是类似的。每次以c(x)的下界c*(x)作为活结点表中节点的权值，每次都去有最小c*(x)的节点（即拥有最理想情况解）的节点作为E-节点进行展开。特殊地，根据这种检索方法，对于可行叶子节点z，会有c*(z)=c(z)=cost(z),即此时成本函数值=成本函数值下界=真实值。 限界方法 那么什么时候会触发限界函数切换E-节点呢，此时我们需要设计一个限界函数来判断此时的节点不再是具有最优成本函数值的节点，从而根据活结点表切换E-节点，这个判断方法如下：每次我们都根据活结点表中记录最优成本值为U，对于正在展开的节点E-节点，当其展开某个子节点x时，如果该子节点x的c(x)&gt;=U,我们就停止展开此子节点，即不将其放入活节点表（因此我们也不难看出，新加入活结点表的值一定是更优的相较于之前的节点），然后此时我们并不是一定要回溯到父节点，这里适合回溯法最大的区别，而是切换到U所对应的节点进行展开，如果展开的新子节点的c(x)&lt;U,则更新U且将这个节点加入活结点表中，并且此时不是立刻切换E-节点为此新子节点，而是继续展开当前的E-节点直至其为一个死节点然后从活结点表中移除该E-节点，然后在切换至U所对应的节点。所以每一次都有U=min{U,cost(x)}。 伪代码 123456789101112131415161718192021222324252627E=T，U=∞ //将活结点表初始化为空 while(true)&#123; for E的每个子节点x注意检验 //得到一组可行解 if(x是叶子节点)&#123; //更新U，此时cost(x)=c(x) U=min&#123;U,cost(x)&#125;; &#125; if(c*(x)&lt;U)&#123; //加入活节点表 Add(x); //此时继续展开其父节点 parent(x)=E; &#125; if(E=NULL)&#123; //活节点表为空，算法结束 //能尝试展开的都尝试完了 return; &#125; delete(E); if(c*(E)&gt;=U)&#123; //剩下的所有活结点表的最优值都大于已知的最优值U //算法结束 return; &#125; &#125; 在上面的伪代码中，算法结束时，如果c*(E)&gt;=U,即活结点表中其他节点x的下界也满足c*(x)&gt;=c*(E)&gt;=U,则展开这些活结点也不能产生更好的解了，所以算法结束时U就是优化值。（c*(x)表示x节点成本值得下界，c*(E)是活结点表中的所有点中成本值的下界，U就是已知的最优值，很好理解上面我的不等式，对于一个新的子节点x，他的可能最优值可能比活结点表中的下界值还要大，但是如果此时他就是产生最优值的节点，那么此时他进入或节点表后活节点表的成本值下界就会和他的成本值下界相等，所以c*(x)&gt;=c*(E)，又因为U是在已知活结点表中的成本值中选取最小值为其自身值，所以c*(E)&gt;=U)。 经典例题精讲 带截止期的作业调度问题 n个作业，1台处理机，每个作业i对应一个三元组（pi,di,ti)。pi是罚款额即不做的罚款值，di是截止日期，ti是需要的处理机时间。求可行的作业子集J，使得罚款额Σpj最小，其中j为不在J中的作业。 我们定义元组表示作业子集：(x1,x2,…,xn)，表示第i个任务是否做，1表示做，0表示不做。下界c*(x)可表示为展开到x时已得到的罚款额。 例如4个作业的三元组{(5,1,1),(10,3,2),(6,2,1),(3,1,1)}对于每个E-节点x都快速计算一个可行解，并以该可行解的成本值，记为u(x)，修改U的值，如下： 是题的状态空间树展开过程，接下来我们就具体分析一下，首先节点1代表讨论第一个任务是否做，此时相当于还没有不做的，所以此时罚款额为0，然后对1进行全扩展，即一直把1展开到死节点位置，这里有两个选择做或者不做1，所以2节点是做，3节点是不做，但是3节点不做作业1时罚款额为5，此时比较发现2节点罚款额小，所以优先2节点，2节点同样展开为4和5，此时5节点的罚款额为10,4节点罚款额还是最小的为0，继续展开4节点，但是此时，发现选择了作业1和作业2后，不能选择作业3了，放不下了，所以只能扩展右子树的节点6，此时6罚款额为6，此时，很重，活结点表中有{3,5,6}三个活结点，LC-检索每次都会优先展开最优的节点，此时6不是最优节点了而3是最右节点了，所以跳转开始展开3节点，此时对3进行展开，左右全都可以展开得到7和8，然后3成为死节点，从活结点表中移除，是7节点罚款额为5,8节点罚款额为15，所以继续展开7节点为9和10,9节点罚款额仍是最小的，所以继续展开节点9，但是选择了作业2和作业3后，作业4放不下了，所以9节点只能展开右子树，得节点11，罚款额为8，此时到达了叶子节点，得到了一组解为[0,1,1,0]，罚款额为8，但是此时活结点表中还有{6,8,10}发现8,10两个节点不用继续展开罚款额都已经大过U=8了，所以不展开8,10,而6罚款额为6，比8小，此时对节点6进行展开，但是发现作业1和作业2选择以后作业4放不下了，所以只能展开右子树得节点12，罚款额为9&gt;U,然后将节点6从活结点表中移除，此时活结点表中还有{8,10}，但是此时都已知比U大了，所以此时处于伪代码中的最后一种情况了，算法结束，得到了最优解就是[0,1,1,0]。 思考：分支-限界法是怎样加快搜索速度的？ 我们发现在分支限界法中，虽然没有向回溯法一样回到父节点，但是他这种每次都跳跃到最理想的节点继续展开，最终就会实现得到最优解且上图中3个节点处都进行了剪枝，从此加快了搜索速度 思考：回溯法和分支-限界法有什么思路上的区别吗？ 有，我们可以两种方法看成是两种人，回溯法就像是一位着眼全局谨慎的人，做任何事（展开子树）前都会先顾后（查看后面是否会出现比已知更好的结果来进行限界判断)来避免进行一些不必要的扩展。而分支-限界更像是一位着眼于现在和已知的历史信息的人，他在每次做事情后都会记录下相应的信息，以便在进行后面的事情（展开子树）时根据现在的情况和历史信息进行对比判断（瞻前），一旦发现自己不再处于最优解的扩展路径上，就马上离开着手于更好的情况。但是归根结底两者都是进行了剪枝策略，避免了没有必要的扩展，从而加快了搜索速度，并且注意，两者无优劣之分，只是对于不同的问题各有偏向（dfs/bfs)。 当然，空间扩展书我们也可以使用M叉树实现，如下： 两个树都可以，但是后者虽然省略了层数，但是不同节点分分枝数不太好进行统计判断。对于上面这种数展开，方法类似，我只给出数据请自行推理： 最大团问题 最大团的有关概念就不介绍了，请查看本篇博客：《回溯算法》这里我们在采用分支限界的方法进行求解。在分枝-限界法中，通常是使用广度优先搜索并且以最小消耗优先的方式解状态空间树。对于下图： 我们在使用分枝-限界法解决上面G的最大团问题之前，先考虑一下具体怎么实现，我们知道分枝-限界主要的限界方法就是设立几个条件，只有符合条件的节点才能进入活结点表，然后每次展开时都是展开活结点表的最优节点，这样不满条件即无法进入活结点表的节点也就被剪枝了，这就是分枝-限界的策略，所以我们需要寻找几个条件进行剪枝，首先我们可以很容易知道一个条件即想展开左子树需要左子节点和已知的团中所有节点相连，而对于所有节点只有满足cn+un&gt;bestn(cn是当前已经选择的节点数，un是当前cn和n-t的和，n-t是剩余所有未选择节点的数，所以un即为可能产生的最大贪心效益团，bestn是当前已知的最大团的最优团数)，un=cn+n-t，所以只有满足已经选择的节点数和所有未选节点数之和比bestn大的才有可能继续产生更大团，所以只有满足cn+n-t的节点才能进入活结点表，接下来就是每次展开时都选择活结点表中的最优节点进行展开，我们知道对于0/1背包问题中我们每次选择的都是具有最大贪心效益值的节点进行展开，而对于最大团问题我们每次都选取活结点表中un最大的节点，但是难免会产生un相等的活结点表节点，此时根据不同的方法我们对状态空间树进行展开并对比两个策略的优劣。为了方便起见，我们将上图中G中的1,2,3,4,5用A,B,C,D,E代替： 策略1：un&gt;bestn&amp;&amp;FIFO队列 此时活结点表使用FIFO队列即先进先出，所以当面对un相同的节点，我们选择最先到的节点，当然节点还是要满足un从大到小排列的。那么状态空间树如下： 我们来一步步推导一下，其中括号包裹的是按顺序排列的活结点表，每次都选取队首节点（因为队首节点就是最优节点）,并且我们可以看出n-t表示的就是剩余节点数量且每一层都讨论的是某一个节点在不同情况下的选取情况，例如第一层表示的就是A的选取情况，第4层表示的就是D的选取情况。第零层根节点表示还没有选择节点，所以第零层的cn=0,un=5,此时还没有选择节点，所以已知最有团大小就是bestn=0。 首先根节点表示还没选择节点呢，所以bestn=0，此时左右分别讨论是否选择A得到两个节点1,2并且1此时的un=5不变，cn=1，2的un=4,cn=0，都满足cn&gt;bestn,所以都插入节点表，并且此时更新bestn=1,虽然我们知道此时还没有形成团（但是可以特殊地看成是1个团大小为1的团），活结点表为（1,2） 取1(此时1一定被展开成死节点，所以就不在活结点表中了），发现选A以后B可选可不选，所以同样左右展开的3和4,3的cn=2,un=5,4的cn=1,un=4,bestn=2,都可以插入活结点表，活结点表为(3,2,4)，虽然3比2来的晚，但是3的un更大，所以排在2前面，而4和2的un相同此时采取FIFO策略，2来的早所以2在前面。 取3(此时3一定被展开成死节点，所以就不在活结点表中了），发现此时选取了A,B不能选C，因为C和A不相连，所以3只能右展开得5，此时cn=2,un=4满足un&gt;bestn5加入活结点表，此时活结点表为(2,4,5) 取2(此时2一定被展开成死节点，所以就不在活结点表中了），2左右展开均可以得节点节点6,7，6的cn=1,un=4,7的cn=0,un=3，均可以进活结点表，活结点表为(4,5,6,7) 取4(此时4一定被展开成死节点，所以就不在活结点表中了），只能右展得节点8,cn=1,un=3，活结点表为(5,6,7,8) 取5(此时5一定被展开成死节点，所以就不在活结点表中了），只能右展得9加入活结点表，活结点表为(6,7,8,9) 取6(此时6一定被展开成死节点，所以就不在活结点表中了），6左右展均可以，得到10,11,10的cn=2,un=4,11的cn=1,un=3，所以加入活结点表，活结点表为(10,6,7,8,9,11),10在最前面是由于un最大。 取10(此时10一定被展开成死节点，所以就不在活结点表中了）,10只能右展得到12，cn=2,un=3此时加入活结点表,活结点表为(7,8,9,11,12) 取7(此时7一定被展开成死节点，所以就不在活结点表中了），7左右展均可以，得到13和14,13的cn=1,un=3,14的cn=2,un=2，所以此时只有13加入活节点表，因为14的un=2==bestn=2，不大于所以剪枝不用再加入活结点表中讨论了。活结点表为(8,9,11,12,13) 取8(此时8一定被展开成死节点，所以就不在活结点表中了），8左右展均可以，得到15,16,15的cn=2,un=3,16的cn=1,un=2,所以只有15加入活结点表，活结点表为(9,11,12,13,15) 取9(此时9一定被展开成死节点，所以就不在活结点表中了），9左右展开均可以得到17和18，17的cn3,un=3,18的un=2,cn=2,此时发现已经到达叶节点了即当cn=un时就是叶子节点了，所以已经找到了最优解，及时在展开其他情况也只是得到不大于此时解的情况，所以此时的解就是一组最优解了，最大团数为bestn=cn=3,之所以不是18节点是因为17的情况更好，所以算法结束啦，最终就是最大团数为3，最优解为[1,1,0,0,1]即{A,B,E}，当然如果你继续展开要全部展开的话也可以，最终还会得到两组解为{B,C,E}和{A,D,E}但是并不会改变bestn的值了，所以剩下的活结点表节点销毁即可。 思考：有没有可以优化的地方？ 仔细观察，我们会发现在出现类似于2,5这种un相同的情况时采取的是FIFO策略存储，所以接下来是展开来的更早的节点，但是按照正常思维来说，我们考虑一下2和5,2节点表示此事还一个节点没选但是最好的可能情况为4，而节点5表示的是在已经选择了两个节点情况下最好的可能情况为4即5节点最好情况和2相同的情况下还保证了最差的情况为至少能得到大小为2的团，而节点2不排除得到大小为1或者0的团，所以按常理来说5比2更好，所以应该是展开5，所以在活结点表中我们应该将5放在2前面，所以我们采取一种大顶堆策略来实现活结点表存储，即每次都按照un从大到小排列的同时，当un相同时cn更大的排在前面。这样就得到了策略2 策略2：un&gt;bestn&amp;&amp;大顶堆 此时就是在un从大到小排序的同时，un相等的情况使用cn更大的节点排在前面的策略来存储，确实步数更少了所以也就优化了搜索效率，具体步骤如下： 首先根节点表示还没选择节点呢，所以bestn=0，此时左右分别讨论是否选择A得到两个节点1,2并且1此时的un=5不变，cn=1，2的un=4,cn=0，都满足cn&gt;bestn,所以都插入节点表，并且此时更新bestn=1,虽然我们知道此时还没有形成团（但是可以特殊地看成是1个团大小为1的团），活结点表为（1,2） 取1(此时1一定被展开成死节点，所以就不在活结点表中了），发现选A以后B可选可不选，所以同样左右展开的3和4,3的cn=2,un=5,4的cn=1,un=4,bestn=2,都可以插入活结点表，活结点表为(3,2,4)，虽然3比2来的晚，但是3的un更大，所以排在2前面，而4和2的un相等，此时cn大的排在前面，所以活节点表为(3,4,2) 取3(此时3一定被展开成死节点，所以就不在活结点表中了），只能右展得节点5,cn=2,un=4,所以5放入活节点表并且因为5比4更好，所以5直接插入到4前面，活节点表为(5,4,2) 取5(此时5一定被展开成死节点，所以就不在活结点表中了），只能右展得到节点6，cn=2,un=3,所以放入活节点表中，活结点表为(4,2,6) 取4(此时4一定被展开成死节点，所以就不在活结点表中了），只能右展得到节点7，cn=1,un=3，所以放入活结点表且7放在6的后面此时活结点表为(2,6,7) 取2(此时2一定被展开成死节点，所以就不在活结点表中了），左右均可展开得到8,9，8的cn=1，un=4,9的cn=0,un=3,所以8放入活结点表头因为他的un最大，而9在最末端因为un=3且cn=0最小，所以活结点表为(8,6,7,9) 取8(此时8一定被展开成死节点，所以就不在活结点表中了），8左右均可展开，所以得到10和11,10的cn=2,un=4,11的cn=1,un=3,所以10放在最前面因为un最大，而11放在7前面，我们发现此时出现了更为特殊地情况即11和7的cn和un均相等，此时可以采取两种策略，第一种就是FIFO，先到先出，这样可以，但是还有一种策略就是将11插入到7前面因为既然11和7的情况完全相同那么我们就继续选择最近完成的情况11进行展开。活结点表为(10,6,11,7,9) 取10(此时10一定被展开成死节点，所以就不在活结点表中了），10只能右展得到12，此时发现又出现特殊情况12和6的情况完全相同，我们还是采取不切换的策略所以活结点表为(12,6,11,7,9) 取12(此时12一定被展开成死节点，所以就不在活结点表中了），左右展开得到13和14并且此时13和14是cn=un所以到达了叶子节点，所以13就是最优解，最大团数为3,解为[0,1,1,0,1]即为{B,C,E},此时也是继续展开肯能还会得到其他团为3的解，但是总体看来最大团数不会再发生改变就是3，所以活结点表中剩余节点销毁即可，算法结束。 思考：对于cn和un都相等的情况使用FIFO是否更好？ 事实是使用FIFO策略更好，因为这样好实现功能，所以我们对上面的进行小更改，此时按照FIFO策略 取8(此时8一定被展开成死节点，所以就不在活结点表中了），8左右均可展开，所以得到10和11,10的cn=2,un=4,11的cn=1,un=3,所以10放在最前面因为un最大，而11放在7前面，我们发现此时出现了更为特殊地情况即11和7的cn和un均相等，此时可以采取两种策略，第一种就是FIFO，先到先出，此时我们就采取FIFO策略，所以11在7的后面9的前面，所以活结点表为(10,6,7,11,9) 取10(此时10一定被展开成死节点，所以就不在活结点表中了），10只能右展得到12，此时发现又出现特殊情况12和6的情况完全相同，我们采取FIFO策略所以活结点表为(6,12,11,7,9) 取6(此时6一定被展开成死节点，所以就不在活结点表中了），左右展开得到13和14并且此时13和14是cn=un所以到达了叶子节点，所以13就是最优解，最大团数为3,解为[1,1,0,0,1]即为{A,B,E},此时也是继续展开肯能还会得到其他团为3的解，但是总体看来最大团数不会再发生改变就是3，所以活结点表中剩余节点销毁即可，算法结束。 所以按照上面的步骤并没有产生对速度的影响而功能实现起来更简单了，最终空间树如下： 所以最终我们发现最好的策略就是un&gt;best&amp;&amp;使用大顶堆&amp;&amp;对于cn，un相等的情况采用FIFO的搜索效率最快且实现也较为简单。 思考：分枝-限界和回溯的区别？ 其实我们在回溯法里已经做过对比了，这里在温习一下，回溯法就是每次都尽量走能取得更好情况的左展（这里有一个左展限界），用时也要进行回溯讨论能否右展（右展限界）最终是得到许多可能产生最优情况的解再对比这多组解得到最优解。而分枝-限界就是一次性左右展都展开（如果有特别需要左右展有限界条件）同时对于每一个节点（无论是左展还是右展）都要用一个限界条件来判断是否可以加入活结点表，只有能够满足条件进入活结点表的节点才有被展开的资格，然后每次展开时都是选取活结点表队首元素即当下能产生最好情况的节点进行展开，最终得到的解就是最优解。无优劣之分，不一定每次分枝-限界都比回溯法搜索效率高。 货担郎问题（旅行商问题TSP） 就是卖货郎要每个城市只能路过一边且最终回到出发城市的最短路径。这里我们也可以使用分枝-限界的方法，进行计算，但是这里使用的是一种无向图权重题求成本函数特有的方法求得成本函数值下界的方法，叫做归约矩阵和归约数的东西。我知道他不太好理解，你一定会问为什么这样算，有没有什么依据，答案肯定是有依据的，只是很难理解，我不会😅。这里有一句话说得好呀： 别试着理解它，感受它 --《信条》by诺兰 所以这里我只介绍方法，反正能解题就行了，如果你也像本博主一样菜鸡，不想知道为什么，那就一来看看求解方法吧！ 我们已经归约矩阵和归约数来求解c(x)，首先我们看一下定义： 什么是归约矩阵？ 每行每列均含有0的矩阵就是归约矩阵，简单来说，就是无论是以行的视角去看矩阵，还是以列的视角去看矩阵，我们都要保证这个矩阵在每一行或每一列都含有0。但是特殊地，如果某一行或者某一列全是∞也可以。 什么是行归约矩阵，什么是列归约矩阵？ 顾名思义，只满足行条件的就是行归约矩阵，只满足列的就是列归约矩阵。 怎样将一个矩阵变为归约矩阵？ 对于一个矩阵，如果某一行没有或者某一列没有0，则就对这一行或者这一列减去最小的数（并且这个数肯定是非零的且不是∞,否则这一行就满足了归约条件）。 什么是矩阵行归约数，什么是矩阵列归约数？ 对于每一行，将进行过归约的行所减去的数求和就是行归约数。对于每一列，将进行过归约的列所减去的数求和就是列归约数。 什么是矩阵归约数？ 矩阵归约数就是矩阵行归约数+矩阵列归约数。 什么是节点归约矩阵 就是对于归约矩阵，如果是节点i到节点j的归约矩阵，则将第i行和第j列全部数值改为∞，还要将(j,i)改为∞，如果此时还满足是一个归约矩阵的话，那么他就是从i到j的归约矩阵。如果不是我们暂称为节点矩阵。 什么是节点行归约数，什么是节点列归约数？ 对于节点矩阵，如果变换以后不满足是一个归约矩阵的条件了，那么需要对它进行规约化，那么相应的行归约数和列归约数就叫做节点行归约数，节点列归约数。 什么是节点归约数 就是节点行归约数+节点列归约数。 然后我们在看一下c(x)和归约数以及归约矩阵的关系。对于某个节点S如果其父节点为R，则就是从R到S的一条路径，那么c(S)=c®+A(i,j)+r,其中c®就是其父节点R的成本函数值，A（i,j)就是其父节点R的节点归约矩阵中从R到S的数值（R,S）,r就是S节点归约矩阵的节点归约数。特殊地，要记住，节点1即根节点的节点归约矩阵就是归约矩阵，其节点归约数就是归约数。 可能你已经看蒙了，没事，我们以一道例题来讲解。 例题 这是城市之间的关系，因为无论从哪里出发最终都是绕一圈回来，所以起点不影响最终结果，所以我们就以1位起点城市开始。 那么首先我们写出城市间的邻接矩阵如下： 不直接相连的城市距离设置为∞，然后发现并不是归约矩阵，所以先归约化。首线先进行行归约化： 因为每一行都不满足行归约条件，所以每一行都要进行归约化，即都要减去最小的数，则每行分别减去了{10,2,2,3,4}，所以行归约数就是10+2+2+3+4=21。然后发现第一列和第三列不满足列归约条件，所以这两列进行规约化，分别减去{1,3}，如下图; 此时已经变成了归约矩阵（同时也是1节点归约矩阵），所以归约数为21+4=25，并且特殊地根节点即1节点的节点归约矩阵也是这个，且节点1即根节点的节点归约数=归约数=25。所以c(1)=25。此时我们展开状态空间树节点1，按照分枝-限界的思路，先将1节点全部打开直至为死节点，所以1节点（代表从1出发，那么肯定已经过了城市1了）展开出2,3,4，5三个节点分别代表出发去这四个城市。那么我们也要分别计算c(2),c(3),c(4),c(5)并将节点2,3,4,5加入到活结点表中。我们先计算c(2),首先按照前面的定义，先写出从1到2的节点矩阵，即将第一行和第二列全部置为∞，然后还要讲(2,1)改为∞，此时矩阵变成： 啊哈，好巧不巧，他直接就是一个归约矩阵，太nice了😋，省去了归约化得过程，那么我们接下来就求解以下c(2),首先c(2)=c(1)+A(1,2)+r(2),此时c(1)=1节点归约数=归约数=25，A(1,2)表示为1的归约矩阵中从1到2的数值查表为10，且此时因为2节点矩阵直接就是节点归约矩阵了，不需要归约化，所以此时r(2)=0。所以c(2)=25+10+0=35。然后我们在计算一个没有那么巧合的c(3)，此时我们需要将归约矩阵的第一行和第三列置为∞，且把(3,1)改为∞，此时变成了3节点矩阵： 我们发现他并不是恰好为一个节点归约矩阵，所以我们先要对它进行归约化，所以发现行全部满足归约条件，对于列第一列不满足，所以第一列归约化，减去11，所以列归约化以后： 此时变成了3节点归约矩阵了，且节点归约数为11，所以此时c(3)=c(1)+A(1,3)+r(3)=25+17+11=53。c(4)也是类似，这样算，所以空间展开书就是如下： c(4)=25，c(5)=31,根据分支-限界思路，我们选择最优情况进行展开，所以展开节点4有6,7,8三个点代表去{2,3,5}三个城市，同样我们需要计算c(6),c(7),c(8)，但是这里要尤为注意，此时计算时c(6)=c(4)+A(4,6)+r(6),表示的是用城市4的节点归约数11，和A(4,6)为在城市4的节点归约矩阵上查找(4,6)的值，并且还需要计算r(6)的值，这个就需要计算6的节点归约矩阵了，此时需要在归约矩阵上将第4行和第2列置为∞和(2,4)置为∞，在归约求解归约数。最终一直算下去就得到了节点11，此时为28意味着具体额优化开销为28，所以最优解就是1-&gt;4-&gt;2-&gt;5-&gt;3-&gt;1,开销只需要28，图貌似有点不太对，忘了标出5城市了，没关系，反正我们知道怎么计算就好了。如果没明白，可以多看看或者留言哦~ 小作业 Questions 对以下最小罚款额调度问题的实例：(10,3,2),(3,4,2),(8,2,1),(6,3,1)利用分枝-限界法求解，要求：写出限界条件，划出展开的部分状态空间树 对以下0/1背包问题的实例：n=4,c=7,w=[3,5,2,1],p=[9,10,7,4]利用分枝-限界法求解，要求：写出限界条件，划出展开的部分状态空间树 Answers 总结 那么本次分枝-限界方法我们了解到了他总是伴随bfs出现，并且每次都要计算c(x)来记录随时切换到最理想的情况进行求解，最终即可同时得到最优值和最优解，所以其根本难点在于计算c(x)，对于罚款额，背包等一般问题我们按照正常思维（每次寻找最少罚款额，每次选取效益值大的情况）即可写出c(x）计算式，对于这种货担郎复杂的图论问题，则需要归约矩阵进行计算c(x)了，那么本次分享就到此为止啦，希望你能有所收获😎！"},{"title":"动态规划","path":"/wiki/手撕算法笔记/动态规划/index.html","content":"什么是动态规划 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优解的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。具体的动态规划算法多种多样，但它们具有相同的填表格式。 从度娘的这番话中我们不难理解，动态规划也是分为许多子问题，然后自下而上或者自上而下建立一个有规律的表达式即递归表达式进行推导复杂问题的最优解和最优解值。但是这里会打表暂存中途的计算结果以减少重复计算的次数提高性能(与dfs最大的不同)。 典型例题精讲 求解多段图的最短路径 对于上图的最短路径1-&gt;3-&gt;5-&gt;7，其子路径3-&gt;5-&gt;7是3-&gt;到目的节点7在图上的最短路径，所以可以总结出无论从1出发到[2,3,4]中的任意一个点，其后的路径也应为最短路径，即最优解的子集仍应该为子问题的最优解，并且前子问题对于后者最优解无影响，这是动态规划算法可以应用的根本前提。 所以借助上文我们可以列出递归表达式如下，设c(i)表示从i出发到目的节点7的最短路径，cost[i，j]为从i出发到j所用的权重，则有 c(1)=min{c(k)+cost(1,k)},k=2,3,4c(1)=min\\{c(k)+cost(1,k)\\},k=2,3,4 c(1)=min{c(k)+cost(1,k)},k=2,3,4 并且我们易知c(7)=0；自此一个已知前提加上递归表达式可以自后向前推导出 出发节点 权重 c(6) 1 c(5) 2 c(4) 8+c(6) c(3) min{1+c(5),5+c(6)} c(2) min{7+c(5),6+c(6)} c(1) min{1+c(2),4+c(3),6+c(4)} 0/1背包问题 解题思路 不选择贪心所用的密度值递减顺序放入物品，也不使用k-优化优化算法提高可信度的方法，而是选择直接用递归枚举求解物品放还是不放的方法。即无论优化解是否放物品1，相对剩余背包容量,优化解对物品2,…,n的放法, 也是优化解。 例如n=5,c=10,w=[2,2,6,5,4],p=[6,3,5,4,6]。其优化解为(1,1,0,0,1),即优化的物品装入背包的方法为物品1,2,5放入。物品1占背包容量2,剩下容量为8.优化解中包含的子问题转化为n=4,c’=c-2(物品1的重量),物品为2,3,4,5(1,0,0,1),即放物品2和5,是上述子问题的优化解，背包问题满足的优化原理。即每次我们都枚举物品是否放入来列递归式，设f(i,y)表示背包现有容量为y,放入物品i,…,n得到的优化效益值，则有： f(i,y)=max{f(i+1,y),f(i+1,y−wi)+pi}f(i,y)=max\\{f(i+1,y),f(i+1,y-wi)+pi\\} f(i,y)=max{f(i+1,y),f(i+1,y−wi)+pi} 当然，上述式子成立的条件是物品i假设可以放入，然后在讨论是否放入的问题，如果无法放入则，就直接抛弃，式子改写为f(i+1,y)，所以可以列出0/1背包dp思路模板如下： f(n,y)={pn,y&gt;=wn//可以放入第n见物品0,0&lt;=y&lt;wn//背包就放不下第n件物品f(n,y)= \\begin{cases} pn,y&gt;=wn//可以放入第n见物品\\\\0,0&lt;=y&lt;wn//背包就放不下第n件物品 \\end{cases} f(n,y)={pn,y&gt;=wn//可以放入第n见物品0,0&lt;=y&lt;wn//背包就放不下第n件物品​ 上面的是前提已知条件，下面是递归模板 f(i,y)={max{f(i+1,y),f(i+1,y−wi)+pi},y&gt;=wi//能放入物品if(i+1,y),0&lt;=y&lt;wi//放不下物品if(i,y)= \\begin{cases} max\\{f(i+1,y),f(i+1,y-wi)+pi\\},y&gt;=wi//能放入物品i\\\\ f(i+1,y),0&lt;=y&lt;wi//放不下物品i \\end{cases} f(i,y)={max{f(i+1,y),f(i+1,y−wi)+pi},y&gt;=wi//能放入物品if(i+1,y),0&lt;=y&lt;wi//放不下物品i​ 根据上面的思路，我们可以写出c代码模板如下： 12345678910int F(int i,int y)&#123; //返回f(i,y) if(i==n)&#123; return (y&lt;w[n])?0:p[n]; &#125; if(y&lt;w[i])&#123; return F(i+1,y); &#125; return max(F(i+1,y),F(i+1,y-w[i]+p[i]));&#125; 下面我们就用上述思路来解题 递归实现 n=5,c=10,w=[2,2,6,5,4],p=[6,3,5,4,6] 首先我们先不想那么多，直接按照上面的递归表达式思路走一发。我们为了求解,调用F(1,10)求解f(1,10)。这里用递归树展开计算经过，其中每个节点用y值来标记，第j层的节点对应F(j,*)，因此根节点表示F(1,10),而它有左、右子节点,分别对应F(2,10)和F(2,8)。 上图中节点标出的是背包剩余容量，未标出的则为后面无法再放物品了，我们会发现本次运行执行了28次递归调用，并且灰色部分是重复进行了计算，这部分就和dfs递归调用等递归求解问题一样的共性缺点，重复计算消耗大量时间，为了减少没有必要的计算，我们可以暂存以前的计算结果，这样就只需要计算19次了，这也是dp算法总是要借助表格的原因。下面我们就介绍两种存储中途结果的方法。 w取整数时迭代实现 n=5,c=10,w=[2,2,6,5,4],p=[6,3,5,4,6] 当物品重量为整数时,可设计一相当简单的算法来求解f(1,y),这里我们使用二维数组f[i][y]存储每一个f(i,y)的值，并且计算一次，就长这个样子： i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 6 6 6 6 6 6 6 4 0 0 0 0 6 6 6 6 6 10 10 3 0 0 0 0 6 6 6 6 6 10 11 2 0 0 3 3 6 6 9 9 9 10 11 现在我们不用关心这个表的具体数值是怎么得到的，只要知道他长这个样子就可以了，所以这里是对每一个i都列举了y从0到10所有可能的情况下的最好取值。所以我们知道了二维数组需要n*c个空间大小。那么表中数字是怎么得到的呢，步骤如下： 首先我们先建立一个表，并初始化为0 i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 然后我们还是需要先找到一个已知条件，这里不难看出就是f(5,y)为已知条件然后根据递归表达式自下而上推导，所以只要y&lt;w5,f(5,y)就为0，当y&gt;=w5时，f(5,y)为p5=6,因为w5=4,所以填入数据。变为： i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 6 6 6 6 6 6 6 4 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 然后推导f(4,y)=max{f(5,y),f(5,y-w4)+p4},所以当y&gt;4时f(5,y)=6,f(5,y-w4)+p4=0,即虽然不能放物品4，但是已经可以放物品5了，所以y&gt;4时至少f(4,y)至少为6，然后在看当y&gt;=9时，此时f(5,y-w4)+p4=10，即4，5都可以放入背包，所以，此时表的值变为： i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 6 6 6 6 6 6 6 4 0 0 0 0 6 6 6 6 6 10 10 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 然后推导f(3,y),同理知道当y&lt;4时，只能取f(4,y)的值，即和上一行的的取值相同，直到,y=6时，此时可以放入3,但是由于去最优化效益值，此时不放入3，即只放入4,5,效益值仍然是最大的，所以还是取f(4,y)的值，直到y取10，此时f(4,y-w3)+p3为11更大，所以效益值变为11，所以表的值变为： i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 6 6 6 6 6 6 6 4 0 0 0 0 6 6 6 6 6 10 10 3 0 0 0 0 6 6 6 6 6 10 11 2 0 0 0 0 0 0 0 0 0 0 0 然后推导2，与上面基本思路相同，所以最后表就变为了 i\\y 0 1 2 3 4 5 6 7 8 9 10 5 0 0 0 0 6 6 6 6 6 6 6 4 0 0 0 0 6 6 6 6 6 10 10 3 0 0 0 0 6 6 6 6 6 10 11 2 0 0 3 3 6 6 9 9 9 10 11 可以看出来我们在给表赋值时用到了递归表达式，但是此时我们发现，和上面的裸递归方法不同，这里由于我们依次填表赋值并自上而下计算时，会用到上面的暂存结果的值，避免了重复计算的步骤，性能大大提升了，但是与次同时空间复杂性也提高了，并且我们还总结出来了中途接过存储数组的维度与条件量是等相关的，例如这里有效益值和背包容量两个限制条件，所以存储的数组就是二维数组，自此延伸思考可以知道如果再增加一个条件，这里需要开三维数组，自此，我们就可以得到y取不同值是从第i个物品开始放的所有情况的效益值了。 c板子如下： 12345678910111213141516171819202122232425262728293031template&lt;class T&gt;//这里的yMax为wivoid Knapsack(T p[],int c,int n,T** f)&#123; //对于所有i和y计算f[i][y] //初始化f[n][] for(int y=0;y&lt;=yMax;y++)&#123; f[n][y]=0; &#125; for(int y=w[n];y&lt;=c;y++)&#123; //初始化第一行 f[n][y]=p[n] &#125; //计算剩下的f for(int i=n-1;i&gt;1;i--)&#123; for(int y=0;y&lt;=yMax;y++)&#123; //都默认为不装入这个物品时为最大值 f[i][y]=f[i+1][y] &#125; for(int y=w[i],y&lt;=c;y++)&#123; //这里的for循环中的条件已经保证了物品i可以放入了 //比较装入和不装入哪个效益值更大取大值 f[i][y]=max(f[i+1][y],f[i+1][y-w[i]]+p[i]); &#125; &#125; //i=1即单独讨论第一个物品放还是不放 f[1][c]=f[2][c]; if(c&gt;=w[1])&#123; f[1][c]=max(f[2][c],f[2][c-w[1]]+p[1]); &#125;&#125;//对比分析，实际上元组法就是这个思路，只不过是用线性表优化了空间复杂度而已 元组法 仔细回想刚刚的方法，你有没有发现这里有一个可以优化的地方，给定了背包容量c后你会发现无论怎么组合，上面的表中貌似并不是所有值都可以取到，并且上种方法伴随着c和n的增大，表的大小以可见得速度增大，虽然时间复杂度没有发生太大变化，但是空间复杂度就过于庞大了，所以我们在这里提出了一种新方法，他不仅仅解决了空间复杂性过大的缺陷，同时这种方法也适用于w为非整数的情况，那么让我们来看一看思路吧。 元组法是将f(i,y)的跳跃点以元组(y,f(i,y))的形式存储于一个线性表p(i)中，表p(i)中的元组(y,f(i,y))按y的增序排列，p(i)中的元组(a,b)表示一种装物品的方法{i,…,n}，能够以a&lt;=y&lt;a’(a’为下一元组的横坐标)，取得效益值b。那么在拥有了f(i+1,y)和p(i+1)以后，我们就可以得出f(i,y)的线性表p(i)，这种算法思路如下：f(i,y)的定义: f(i，y)=max{f(i+1,y),f(i+1,y-wi)+pi},首先需要从P(i+1)得到函数f*(i+1,y)=f(i+1,y-wi)+pi的元组集合Q,设(a,b)∈Q, 则(a-wi, b-pi)必为P(i+1)的元组,反之亦然. 所以,P(i+1)的每个元组(w,p)对应Q的一个元组(w+wi, p+pi)。Q的元组(u,v)代表装物品{i,…,n}的一种方案:以背包容量u,能得到效益值v。接下来，是一种算法从p(i+1)和Q得到f(i,y)的元组(即p(i)的元组)。 从P(i+1)和Q得到P(i)的元组:因P(i+1)和Q内元组均按w和p的增序排列，所以可用以前学过的merge算法进行合并。合并时使用以下支配(优选)规则： 设(a,b)和(u,v)是来自P(i+1)和Q的元组,若a≥u且b＜v,则称(a,b)受(u,v)支配. 因为(a,b)代表以容量a得到效益值b的方案,而(u,v)代表以较少的容量u得到较大效益值v的装包方案。合并时舍弃被支配的元组。 至此，我们利用上述方法从p(n)逐渐向下推导至p(2)并舍弃被支配元组，得到p(2)后不再产生p(1),p(2)的最后一个元组是f(2,c)对应的元组，设p(2)中满足w+w1&lt;=c的最后一个元组为(w,v)，则将v+p1和p(2)的最后一个元组对应的效益值p作比较，效益值大的即为优化效益值。 如果你没有看懂，没关系，我也没咋看懂😅😆，直接看例题就好理解啦~ 例题1 n=5,c=10,w=[2,2,6,5,4],p=[6,3,5,4,6] 即求f(1,10),首先我们可以知道p(5)=[(0,0),(4,6)](即放入物品5以后的跳跃点集合)，Q=[(5,4),(9,10)](即加入物品4以后的跳跃点)，因为(5,4)代表一种方案，其效益值不如(4,6)(即不是最优效益值)，所以舍弃(5,4)，得p(4)。 上述方法我们可以转化成函数来更直观的观看，每一次加入物品，可以看成是函数向右上平移，然好merge合并就是取外交点，如下图： ​ 在上图中加入物品4后我们发现(5,4)在原来p(5)折线的下方，而(9,10)在p(5)折线的上方，所以根据支配原则，(5,4)被舍弃，p(4)取所有折线的外围，得p(4)的图像如下 回想一下原理，我们知道p(4)表示的是从i=4开始放物品，随着y增大，p的曲线，其中折线为跳跃点，那么很容易理解，当Q(5,4)时表示的是在y取值5以上时放入物品4不放入5，但是此时放入5时可以得到更大的效益值，所以(5,4)这个方案不是最优效益组合，当然就被pass了，而y=9时，原先放入的是物品5，但是加上Q(5,4)后表示的就是在可以放入物品5的同时，还可以再放进4，此时效益值达到了10且此时y=9&lt;=c(10)，所以p(4)在y&gt;=9时取外围得到效益值为10，所以合并的含义就是根据只放入物品5时的折线(p(5))和只放入物品4时的折线(Q)，综合考虑得到最优的组合方案取外部折线得到的即位从物品4开始放时y取不同值时的最优效益解。 同理，根据上面的思路，p(4)=[(0,0),(4,6),(9,10)],加入物品3，此时Q=[(6,5),(10,11)]，之所以没有(15,15)，是因为背包容量不够，所以直接舍弃，合并得到p(3)=[(0,0),(4,6),(9,10),(10,11)]，然后放入物品2，得到p(2)=[(0,0),(2,3),(4,6),(6,9),(9,10),(10,11)],最后再逐一加上物品1，发现(2,6)+(6,9)=(8,15)&gt;(10,11),所以最终的效益值即为15，之所以不求p(1),是因为，此时得到的p(1)=[(0,0),(2,3),(4,6),(6,9),(8,15)]就是之前求得的Q，但是要注意这可不是表示的一组优化效益解😲，如果你认为这是一组优化解说明没有理解元组法哦，建议再反复思考一下，此时的p(1)应该表示的是从物品1开始放入，y取不同值时的最佳效益值，每一个值都代表了不同的组合方案！！所以我们现在虽然得到了y取不同值时的最佳优化效益值，以及容量c时的最大效益值，但是此时我们还并不会求优化解，即组合方案，别着急，后面我们会讲到，此时我们先复习一下，上题我们是自后而前推导的，那么下面这道题我们在自前而后推导一下，顺便检验一下是否真正理解透彻此方法。 例题2 n=4,c=20,w=(10,15,6,9),p=(2,5,8,1) P(1)={(0,0)},(10,2)},Q={(15,5)} P(2)={ (0,0)},(10,2), (15,5)},Q={(6,8),(16,10)} P(3)={(0,0),(6,8),(16,10)} 因(6,8)+(9,1)=(15,9),效益值为9，小于(16,10)的效益值10。所以优化的效益值为10。 回溯法求解最佳组合方案 如果你理解了不放入物品i时的递归式，会很容易发现，f(i,y)==(fi+1,y)，而回溯法也是利用了这个等式进行求解的。下面我们就以例题2为例回溯求解最佳组合方案。 首先g(4,20)(效益值为10)==g(3,20)(效益值为10),表示我们并没有放入物品4，然后g(3,20)(效益值为10)!=g(2,20)(效益值为5),所以说明放入了物品3后最佳效益值由5涨到了10，所以放入了物品3，此时y=c-w3=14，p=20-p3=2，所以变为g(2,14),然后g(2,14)(效益值为2) ==g(1,14)(效益值为2),所以没有装物品2，最后g(1,14)(效益值为2)!=0,说明装入了物品1，所以最佳组合为[1,0,1,0]。 矩阵乘法链 学过线性代数的同学都知道，不同的矩阵相乘方法，所用的乘法次数也是不同的，比如假定A为100×1矩阵,B为1×100矩阵,C为100×1矩阵,(A*B)*C需乘法数为100×1×100＋100×100×1＝20000而 A*(B*C) 所需乘法数为1×100×1＋100×1×1＝200,(温馨提示：m×n矩阵A与n×p矩阵B相乘需要做m*n*p个元素乘法,原因想一想就懂了)。 矩阵乘法链问题就是求得所用乘法次数最少的乘法顺序并求得最小乘法次数，我们考虑，每次Mi×…,×Mj (i&lt;=j)，每次将这部分分成两部分，即取一个i&lt;=k&lt;=j，将矩阵乘法链分为M(i, k)×M(k+1,j)。那么计算M(i,j)的优化乘法顺序在计算子链M(i,k)和M(k+1,j)时的也是优化的。因此我们可以得到以下递归式： 用c(i,j)表示为计算M(i，j)的优化乘法数 c(i,j)=min{c(i,k)+c(k+1,j)+Rowi∗Rowk+1∗Columnj},i&lt;=k&lt;=jc(i,j)=min\\{c(i,k)+c(k+1,j)+Row_i*Row_{k+1}*Column_{j}\\},i&lt;=k&lt;=j c(i,j)=min{c(i,k)+c(k+1,j)+Rowi​∗Rowk+1​∗Columnj​},i&lt;=k&lt;=j 并且kay(i,j)为c(i,j)达到最小值的k，并且c(i,i+1)表示Mi×Mi+1,即两个矩阵相乘无法在分隔可以求得具体数值，c(i,i)则表示一个矩阵即默认最后在乘所以次数为0，所以可以解题： 设q = 5和r =(10 , 5 , 1 , 10 , 2 , 10)，这里表示有5个矩阵，分别为10×5,5×1,1×10,10×2,2×10,所以根据动态规划的递归式得 c(1,5)=min{c(1,1)+c(2,5)+500,c(1,2)+c(3,5)+100,c(1,3)+c(4,5)+1000,c(1,4)+c(5,5)+200},这里c(3,5),c(2,5)都可以再次分隔。 c(2,5)=min{c(2,2)+c(3,5)+50,c(2,3)+c(4,5)+500,c(2,4)+c(5,5)+100} c(3,5)=40,kay(3,5)=4,c(2,4)=30,kay(2,4)=2,所以在c(1,5)中,方案2，即从2第一次分隔锁的乘法次数最少为c(1,2)+c(3,5)+100=50+40+100=190,回溯法求得顺序： M(1,5)=M(1,2)×M(3,5),M(3,5)=M(3,4)×M(5,5),所以最终顺序为[M(1,1)×M(2,2)]×{[M(3,3)×M(4,4)]×M(5,5)},最少乘法为190。 All-pair最短路问题 最短路径:假设G为有向图,其中每条边都有一个成本(cost),图中每条有向路径的长度(或成本)定义为该路径上各边的成本之和。对于每对顶点(i, j), 定义从i 到j 的所有路径中,具有最小长度的路径为从i 到j 的最短路。All-Pair最短路问题:求每对点间的最短路。假定图上无负成本的环路, 这时只需考虑简单路径: 加上环路只会增加路径成本。 我们的解题思路为将节点1到n进行任意顺序编号，然后定义c(i,j,k)表示为从i出发到节点j的路过的节点序号不超过k的最短路长度，即包含i,j和1,…,k的子图上的最短路。所以，c(i,k,k)=c(i,k,k-1),c(k,j,k)=c(k,j,k-1)并且对于所有的k,均有c(i,i,k)=0，特别的c(i,j,0)=cost(i,j)。 例如下图： 我们可以建立递推公式，即 c(i,j,k)=min{c(i,j,k−1),c(i,k,k−1)+c(k,j,k−1)}c(i,j,k)=min\\{c(i,j,k-1),c(i,k,k-1)+c(k,j,k-1)\\} c(i,j,k)=min{c(i,j,k−1),c(i,k,k−1)+c(k,j,k−1)} 表示在最短路上或不包含k或包含k,如果直接用递归程序求解，则计算c(i,j,n)的复杂度会极高，所以这里利用迭代的方法暂存中途计算结果。 这里我们用迭代矩阵的方法求解，建立矩阵C(k)代表矩阵(c(i,j,k),i,j=1,…,n),因为c(i,i,k)=0，所以不用想矩阵的对角线元素均为0，然后算法迭代，初始化的C(0)即为图的邻接矩阵，即不经过任意中间节点从i到j的路径长度，不能到达即为∞，然后每次迭代时由于c(i,k,k)=c(i,k,k-1),c(k,j,k)=c(k,j,k-1)，所以矩阵C(k)的第k列和第k行的元素值不发生变化，即C(k)(i,k)=C(k-1)(i,k),C(k)(k,j)=C(k-1)(k,j),而其他行，列的元素则需要按照上面的递归式进行求解，C(k)(i,j)={C(k-1)(i,j),C(k-1)(i,k)+C(k-1)(k,j)},又因为C(k)=c(i,j,k),所以C(k-1)(i,k)=C(k)(i,k),C(k-1)(k,j),所以前面的式子可以改写为C(k)(i,j)={C(k-1)(i,j),C(k)(i,k)+C(k)(k,j)}，所以算法实现时即为每次跌倒第k个矩阵时，k行k列照抄前面的矩阵就好，其他的逐一用之前i-&gt;j的长度和新的i-&gt;k+k-&gt;j比较选短路径即可。如下图： 右边的即为邻接矩阵同时也就是C(0),接下来迭代，有几个点就迭代几次，上图3个点，所以迭代3次。 我们发现第一行和第一列都是直接照抄没变化，而C(1)(3,2)=min{C(0)(2,3),C(0)(3,1)+C(0)(1,2)},因为C(0)(3,2)=∞,而后者为7，所以更新C(1)(3.2)=7。然后迭代得C(2). 第二行和第二列照抄，然后C(2)(1,3)=min{C(1)(1,3),C(1)(1,2)+C(1)(2,3)}=min{11,4+2}=6 其他情况经计算无太大变化，然后迭代得C(3)。 第三行和第三列不变，检验其他的情况，发现 C(3)(1,2)=min{4,6+7}=4,所以这种情况不变，而C(3)(2,1)=min{6,2+3}=5所以更新，最后C(3)即为各个点之间最短路径权重，回顾整个过程，我们每一次迭代都是遵循了递归表达式，并且由于每次都将中间结果进行了暂时储存，所以也避免了重复的计算。 最长公共子序列 最大公共子序列问题和最大公共子串问题不一样，子序列并不要求是连续的，我们首先给出子串的定义。 思考:什么是子序列? 一个给定的序列的子序列就是将给定序列中零个或者多个元素去掉之后得到的结果，即元素不需要连续如下图： 所以最长公共子序列就是对于给定序列X和Y，需要找出一个子序列Z使得Z同时是X和Y的子序列并且还要是最长的，那么Z就是最长公共子序列又简称为LCS。那么如何求得最长公共子序列的长度呢？ 思考：LCS长度求解的方法？ 首先我们想到的就是暴力循环穷举来求得LCS的长度，但是显然时间复杂度为O(2^n)太大了，我们需要降低时间复杂度，所以寻找一种更好的方法即dp算法找到递归式即可，如下： 首先我们思考一个问题，对于两个给定序列A=&quot;a0,a1,…,am&quot;和B=&quot;b0,b1,…,bn&quot;他们的最长公共子序列为Z=&quot;z0,z1,…,zk&quot;那么我们很容易得到如下规律： 如果am=bn且zk=am=bn，那么显然&quot;z0,z1,…,z(k-1)&quot;是&quot;a0,a1,…,a(m-1)&quot;和&quot;b0,b1,…,b(n-1)&quot;的一个最长公共子序列。 如果am!=bn且zk!=am，那么zk==bn,所以显然&quot;z0,z1,…,zk&quot;是&quot;a0,a1,…,a(m-1)&quot;和&quot;b0,b1,…,bn&quot;的一个最长公共子序列。 如果am!=bn且ak!=bn,那么zk==am，所以显然&quot;z0,z1,…,zk&quot;是&quot;a0,a1,…,am&quot;和&quot;b0,b1,…,b(n-1)&quot;的一个最长公共子序列。 所以我们可以列出以下递归式：其中C表示LCS长度，i,j是两个串的下标值 C(i,j)={0,ifi=0orj=0C[i−1，j−1],ifi,j&gt;0andxi=yimax{C[i,j−1],c[i−1,j]}ifi,j&gt;0andxi≠yiC(i,j)=\\begin{cases} 0,&amp;if&amp;i=0orj=0\\\\ C[i-1，j-1],&amp;if&amp;i,j&gt;0andx_i=y_i\\\\ max\\{C[i,j-1],c[i-1,j]\\}&amp;if&amp;i,j&gt;0andx_i≠y_i \\end{cases} C(i,j)=⎩⎪⎪⎨⎪⎪⎧​0,C[i−1，j−1],max{C[i,j−1],c[i−1,j]}​ififif​i=0orj=0i,j&gt;0andxi​=yi​i,j&gt;0andxi​=yi​​ 根据上面的式子我们也不难理解就是下面的情况：设 p1表示A的前i-1个字符和B的前j-1个字符的LCS的长度 p2表示A的前i个字符和B的前j-1字符的LCS的长度 p表示A的前i-1个字符和B的前j-1个字符的LCS的长度 p0表示A的前i个字符和B的前j个字符的LCS的长度 如果A的第i个字符和B的第j个字符相等，则p0=p+1 如果A的第i个字符和B的第j个字符不相等，则p0=max{p1,p2} 所以也是和上面的背包问题相似打表求解如下图，我们只要从C[0][0]开始打表，填到C[m][n]就是LCS的长度，那么具体做法如下： 首先我们需要将两个序列串的初始化，即表格的第零行和第零列填零（根据公式1，i或者j有一个为零时，LCS的长度都为0）： 这样我们接下来对每一个格的数值计算就是按照公式2和公式3展开，例如S1的3和S2的3相同所以他们的值(S11，S21)=(S10+S20)+1=(0,0)+(1,1)=(1,1)，所以表中(1,1)的位置处的值为1，即： 对于两个字符相等的地方他们的值来自左上角的值+1，而对于不相等的位置则根据公式3知道为左边的值和上边的值中最大的值决定，如下： S1的3和S2的5不相同，所以根据公式3可以得到值来自黄格中较大的值，所以为1，这样我们对所有行进行填写，直至填满整个表（实际上代码中是使用二维数组来打表）。就可以得到如下： 所以我们求得整个表的所有值后最右下角的就是解，所以对于上面的这个序列串，最终的LCS长度就是C[8,9]=5，那么我们又怎样求得具体的LCS是什么呢？ 思考：LCS具体求解的方法？ 我们需要进行回溯求解，如下从C[8,9]开始分别和左，左上，上的三个格进行对比，相同的格子值就是来的路径也就代表了是根据公式几推得的，那么我们也就知道了求解时的情况，如下： 我们发现C[8,9]的值和C[8,8]的值相同，所以说明C[8,9]是由公式3推得的，所以说明S18和S29的元素不相同，而对于C[8,8]的值来自于C[7,7]是公式2推得的，所以说明C[8,8]所对应的S18和S28元素相同，这样我们就可以找到相同元素了如上图的棕色方块（所以就是如果这个方块K所对应的值和其左上角的格值相同则K所对应的坐标值是元素相同的一个坐标，否则就不是），如果不是相同元素即S1[i] != S2[j] 且遇到了c[i-1][j] = c[i][j-1]即左方块和上方块值相同时永远要取一个方向，要么都左，要么都上，这样我们一直到最左上方，所有棕色方块所组成的就是一个LCS，如上图中的每次都是取左最终得到的LCS是{3,4,6,7,8},而如果每次都取上方： 那么得到也是一个大小为5的LCS，是{3,5,7,7,8}。这种求解方法的时间复杂度仅仅为O(m+n)，空间复杂度也只是O(mn)很是简单高效。 拓展：另一种打表格式 对于上面这种打表直接求值很是难以直接方便看出回溯路径，所以我们知道了原理后可以得到一种更为简单的路径，即： 在对应字符相等的时候，用↖标记 在p1 &gt;= p2的时候，用↑标记 在p1 &lt; p2的时候，用←标记 这样我们得到的打表最终结果会如下： 这样我们就可以更好的找到回溯路径求得LCS了，并且如果可以同时添加上数值也就很容易能够同时求解得到LCS的长度。 小作业 Questions 设c(i)为多段图上节点1到目的节点的最短路长度，试列出动态规划的递归式.并就课堂上的 例子给出求解过程。 0/1背包问题: n=4,c=20,w=(10,15,6,9) p=(2,5,8,1) 请使用元组法求解该背包问题的优化值和优化解。 子集和数问题:设S={s1,s2,…,sn} 为n个正数的集合,试找出和数不超过M且最大的S的子集, 该问题是NP-难度问题,试用动态规划法设计一算法。 设一个矩阵乘法链的行列数为r=(10,20,50,1,100),用动态规划算法给出优化的乘法顺序和 优化的乘法数。 Answers 参考文献 动态规划求LCShttps://blog.csdn.net/hrn1216/article/details/51534607 结尾语 本节我们对dp算法有了深刻的了解，知道了解题过程，解题思路就是先建立递归表达式，然后找到已知条件，借助矩阵，线性表等数据结构进行中途结果的暂存，然后通过递归求解所有情况的优化值，那么本次分享就到这里😬！"},{"title":"前缀和与差分","path":"/wiki/手撕算法笔记/前缀和与差分/index.html","content":"本文借鉴了pengpenglang大佬的《差分》感谢大佬的精彩讲解。 前缀和 概念&amp;用途 前缀和就是对数组中的元素进行预处理，进行前n项求和。他的作用常用于区间的求和，合理使用前缀和可以简化复杂的区间求和问题降低复杂度。假设现在我们定义一维前缀和s[i]，那么他就表示对数组中第1~i个元素的值进行求和，如下所示 S[i]=a1+a2+a3+...+aiS[i]=a_1+a_2+a_3+...+a_i S[i]=a1​+a2​+a3​+...+ai​ 一维前缀和 假设我们现在要输入一个长度为n的整数序列，接下来再输入q个查询，每一个询问都会输入一个l,r表示此次要求和查询的区间（闭区间）。那么我们该如何解决这道题呢？ 首先第一想法就是暴力求和，对[l,r]内的元素逐一累加输出求和结果，但是这样当n和q稍微大一点就可能造成时间超时。原因就是时间复杂度过高了为O(n*q)，总是出现相邻查询的元素有大量重叠造成多次遍历，比如第一次要查询[3.7]内的元素之和，第二次要查询[2.5]的元素之和，那么每一次查询都要扫一次数组，就会很慢，因此我们需要用到一维前缀和进行预处理加快每一个查询的速度。 我们可以如下处理，假设传进来的元素存入num列表，那么我们再定义一个pre列表专门来存放前i个元素的和即前缀和，因此pre[i]的定义就是： pre[i]=num[1]+num[2]+...+num[i]pre[i]=num[1]+num[2]+...+num[i] pre[i]=num[1]+num[2]+...+num[i] 紧接着我们很容易就可以看出pre[i]和pre[i-1]存在以下递推关系： pre[i]=pre[i−1]+num[i]pre[i]=pre[i-1]+num[i] pre[i]=pre[i−1]+num[i] 很明显pre列表的长度应该与num列表长度相同，那么假设现在我们已知了输入的num列表元素，如何才能求得pre列表呢？很简单，我们只需要扫一遍num列表就可以通过如上递推公式求得pre列表了： 123#pre[0]和num[0]都初始化为0for i in range(1, n+1): pre[i] = num[i]+pre[i-1] 也就是说我们只用一个时间复杂度O(n)就完成了一维前缀和数组pre的生成，加下来对于q次查询，我们如何对每一个[l,r]区间的元素进行求和呢？ 也很简单，只需要用pre[r]-pre[l-1]就可以轻松地计算出[l,r]内所有元素之和了，原理如下： 这样每一次查询就不用再扫一遍num数组了，时间复杂度降为了O(1)，那么q次查询 时间复杂度就是O(q)，因此使用一维前缀和解决这个问题的时间复杂度从O(n*q)降低为了O(n+q)。 回顾下一维前缀和的总体流程，实际上就是如下图所示： 接下来给出板子： 12345678910111213# 一位前缀和# 对下标范围[1,n]的数组查询q次指定区间的元素之和def solve(): n, q = map(int, input().split()) #一定要注意num和pre的第0个元素初始化为0 num = [0] pre = [0]*int(1e5+5) num.extend(list(map(int, input().split()))) for i in range(1, n+1): pre[i] = num[i]+pre[i-1] for i in range(q): l, r = map(int, input().split()) print(pre[r]-pre[l-1]) 思考：为什么num和pre的第0位要初始化为0? 我们思考一下这个递推公式，为什么我们能够通过pre[i]=pre[i-1]+num[i]就可以计算出pre[1]呢？实际上当i=0时，才能出现pre[1]=pre[0]+num[1]即pre[1]=num[1]的公式从而进行接下来的递推求解。 要注意在算法题中，相较于0~len(arr)-1方式的存储，我们更倾向于按照1~len(arr)的方式存储，因此在python中for循环要用range(1,len(arr-1))，同时初始化时数组要特别留意将第0位初始化为0方便后面的计算。 二维前缀和 二维前缀和实际上就在一维前缀和的基础上增加了一维，因此我们此时再看待前缀和就不要再一维的数轴，长度上进行思考，而应该从二维矩阵，面积上进行思考。 先看题意，假设现在输入了一个n行m列的整数矩阵，在输入q个查询，每一个查询包括四个整数x1,y1,x2,y2表示一个子矩阵的左上角坐标和右下角坐标。对于每一个查询输出两个坐标所表示的矩阵内的元素之和（包括边界上的）。 实际上本质上并没有变，我们还是要先预处理计算出二维前缀和，此时很明显我们需要使用num[][]和pre[][]来存储矩阵元素值和计算生成的前缀和了。此时num[i][j]很容易理解就是表示二维矩阵中某个点对应元素的值，而pre[i][j]表示应该是从左上角原点[1][1]到第i行第j列所在点[i][j]所形成的矩形包含的所有元素值之和。那么我们如何计算这个pre[i][j]呢？ 在一维中，我们是参考了长度来得出了pre[i]的递推公式，那么此时我们需要参考面积来得出pre[i][j]的递推公式了，如下所示： 对于一维中我们是知道了pre[i-1]和num[i]从而通过递推公式计算得出了pre[i]，那么这里的二维我们肯定是知道了pre[i-1][j-1]和num[i][j]进行递推计算出pre[i][j]。从上面的面积计算与容斥原理的应用，我们很容易就可以得到大蓝色面积pre[i][j]的计算递推公式即等于绿色面积pre[i-1][j]和紫色面积pre[i][j-1]之和再加上小蓝面积num[i][j]后再减去一个红色面积pre[i-1][j-1]得到的，因此递推公式就是 pre[i][j]=pre[i−1][j]+pre[i][j−1]+num[i][j]−pre[i−1][j−1]pre[i][j]=pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1] pre[i][j]=pre[i−1][j]+pre[i][j−1]+num[i][j]−pre[i−1][j−1] 同样的我们再将pre的第0行和第0列初始化为0，num的第0行和第0列初始化为0就可以通过递推公式完成二维前缀和的处理了。 如下所示： 123456num = [[0] for i in range(int(1e5+5))]pre = [[0]*int(m+5) for j in range(int(n+5))]for i in range(1, n+1): num[i].extend(list(map(int, input().split()))) for j in range(1, m+1): pre[i][j] = pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1] 注意python的二维矩阵初始化代码写法，n行m列要先循环设置m再循环设置n，同理，如果要设置三维数组n行m列k层，那么此时代码如下所示： 1pre=[[[0]*(k+5) for i in range(m+5)]for j in range(n+5)] 之所以要多开5个内存单元是为了减少处理列表边界的麻烦问题。同时切记不能写成如下这样是错误的！！ 1pre=[[[0]*(k+5)]*(m+5)]*(n+5) 这种写法会因为使用了浅复制造成多个一维数组之间指向了统一内存单元。必须使用for循环构造器才能深拷贝保证每一个元素指向独立的内存单元。 但是此时我们只是完成了二维前缀和数组的计算，还没有进行q次查询，那么接下来我们如何进行查询的操作呢？ 很明显我们也要参考面积，假设要求的是x1,y1和x2,y2组成的矩阵内的元素之和，那么他的变化就是此时这个矩阵不再是从左上角的[1][1]开始的了，因此肯定是使用了多个矩阵pre进行相减得到的。如下所示： 此时我们要查询得区间之和实际上就是对应的绿色面积，那么很明显借助面积和容斥原理有如下规律：绿色面积即为大蓝色面积pre[x2][y2]减去黄色面积pre[x2][y1-1]再减去紫色面积pre[x1-1][y2]后再补加上一个红色面积pre[x1-1][y1-1]得到的，因此查询的公式就是 ans=pre[x2][y2]−pre[x2][y1−1]−pre[x1−1][y2]+pre[x1−1][y1−1]ans=pre[x2][y2]-pre[x2][y1-1]-pre[x1-1][y2]+pre[x1-1][y1-1] ans=pre[x2][y2]−pre[x2][y1−1]−pre[x1−1][y2]+pre[x1−1][y1−1] 总体的流程就是： 因此时间复杂度也仅仅为O(nm+q)，还是很小的。给出代码板子： 123456789101112131415# 二维前缀和# 求下标从1开始n行m列的二维数组查询q次指定矩阵内的元素的和# (i,j)表示第i行第j列的数值元素def solve(): n, m = map(int, input().split()) num = [[0] for i in range(int(1e5+5))] pre = [[0]*int(m+5) for j in range(int(n+5))] for i in range(1, n+1): num[i].extend(list(map(int, input().split()))) for j in range(1, m+1): pre[i][j] = pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1] q = int(input()) for i in range(q): x1, y1, x2, y2 = map(int, input().split()) print(pre[x2][y2]-pre[x1-1][y2]-pre[x2][y1-1]+pre[x1-1][y1-1]) 前缀和进阶 1、思考num和pre是必须的吗？ 我们发现无论是一维前缀和还是二维前缀和，我们都借助了两个同样大小的数组num和pre，然后通过递推完成了前缀和数组pre的初始化赋值。但是我们真的必须使用num吗？实际上如果我们不需要后期使用num数组来记录输入的值，那么完全可以使用一个pre就可以直接根据输入得到前缀和数组。首先我们一开始就将输入的元素值直接存储到pre中，那么很明显一开始pre[i]或者是pre[i][j]存储的并不是前缀和数值而是输入的元素值，然后通过递推式： 123456789101112# 原先的一维前缀和计算公式 pre[i] = num[i]+pre[i-1]# 由于前缀和pre[i]会用到数值元素num[i]和已经记录前缀和的pre[i-1]# 而此时pre[i]就可以先存储元素值，然后通过上面递推式再更新自己为存储前缀和# 因此一位前缀和计算公式可以更改为pre[i] = pre[i]+pre[i-1]# 同样的原二维前缀和递推公式pre[i][j] = pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1]# 也可以更新为pre[i][j] = pre[i-1][j]+pre[i][j-1]+pre[i][j]-pre[i-1][j-1] 即只需要使用一个pre数组就可以完成，减少了内存的开支，当然一般情况下还是借用两个数据方便代码的可读性与理解。 2、思考：什么是后缀和suffix? 前缀和prefix我们已经理解了，那么后缀和suffix也很容易理解了，他只不过是将pre[i]更改为了计算从末尾到第i个元素的和，因此递推公式变成了 pre[i−1]=pre[i]+num[i−1]pre[i-1]=pre[i]+num[i-1] pre[i−1]=pre[i]+num[i−1] 3、思考：如果二维前缀和给的坐标是左下角[x1][y1]和右上角[x2][y2]怎么计算？ 此时实际上也可以使用二维前缀和递推公式并且没有任何变化，此时只是原点变成了左下角，如下所示： 因此递推公式并没有发生变化还是 1pre[i][j] = pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1] 很明显查询计算公式也没有发生变化还是 1print(pre[x2][y2]-pre[x1-1][y2]-pre[x2][y1-1]+pre[x1-1][y1-1]) 差分 概念&amp;用途 差分和前缀和的关系类似于数学中的求导和积分，差分可以看成是前缀和的逆运算。假设现在我们已知q次区间操作，每一次操作都是对数值数组的某一个区间[l,r]进行整体加或者减一个数值k(每一次k都不一样）。然后问q次操作以后的某一个位置的元素数值变成了多少，那么我们该如何进行问题解决呢？我们的第一个想法肯定还是暴力操作，但是复杂度太高了，因此会使用接下来介绍的差分操作。差分是一种与前缀和相对的策略，对于一个数列num，我们之前使用前缀和维护的前i个元素的值之和，而现在我们使用差分以后，是维护两个相邻元素的数值之差。 一维差分 假设给定了一个原数组num，那么此时我们该如何预处理计算得到差分数组呢？很显然diff差分数组和num数组一样长，同时对于差分数组中第i个元素diff[i]记录就是num[i]相较于num[i-1]的数值增量，即 diff[i]=num[i]−num[i−1]diff[i]=num[i]-num[i-1] diff[i]=num[i]−num[i−1] 很显然此时num就是相对于diff的前缀和数组，即num[i]=diff[1]+diff[2]+…+diff[i]。原理如下所示： 很明显上图中a[2]=b[1]+b[2]。很明显此时如果我们想要得到q次修改操作以后某个元素的数值只需要通过q次修改操作后的diff数组进行累加就可以了，因此查询变成了O(1)。但是我们怎么来用diff数组表示[l,r]内的变化k呢？ 无论是加k还是-k，实际上我们都可以看成是加上了一个增量c(即|k|=c)，那么如果我们现在想要在[l,r]内操作添加一个增量c(此时c可正可负)，那么该如何实现呢？我们只需要如下操作： 首先我们让差分数组diff[l]加上增量c，即diff[i]+c，那么根据定义很容易我们就可以推得，此时a[i]、a[i+1]、…、a[r]、a[r+1]、…、a[n]都增加了一个增量c，即此时自l以右的元素全部增加了c 但是我们只是想要 [l,r]内的元素增加一个增量c，因此我们还需要进一步操作将a[r+1]即以后的元素再减去一个增量，因此还需要进行diff[r+1]-c的操作 这样我们就完成了对[l,r]内部的一次修改，时间复杂度也仅仅为O(1)，下面是原理图： q次操作以后，我们就该输出每一个变化后的num元素了，前面我们讲到了num数组实际上就可以看成是差分数组的前缀和数组，因此num[i]的计算公式就是： num[i]=num[i−1]+diff[i]num[i]=num[i-1]+diff[i] num[i]=num[i−1]+diff[i] 通过上面的递推式我们就可以得到每一个要查询到的q次修改操作以后的第i个位置元素的值了，板子如下： 1234567891011121314151617181920212223# 一维差分# 对下表范围[1,n]数组进行q次区间修改，然后查询某个位置元素的值# diff[i]记录的是num[i]比前者num[i-1]的增量num = [0]*int(1e5+5)diff = [0]*int(1e5+5)def update(l, r, x): diff[l] += x diff[r+1] -= xdef solve(): n, m = map(int, input().split()) for i in range(1, n+1): x = int(input()) update(i, i, x) for i in range(m): l, r, x = map(int, input().split()) update(l, r, x) for i in range(1, n+1): num[i] = num[i-1]+diff[i] print(num[i], end=&quot; &quot;) 思考：为什么存储输入时是使用update存储到diff中而不是直接存储到num中？ 很明显输入就是还没有进行q次修改操作之前的每一个num的初始值，但是我们需要将它存储到num中吗？我们思考一下之前的讲解，实际上我们是使用diff数组来进行值修改操作的表示的，然后最终通过diff来计算每一个num的，因此对于输入的初始值我们也可以看成是对0数组多次区间操作（只不过此时每一次区间操作都是整范围的）来直接存储为diff格式，方便后面进行操作。当然如果你不理解也可以先将输入存储到num中，然后再通过num和diff的关系生成差分数组。 思考：我们能否根据差分数组直接生成num数组的前缀和数组pre? 首先我们来看一下差分数组，元素数组与前缀和数组的关系，很明显他们有以下转换关系： 但是我们能不能直接从diff到pre呢？即如下关系能否建立？ 实际上也是可以得，如下是递推关系： 因此我们还可以再初始化diff的同时，再维护一个序列即q序列，他与diff的关系为： q[i]=(i−1)∗diff[i]q[i]=(i-1)*diff[i] q[i]=(i−1)∗diff[i] 这样子，我们通过以下公式就可以通过diff数组直接计算出q次修改以后的前缀和pre[i]: pre[i]=i∗(diff[1]+diff[2]+...+diff[i])−(q[1]+q[2]+...+q[i])pre[i]=i*(diff[1]+diff[2]+...+diff[i])-(q[1]+q[2]+...+q[i]) pre[i]=i∗(diff[1]+diff[2]+...+diff[i])−(q[1]+q[2]+...+q[i]) 二维差分 同样的，差分也可以拓展到二维，此时我们也要类比矩阵面积，坐标来思考。根据二维前缀和表示的是左上角矩型的和，由于差分只涉及前面相邻的数（由一维可以推出），并且由前面范围的数相加得到这个位置的数，那么类比二维前缀和与一维差分，我们可以简单推测出二维差分的计算公式为： diff[i][j]=num[i][j]−num[i−1][j]−num[i][j−1]+num[i−1][j−1]diff[i][j]=num[i][j]-num[i-1][j]-num[i][j-1]+num[i-1][j-1] diff[i][j]=num[i][j]−num[i−1][j]−num[i][j−1]+num[i−1][j−1] 即为相邻2*2矩阵的主对角元之和减去次对角元之和。这样我们就可以得到二维差分数组了。接下来我们同样需要使用二维差分数组来表示q次的修改： 参考上图，我们可以得到要修改[l,r]内元素，只需要如下进行增量修改： {diff[x1][y1]+=cdiff[x1][y2+1]−=cdiff[x2+1][y1]−=cdiff[x2+1][y2+1]+=c\\begin{cases} diff[x1][y1]+=c\\\\ diff[x1][y2+1]-=c\\\\ diff[x2+1][y1]-=c\\\\ diff[x2+1][y2+1]+=c \\end{cases} ⎩⎪⎪⎪⎪⎨⎪⎪⎪⎪⎧​diff[x1][y1]+=cdiff[x1][y2+1]−=cdiff[x2+1][y1]−=cdiff[x2+1][y2+1]+=c​ 这样我们也完成了q次操作以后的二维差分数组，接下来我们同样根据这个二维差分数组进行num[i][j]的求解，其实此时num[i][j]得求解公式很容易就得到了就是之前diff[i][j]公式定义的逆推导： num[i][j]=num[i−1][j]+num[i][j−1]+diff[i][j]−num[i−1][j−1]num[i][j]=num[i-1][j]+num[i][j-1]+diff[i][j]-num[i-1][j-1] num[i][j]=num[i−1][j]+num[i][j−1]+diff[i][j]−num[i−1][j−1] 最终我们就得到了二维差分的板子： 12345678910111213141516171819202122232425262728293031# 二维差分# 对下标从1开始n行m列的二维数组进行q此修改操作并查询所有位置的数# 注意此时diff[i][j]递推式比较复杂并不是num[i][j]-num[i-1][j-1]# 而是diff[i][j]=num[i][j]+num[i-1][j-1]-num[i-1][j]-num[i][j-1]# 即主对角线相邻元素之和相较于次对角线相邻元素之和的增量num = [[0] for i in range(int(1e5+5))]diff = [[0]*int(1e5+5) for j in range(int(1e5+5))]def update(x1, y1, x2, y2, x): diff[x1][y1] += x diff[x2+1][y2+1] += x diff[x2+1][y1] -= x diff[x1][y2+1] -= xdef solve(): n, m, q = map(int, input().split()) for i in range(1, n+1): tmp_list=[0] tmp_list.extend(list(map(int, input().split()))) for j in range(1, m+1): update(i, j, i, j, tmp_list[j]) for i in range(q): x1, y1, x2, y2, x = map(int, input().split()) update(x1, y1, x2, y2, x) for i in range(1, n+1): for j in range(1, m+1): num[i][j] = num[i-1][j]+num[i][j-1]-num[i-1][j-1]+diff[i][j] print(num[i][j], end=&quot; &quot;) print() 算法练习 1）一维前缀和 题目描述 一天，在宿舍睡觉的你，突然梦到了游戏之神，他说：去玩《极限脱出》吧，这部作品的剧情和世界观绝对会带来很大的震撼，值得一玩。 对了，这部作品的第一代发布在nds上，所以要想在电脑上玩，你需要游戏模拟器：推荐desmume，也可以选择nogba，前者虽然优化差一些，但自带了模拟器的即使存档功能，且可以全屏。 … 但由于你没有吃安利，游戏之神很愤怒（这么好的游戏不玩，暴殄天物啊！），决定对你进行惩罚。 现在，游戏之神给了你n个非负整数，分别记为第1个数字至第n个数字，游戏之神还会向你提出q个问题，询问你第f个数到第t个数之间所有数字的和，请你正确回答游戏之神的所有提问，否则你以后打游戏必掉线。 输入描述 输入的第一行包含两个整数n,q( 1&lt;=n,q≤1e5 )，含义如题面所示； 第二行包含n个非负整数，每个数字均不超过1e9； 下面q行，每行包括两个数字f,t（1≤f≤t≤n），含义如题面所示。 输出描述 对于这q行中的每一行，请你输出一个数字，回答游戏之神的提问。 样例 输入 1234569 41 3 4 6 2 5 1000000000 1000000000 10000000001 67 93 54 4 输出 1234213000000000126 解题思路 就是一道简单的一维前缀和模板题，直接上板子就好了 解题代码 123456789101112131415# 一位前缀和# 对下标范围[1,n]的数组查询q次指定区间的元素之和def solve(): n, q = map(int, input().split()) num = [0] pre = [0]*int(1e5+5) num.extend(list(map(int, input().split()))) for i in range(1, n+1): pre[i] = num[i]+pre[i-1] for i in range(q): l, r = map(int, input().split()) print(pre[r]-pre[l-1])if __name__==&quot;__main__&quot;: solve() 2）子矩阵求和 题目描述 给出一个 n行 m 列的矩阵，矩阵的每个位置有一个非负整数 a[i][j]，有 q 次询问，每次询问求一个左上角为 (a,b)，右下角为 (c,d) 的子矩阵的所有数之和。 输入描述 第一行两个整数 n,m，表示矩阵的行和列的大小。 接下来 n 行每行 m 个整数，为矩阵内容。 接下来一行为一个整数 q，表示询问次数。 接下来 q行每行 4个整数 a,b,c,d，含义见题面。 输出描述 共 q行，第 i 行为第 i 个询问的答案。 数据范围 n×m≤100,000，a[i][j] &lt;=1000，q&lt;=100,000，1&lt;=a&lt;=c&lt;=n，1&lt;=b&lt;=d&lt;=m。 样例 输入 123456783 51 2 3 4 53 2 1 4 72 4 2 1 231 1 3 52 2 3 31 1 3 3 输出 12343920 解题思路 就是一道简单的二维前缀和模板题，直接上板子就好了 解题代码 12345678910111213141516171819import sysinput = sys.stdin.buffer.readlinedef solve(): n, m = map(int, input().split()) num = [[0] for i in range(int(1e5+5))] pre = [[0]*int(m+5) for j in range(int(n+5))] for i in range(1, n+1): num[i].extend(list(map(int, input().split()))) for j in range(1, m+1): pre[i][j] = pre[i-1][j]+pre[i][j-1]+num[i][j]-pre[i-1][j-1] q = int(input()) for i in range(q): x1, y1, x2, y2 = map(int, input().split()) print(pre[x2][y2]-pre[x1-1][y2]-pre[x2][y1-1]+pre[x1-1][y1-1])if __name__ == &quot;__main__&quot;: solve() 3）Margarite and the best present 题目描述 Little girl Margarita is a big fan of competitive programming. She especially loves problems about arrays and queries on them. Recently, she was presented with an array aa of the size of 10^9109 elements that is filled as follows: a1 = -1 a2 = 2 a3 = -3 a4 = 4 a5 = -5 And so on … That is, the value of the i-th element of the array a is calculated using the formula. a[i]=i∗(−1)ia[i]=i*(-1)^i a[i]=i∗(−1)i She immediately came up with q queries on this array. Each query is described with two numbers: land r. The answer to a query is the sum of all the elements of the array at positions from l to r inclusive. Margarita really wants to know the answer to each of the requests. She doesn’t want to count all this manually, but unfortunately, she couldn’t write the program that solves the problem either. She has turned to you — the best programmer. Help her find the answers! 输入描述 The first line contains a single integer q (1&lt;=q&lt;=1e3) — the number of the queries. Each of the next q lines contains two integers l and r (1&lt;=l&lt;=r &lt;=1e9) — the descriptions of the queries. 输出描述 Print q lines, each containing one number — the answer to the query. 样例 输入 12345651 32 55 54 42 3 输出 12345-2-2-54-1 样例说明 In the first query, you need to find the sum of the elements of the array from position 1 to position 3. The sum is equal to a1 + a2 + a3 = -1 + 2 -3 = −2. In the second query, you need to find the sum of the elements of the array from position 2 to position 5. The sum is equal to a2 + a3 + a4 + a5 = 2 -3 + 4 - 5 =−2. In the third query, you need to find the sum of the elements of the array from position 5 to position 5. The sum is equal to a5 = -5. In the fourth query, you need to find the sum of the elements of the array from position 4 to position 4. The sum is equal to a4 = 4. In the fifth query, you need to find the sum of the elements of the array from position 2 to position 3. The sum is equal to a2+a3 = 2 - 3 =−1. 解题思路 这道题乍一看感觉就是为一个非常简单的一维前缀和板子题，但是我们使用板子以后会发现由于数组长度为1e9明显超过了测试平台允许的最大空间，会导致内存超限。因此我们不能直接使用一维前缀和板子进行解题，而是需要打表找规律，我们很容易就可以看出前缀和数组中的元素应该有规律的，因此我们可以先进行局部前缀和元素（比如前50个）的打表，最终我们可以找到如下规律： pre=[-1,1,-2,2,-3,3,-4,4,-5,5…]，很明显对于第i个前缀和元素pre[i]，当i为奇数时必定为负数，同时pre[i]的数值的绝对值有如下规律： pre[i]=(−1)i∗[(i//2)]向上取整pre[i]=(-1)^i*[(i//2)]_{向上取整} pre[i]=(−1)i∗[(i//2)]向上取整​ 解题代码 123456789101112131415if __name__ == &quot;__main__&quot;: q=int(input()) for i in range(q): l,r=map(int,input().split()) a=l-1 b=r if a%2!=0: a=0-(a//2+1) else: a//=2 if b%2!=0: b=0-(b//2+1) else: b//=2 print(b-a) 对于这种非常容易看出来有一定内在规律的题，可以尝试进行打表很容易就可以找到内在规律用递推公式表示规律，从而简化题目的解，大幅降低时间复杂度和空间复杂度 4）Star Sky 题目描述 The Cartesian coordinate system is set in the sky. There you can see n stars, the i-th has coordinates (xi, yi), a maximum brightness c, equal for all stars, and an initial brightness si (0 ≤ si ≤ c). Over time the stars twinkle. At moment 0 the i-th star has brightness si. Let at moment t some star has brightness x. Then at moment (t + 1) this star will have brightness x + 1, if x + 1 ≤ c, and 0, otherwise. You want to look at the sky q times. In the i-th time you will look at the moment ti and you will see a rectangle with sides parallel to the coordinate axes, the lower left corner has coordinates (x1i, y1i) and the upper right — (x2i, y2i). For each view, you want to know the total brightness of the stars lying in the viewed rectangle. A star lies in a rectangle if it lies on its border or lies strictly inside it. 输入描述 The first line contains three integers n, q, c (1 ≤ n, q ≤ 1e5, 1 ≤ c≤ 10) — the number of the stars, the number of the views and the maximum brightness of the stars. The next n lines contain the stars description. The i-th from these lines contains three integers xi, yi, si (1 ≤ xi,yi ≤ 100, 0 ≤ si ≤ c ≤ 10) — the coordinates of i-th star and its initial brightness. The next q lines contain the views description. The i-th from these lines contains five integers ti, x1i, y1i, x2i, y2i (0 ≤ ti ≤ 1e9, 1 ≤ x1i &lt; x2i ≤ 100, 1 ≤ y1i &lt; y2i ≤ 100) — the moment of the i-th view and the coordinates of the viewed rectangle. 输出描述 For each view print the total brightness of the viewed stars. 样例1 输入 1234562 3 31 1 13 2 02 1 1 2 20 2 1 4 55 1 1 5 5 输出 123303 样例2 输入 123456783 4 51 1 22 3 03 3 10 1 1 100 1001 2 2 4 42 2 1 4 71 50 50 51 51 输出 12343350 样例说明 Let’s consider the first example. At the first view, you can see only the first star. At moment 2 its brightness is 3, so the answer is 3. At the second view, you can see only the second star. At moment 0 its brightness is 0, so the answer is 0. At the third view, you can see both stars. At moment 5 brightness of the first is 2, and brightness of the second is 1, so the answer is 3. 解题思路 这道题是一个cf1600的题，是对二维前缀和的变式应用。首先我们读完题意会发现此时矩阵内的星星亮度是会变得，每一个时刻都是不同的，同时星星数量理论上是可以大于矩阵面积的，因此说明一个坐标可能会有多个亮度不同的重叠的星星。因此我们此时使用二维前缀和是不够的，我们需要三维来记录，即pre[i][j][k]表示的是初始时刻[i][j]中亮度为k的星星的个数。这样如果我们要统计t时刻某个一个范围内的所有星星亮度，只需要枚举统计该范围内不同初始亮度的星星在t时刻的亮度和个数，然后用亮度*个数再累加记得到了t时刻该范围的所有星星的亮度之和。 解题代码 123456789101112131415161718192021# import io,os# input = io.BytesIO(os.read(0, os.fstat(0).st_size)).readlineimport sysinput=sys.stdin.buffer.readlinea = [[[0]*15 for i in range(105)]for j in range(105)]pre=[[[0]*15 for i in range(105)]for j in range(105)]if __name__ == &quot;__main__&quot;: n,q,c=map(int,input().split()) for i in range(n): xi,yi,si=map(int,input().split()) a[xi][yi][si]+=1 for k in range(c+1): for i in range(1,101): for j in range(1,101): pre[i][j][k]=a[i][j][k]+pre[i-1][j][k]+pre[i][j-1][k]-pre[i-1][j-1][k] for i in range(q): t,x1,y1,x2,y2=map(int,input().split()) ans=0 for k in range(c+1): ans+=(k+t)%(c+1)*(pre[x2][y2][k]-pre[x2][y1-1][k]-pre[x1-1][y2][k]+pre[x1-1][y1-1][k]) print(ans) 5）Matrix Subtraction 题目描述 Given a matrix M of size n×m and two integers a,b，determine weither it is possible to make all entrys of M zero by repeatedly choosing a×b submatrices and reduce the values in the chosen matrices by 1. If possible, print ^_^ in one line, or print QAQ in one line. 输入描述 The first line contains one integer T (1≤T≤100), denoting the number of test cases. For each test case: The first line contains four integers n,m,a,b (1≤n,m≤1000,1≤a≤n,1≤b≤m), denoting the size of given matrix and the size of chosen submatrices respectively. The next n lines each contains m integers Mi,j (0≤Mi,j≤109), denoting the entrys of matrix M. It’s guaranteed that ∑nm≤1e6. 输出描述 Print T lines each containing a string ^_^ or QAQ, denoting the answer to each test case. 样例 输入 123456722 2 1 21 21 22 3 1 21 2 11 2 1 输出 12QAQ^_^ 样例说明 For the second case, one possible scheme is to choose (1,1)−(1,2),(1,2)−(1,3),(2,1)−(2,2),(2,2)−(2,3) respectively. 解题思路 二维差分的应用，很明显我们需要使用到二维差分中的update函数对选中的子矩阵进行整体减的操作。但是每一次我们的子矩阵的左上角坐标应该选择那里呢？实际上我们会发现每一次最左上角的元素如果想要变为0，那么只能通过让这个元素位于子矩阵的左上角，假设这个元素值为tmp,那么就要用tmp次该子矩阵进行减操作处理才能变成0。然后紧接着他右侧和他下侧的元素就有可能成为下一个边角元素，因此我们的子矩阵左上角开始坐标只需要自左向右，自上到下遍历整个矩阵即可，一旦检验到当前位置的元素值小于0了，那么无论怎样处理也不可能变回0了（因为我们只能通过子矩阵进行范围-1，而不能+1),那么此时就说明不可能实现了，输出QAQ，否则我们就一直检验（遇到0就跳过），当一直检验到了最后一个都可以变为0 ，那么就可以将这个矩阵变成0矩阵，输出^_^.我们还要特别注意很明显这个子矩阵的左上角起始坐标并不能遍历整个矩阵，他需要保证子矩阵始终在大矩阵范围内所以还需要满足j+b-1 &lt;= m and i+a-1 &lt;= n 解题代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# -*- encoding: utf-8 -*-# @File : ac10.py# @Time : 2022/02/06 18:33:43# @Author : langwenchong# @Desc : edit in python3.8.8import sys# sys.stdout = open(&#x27;./IO/out.txt&#x27;, mode=&#x27;w&#x27;, encoding=&#x27;utf-8&#x27;)# sys.stdin = open(&#x27;./IO/in.txt&#x27;, mode=&#x27;r&#x27;, encoding=&#x27;utf-8&#x27;)input = sys.stdin.buffer.readlinedef update(diff, x1, y1, x2, y2, x): diff[x1][y1] += x diff[x2+1][y2+1] += x diff[x2+1][y1] -= x diff[x1][y2+1] -= xdef solve(): t = int(input()) for i in range(t): v = True n, m, a, b = map(int, input().split()) diff = [[0]*(m+5) for i in range(n+5)] for i in range(1, n+1): tmp_list=[0] tmp_list.extend(list(map(int, input().split()))) for j in range(1, m+1): update(diff,i, j, i, j, tmp_list[j]) for i in range(1, n+1): for j in range(1, m+1): tmp = diff[i][j] if tmp == 0: continue elif tmp &lt; 0: v = False break elif j+b-1 &lt;= m and i+a-1 &lt;= n: #注意要减tmp次1也就是减tmp update(diff,i,j,i+a-1,j+b-1,-tmp) else: v=False break if(v): print(&quot;^_^&quot;) else: print(&quot;QAQ&quot;) returnif __name__ == &quot;__main__&quot;: solve()"},{"title":"算法分析","path":"/wiki/手撕算法笔记/算法分析/index.html","content":"本章与其他的文章不同，不是单一介绍一种思想，而是宏观角度讲解一下什么是算法，算法的种类，和算法分析的方法等概念 什么是算法 算法是对特定问题求解步骤的一种描述，是指令的有限序列 从上面的描述中我们可以看出算法强调的是解题步骤，而不是具体求解问题的具体代码指令。 思考：程序==算法？ 程序不等于算法，程序是算法用某种程序设计语言的具体实现，所以可以看出算法一种脱离于编程语言限制的抽象化得解题思路，所以算法可以说永远不会过时，而程序则可能会一直变化使用更优秀的编程语言来编写。 算法的特点 输入：算法有零个或多个输入量（一定要注意是可以没有输入的） 输出：算法至少要产生一个输出量 确定性：算法的每一条指令都有确切的定义，没有二义性 能行性：算法的每一条指令必须足够基本，它们可以通过已经实现的基本运算执行有限次来实现 有穷性：算法必须总能在执行有限步之后终止 思考：OS是程序还是算法？ 我们学习了OS后知道OS实质上也是一个运行于硬件层上的软件程序，只不过他比较特殊是一个在无限循环中执行的程序，因而不是一个算法。但是操作系统的各种任务可以看成是单独的问题，每一个问题由操作系统中的一个子任务通过特定的算法来实现，该子程序得到输出结果后就终止。 算法应用的问题 搜索问题（在给定的数据集合中寻找满足条件的数据对象） 排序问题（把无需的数据按照一定的规则排列） 图论问题（一般数据结构是图形结构或者树形结构，常用于解决交通，通讯，工程项目时间表和各种流量问题） 组合数学问题（例如图着色或者TSP旅行商等） 几何问题（凸包等） 数值计算（估算最大或最小值，常常不能给出精确值） 十大经典算法实例 蒙特卡罗算法（随机性模拟算法，通过计算机仿真来解决问题的算法，同时可以通过模拟来检验自己模型的正确性，是比赛时必用的方法） 数据拟合，参数故居，插值等数据处理算法（大数据处理，常常需要借用matlab作为工具） 线性规划，整数规划，多元规划，二次规划等规划类问题（建模竞赛大多数属于最优化问题，很多时候这些问题可以用数学规划类算法描述，常借用Lindo,Lingo等软件实现） 图论算法（最短路，网络流，二分图等算法） 动态规划(dp)，回溯搜索（tranceback),分枝限界等计算算法。 最优化理论的三大非经典算法：模拟退火法，神经网络，遗传算法（这些问题是用来解决一些较困难的最优化问题的算法，但是实现困难） 网络算法和穷举法（暴力搜索最优点的算法，模拟常用） 连续离散化方法（以离散极限模拟连续） 数值分析法（方程组求解，矩阵运算，函数积分等算法） 图像处理算法 算法的复杂性 空间复杂度 空间复杂度是指程序运行时所需的内存空间大小和实例特征的函数关系，一般所需空间包括： 指令空间（常数，与实例无关的有限整数） 数据空间：常量和简单变量与实例无关，但是复合变量（如数组，链表，树和图等）以及环境栈空间（函数调用需要）大小与实例和是否递归有关。 对于非递归的算法，一般分析实例有关的数据结构大小即可分析出空间复杂度，而对于递归算法还要讨论递归调用的深度和实例的关系。 时间复杂度 指程序执行时所用的时间，一般与循环层次，递归调用深度，算法性能有关。除了优先指令所运行的基本操作固定步数时间以及输入输出的有限时间，时间复杂度主要是与运行的深度呈正相关。一般对于不同的实例特征，同一个算法对应的时间复杂度也不一定相同，一般可分为最好，最坏和平均时间复杂度。一般算法的整体性能好坏由最坏时间复杂度和平均时间复杂度决定。 算法渐进符号分析 对于算法的性能我们通常会用到渐进分析符号来表示算法的上界或者下界。这里一般会用到三种符号 O–渐进上界 lim⁡n→+∞∣fn/gn∣=c,c&gt;1则fn=O(gn)\\lim_{n\\rightarrow+\\infty}{|fn/gn|}=c,c&gt;1\\\\ 则fn=O(gn) n→+∞lim​∣fn/gn∣=c,c&gt;1则fn=O(gn) f(n)=O(g(n)) 当且仅当存在常数c和n0使得对所有n&gt;n0 有f(n)&lt;cg(n) 成立。即O表示一个算法的上界，例如：O(n)表示这个算法最大的复杂度f(n)一定存在一个常数c使得c*n&gt;f(n)。例如f(n)=n^3+20n^2+6n-10000=O(n^3) Ω–渐进下界 lim⁡n→+∞∣fn/gn∣=c,0&lt;c&lt;1则fn=Ω(gn)\\lim_{n\\rightarrow+\\infty}{|fn/gn|}=c,0&lt;c&lt;1\\\\ 则fn=Ω(gn) n→+∞lim​∣fn/gn∣=c,0&lt;c&lt;1则fn=Ω(gn) f(n)=Ω(g(n)) 当且仅当 存在常数c和n0使得对所有n&gt;n0,有f(n)&gt;cg(n*)成立。即Ω表示一个算法的下界，例如：Ω（n)表示这个算法小的复杂度f(n)一定存在一个常数c使得c(n)&lt;f(n)。例如fn=(0.001)n^2-10n-1000=Ω（n^2) Θ–同阶 lim⁡n→+∞∣fn/gn∣=c,c=1则fn=Θ(gn)\\lim_{n\\rightarrow+\\infty}{|fn/gn|}=c,c=1\\\\ 则fn=Θ(gn) n→+∞lim​∣fn/gn∣=c,c=1则fn=Θ(gn) 如果f(n)=O(g(n))同时 f(n)=Ω(g(n))则f(n)=Θ(g(n)),并称f(n)与g(n)同阶。即渐进上界和渐进下界都逼近于一个量级，则就说这个算法的复杂度f(n)=Θ(g(n))，例如fn=(n^2.8)+10000=Θ(n^2.8) 特殊地，我们约定O(1)代表常数，因为对于任意一个复杂度为k的复杂度，我们都存在一个常数c=k+1使得c*O(1)&gt;k。对于g(n)函数我们一般尝试取n^k,log2n,n^klog2n等进行估计。 几种g(n)的增长率 一般算法时间复杂度为nlogn,n或者logn为较为优秀的算法，2^n就非常糟糕，n^2还可以接受但是也不是特别好，一般能避免尽量避免。 伪代码 一般算法可以在任何一种语言下都可以具体实现，但是为了具体描述算法的解题步骤，一般我们使用伪代码来具体描述算法步骤。例如下图： 其中&lt;-代表赋值，while,do就是循环和具体的简单执行操作，当然你也可以加入注释来当做伪代码的一部分。我们一般在伪代码中忽略数据类型，变量的说明等于算法无关的部分。 算法分析–递归树和解递归 这里我们以归并排序的merge合并为例，假设现在要将两个数组进行merge归并，那么我们很容易想到每次都比较两个数组代插入新数组的数，每次都选择大的数插入，如下图： 竖着的代表一个数组，那么总体来看时间复杂度就是Θ(n)对于n个元素。这里我们列出递归式，归并排序每次都是将一个数组进行以2拆分，所以每次都会形成两个n/2元素的数组（这里就忽略不够n/2的过着看成n/2即可）那么我们刚刚说了merge时n个元素就是Θ(n)的复杂度，所以对于一个数组n进行拆分成了两个n/2的数组在merge就是T(n)=T(n/2)+T(n/2),再加上有限个步骤的指令所花费的时间Θ(n)，我们可以列出递归式： T(n)=2T(n/2)+Θ(n)T(n)=2T(n/2)+Θ(n) T(n)=2T(n/2)+Θ(n) 展开递归树 那么接下来我们一般是根据递归式展开递归树，如下图 这是拆分两次后形成了4个n/4的子数组，然后需要一直拆分到T(1)，因为T(1)是一个具体的时间，所以最终T(n)用一个仅包含T(1)的式子表示就可以求出具体的时间复杂度了，如下我们继续展开递归树至T(1): 最终经过n此拆分，终于拆分结束发现树一共有log2n层一般表示为logn，那么我们最终进行估值，我们可以看出最后 cnlog2n&lt;=T(n)&lt;=cnlogn2n+O(n)cnlog2n&lt;=T(n)&lt;=cnlogn2n+O(n) cnlog2n&lt;=T(n)&lt;=cnlogn2n+O(n) 所以最终归并排序的时间复杂度为Θ(nlogn)这就是根据递归树求解时间复杂度渐进分析。 所以对于a和b的T(n)=aT(n/b)+cn，我们使用展开递归树时会得到下面的规律： 即对于T(n)=aT(n/ba)，最后我们会展开到h=logbn层，所以也就有a^h个叶子节点，所以就是n^logba个T(1)所以前项aT(n/b)就是Θ(n^logba)（其实这就是master最有力的理论证明)。 小练习 展开递归树求解T(n)=T(0.1n)+T(0.9n)+Θ(n)： 但是我们会发现展开递归树太难了，一步步展开递归树太反人类了，所以就有了解递归求解。 解递归–迭代展开 实际上展开递归树的过程就是迭代展开的过程，我们可以用公式来求解，如下： 我们求解T(n)=4T(n/2)+n T(n)=4T(n/2)+n =4(4T(n/2^2)+n/2)+n =42T(n/2^2)+n+2n =43T(n/2^3)+n+2n+2^2n =4hT(n/2^h)+n(1+2+┅+2^h-1) =n^2T(1)+n(2^h-1) =Θ(n^2) 很多的递归式用递归解不出来我们可以使用递归式迭代展开求解，其实主要重点就是后面逐渐增大的等比数列求和以及总结归纳层数即次数问题，这里寻找层数h可以通过递归树来寻找规律。 思考：有没有一种较为特殊的系数递归式规律？ 我们思考对于常数a,b的递归式T(n)=aT(n/b)+cn，拿到对于每次的a和b我们都一次次画递归树展开然后在迭代解递归求解？那计算量未免也太大了，我们试图寻找一种一劳永逸的解决结论，例如现在我们就对这个递归式进行迭代展开，对于a和b的具体数值我们不感兴趣。 那么T(n)=a^hT(1)+cn(1+(a/b)+…+(a/b)^h-1)= a^hT(1)+cb^h(1+(a/b)+…+(a/b)^h-1) ，此时对于b^h&lt;n&lt;b^h+1,仍然有h=Θ(logbn)即限界函数g(n)仍然受到参数b的影响，这里我们使用换底公式logbn=log2n/log2b，又因为log2b是一个常数对整体影响不大，所以我们知道h=Θ(logn),所以此时我们就总结出了以下结论又称为master定理： 递归式分析–Master定理 对于任意一个递归式T(n)=aT(n/b)+f(n），其中a&gt;=1,b&gt;=1且为整数，f(n)&gt;0，我们总是有 aT(n/b)的时间复杂度为： aT(n/b)=Θ(nlogba)aT(n/b)=Θ(n^{log_ba}) aT(n/b)=Θ(nlogb​a) 又因为T(n)总是由最高次项所决定，所以T(n)主要是由n^logba和f(n)所决定。这里就会出现三种情形： 情形1 fn=O(n^(logba-ε))所以f(n)的增长会渐进地慢于n^logba,所以最终T(n)由前面一项所决定，所以T(n)=Θ(n^logba)。 情形2 fn=Θ(nlogba*(lgn)^k),即f(n)和n^logba几乎有相同的渐进增长率，所以T(n)=Θ(n^logba*(lgn)^k+1)。 情形3 fn=Ω(n^(logba+ε)),即f(n)多项式会逐渐地快于n^logba，则T(n)由后一项决定，所以T(n)=Θ(f(n))。 小练习 那么我们在用master定理求解以下几个式子： T(n)=4T(n/2)+n,所以4T(n/2)=Θ(n^2),而f(n)=n慢，所以T(n)=Θ(n^2)。 T(n)=4T(n/2)+n^2,此时f(n)/n^2=1=(logn)^0,所以k=0,所以T(n)=Θ(n^2logn)(一定要注意这里是(logn)^k+1)。 T(n)=4T(n/2)+n^3,f(n)更大，所以T(n)=Θ(n^3)。 总结 其实这篇文章最后整理就是因为其最难理解，往往概念性的东西最难理解，例如时间复杂度的分析，对于递归树展开，递归式得迭代展开和master定理得使用要熟练掌握，如果学有余力，最好了解一下证明过程这样也有助于记住结论，那么希望你能有所收获😝。"},{"title":"什么是操作系统","path":"/wiki/操作系统笔记/什么是操作系统/index.html","content":"操作系统的概念功能和目标 操作系统的结构分布 OS系统就是连接用户和应用程序与硬件之间的中间载体，他来实现两层结构间的数据交换，因此一个程序运行一定要在操作系统上才可以运行。 操作系统的定义 操作系统（Operating System,OS)是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境。它是计算机系统中最基本的系统软件。 从上面的定义我们可以看出操作系统的几个根本功能： 操作系统是系统资源的管理者，任务是分配资源 为上层应用提供易用的服务和环境 是最接近硬件的一层软件（因此还是由算法编程实现的） 任务管理器中，左侧是对应的用户程序，而右侧就是硬件的信息。 思考：内存的作用？ 执行一个程序前需要先将该程序（包裹执行代码，数据块）等放入内存中才可以在CPU上面执行。 以打开QQ和朋友聊天为例： 在各个文件夹中找到QQ安装的位置 第一步是找到程序的存放位置，当然一般上左面的快捷方式直接映射到了执行程序的存放位置 双击打开QQ.exe 将程序的执行代码和数据等放入内存中，做好准备后等待CPU执行此程序 QQ程序开始运行 执行程序开始在CPU上被执行 开始和朋友视频聊天 需要将摄像头设备分配给QQ进程来使用 在上面得到一系列过程中存入内存，分配进程等工作就是OS系统的任务。 操作系统的功能–为上层提供方便易用的服务 向上层提供方便易用的服务 将各个硬件进行封装为多个功能接口并分配给进程程序使用。如下图： 美丽就好像一个接口他需要多个硬件提供支持，而操作系统就是提供接口的服务者，之所以软件层和硬件层不能直接运行而需要OS系统提供媒介的主要原因就是因为语言障碍，软件层是高级语言如“服务A”，而硬件层并不能理解，因此需要OS系统进行指令翻译为提供“美丽”接口同时传达给硬件层能够理解的二进制指令。 GUI：图形用户接口 封装思想：操作系统把一些丑陋的硬件功能封装为简单易用的服务，使用户能够更加方便的使用计算机，用户无需关心底层硬件的原理，只需要对操作系统发出命令即可。 类似于前后台，用户和程序就像前台，只关注于页面设计和数据呈现，而具体的数据提供与数据分析就是由硬件系统这一&quot;后台&quot;来完成，而他们之间的联系者就是OS，提供对应的接口。 很多现代的操作系统都提供了GUI，即图形化用户接口，用户可以使用形象的图形界面进行操作，而不再需要记忆复杂的命令，参数。例如下图： 因此像古老的计算机就是拥有的没有GUI的操作系统，无论是打开文件或者开关机都是需要输入相对应的指令的，而现在的计算机和手机等设备就是拥有GUI的现代操作系统，例如菜单栏，管理文档的文档区等都属于GUI，类似的应用程序也有有无GUI的区分，像vim等就是没有GUI的编辑器，他们需要手动输入指令来打开文件，退出文件等行动，而VSCODE就是拥有GUI的应用程序。 联机命令接口 联机命令接口是交互式命令接口。如win系统计算机必备的cmd窗口就是一个没有GUI的命令窗口。特点就是用户说一句系统就做一步，打开方式： win+R 输入cmd,回车，打开命令解释器 尝试使用time指令，ipconfig指令 类似像git命令窗口也是这种特点的接口，用户输入一条指令，就执行一步，然后在等待用户输入指令在执行。 脱机命令接口 脱机命令接口是批处理命令接口，例如win系统自带的文档搜索功能，他是在用户输入一条指令后进行多步处理即用户说一堆指令，系统跟着做一堆指令，这是与交互式命令接口的根本区别。 程序接口 可以再程序中进行系统调用来使用程序接口。普通用户不能直接使用程序借口，只能通过程序代码间接使用。例如程序猿编写程序时调用的C语言库就是一种程序接口的调用过程。 这种系统调用（或者叫做广义指令）类似于函数调用，使用用程序请求操作系统服务的唯一方式。例如C语言中的输出指令printf函数就是调用的C库函数中的一个原函数，相对应的就会在底层调用操作系统提供的显式相关的&quot;系统调用&quot;,而一般平时情况用户是无法通过输入指令来通过操作系统调用这个接口的。 总结： 所有的有关软硬层直接的信息传输和功能调度都是一定要经过OS处理的，对于命令接口和程序接口了解即可。 操作系统的目标–作为最接近硬件得层次 简而言之，操作系统就是实现对硬件机器的扩展，只有一个裸机安装上了操作系统才能够提供方便用户的服务功能，从而大幅提高了机器的便捷性和功能使用性。我们通常把覆盖了软件的机器称为扩充机器或者虚拟机。 如果将一台设备比喻成一个汽车，那么硬件就像是发动机（只会转），轮胎（只会滚），在原始的硬件机器上覆盖一层系统才能够让发动机有目的性得带着轮子转，即操作系统是连接各个硬件的关键者，他使得各个独立工作的硬件之间产生了协调配合，互相合作的联系从而才能够使用简单的硬件设备之间的合作来实现复杂的功能。 总结 操作系统的四个特征 特征1–并发性 并发是指两个或多个事件在同一时间间隔内发生。这些事件宏观上看是同时发生的，但是实际上微观上看是交替发生的。即cpu频繁的不断切换为两个多个进程服务，因为进程并不是一直不间断的连续需要cpu时刻在旁边提供服务，而是在完成某个阶段的任务后向cpu发起一个服务需求，然后cpu在提供计算服务。这就类似于餐厅内的顾客和服务员，应用程序就像顾客，cpu就像服务员（因为这里讨论的是单核，所以就是一名服务员），服务员需要同时为这几桌的的顾客提供上菜等服务，所以整体上看可以同时为多个顾客提供服务，而微观上服务员一次只能为一个顾客提供服务，所以叫做同一时间间隔内发生。 思考：并行性与并发性的区别？ 并行性就是指两个或多个事件在同一时间内发生，这个才是真正的微观上的同时发生，类似于每一个顾客都有一名服务员，他们之间如果同时需要服务时，则不需要等待或者频繁切换服务员走动，可以真正做到一人配一个实时服务的情况。因此也不难推测到，并行性一般对应是多核CPU，才可以做到同时执行多个程序，实现并行执行。但是注意并行性可不是操作系统的四大特征之一。 思考：并法与并行是互斥事件吗（即操作系统不能同时兼具）？ 并不是，首先毋庸置疑，单核CPU的操作系统肯定就是只有并发性了，毕竟就一个可以提供服务的cpu，但是对于多核的计算机，一般是同时兼具并发性和并行性，原因很好理解，对一个n核cpu处理器，当需要同时服务n+k(k&gt;0)个事件时，也需要并发执行，当然同时也是具有并行性的毕竟一次可以同步执行n个事件。 特征2–共享性 共享是指资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。 所以资源共享所说的也是宏观上的同时“共享”，在微观上来看，有可能是交替的对资源进行访问的（分时共享）。 互斥共享 例如QQ和微信同时使用视频聊天，但是同一段时间内摄像头只能分配给其中的一个进程使用。 同时共享 QQ发送文件A，同时微信发送文件B，两边都在同时读取发送硬盘里的文件资源，从读取数据来看他们宏观上在同时共享硬盘资源，但是微观上来看，两个进程还是交替着访问硬盘的。 思考：互斥共享和同时共享的本质区别？ 首先需要声明，无论是这两种共享方式的哪一种本质上都不是真正的并行性共享，即都是分时共享，互斥共享指的仅仅是物理设备位置上的共享，时间上是根本不共享的，即这一时间段内就是只能有一个程序使用。而同时共享在物理设备位置上的共享基础上，在时间间隔内还有类似于并发性的特点，即这一段时间间隔内切换着同时为两个进程资源服务。至于真正做到的并行性共享即同一时间内两个进程或多个进程同时同地对于一个资源进行操作是尽量避免的，互斥锁也正是由这个应运而生的，因为会造成重大的Bug，应该尽量避免此类共享的发生。 思考：并发和共享的关系？ 并发性是指计算机系统中同时存在着多个运行着的程序。而并发性是指计算机系统中的资源科供内存中多个并发执行的进程同时使用。 对于上面QQ和微信同时发送文件A和B的例子来看，并发性体现在两个进程在同一个时间间隔内共同执行，共享性体现在在同一段时间间隔内两个并发执行的程序同时共享的访问硬盘资源。 特质3–虚拟性 虚拟是指把一个物理上的实体变为若干个逻辑上的对应物，物理实体是实际存在的，而逻辑对应物是用户感受到的，但是并不是真实存在的。 举个例子，例如一个程序需要在第7个地址空间存储一个数据，然后再在第50000个地址空间存储一个数据，那么中间没有进行存储的8-49999地址空间不可能真正的留白空出，而是操作系统进行了虚拟化，比如物理地址上的1对应着虚拟地址7，物理地址上的3对应50000，这样就可以有效提高空间的利用率同时压缩了真实物理空间的大小。在实际生活中我们时常发现一个大型主机游戏需要4-20GB的运行内存，而我们的电脑一般只有4-8G的内存，理论上如果按照物理地址1:1对应映射存储的话，根本就不可能将程序放入到内存中（这里先不讨论内外存动态存储，就默认必须直接一次性全部放入才可执行），更别提运行程序了，这时候虚拟的特征就解决了这个问题。再比如，一个程序放入到内存后会分配给cpu执行，但是单核cpu的计算机在频繁切换执行时却可以给用户造成一种同时运行对个程序的感觉（当然实际上是并发运行的），这也能体现虚拟性，这种方法就体现了“分时复用”的一个特点。 思考：虚拟性和并发性的特点？ 虚拟就是一种用逻辑上的映射来加快物理上的执行效率，从而产生了一种同时执行的错觉。所以虚拟是建立在并发的基础之上的，如果每次就运行一个程序，那么也就没必要实现虚拟了。 特征4–异步性 异步是指，在多道程序环境下，允许多个程序并发执行，但是由于资源有限（即使是用来虚拟，实际上空间也是远远不够的），进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是异步性。 思考：异步性和并发性的关系？ 因为异步也是在多程序同时进行才能体现出来的特征，所以如果失去了并发性，即系统只能串行的运行各个程序，那么每个程序的执行就会一贯到底，也就没有异步性了，所以只有系统拥有并发性，才有可能导致异步性。 总结 我们通过上面的四大特征的定义以及思考对比，发现虚拟和异步都是建立在异步的基础上才会有可能体现出来的，而共享和并发则是相互体现，互为存在的条件，因此并发和共享才是一个操作系统的最基本额两个特征。 操作系统的发展与分类 这部分了解即可，主要是关注和理解各类不同的操作系统主要想解决的问题是什么，以及各自的优缺点。 手工操作阶段 最早的阶段，基本上等同于没有操作系统的阶段，就是人机交互，用户需要和硬件之间进行交互操作导致消耗大量时间，效率极低。即使机器的运行效率很快，但是运行时间的上限非常受人机交互操作的限制。 批阶段处理阶段 单道批处理系统 引入脱机输入、输出技术，（用外围机和磁道完成），并且由监督员负责控制作业的输入和输出），即输入和输出时不再是人机交互，而是引入一些类似磁带等外部接入设备加快输入与输出速度，如下图： 这样没有了超慢和慢两个环节，速度大幅提升： 但是缺点为内存中仅能有一道程序执行，运行结束后才可以调入下一个程序，即没有并发性，cpu利用率太低，空闲时间长。 多道批处理系统 既然读入的程序太少，那就多读，每次都输入多个程序存入内存中并发执行可以进一步加快速度： 多个程序并发进行，共享计算机的资源，资源利用率大幅提升，cpu和其他资源能够长时间保持“忙碌”状态，系统的吞吐量提升： 可以看到这种多条线有交集的就是并发性图的特点，现在流水线加工也一般是这种并发执行。 但是多道批处理系统仍然有缺点，即用户相应时间过长，从输入数据开始后用户就一直得等到输出完成，中间没有人机交互功能，即一旦将作业提交给机器就只能等待机器执行完，这期间用户无权在控制访问自己的作业，这种情况导致程序无法在机器执行时被用户调试或者用户在运行过程中添加其他的参数或选项（当然这种问题手工操作和单道批处理系统也是拥有此缺陷的，但是但是速度都上不来，就更没有考虑此问题，现在速度提上来以后又发现了新的缺陷）。当然多道批系统还是象征着操作系统开始出现，毕竟操作系统主要是为了提供人机随时交互的便捷服务，提升运行速度并不是其根本任务，当然也是重要任务之一。 分时操作系统 计算机以时间片为单位轮流的为各个用户/服务，各个用户可以通过终端（终端概念在此时出现）与计算机进行交互。 优点：用户请求可以及时响应了，及用户可以实时对作业进行暂停，加入新参数或者中途终止任务等，并且这种并发性执行也允许了多个用户同时使用一台计算机进行任务调度，并且用户对计算机的操作相互独立，感受不到其他用户的存在，即各个用户之间操作相互独立，互不打扰。 缺点：不能优先处理一些紧急任务，操作系统是对各个用户/作业绝对公平的，循环的为每一个作业服务一个时间片，不区分任务的紧急性。 实时操作系统 其实就是在分时操作系统的基础上解决了缺点，可以能够优先相应一些紧急任务，某些紧急任务不需要时间片排队，而是优先一直执行完。在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在严格的时限内处理完事件（可以认为根据不同的事件的时限对每一个事件增加了优先级），这种操作系统主要特点为及时性和可靠性。 当然也有特例，例如软实时系统允许偶尔超时。 其他几种操作系统 网络操作系统 伴随着网络的产生应运而生的，能把网络中各个计算机有机集合，实现数据传送等，这种操作系统一般应用于后台大型服务器，主要是实现网络中各种资源的共享（如文件共享）和各台计算机之间的通信。 分布式操作系统 主要特点就是分布性和并发性，系统中的各台计算机地位相同，任何工作够可以分布在这些计算机上，由他们并行、协作完成。 个人计算机操作系统 个人使用，win XP,MacOS等，以上介绍的几种通常都是用于大型服务器的。 总结"},{"title":"内存管理概念","path":"/wiki/操作系统笔记/内存管理概念/index.html","content":"内存基础 内存的定义和作用 其实我们在前面学习进程时已经经常提到了内存的部分知识，我们知道一个进程在上cpu之前需要现在内存中处于就绪态，上cpu后进程实体的PCB,数据段，代码段大部分都处于内存中方便随时和cpu进行信息交换。所以内存可存放数据，程序执行前需要先放到内存中才能被cpu处理----所以cpu的功能是缓和cpu与硬盘之间的速度矛盾。 思考：内存如何区分多个程序的数据存储地？ 我们知道在多道程序环境下，系统中会有多个程序并发执行，也就是说会有多个程序的数据需要同时放在内存中，那么如何区分每一个数据段是属于哪个程序的呢？实际上内存会分为许多部分，有一个一个小房间，每一个小房间就是一个“存储单元”，内存地址从0开始，每个地址对应一个存储单元。 如果计算机“按字节编址”，则每个存储单元为1字节（1Byte)，即1B，即8个二进制位。 如果字长为16位的计算机“按字编址”，则每个存储单元为1个字，每个字的大小为16个二进制位，所以一个字=两个字节。 补充：常用的数量单位与换算 1KB(1K)=210Byte1KB(1K)=2^{10}Byte 1KB(1K)=210Byte 1MB(1M)=220Byte1MB(1M)=2^{20}Byte 1MB(1M)=220Byte 1GB(1G)=230Byte1GB(1G)=2^{30}Byte 1GB(1G)=230Byte 所以我们知道换算进制为2^10也就是1024Btye,所以1K实际上已经非常大了。 思考：4GB内存是什么意思？ 一台手机/电脑的内存为4GB，是什么意思。我们按照上面的公式计算，4GB=4*2^30Byte,如果内存是按照字节编址的，那么也就是会有2^2*2^30=2^32个房间，又因为是从0开始编号，所以房间编号为0~2^32-1。所以需要2^32个地址一一标识这些房间，所以需要32个二进制位来表示。 指令的工作原理 我们思考现在要对x=x+1指令语句进行执行，具体过程如下图： 首先高级指令x=x+1翻译成处理机可以看懂的二进制指令串（可能一个高级指令会对应多条二进制指令），然后cpu执行这个二进制指令串。 我们从上面可以看到cpu根据二进制指令找到010011111处的数据进行取出到寄存器中，然后+1操作，在返还该值到地址处，这样就完成了一个读写操作将x+1。可见，我们写的代码要翻译成CPU能识别的指令，这些指令会告诉CPU应该去内存中的那个地址读/写数据，这个数据应该做什么样的处理。在这个例子中，我们默认这个进程的相关内容从地址#0开始连续存放，指令中的地址参数直接给出了变量x的实际存放地址（物理地址）。 思考：如果进程不是从地址#0开始存放的会影响正常执行吗？ 比如如下面这个案例，我们现在将79处的存储单元写入10然后再将79处的数据读入到寄存器3中，如果进程是从#0开始存放数据的，那么确实可以正常执行： 从上面的图中我们也可以看出程序经过编译，链接后生成的指令中指明的是逻辑地址即相对地址，即相对于进程其实地址而言的地址，如上图中实际上指令中的地址为79处并不是指的物理地址79处，而是相对于进程起始处79处的地址，只不过是刚好此时进程是从地址为#0开始存储的，所以逻辑地址处的79就是映射的物理地址的79处。所以可以正常运行。（为了简化理解，本次我们都默认操作系统为进程分配的是一片连续的内存空间）。 但是实际上情况不可能总是如此的理想。如下图： 我们如果默认逻辑地址就是物理地址的话，此时上面的过程就会出现重大错误。因为此时指令0和1值的还是逻辑地址处的79，但是此时这个进程并不是放到内存中的#0地址开始毕竟内存中会存入许多进程（并发性导致许多进城会在内存中存储随时准备就绪上cpu)，所以此时指令0和1处的所说的的逻辑地址79处实际上是相对于此时起始地址#100开始后面的79个存储单元即绝对地址179处的数据，但是如果我们仅仅是按照逻辑地址==绝对地址执行的话，那么此时就会映射到其他进程的数据段（物理地址79处）这明显是不对的，所以我们在装入模块（可执行文件）进入内存时（这是高级调度/作业调度）需要对地址进行转换以达到在执行指令时读/写数据的地址正确，此时我们需要某些策略来使得指令中的逻辑地址转换为正确的物理地址。 思考：如何将指令中的逻辑地址转换为物理地址？ 策略1：绝对装入 策略2：可重定位装入（静态重定位） 策略3：动态运行时装入（动态重定位） 模块装入的三种方式 绝对装入 在编译时，如果知道程序将放到内存中的那个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存。比如上面那道题我们在装入模块到内存之前知道将要在内存地址为100的地方开始存放。 那么此时在对文件进行编译，链接后指令中不在使用逻辑地址，而是直接转换为物理地址如上图，此时在将装入模块（可执行文件）放入内存中，当处理机执行到指令0和指令1时就会到正确的存储单元（物理地址为179）读/写数据。如下图： 虽然没有什么大问题，但是绝对装入只适用于单道程序环境。程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。通常情况下都是编译或汇编时在转换为绝对地址。 思考：为什么只使用于单道程序环境？ 很简单，因为在装入模块进入内存后指令一直是不变的物理地址，但是我们知道在多道程序环境中进程是并发异步执行的，不可能一直存储于内存的一个固定地方，但是一旦装入模块变换了存储地址那么初始地址就也改变了，那么此时很显然此时装入模块中的地址就又出现指向错误了，而且如果绝对装入只能适用于单道环境程序，显然也不满足进程并发执行和内存建立的初衷，所以这种方法缺陷较大，有待改进。 可重定位装入（静态重定位） 静态重定位（可重定位装入），顾名思义肯定是能够弥补上面绝对装入的缺陷，具体做法是编译，链接后的装入模块的地址还是从0开始的，但是指令中使用的地址，数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块放入内存的适当位置。装入时进行重定位，将逻辑地址变换为物理地址（地址变换是在装入时一次完成）。 我们从上图可以看到，他是在装入时对于逻辑地址进行了+100的处理，这样当再次进入内存分配到内存的其他地方时也可以随时更新为正确的地址，不像绝对装入那样直接改变为绝对地址当再次进入内存就有可能出现错误。 思考：还有没有什么可以改进的地方？ 我们对比一下绝对装入和静态可重定位装入两者的区别。 装入策略 地址变化 异同点 绝对装入 编译后逻辑地址-&gt;绝对地址装入内存 有效解决了逻辑地址-&gt;绝对地址的问题，使得可以映射到正确的物理地址上，但是编译后直到运行完销毁前起始存放地址不许更改 静态重定位装入 编译后仍是逻辑地址，装入内存时逻辑地址-&gt;绝对地址 在编译后还是逻辑地址，只有在放入内存前进行+起始地址操作转换为正确的绝对地址，当出内存再次进内存时如果更改了起始存放地址可动态转换为正确的物理地址 但是我们发现静态重定位的特点是一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，作业就不能装入该内存并且最大缺陷是作业一旦进入内存后，在运行期间就不能在移动，也不能再申请内存空间。所以我们好需要解决在内存运行期间移动的问题。 动态运行时装入（动态重定位） 动态重定位：编译，链接的装入模块的地址还是从0开始的，装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方法需要一个重定位寄存器的支持。 装入时： 执行时： 我们看出动态重定位满足所有要求是最好的策略。动态重定位在满足程序在内存中移动的同时，还可以将程序分配到不连续的存储区，所以他区别于静态重定位不需要一次性申请所有连续的地址空间并且每次都只需要取出部分代码执行，如果需要映射地址则通过重定位寄存器可以随时指向正确的存储单元（都不需要连续存储了），简直是太棒了。并且由于是重定位寄存器更改映射地址所以可以向用户提供一个比存储空间大得多的地址空间（虚拟性）。 思考：总结三种策略的异同点？ 我们从以下几个角度区分这三个策略： 装入模块起始地址：绝对装入策略装入模块中的起始地址未必是0，但是静态重定位和动态重定位一定是0 逻辑地址-&gt;物理地址转换时期：绝对装入策略中是在编译，链接后即将逻辑地址转换为物理地址，静态重定位是在装入内存时，而动态重定位是在执行时借助重定位寄存器转换。总的来说，只有动态重定位是在内存中还保存逻辑地址。 借助外界手段：只有动态重定位需要一个辅助的重定位寄存器，静态重定位不需要。 装入的地址要求：绝对装入和静态重定位都需要一次性申请一片连续的容量够大的地址空间，而动态重定位可以离散装入。 思考：链接编译到底是什么？ 我们知道在一个程序从写到运行一次需要经过以下几个过程： 编译就是将用户源代码编译成若干个目标模块（编译就是把高级语言翻译为机器语言），而链接程序将编译后形成的一组目标模块，以及所需要的的库函数链接在一起，形成一个完整的装入模块，装入是由装入程序将装入模块装入内存运行。所以链接很重要，他是形成一个模块的关键步骤，这里面有3中链接方式。 链接的三种方式 静态链接 静态链接就是在程序运行之前先将各目标模块及它们所需要的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。如下图： 没啥大问题，但是这样就必须一次性申请一片连续的存储地址貌似难以实现因为内存中会造成许多内存碎片。而且准备工作时间很长，没有链接成一个完整的模块之前不能进入内存执行。 装入时动态链接 将各目标模块装入内存时，边装入边链接的一种链接方式，如下图： 这样即使还没有完成全部链接，但是前面的部分模块已经可以进入内存，准备工作时间明显缩短。 运行时动态链接 在程序执行中需要该目标模块时，才对他进行链接。如下图： 不但占用内存空间小，准备时间短，而且便于修改和更新，便于实现对目标模块的共享。 思考：怎么就便于实现目标模块的共享了？ 我们思考有两个程序现在都有一个调用打印机I/O设备的代码段，那么对于运行时动态链接的好处是不需要写两份了，谁需要谁就链接这部分模块，加大了模块的可重复利用率，这也是组件化思想的体现。 总结 基本上全是重点和易错点 内存管理 回顾前面所讲的知识，我们主要着重于对装入模块装入内存前和装入内存时的问题如正确的地址转换，链接方式等，那么接下里来我们在讨论一下对于内存中运行时对于各进程的管理。 内存空间的分配与回收 操作系统作为系统资源的管理者，当然也需要对内存进行管理，要管些什么？首先对于内存空间的分配和回收的任务必不可少。如下： 这些问题都会涉及到许多后续问题所以有不同的算法策略，后面我们将详细讲到。 内存空间的扩展 我们前面也讲过操作系统的虚拟性，实际上就是用过逻辑地址和物理地址的映射以及内外存切换装入等方式实现的，从而能够在有限大小的内存空间中虚拟出远大于物理空间大小的内存空间。所以操作系统需要提供某种技术从逻辑上对内存空间进行扩展。 地址转换 为了使变成更方便，程序猿写程序时应该只需要关注指令、数据的逻辑地址，而逻辑地址到物理地址的转换（这个过程称为地址重定位就是之前讲的三种装入策略）应该由操作系统负责，这样就保证了程序猿写程序时不需要关注物理内存的实际情况。类似的还有刚学写管程概念，也是为了更加方便于程序猿只集中于程序的编写而提出的。所以对于三种装入方式，我们可以看出只有动态重定位是现代操作系统才拥有的，毕竟其他两种方式还需要程序猿关注地址转换为体以防止出错。 内存保护 同时操作系统还需要提供内存保护功能，保证各进程在各自存储空间内运行，互不干扰。这里有两种策略： 策略1: 在cpu上设置一对上、下限寄存器，存放进程的上，下限地址。进程的指令要访问某个地址时，cpu检查是否越界。 所以可以看出上、下限寄存器存储的是物理地址。 策略2 采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界的检查，重定位寄存器中存放的是进程的起始物理地址，界地址存放的是进程的最大逻辑地址。 所以管理判断是否越界的是界地址寄存器，并且策略2是根据逻辑地址进行越界检查的，而策略1是根据物理地址进行越界检查的。 总结 覆盖与交换 这里我们讲的覆盖与交换技术不用想肯定是内存空间扩充的技术来实现操作系统的虚拟性，扩大内存空间大小。 覆盖技术 在早期的计算机内存很小，也没有操作系统所以无虚拟性的概念，即就是逻辑地址==物理地址的情况，那么比如IBM推出的第一台PC机最大只支持1MB大小的内存，那么就真的只是1MB了，所以会经常出现内存大小不够的情况出现（比如一个文件为20MB，那么放都放不进去更谈何运行）。所以后来提出了覆盖技术来解决程序大小超过物理内存总和的问题。 覆盖技术的思想是将程序分为多个段（多个模块）。常用的段常驻内存，不常用的段在需要时再调入内存（很容易想到）。所以内存中相应的有一个“固定区”和多个“覆盖区”。需要常驻内存的段放在“固定区”，调入后就不再调出（除非运行结束），不常用的段放在“覆盖区”，需要用到时调入内存，用不到时调出内存。如下： main函数部分在固定区，而BCDEF在覆盖区，这种覆盖技术确实解决了问题，但是必须由程序猿声明覆盖结构，操作系统完成自动覆盖。所以缺点是对用户不透明，增加了用户编程负担。覆盖技术只用于早期的操作系统，现在已经成为历史。并且我们发现还有一个小细节操作系统还可以做到让不能同时被访问的程序段共享同一个覆盖区，这样也做到了一定的减少占用内存空间的作用。 交换技术 交换技术（对换技术）的设计思路是当内存空间紧张时，系统将内存中某些进程暂时换出内存，把外存中某些亿具备运行条件的进程换入内存（进程在内存与磁盘间动态调度，这也是绝对装入方式易出错的地方）。 这里面的进程挂起和就绪运行的状态切换涉及的是中级调度（内存调度），就是决定将那个处于挂起状态的进程重新调入内存。 所以暂时被换出到外存等待的进程为挂起状态（suspend),挂起态又可细分为就绪挂起和阻塞挂起两种状态，这就不得不再提一下状态经典三角切换模型。 思考：交换技术应该将挂起的进程放在外存（磁盘）的什么位置？ 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式（空间碎片少）。 对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换出速度，因此通常对换区采用连续分配方式（学过文件管理章节后即可理解）。总之，对换区的I/O速度比文件去更快。 思考：什么时候应该交换？ 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页（后面会讲）就说明内存紧张，此时就可以换出一些进程，如果缺页率明显下降了，那么就可以暂停换出了。 思考：换出时应该换出那些进程？ 可优先换出阻塞进程（毕竟在哪都是等😉），可优先换出优先级低的进程，为了防止优先级低的进程在被调入内存后很快又被换出，有的系统会考虑进程在内存的驻留时间来决定换出哪个进程。但是一定要注意PCB是一定不会被换出的，他是常驻内存的。 总结 一定要注意覆盖技术和交换技术的区别在于角度不同，覆盖技术着眼于一个程序或进程，而交换技术是着眼于全局多个进程之间的关系，所以覆盖技术与交换技术互相配合最大限度的对内存空间进行扩展。"},{"title":"什么是进程","path":"/wiki/操作系统笔记/什么是进程/index.html","content":"进程的概念，组成，特征和组织方式 进程的概念 程序是静态的，就是存放在某个磁盘里的可执行文件，是一系列指令的集合。而进程是动态的，是程序的一次执行过程，所以同一个程序会对应多个进程。 如上图，QQ是一个程序，而图中的三个框分别对应着QQ程序三次执行过程，因此各为一个进程。仔细回想，你会注意到并发性所描述的是进程在同一个时间间隔内同时进行。 进程的组成 那么操作系统该如何区分每一个进程呢，毕竟有些进程在我们看来是一模一样的根本不好区分，操作系统则是根据PID来区分不同的进程。当一个进程被创建时，操作系统就会为这个进程分配一个唯一的且不重复的“身份证号”–PID。 而操作系统要记录PID和进程所属用户ID（UID)，这个是进程最基本的描述信息，可以使操作系统区分各个进程。例如上图中的3个QQ登录进程实际上在操作系统看来并不相同，他们每个进程各对应着一个独一无二的PID号码。 并且操作系统还要记录为进程分配了那些资源（如：分配了多少内存，正在使用那些I/O设备和正在使用哪些文件），这样以便实现操作系统对于共享资源的管理和分配。 同时还要记录进程的运行情况（如：CPU使用情况，磁盘使用情况，网络流量使用情况等）以方便实现操作系统对进程的控制和协调调度。 而这些信息均被存放在一个数据结构–PCB中（Process Control Block)中，即进程控制块，操作系统需要对各个并发运行的进程进行管理，但凡是管理时所需要的的信息，都会被放在PCB中，因此PCB不仅仅是记录PID号码而已，而是进程的信息以及所运行的环境都要记录，这样放切换不同的进程时操作系统可以保证其在合适的运行环境下进行适当的工作。并且要注意每一个进程都对应一个自己的PCB存储着自己的信息，当进程结束时操作系统会回首PCB，因此可以说PCB是存储进程完整信息的最小单位。 同时进程还拥有程序段和数据段，分别用来存储程序的代码和运行过程中的各种数据。而PCB虽然也属于进程的一部分，但是他并不是提供给进程自身使用的，而只是一个个人身份信息卡，用来提供给操作系统使用，只有程序段和数据段才是进程自己使用的。 思考：程序是怎么运行的？ 先看下图： 这个是一个高级语言翻译到指令然后由cpu执行的过程，那么高级语言-&gt;指令-&gt;cpu执行所对应的一个程序具体的运行过程是怎样的呢？如下图： 高级语言所编写的可执行文件.exe存放于硬盘上存储，当双击打开程序的一个进程时，首先会把程序放入内存，并且操作系统会创建一个PCB分配给这个进程，此时进程所组成的三部分PCB，程序段和数据段都被存放在了内存中，并且程序段中是二进制指令，这样cpu在执行指令时会取出相对应的指令，并将执行所产生的的数据存放在数据段，在进程运行时cpu和内存会频繁的进行信息交换。 我们在这里定义一个新名词叫做进程实体或者进程映像，就是程序段，数据段，PCB三部分的组合，那么引入进程实体后，我们可以更加准确的定义进程：进程并不是一个可见的物质实体，而是一个进程实体的运行过程即是一种连续性的状态组成的，是系统进行资源分配和调度的独立单位，所以准确来说我们之前所称呼的进程实际上是进程实体，因此对于每一个进程，他们的PCB，数据段各不相同会时刻发生着变化，而程序段就是指令集合，一般同一个程序所产生的进程程序段代码会相同。又因为PCB是记录进程的信息，所以PCB中的某些信息（如占用内存的状况等环境信息，当然PID除外）肯定也是时刻发生变化的并且PCB是进程存在的唯一标志。 进程的特征 程序是静态的而进程是动态的，因此进程拥有以下几个特征： 动态性：进程是程序的一次执行过程，是动态产生，变化和消亡的，这也是进程最基本的特征。 并发性：内存中有多个进程实体，各进程可以并发地执行。 独立性：进程是能够独立运行、独立获得资源、独立接受调度的基本单位。 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制”来解决异步问题。 结构性：每个进程都会配置一个PCB，结构上看，进程由程序段、数据段、PCB组成。 进程的组织方式 在一个系统中，一般会有数十至数百乃至数千个PCB，为了能够对他们有效的管理，需要适当的方式将PCB组织起来存储管理。进程的组成讨论的是一个进程内部的组成结构信息，而进程的组织讨论的是多个进程之间的组织方式。这里我们讨论两种方式。 链接方式 链接方式是按照进程的状态将PCB分为多个队列，操作系统持有各个队列的指针方便管理进程。如下： 这种方法优点很明显，各个PCB形成一个队列并且PCB指针执行下一个PCB，由指针统一指向调配，切换时更改指针指向后一个PCB即可，切换简便，但是缺点时当有对个PCB块时采用这种队列，当中途需要删除或者提高某个PCB优先级时则需要对两边的指针进行更新比较复杂。 索引方式 根据进程状态的不同，建立几张索引表用来记录PCB地址，操作系统指向各个索引表的指针。如下： 这种方法优点是建立索引表存储，更改指针执行即可切换进程，并且创建删除只需对索引表项进行操作，非常简便，但是缺点是当PCB很多时，索引表就会长可能需要建立多级索引表，同时索引表也许占用额外的空间。 进程的状态与转换 进程的状态 这是个非常重要的概念，他根据不同的进程所处信息环境将进程分为以下几个状态： 创建态 进程正在被创建时，他的状态就是创建态，这个阶段操作系统会为进程分配资源并初始化PCB。因此可能会有多个程序处于就绪态都带等待cpu的情况出现。 就绪态 当进程创建完成后并不是立刻就上cpu执行，当创建完成后便进入了就绪态，此时已经具备了运行条件，但是如果此时cpu没有空闲，则该就绪态进程则需要等待暂时不运行随时准备进入cpu执行，当然运气好的话，也可能刚创建完就上cpu。 运行态 当cpu空闲时，并且内存中有处于就绪态的进程，操作系统就会选择一个就绪态进程（这个会涉及到多种不同的算法，后面介绍）让其上处理机pu执行，此时这个进程就是处于运行态。 阻塞态 当然进程不可能会提前将所有图中的准备都一次性做好，他在运行时可能中途会请求等待另一个事件的发生后才能继续执行，或者发现某个所需的共享资源已被占用，则需等待其他进程的相应，此时操作系统会让这个进程下cpu，并让他进入阻塞态等待（毕竟cpu不只是服务这一个进程，可没时间一直等），此时操作系统就会启动另一个就绪态的进程运行。所以阻塞态不可能直接变为运行态，一定要先恢复到就绪态（毕竟要先准备好切回该进程的工作环境等工作）。并且可以看出在阻塞态之前进程一定是处于运行态。 终止态 一个进程已经执行完成或者中途被用户关掉时就会执行exit系统调用，此时会请求系统终止该程序，然后程序就会进入终止态，操作系统让该进程下cpu，并回收内存空间等资源，最后还要回首该进程的PCB，当终止进程的工作完成之后，这个进程就彻底消失了，如果是连接形式组织方式，那么这个PCB就会删除，指针指向它所指向的下一个PCB，而如果是所以方式，则PCB删除的同时，索引表的项也会删掉。注意就绪态/阻塞态/运行态的进程都可能立刻转换为终止态。 进程状态的转换 这个模型非常重要，需要牢记。 从上图可见运行态和就绪态之间是双向可以切换的，而当是外界因素例如时间片或者其他进程抢占导致的下cpu实惠直接回到就绪态，只有是通过系统调用的方式申请请求时才会切换到阻塞态，即是进程一种的自愿让出cpu的主动行为，所以可以理解为此时自愿下cpu,所以会将工作环境，工作的状态等记录下后下cpu,当可以继续执行的时候则首先需要在配置回所需的工作环境并做好之前的工作状态到达就绪态才能继续执行，而当是被动的不情愿下cpu时则会随时准备抢回cpu的使用权所以会直接切换到就绪态。当然要注意阻塞态切换到就绪态是被动地行为因为这不是进程想继续回到就绪态准备执行就可以随时自主切回就绪态的，而是需要等到某个事件发生后才能回到就绪态，由于时间无法预测所以只能被动等待。而运行态到终止态一般是调用了exit函数（不一定是正常执行完成，当遇到重大的bug如数组越界等导致进程无法继续运行也会触发），一旦转换为终止态，则只能重新创建进程了。 在进程PCB中，会有一个state变量来记录当下进程的状态，1代表创建态，2代表就绪态，3代表运行态…为了对同一个状态下的各个进程进行统一的管理，操作系统会将各个进程的PCB以链接形式或者索引形式统一存储管理。 进程控制 进程控制就是对系统中的进程实施有效的管理，它具有创建新进程，撤销已有进程，实现进程状态转换等功能，其中最重要的就是实现进程的状态转换。 进程控制的实现 实现进程的控制肯定会也是需要程序来实现的，而这个程序就是内核中的原语部分（重点：原语是一个程序），原语是一种特殊的程序，他的执行具有原子性，即这段程序的运行必须是一气呵成无中断的。 思考：原语为什么不能有中断？ 因为如果不能一气呵成，那么就有可能导致操作系统在某些关键数据结构信息处不统一，从而影响操作系统进行个别的管理工作。如果可以中断，就会出现重大的bug，如： 这是一个以连接形式组织的PCB队列，此时假设系统要执行将PCB2（此时他在队列头部，该轮到他了）所对应的进程2等待的进程已经发生了，则此时需要从阻塞态转换到就绪态，即放到就绪队列中，此时原语程序需要进行以下两个步骤： 将PCB的state变量设为1（假设1表示就绪态，2表示阻塞态） 将PCB2从阻塞队列放到就绪队列 那么如果原语可以被打断的话，此时刚刚执行完第一个步骤后收到了中断信号停止执行原语程序，就会出现state=1但是却在阻塞队列的bug。所以原语必须具有一气呵成的特点。 思考：如何实现原语的“原子性”？ 我们可以使用“关中断指令”和“开中断指令”两个特权指令实现原子性。 我们首先知道cpu在每执行完一个指令后都会例行检查是否有中断信号需要处理，如果有，就会暂停运行当前的这段程序，转而执行相应的中断处理程序。如下： 那么显然在执行原语时我们需要cpu不在根据中断信号而停止运行原语程序，因此就有了关中断指令和开中断指令两个特权指令（此时其他的指令如指令1，2和a,b还是非特权指令），那么可以这样实现：当cpu执行了关中断指令后，就不在例行检查中断信号，知道执行到开中断指令之后在恢复检查。这样关中断和开中断之间的这些指令序列（指令a,b)就是不可被中断的了，当然在这期间cpu还是会受到中断信号，但是此时不检查，就可视为忽略了，知道开中断以后在执行中断信息。如下图： 显然关开中断指令必须是特权指令，否则用户可以修改就会造成原语程序被打断的情况出现。 进程控制相关的原语 首先我们看有关进程创建的原语： 有关进程终止的原语： 这里面将该进程拥有的所有资源归还给父进程或操作系统要特别注意。撤销原语是指由就绪态/阻塞态/运行态切换到终止态再到释放时所执行的原语程序。 有关进程的阻塞和唤醒的原语 有关进程的切换的原语： 我们可以看出大部分原语都会有许多步骤，并且引起原语的事件也各不相同。 程序是如何运行的 学完进程转换后，我们在更加详细的讨论一下程序在运行时切换进程在切回进程的具体步骤。首先我们需要了解一个新的概念–寄存器，就是用来存储信息的，这里寄存器可以分为许多类（机组原理有讲），如下图： 我们可以看出PC和IR的作用分别是存储下一条指令和现在正在执行的指令的特殊功能寄存器，并且回忆PSW寄存器是用来记录当前cpu处于管态还是目态的，通用寄存器就是用来存储中间的某些计算数据结果的，所以PC和IR肯定是经常与内存中进程处的程序段进行交流的，而通用寄存器就是与数据段进行频繁的信息交换。 当执行完指令1后PC和IR会立刻更新，并且如果需要通用寄存器会存储信息。那么鸡舍现在进程A执行到了指令3以后需要开始执行另一个就绪进程B，则此时进程A需要切换到阻塞态，因为通用寄存器和PC,IR都是共享资源，那么进程A的信息肯定就不能在占用了，那么之后执行完进程B切换回进程A时如何能够恢复到之前的运行环境呢？如下图： 上图是执行进程B到指令x，此时需要切换回进程A的运行环境并开始执行进程A。这时我们就需要PCB来保存之前进程A运行态时的环境信息（一些必要的寄存器信息），这样在切换回进程A（当然这之前进程A肯定是要先到达就绪态）后可以保证其正常运行。如下图： 因此PCB会存储一些进程必要的环境信息，所以我之前说道PCB会随时发生小部分变化。但是要注意到这个信息是提供给操作系统，然后操作系统进行恢复cpu到之前进程A的运行环境的任务。所以PCB存储的环境信息也是提供给操作系统的，进程自身不使用。 进程通信 顾名思义，进程之间也是需要信息交换的，进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间。但是进程之间的信息交换又是必须实现的，所以为了进程之间的通信安全，操作系统提供了一些方法。 共享存储 即有一个共享空间可以来实现两个进程之间的信息交换，但是需要满足两个进程对共享空间的访问必须是互斥的（互斥访问通过操作系统提供的工具实现）。操作系统只负责提供共享空间和同步互斥工作，具体的信息编写和读入是由进程之间完成的。 思考：为什么共享空间的访问要互斥？ 访问互斥即意味着每次只能有一个进程进入共享空间进行读写，原因很简单，如果可以有多个进程同时进入共享空间进行信息的编写，那么就会出现冲突，即两个进程可能同时对某一个变量更改，这种冲突应该避免。 思考：共享空间的实现方式 共享存储有基于数据结构的共享和基于存储区的共享两种方式来实现，两种不同的共享空间会对共享速度产生影响。 基于数据结构的共享：比如共享空间里只能放入一个长度为10的数组，这种共享方式速度慢并且限制多，是一种低级的通信方式。 基于存储区的共享：在内存中划出一块共享存储区，数据的形式，存放位置都由进程控制，而不是操作系统，相比之下，这种共享方式速度更快是一种高级的通信方式。 消息传递 进程间的数据交换格式与共享一个空间不同，而是“信书传递”，数据交换以格式化的消息为单位，进程通过操作系统的“发送消息/传递消息”两个原语（不可打断）进行数据交换。一般一个消息由两部分组成： 而消息传递又有两种方式，一种是直接通信方式，类似于邮递员链接，消息直接挂到接受进程的消息缓冲队列上，另一种是先发送到中间实体类似于信箱，然后另一个进程从中间实体收取，因此也称为“信箱通信方式”。如下图： 上半部分是直接通信，下半部分是简介通信方式，无好坏之分。 管道通信 如下图： 管道实际上是一个用于连接读写进程的一个共享文件，又名pipe文件，其实就是在内存中开辟一个大小固定的缓冲区。那么他和共享空间又有什么本质区别呢？ 管道采用的是半双工通信，某一个时间段内只能实现单向的传输，即一个时间段只能我传给你或者你传给我，当然方向可以任选只是一个时间段只能一个方向，如果需要双向同时通信，则只能在设置一个管道即两个管道才能同时双向通信。因此管道在一个时间段内永远只有一端是可以写数据的口，另一端是读数据的口，且不能同时打开。 各进程要互斥的访问管道（即读写不同时）。 数据以字符流的形式写入管道，当管道满时，写进程的write()系统调用就会被阻塞即使没有写完，等待读进程将数据取走。当读进程将数据全部取走后，管道变空后，此时读进程的read()系统调用会被阻塞，此时才能继续write()。 如果没写满，就不允许读，如果没读空，就不允许写。 数据一旦被读出，就从管道被抛弃，这就意味着读进程最多只有一个，否则可能会有读错误数据的情况，但是写进程可以有多个。 小测试：项目实战 如果你对管道通信了解透彻了，尝试完成以下这个大作业吧😬：作业大礼包"},{"title":"什么是线程","path":"/wiki/操作系统笔记/什么是线程/index.html","content":"线程的概念和特点 线程的概念 考虑一个问题，如下图 很明显这是三个进程并发进行。那么在实际上的并发运行中操作系统会频繁的切换进程以达到同时以某种未知的速度进行（异步性的体现）。那么上节我们知道每次切换进程都要进行PCB更新来记录离开时的运行环境，毋庸置疑，这需要很大的时间开销。 并且从上图我们也可以看出进程是调度（即任务分配）和资源分配的基本单位，那么有没有一种而更好的模型可以减少时间开销的同时还能够保证功能的实现？ 这时我们就引入了一个新的概念–线程，其实线程和进程很相似，如下图： 线程的优点 对比之前的模型，我们发现三个进程合并在了一个进程里，此时合并成为了一个QQ进程，而此时进程依然是资源分配的基本单位，他是分配资源的最下单位，但是此时三个合并的进程更名为线程，此时他们不再是资源分配的基本单位，三者共同共享QQ进程这一进程的共享资源，但是线程仍然是cpu调度的基本单位。此时进程成为了资源分配的基本单位，线程是调度的基本单位，这样，当切换线程时就没有必要频繁更新PCB的环境信息了也就减少了切换的时间开销。 对比两种模型，线程的引入只是减小了线程间并发的时间开销，而当时切换不同进程下的线程时，在时间开销并未得到优化，开销还是很大。当然此时，从属于不通进程的线程间的通信仍然必须请求操作系统的系统服务，而统一进程下的线程间可以直接在共享资源空间下进行读写的操作，所以此时同一个进程下的线程间通信不在需要操作系统的服务。 思考：引入线程的概念后进程发生了哪些变化？ 引入线程前，进程同时是cpu调度和资源分配的基本单位，而当引入线程后，进程只是资源分配的基本单位，而线程成为了cpu调度的基本单位。所以可以理解为线程是一个寄存在进程下的小进程，小进程之间拥有直接通信，切换不用更新PCB，共用共享资源的特殊点而已。但是由于线程不是资源分配的单位，所以线程基本上不拥有独属于自己的资源空间，大部分都是共用的一个进程下的共享空间。当然在多cpu的环境下，各个线程也可以分配到不同的cpu上并行地执行且时间开销还很小。但是这里我们只讨论单核，所以线程之间也只会并发执行。 引入了线程的概念后，进程不仅仅是只能串行的执行某一个任务了，从宏观视角来看，此时cpu上的进程可以并发进行，同时某一个进程内的线程也在并发进行，所以并发性显著提高，此时进程只作为除cpu之外的系统资源的分配单元（如打印机，内存地址空间等都是分配给进程的），而线程则成为了处理机的分配单元。 线程的实现方式 用户级线程 用户级线程（User-Level Thread,ULT),用户级线程由应用程序通过线程库实现。所有的线程管理工作都由应用程序负责（包括线程切换），用户级线程中，线程切换在目态即可完成，无需操作系统的干预。在用户看来是有多个线程，但是在操作系统的视角来看，操作系统并意识不到线程存在（用户级线程对用户不透明，对操作系统透明），即用户级线程只是从用户的视角能够看到线程。 在早期的操作系统（如早期的UNIX），只支持进程，不支持线程。当时的“线程”是由线程库实现。以操作系统视角来看，根本就没有线程，而是就是三个进程。即在操作系统看来： 还是三个进程。。如果我们从代码的角度来看，线程其实就是一段代码逻辑，上述三段代码逻辑上可以看做是三个“线程”，而while循环就是“线程库”，线程库完成了对线程的管理工作（如调度，当然while循环就是通过If-else判断管理线程的）。 123456789int main()&#123;int i=0; while(true)&#123; if(i==0)&#123;//处理视频聊天的代码&#125; if(i==1)&#123;//处理文字聊天的代码&#125; if(i==2)&#123;//处理文件传输的代码&#125; i=(i+1)%3; &#125;&#125; 很多变成语言提供了强大的线程库，可以实现线程的创建，销毁和调度等功能。因为用户级线程是由应用程序通过线程库实现的，所有的线程管理工作都是由应用程序负责（包括线程切换），所以在用户级线程中，线程切换在目态即可完成，无需操作系统的干预，当然进程切换还是得有操作系统完成的，不同进程下的线程间信息交流也需要操作系统的服务。由于用户级线程是只是在用户视角下有体现线程，但是在操作系统看来还是几个进程并发进行，所以一旦一个用户级线程被阻塞，整个进程就都被阻塞了，即其他的几个线程也会阻塞，并发度并不高。此时的多个线程不可在多核处理机上并行运行，因为只有在操作系统中的线程才可以在多核cpu上并行运行，而现在虽然有多个线程，但是在系统看来并没有意识到线程。 内核级线程 内核级线程（Kernel-Level Thread,KLT)又称“内核支持的线程”，内核级线程中用户所看到的线程都和操作系统中某一个线程对应（注意不一定是一一对应），所以此时的线程管理工作是由操作系统内核完成，线程调度、切换工作也都是由内核负责，所以也就不需要线程库了，因此内核级线程的切换需要在管态下才能完成。可以简单地理解为此时从操作系统的视角看内核可以看到线程。大多数的现代操作系统都实现了内核级线程，如windos,linux。 以上这些都属于内核级线程，一定要特别注意内核级线程和用户级线程的本质区别就是内核有没有内核级线程的概念，至于所说的多线程模型（下面会将）都是针对内核级线程而讨论的。并且一定要注意，因为操作系统只能看得到内核级线程，所以只有内核级线程才是处理机分配的单位。 操作系统为每一个内核级线程都建立了TCP（Thread Control Block,线程控制块，线程是Thread,进程是Process，所以进程控制块叫做PCB)来对内核级线程进行管理。优点是此时当一个线程在被阻塞后别的线程可以继续并发执行。且因为此时操作系统可以看到线程，所以此时的多线程可以在多核处理机上并行执行。缺点是一个用户进程会有许多的内核级线程，又因为此时的线程是由操作系统内核完成，所以需要频繁的变态，因为管理成本高，开销大。并且对比思考，PCB有不同的组织方式，那么TCB应该也有不同的组织方式。 思考：用户级线程和内核级线程的根本区别？ 就是在操作系统内核看来能否意识到线程的存在即有无内核级线程的概念。 多线程模型 首先我们需要注意的是，当说到多线程模型时，操作系统首先是一定有了线程的概念，即此时肯定是可以意识到线程的存在的，所以用户级线程就没有多线程模型的以下几个分类的概念，即用户级线程不属于下面的任意一种。在支持内核级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分为以下几类。 一对一模型 一个用户级线程就对应与一个内核级线程，每个用户进程有与用户级线程同数量的内核级线程，优点是当一个线程被阻塞后，别的线程还可以继续执行，并发能力强，且此时多线程可在多核处理机上并行执行。缺点是一个用户进程就会占用多个内核级线程，线程切换由内核完成成本高。 多对一模型 优点是用户级线程的切换在目态下切换即可，线程管理的系统开销小，效率高，但是当一个用户级线程阻塞时，整个进程都会被阻塞，并发度不高。多个线程不可以在多核处理器上并行运行。（和用户级线程很想，但不是用户级线程的模型，因为此时系统能够意识到线程即内核级线程的存在）。 多对多模型 n个用户线程映射到m个(m&lt;=n)内核级线程，每个用户进程对应着m个内核线程。克服了多对一模型的并发度不高的缺点的同时又克服了一对一模型中开销太大的缺点，所以性能较为稳定不极端。还记得前面强调的内核级线程才是cpu调度的基本单位吗，所以此时这个用户进程虽然有3个用户级线程，但是一次性只能个有两个内核级线程获得cpu的调度。 因此我们可以理解为用户级线程是“代码逻辑”的载体，而内核级进程是“运行机会&quot;的载体，内核级线程才是处理机分配的单位，例如：多核cpu环境下，上面这个进程最多被分配到两个和并行执行。一段”代码逻辑“只有获得了“运行机会”才能被cpu执行。内核级线程可以运行任意一个有映射关系的用户级线程的代码，所以只有两个内核级线程中逻辑都被阻塞时，这个进程在会被阻塞。 总结"},{"title":"贪心思想","path":"/wiki/手撕算法笔记/贪心思想/index.html","content":"什么是贪心思想 贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，算法得到的是在某种意义上的局部最优解。贪心算法不是对所有问题都能得到整体最优解，关键是贪心策略的选择。也就是说，不从整体最优上加以考虑，做出的只是在某种意义上的局部最优解 根据度娘的介绍，我们可以看出贪心算法是一个比较契合人类思维的算法，他就是每次都选取当下最好的情况，所以得到的未必是最优解，但是一定是局部最优解，一个非常接近最优解的情况。 贪心思想的特点 不回溯：选定一个分量后，就不重试其他可能了，这也是为什么回溯法最终得到的是全局最优解而贪心只能得到局部最优解的原因。 使用局部优化策略即贪婪策略的主要原因不是得到全局最优解，而是尽量使用较小的计算开销得到一个较为贴近最优解的优化解，因此极有可能得到的就是一个近似解。 不同的贪心策略会得到不同的贪心近似解，但是大致上都是在精确最优解附近摆动。 常常使用的是使目标函数有最大收益的策略就是贪心策略，即局部性概念。 典型例题精讲 找零钱问题 假设有4种硬币，他的面值分别是二角五分、一角、五分和一分。现在要找给某顾客六角三分钱。 正常思维:我们会不假思索地拿出2个二角五分的硬币,1个一角的硬币和3个一分的硬币交给顾客。 这种找硬币方法与其他的找法相比，所拿出的硬币个数是最少的。这里，我们下意识地使用了这样的找硬币算法： 首先选出一个面值不超过六角三分的最大硬币，即二角五分；然后从六角三分中减去二角五分，剩下三角八分；再选出一个面值不超过三角八分的最大硬币，即又一 个二角五分，如此一直做下去。即每次都选择尽可能大的硬币进行拼凑，这种找硬币的算法实际上就是贪心算法，只是巧合的是，这里的贪心近似解与全局最优解刚好相同。 总结：所以贪心算法总是作出在当前看来是最好的选择。也就是说贪心算法并不从整体最优 上加以考虑，它所作出的选择只是在某种意义上的局部最优选择。 活动安排问题 设有n个活动的集合E={1,2,…,n}，每个活动都有相对应的占用舞台的起始时间和结束时间，并且只有一个舞台可以使用，而且保证一个活动开始时必须一直进行到结束，即不能中途切换活动。我们要寻找到一个最好的策略使得尽可能多的活动使用这个舞台。 首先，由于活动不能中途切换，且后面的活动必须等到前面的活动结束才能开始，所以每个活动之间肯定是相容的，即任意两个活动的占用舞台的时间区间不相交。这里我们保证输入的活动是以其完成时间的非递减顺序排列的，所以按照贪心策略，我们只需要每次都选择最早完成时间的相容活动加入活动集合中即可，这种方法每次都选择相容活动并且由于每次选取的都是最早完成的活动，直观上来看，也就为后面的活动留下了更过的时间，所以可以将时间段极大化，应该能够得到一个较为接近全局最优解组合的答案。并且由于我们只需要每次选取最早完成的活动即可，所以只需遍历一遍活动数组即可，时间复杂度仅仅为O(n)，空间复杂度没有借用队列，堆栈等辅助数据结构题，所以空间复杂度也只是一个一维n数组，空间复杂度也仅仅为O(n)，那么总体来看，我们只是用了很小的时间和空间复杂度就得到了一个非常接近全局最优解的组合，可见其开销之小，因此这种方法非常适用于实际生活中。即使输入的活动完成时间是混乱排序的，那么只需要使用快排或者堆排序，归并排序进行重排列即可，时间开销也只是提升到了O(nlogn)。伪代码如下： 123456789101112131415161718192021222324public static int greedySelector(int [] s,int [] f,boolean a[])&#123; //记录数组边界值 int n=s.length()-1; //用来记录a[i]活动是否选择进行，第一个活动肯定是要进行的 a[1]=true; int j=1; //选择的活动数量，因为已知第一个活动进行，所以初始化为1 int count=1; for(int i=2;i&lt;=n;i++)&#123; //对活动i进行检验看是否是最早的当前完成时间 //s[i]代表活动i的开始时间 //f[j]代表活动j的结束时间 if(s[i]&gt;=f[j])&#123; a[i]=true; j=i; count++; &#125; else&#123; //不选择此活动 a[i]=false &#125; &#125; return count;&#125; 机器调度问题 现在有n个任务和足够多台的机器，假定任何时间一台机器只能执行一个任务，设任务i的开始时间为si,完成时间为fi,那么si&lt;fi,[si,fi]代表任务i的作业时间区间，成两个任务i,j重叠是指两个任务的时间区间有重叠，例如：区间[1,4]和区间[2,5]，而[1,4]和[4,7]没有重叠。可行的任务分配是指分配中没有将重叠的任务分配给同一台机器。最优分配是指占用机器数最少的可行分配。例如： 任务序号 任务开始时间 任务结束时间 a 0 2 b 3 7 c 4 7 d 9 11 e 7 10 f 1 5 g 6 8 按照贪心策略：那么每次我们都将遇到重叠任务时加一台机器，且每次都尽可能将任务放到所有空闲机器中完成时间最小的机器上。如下图： 这里一共有7和任务，我们按照贪心策略，每次都尽量使用旧机器，实在迫不得已了在开新机器，然后每台用过的机器的可用时间为这台机器上最近执行任务的完成时间。如果一个新任务的起始时间&gt;=这些机器的最小可用时间，则安排在这个旧机器上，否则就只能使用新机器了，如上图，M2是在M1在执行a，而f无法执行时开始使用的，M3是在执行c却发现M1,M2都繁忙时使用的，d其实用M2,M3均可以，这里因为每次都尽可能保证三台机器平均使用寿命相同，每次都选择空闲时间更长的机器。这里的任务并不是按照开始时间非递减顺序排列的，所以我们首先可以使用Min-堆存放每台机器的可用时间即进行堆排序重排列，这样每次取出的新任务一定是当前开始时间最早的，所以时间复杂度为O(nlogn)。 我们发现虽然理论上贪心算法一般不能得到全局最优组合，但是对于这种机器调度或者找零钱等问题，一般使用贪心算法却总是能够直接得到整体最优解。所以贪心算法也并不是一定相对整体最优解有偏差。 最短路径 给定一个有向图G，一个源节点s，目的节点d,找到一条从s到d的对短路径。这里如果不是用回溯法或者分枝-限界法，一般最终求得的都不是整体最短路径，而只是一个相对最短路径，但是相对的时间开销也会小很多。如果利用贪婪算法，那么每次我们离s点最近的下一个节点q，然后在选择离q最近的且不再前面选择过的节点t，直至到达d，这种策略即为最短路径贪婪策略。 例如下面这道例题，我们寻找从1到5的最短路径： 按照贪婪策略应该为1-&gt;3-&gt;4-&gt;2-&gt;5，路径长度为2+2+1+5=10,但是对于1-&gt;4-&gt;5只需要6就可以到达，所以按照贪心法找大的一般都不是整体最短路径，而只是一个优化组合。 装载集装箱问题 尽可能在有限的承重量情况下多装入集装箱。这里我们所采用的贪心策略就是尽可能选择装入小（从小到大排序装入）的集装箱直至装到不能再装入集装箱。对于混乱排列的集装箱使用快排即可。我们发现其实这里得到的贪心解就是最优解。证明如下： 首先一定是替换集装箱，而不是加入集装箱。因为此时已经不能装入更多的箱子里，并且因为是从小到大装入的，所以肯定是不足以装入下一个箱子了，所以唯一的一种情况就是取除前面已经装入的某个箱子后+剩余的不足以装入更大箱子空间后可以装入后面更大的箱子了，但是总体来看，箱子数没有发生变化，只是剩余空间变小了，空间利用率变大了。 所以有关数量不涉及到空间利用率或者效益值的问题，一般贪心得到的就是最优解。 0/1背包问题 与上面不同的是，这里就涉及到了效益值的问题，题意如下：设有容量c的背包和n件物品,物品i的重量为wi ;假定装入物品i获得的效益值pi,试给出一装入物品的方法,使获得的总效益值最大。 第一种贪心策略： 对于这种问题，我们第一个想法就是尽可能装入更多的物品，那么效益值应该也会尽可能的大，所以才用的是每次都装入小的物品，直至不能装入物品了。这种策略并不一定会得到最优解。对于质量小的物品效益值特别低，质量略大的物体效益值特别大的情况就有一点捡了芝麻丢了西瓜的意思，如下：n是物品数量，c是背包容量，p是效益值 n=3,c=105,p=[100,10,10]，我们按照上面的贪心策略最终得到的贪心解为[1,0,0]效益值为20，但是最优解却是[0,1,1]效益值为30，所以需要改变策略。 第二种贪心策略： 那么还有一种就是每次尽可能选大的效益值物品拿，这样整体效益值也会尽可能的大，所以每次都是效益值最大的物品，直至不能装入物品了。这种策略其实也不一定能够得到最优解。对于效益大的物品质量特别大，而效益值略小的物品质量却特别小的情况就有些欠妥，如下： n=3,c=25,w=[10,15,20],p=[80,99,100]，此时按照上面的贪婪策略最终得到的贪心解为[0,0,1]效益值为100，但是最优解却为[1,1,0]效益值为179。所以综合来看上面两种贪心策略都不是太好，他们距离最优解都有较大的差距，所以需要采用一种折中的方法如下： 第三种贪心策略： 我们每次不是选择质量小或者效益值大的物品装入，而是引入一种新的概念效益密度值，他的计算公式为m=p/w,表示单位质量的某种物体所含有的效益值，这样我们每次都选取效益密度值更大的物体，对于整体视角来看，每次选取的都是相对来说效益值较大的物体。这样却是可以缩小贪心解和最优解之间的误差，但是也会存在特殊情况，因为某种物品的效益值=该物品效益密度值*物体总质量，那么对于效益密度值很大，但是其物体质量太小，最终产生的效益值微乎其微不能对总体带来太大影响反而占用了部分空间从而造成了较大的背包碎片没办法放入大质量物体也会导致误差较大，例如： n=3c=30,w=[20,15,15],p=[40,25,25],我们按照上面的策略进行选取，首先需要计算出效益密度值并按照密度值递减顺序进行重排序，最后贪心解为[1,0,0]效益值为40，优化解为[0,1,1]效益值为50，之所以会产生这种偏差，就是因为选取了物品1以后产生了较大的背包剩余空间，而无法放入2,3，仅仅物品1产生的效益值又不是太大导致的。但是综合考虑，三种贪心策略中第三种贪心策略发生特例的情况概率较小，且一般产生的误差不是太过于离谱，所以对于一般的0/1背包问题，我们选择效益密度方法进行贪婪选取。 伪代码如下： 12345678910111213141516171819202122void Selector(int [] w,int []p,int c)&#123; //一定要记住首先需要转换类型 //因为密度值一般只有在小数部分才能比出大小 //两个整型相处得整型 int-&gt;double //计算效益密度值 double m[]; for(int i=0;i&lt;w.length();i++)&#123; m[i]=p[i]/c[i] &#125; //快排按照密度值重排列 //贪婪选取 for(int i=0;i&lt;w.length();i++)&#123; if(物品i可以装入背包)&#123; //装入物品i，此时i应该是效益密度值最大的物品 &#125; else&#123; //舍弃物品i continue; &#125; &#125;&#125; 算法时间复杂度为O(nlogn)，因为贪心法往往不能得到精确解，所以定义贪心解和最优解的误差用一下比值的百分比来度量： 误差=∣优化值−贪心解值∣/优化值∗100%误差=|优化值-贪心解值|/优化值*100\\% 误差=∣优化值−贪心解值∣/优化值∗100% 对于上面的三种策略一般误差不会超过100%，但是当出现某个物品的质量和密度值非常大远超其他物品的时候，误差往往超过100%，即贪心解几乎是优化解的n倍😂！ 思考：能否进一步优化保证误差小于30%? 实际上是可以做到的，这里介绍一种k-优化算法，他可以保证贪心解与最优解的误差非常之小，但是相对来说也更复杂，但是对比回溯法和分枝-限界法时间开销和空间开销又较小。其改良后的误差范围为 误差=1/(k+1)∗100%误差=1/(k+1)*100\\% 误差=1/(k+1)∗100% 所以一般对于这种方法k=2误差就已经非常小了。那么这种算法思路入下： 首先k-优化算法也需要对物品进行效益密度值从大到小重排列 先将一些物品按照分类讨论的方法装入背包，然后剩下的物品在进行贪心法选取 预先装入的物品（即分类讨论装入的物品）数量不能超过k 对所有物品数不超过k的物品子集都执行上面的过程，并从多个效益值解中选取最好的解作为k-优化算法的优化解 例如：n=4,w=[2,4,6,7],p=[6,10,12,13],c=11。我们这里使用2-优化算法，理论上误差值应该控制在了33%以内。最后我们将证明误差是否在33%以内，其步骤如下： 首先当k=0时，即有0件物品事先装入背包，剩下的物品按照贪心策略选取，实际上不就是直接按照效益密度值贪心策略选取嘛😄，最终贪心解为[1,1,0,0]效益值为16。 当k=1时即说明有一件物体可以不用按照贪心策略方法选取而是直接事先装入背包，此时有{1},{2},{3},{4}四个子集情况，对于事先放入{1}和{2}实际上与k=0产生的结果相同，因为他们两个是效益密度值较大的前两位，对于此时k=1时最终的选取结果都是[1,1,0,0]和k=0时无差异。而当事先放入物品3，然后剩下的物品进行贪婪策略选取时，最终的解是[1,0,1,0]效益值为18，当事先放入物品4时，产生的解则为[1,0,0,1]效益值为19。因此此时已经发现产生更好的优化解了，为[1,0,0,1]。 当k=2时，考虑的情况有{1,2},{1,3},{1,4},{2,3},{2,4},{3,4}。因为{3,4}已经超出范围了所以直接排除，剩下的解分别为[1,1,0,0],[1,0,0,1],[0,1,1,0],[0,1,0,1]最终发现最后一种情况即{2,4}会产生更好的效益值为23，因此k=2时最终的优化解为[0,1,0,1]，效益值为23。 综合上面三个解，最终的优化解就是[0,1,0,1]，效益值为23并且经过检验发现此时的组合就是最优解的答案，误差为0，确实在33%以内，而对于k=1是产生的误差为(23-19)/23*100%=17.4%在理论值50%以内。因此k-优化算法确实做到了事先要求的解，他相较于效益密度值贪婪策略更为优秀。 思考：既然如此为什么还要用回溯法和分枝-限界法？ 你一定会有上面这种疑惑，既然k-优化算法已经如此优秀了，只要每次都使用2-优化甚至3-优化算法就已经可以得到误差非常小的贪心解了，在使用回溯法和分枝-限界法不是多此一举吗？实际上这种k-优化算法使用次数非常少，其根本原因是违背了算法的本质目的，算法是尽可能找到一个内在规律然后进行推算选中最优解，而k-优化算法确实在对特殊情况进行枚举分类讨论，对于小问题还好，对于数量级非常大的问题，其方法就非常复杂了，远不如回溯和分枝-限界法的扩展状态空间树方便，并且归根结底k-优化算法还是会产生误差的，对于精确计算，回溯法和分枝-限界法还是更加可信。 构造哈夫曼编码 概念：什么是哈夫曼编码？ 哈夫曼编码是广泛地用于数据文件压缩的十分有效的编码方法。其压缩率通常在20%～90%之间。哈夫曼编码算法用字符在文件中出现的频率表来建立一个用0，1串表示各字符的最优表示方式。给出现频率高的字符较短的编码，出现频率较低的字符以较长的编码，可以大大缩短总码长。例如一个包含100,000个字符的文件，各字符出现频率不同，如下表所示。定长变码需要300,000位，而按表中变长编码方案，文件的总码长为：（45×1+13×3+12×3+16×3+9×4+5×4）×1000=224,000。 这样使用更频繁的字符如a变长码长度更短仅仅为1个位，比用定长码的情况总码长度少了约45%。 思考：哈夫曼编码有什么特点？ 哈夫曼编码中每一个字符的编码都是前缀码，即对于每一个字符规定用0,1串作为其代码，并且要求任一字符的代码都不是其他字符代码的前缀，这种编码就是前缀码。例如a的前缀码为0，那么只要是这种0就一定是a，不会产生歧义。例如001011101就唯一地表示为aabe，不会产生其他歧义字符串。编码的这种前缀性质就会非常利于对一个01串进行解码，并且平均长度也很好计算为： B(T)=Σf(c)dT(c)B(T)=\\Sigma{f(c)dT(c)} B(T)=Σf(c)dT(c) 而哈夫曼编码就是一种是平均码长达到最小的前缀码编码方案。 思考：怎样构造哈夫曼编码？ 哈夫曼编码的构造是使用二叉树构造的，考虑一个问题，越是处于深层的字符其相对应的01串长度也就会更长，而使用频率更频繁的字符其相对应的位数应该越小越好，所以我们很容易就想到了一种贪心法构造哈夫曼编码，即尽量每次选取使用频率更小的字符来当做叶子节点，而频率更大的字符则尽量在树的上层，所以就有了如下的构造方法： 根据n个权值{w1，w2，…，wn}构成n棵二叉树的集合F={T1，T2，…，Tn}，其中每棵二叉树Ti中只有一个带权为wi的根结点，其左右子树均为空。 在F中选取两棵根结点的权值最小的树作为左右子树来构造一棵新的二叉树，且置新的二叉树的根结点的权值为其左、右子树结点的根结点的权值之和。 在F中删除这两棵树，同时将新得到的二叉树加入F中。 重复（2）和（3），直到F中只含一棵树时为止。称这棵树为最优二叉树（或哈夫曼树）。 如果约定将每个节点的左分支表示字符‘0’，右分支表示字符‘1’，则可以把从根节点到某叶子节点的路径上分支字符组成的字符串作为该叶子节点的编码。 哈夫曼树算法是一种以自底向上的方式构造表示最有前缀码的二叉树T。算法以|C|个叶子节点开始，执行|C-1|次的合并运算后产生最终所要求的的树T。相信你也看不懂介绍，直接上例题✍。 对于上面的表格，那个哈夫曼编码是怎么得到的，我们做一次推导： 首先我们将5个字符和其使用次数一次从小到大列出，然后按照贪婪策略，每次选取两个小的合并来当做底层树枝，相对应的他们的01串位数也就相对应的会更长。这里先选取了f和e进行合并，合并后的使用次数为14，然后在观察发现，c和b是使用次数最少的，所以合并c和b,次数为25，此时14是由f和e合并得到的，25是由a和b得到的，每次合并后都要重现从小到大排列，此时还剩下14,16,25,45,我们接下来要合并的是14和16得到30，然后重排列后为25,30,45，合并25和30得55，最后45和55得到根节点，根节点代表所有字符频率之和。最后树就是右下角这个样子，由于每次都是从小到大排序，所以检查是不是左边的节点永远小于右边的节点，是不是上一层的节点永远比下一层的节点权值要大，这样我们就实现了权值大的节点即使用频率多的字符更靠近上层，相对应的其01表示串的位数也就少了，最后按照左0右1编码就得到了a是0，b是101，c是100，d是111，f是1100，e是1101，确实和表中的前缀码一致。 思考：时间复杂度是多少？ 这里的每次从小到大重新排列我们可以采用一种较为巧妙的方法进行选取合并从而不用多次进行排序，那就是使用优先队列，权重越大选取合并优先级就越低。这样每次合并以后的频率插入优先队列Q中就会自动拥有一个被选取的优先级顺序。那么此时唯一会消耗大量时间的就是插入和删除以及n-1次合并的时间了，最终时间复杂度可以控制到O(nlogn)。 拓扑排序 定义：什么是拓扑排序？ 任务的先后顺序可以用有向图来表示，成为AOV（Activity On Vertex)。有向图的顶点代表任务，有向边(i,j)表示先后关系：任务i完成以后才能完成j，即i是j执行的前提。根据这种AOV网络我们要对任务进行排序使得排序序列的先后关系与AOV网定义的先后关系一致。这种根据任务的有向图建立拓扑序列的过程就称为拓扑排序。所以拓扑排序是根据有向图即AOV神经网来进行节点排序。 下图就是一个AOV神经网络图： 1和2入度为零，说明没有前提任务节点，3的入度为1其前提任务节点就是先驱节点1,4入度为3说明其有三个前提任务节点，即需要1,2,3都完成以后才能开始执行任务4，所以其前提任务节点是1,2,3。以此类推。 首先对于每个节点进行逐一检验的方法肯定是行不通的，双重循环时间复杂度过高O(n!)。这里我们采用贪心思想进行拓扑排序。贪心策略从空集开始进行节点选取，每步产生拓扑排序序列中的一个顶点w，那么这个节点w该如何选取呢？ 思考：怎样实现贪心策略？ 在尚不在拓扑排序序列中选择一个节点w，他需要满足的条件是他前面的任务都已经完成了，即其所有先驱节点v都已经在产生的拓扑序列中（或者无先去节点也可以），然后如果满足条件就将其加入到拓扑序列中。所以这个节点的入度一定为0，这样才代表其没有先去节点或者先去节点任务已经完成。 用减节点入度的方法来更新，每次选取一个节点加入拓扑序列中意味着这个任务现在被完成了，那么从这个节点w所连接的后继节点q看来就是他少了一个前提任务，所以前提条件少了一个，对应的就是q入度减1，所以w所连接的后继节点相应的入度减1，当后继节点q的入度变为0时，则意味着他的所有先驱任务节点都已经完成，则他就也像w一样可以加入到拓扑序列中去了。 伪代码 1234567891011121314void topologicalOrder(int *theOeder)&#123; //计算每一个顶点的入度（需要用到邻接矩阵） //将入度为0的节点push到栈中 while(stack!=NULL)&#123; //当栈不为空时，即还有可以执行的任务 //栈内所有节点入度均为0，表示现在都等待执行 //随机任取一个入度为0的节点放入拓扑序列中 //将其后继节点的入度-1 //如果有新的入度为0的节点出现，将其放入栈中 &#125; //如果还有剩余的没进入栈（当然也就没进入拓扑序列)中的节点 //那么他的入度还不为0 //所以有向图内存在环路&#125; 所使用到的邻接矩阵： 有向图带有方向表示的邻接矩阵，由于没有权重路径长度一说，所以相连通就为1，不通就为0即可。至于所说的存在环路的情况： 就像这种情况，各个任务互为先决条件，很明显有问题，是一种悖论，不是题错了就是你写的邻接矩阵出错了。 时间复杂度 这里如果使用的是邻接矩阵那么就为O(n^2)，如果使用的是邻接表，那么时间复杂度仅为O(n+e)，首先无论是哪种初始化一定是O(n)，而计算入度的时候，如果使用的是邻接矩阵，那么需要二重循环所以时间复杂度为O(n^2),而如果使用的是邻接表，那么所用的时间仅为O(n+e)，进出栈(如果没有环路的话),时间复杂度为O(n),对于邻接矩阵，每次修改入度时时间复杂度为O(n)，而使用邻接表时每步修改时间为O(节点w的出度)。所以时间复杂度为最高次项决定所以分别为O(n^2)和O(n+e)。并且有所有节点的出度之和等于有向图的边数。 单源最短路径问题（迪杰斯特拉算法） 任意给一个有向图G，他的每条边都有一个非负的权值a[i][j],路径的长度就是各边的权值之和。单源最短路径问题就是给定一个源节点（即起始点），找出s到图中所有其他节点的最短路径，注意是都从s出发，所以就是找最短路径问题，只不过这次是一次性找到所有s到其他点的最短路径。这个和上面的最短路问题不太一样，原因是他可以中途对比几条从s到终点q的路径然后选出最优路径，当然局部来看还是在每次找最短子路径的贪婪策略。这种题模型经常在实际生活中出现，例如网络中传输数据流时，要消耗网络的带宽和存储资源，使用跳数少的路径节省网络资源等，并且IP路由使用最短路算法（OSPF），因为IP路由表按目的节点索引（查找），所以，OSPF协议就是使用的该算法求出网络中目的节点到任意节点的最短路径。 思考：怎样具体实现迪杰斯特拉算法？ 维护一个集合S，该集合中源节点到其他节点的最短路已知，即记录已经求出的s到其他节点的当下最短路径值，初始化时为空。 从V-S结合中找一节点V，满足源节点到该节点距离最小。 更新V的临界点的到源节点的距离值。 具体实现如下图： 首先有向图如下，我们建立一个索引表Q用来存储中途最短路径值，S用来存储节点，我们以求A为源节点为例，首先S初始化为空，即默认A此时到其他的点距离为∞。 然后寻找A所能直接到达的点并选取最小的距离，这个最小距离肯定是A到最相邻的点的最优值，而其他较大的就有可能会产生更小的最小路径。 此时A与B,C直接相连，且到达C的距离最短仅为3，而到B的距离为10，所以C和A肯定已经是最短距离了，而B则未必，可能存在一条经过C的更短路径可以到达B。至于为什么C一定是与A连接的最短路径了呢？想想也知道，如果不是，那么也就是说可能存在一条经过B的到达C的更短路径，但是A到B就已经10了，所以根本不可能，将B,C两个索引表建立新节点并更新A到这两个节点的当前值10和3，并且将C加入到S中，然后来到C点。 那么接下来看C与B和D,E相连，且值分别为4,8,2，所以相应的A到B，D,E的值分别更新为7,11,5，发现A到B的路径确实变短了，但是此时A到E的路径最短，所以A到E的路径已经是最优的最短路径了。而A-&gt;B,A-&gt;D则可能还会存在更短的路径。先更新邻接表： 此时A到E的距离最短，所以将E加入集合S，并且来到E节点： 此时观察E直接相连的节点有D，所以E到D的距离为9，那么A到D的距离为14（如果要路过E的话）比A-&gt;C-&gt;D要更长，所以不更新D的值，而B的值也未发生变化： 此时有A-&gt;B,A-&gt;D两条路，A-&gt;B更短，所以此时可以确定A-&gt;B的最短路径长度就是7了，即A-&gt;C-&gt;B，然后将B加入到集合S，然后来到节点B。 此时观察B的直接相连节点有D,C，但是B就是从C来的，且已经将C加入到集合S中了，所以只观察为将入到集合S的D节点，发现B到D的路径长度为2，所以A-&gt;D的路径长度为9（如果按照A-&gt;C-&gt;B-&gt;D）的话比11要短，所以更新D的节点，并将D加入到集合S中去。 此时发现所有节点都已经加入到S中去了，所以算法结束，得到了集合S，和一个更新完后的邻接表，那么这两个数据结构有什么作用呢？ 思考：我们从两个数据结构表中能够知道那些信息，尤其是S？ 首先邻接表就不用想了，肯定是记录的是A到其他各个点的最短路径长度，那么S有什么用处呢？我们发现在集合S中距离A越近的点距离也相对应的越短，所以我们通过邻接表和S就可以轻松知道各个点与A节点的定性和定量的最短路径距离了。 小试牛刀：用迪杰斯特拉算法计算下面这两个图的单源最短路径。 1 2 思考：对于没有权重的有向图能否也使用迪杰斯特拉算法？ 实际上可以，这里我们以中途经过的节点数目来表示路径长度。如下图： 这里我们寻找以a为起点的单源最短路径。那么a直接相连的是b,d且路径长度均为1，此时这两个实际上都已经是a到这两个点的最短路径了我们随意选取一个点作为下一步的出发点其实都可以，这里我们以b为例。 此时在b点看来，直接相连的有c,e且均为2，此时a到c和e都已经是最短路径长度了，即a到c和a到e的路径长度均为2。 这里a-&gt;b的路径是最短的，所以接下来我们讨论b点。（即每次都选择已知最短的路径所连接的点） 在d点看来他只与e点相连间距为1，所以a-&gt;d-&gt;e的路径长度也是2并没有改变a-&gt;e的最短路径长度。此时我们还剩两个点c,e可以讨论，因为都是2又已经是已知的最短路径了，这里就接下来讨论c。 发现c也是只与e点相连，并且经过c点到达e点距离为3比a-&gt;b-&gt;e或者a-&gt;d-&gt;e还要更长，所以不改变a-&gt;e的最短路径，什么也不更新，直接将c接入到集合S中，然后此时只剩下了e点，所以接下来讨论e点。 e点与g,i直接相连，并且a-&gt;g和a-&gt;i的距离都是3，所以此时选择两个中的任意一个都可以，所以在这里我们选择g。此时 g连接的有f点，并且a-&gt;f现在已知的最短距离为4，而a-&gt;i仅为3，所以接下来讨论i点。 发现a-&gt;i-&gt;h的距离为4，所以此时f,h任取。我们这里接下里讨论f点，发现f-&gt;h为1，所以a-&gt;f-&gt;h距离为5比a-&gt;i-&gt;h距离还要长，所以不更新a-&gt;h的距离，所以直接加入f点到集合S然后讨论h点，发现所有点都已经走过了，算法结束。 我们发现对于无权值的有向图来说，每次产生的新节点其实距离都是相同的，因为都是加1，所以每次得到的第一个值大概率就已经是最短路径了。 总结 对于迪杰斯特拉算法，首先需要规定的就是有向图的权重值必须为非负的，首先是因为在现实生活中负的权值没有意义也不可能存在，其次对于负权值的情况会出现严重的bug,因为会导致出现反复循环走一种越走路径越短的闭合回路的情况。并且我们发现迪杰斯特拉广泛应用的原因不仅仅是因为其操作简便，思路简单，更重要的是使用贪心法得到的却一定是整体最优路径，即贪心解与最优解无偏差，误差为0。 最小生成树问题 具有n个顶点的连通的无向图G，图的每条边e有一个非负权值c(e)，也称为成本，求有最小成本的生成树。每个生成树刚好具有n-1条边，所以问题是用某种方法选择n-1条边使得他们形成G的最小生成树。我们将采用两种不同的贪心策略选择这n-1条边，这两种贪心策略对用求解最小生成树的两个算法：克鲁斯卡尔(Kruskal’s)算法和普里姆(Prim’s)算法。 克鲁斯卡尔算法 贪心策略，每次都选取权值c(e)最小的且不和前面所选择的边构成回路的边e。上述算法要求按权值从小到大对边排序。如下图演示： 如上面所示，我们每次都尽量先选择权值小的边进行连接，并且要满足和前面的边不构成回路。最后检验时可以看是否是n-1条边。总体来看，非常好理解。并且这种算法同样是贪心解即为整体最优解，证明略。对于该算法，动态产生的子树，需要反复进行union和fond操作，因此使用union-find数据结构（并查集）最合适，初始时为单个顶点的集合，对每条边做两次find找到边的端点所在的集合，如果两个端点在同一个集合（形成回路了）就舍弃该条边，否则就将2个集合合并（union操作）。这样算法复杂度可控制在O（n+eloge)内。 小练习：构造如下图的最小生成树 普里姆算法 普利姆算法也很好理解，简单来说就是一条路走到黑，每次都以选取的下一个节点为起点寻找还可以走的最短的路径，如果只剩一条路可走，那无论权值多大都是走这条路经。如下图演示： 和克鲁斯卡尔算法演示的图一样。 就如上面偶说的那样，它区别于克鲁斯卡尔算法，当选去了1-&gt;6后并没有选择更短的3-&gt;4，而是在6的基础上继续走可以选择更短的路径。虽然与克鲁斯卡尔算法略有区别，但是最终的结果是相同的，都是贪心解等于最优解。 偶图覆盖问题（二分覆盖） 偶图是一个无向图，他的n歌顶点分为了集合A和集合B，且同一集合中任意两个顶点无边相连。A的一个子集A’覆盖集合B当且仅当B中的每一个顶点都至少和A’中的一个顶点相连，覆盖A’的大小用A’所含有的顶点数目表示，我们要寻找最小的覆盖的问题就是偶图覆盖问题。 例如面这道例题：有17个顶点分为两部分，其中上部分为集合A={1,2,3,16,17}，B={4,5,6,7,8,9,10,11,12,13,14,15} 那么很明显覆盖首先需要包括B中的所有顶点，子集A’={1,16,17}就已经覆盖了B中所有的点了，所以这就是B的最小覆盖。而单独来看1覆盖{4,6,7,8,9,13},16覆盖{5,6,8,12,14,15}，17覆盖{4,9,10,11}。那么怎么找到这个最小覆盖呢？ 思考：怎样寻找到最小覆盖？ 很简单，就是使用贪婪策略：每次都选取A中能够覆盖更多的B中还没有被覆盖的顶点的顶点，例如上题中，一开始A’为空集，覆盖了0个B中节点，然后1是覆盖最多剩余节点的顶点{4,6,7,8,9,13}所以讲1加入到集合A’中，此时剩余节点还有{5,10,11,12,14,15},而16是覆盖剩余节点最多的顶点{5,6,8,12,14,15}(一定要注意是剩余节点的个数，已经覆盖过得对结果没有影响)，然后最后是顶点17。 连续背包问题 与0/1背包问题不同的是此时可以连续性的装入，即按比例装入，那么贪婪政策每次都使用更大效益密度的物品装入直至不能再装入物品即可。并且易证得此时贪婪解就是最优解了。 小作业 Questions 用1-优化算法求解以下0/1背包问题，已知：n=8,[16,20,4,15,25,10,5,8],p=[100,200,50,90,175,50,20,60],c=70。 写出C语言代码。 Answers 代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;bits/stdc++.h&gt;using namespace std;//自定义一个物品结构体struct Goods&#123; //一件商品属性 //花费 double cost; //幸福感 long long int happy; //效益密度值 double p;&#125;;bool cmp(Goods a, Goods b)&#123; //按效益密度值排序 return a.p &gt; b.p;&#125;int main()&#123; int t; cin &gt;&gt; t; while (t--) &#123; int money, num; cin &gt;&gt; money &gt;&gt; num; Goods goods[num]; for (int i = 0; i &lt; num; i++) &#123; cin &gt;&gt; goods[i].cost; //存价格 goods[i].cost *= 0.9; //更新价格为9折 &#125; for (int i = 0; i &lt; num; i++) &#123; //存开心程度 cin &gt;&gt; goods[i].happy; //计算开心密度并存储 goods[i].p = goods[i].happy / goods[i].cost; &#125; //按效益密度值排序 sort(goods, goods + num, cmp); long long int ans = 0; /*for (int i = 0; i &lt; num; i++) &#123; if (money-goods[i].cost &gt;= 0) &#123; ans += goods[i].happy;//能装就装 money-=goods[i].cost; &#125; else &#123; break;//不装退出 &#125; &#125;*/ //1-优化才能得到正确答案 for (int i = 0; i &lt; num; i++) &#123; long long int tmp = 0; int cnt = money; tmp += goods[i].happy; cnt -= goods[i].cost; for (int j = 0; j &lt; num; j++) &#123; if ((j != i) &amp;&amp; (cnt - goods[j].cost &gt;= 0)) &#123; tmp += goods[j].happy; cnt -= goods[j].cost; &#125; &#125; if (tmp &gt; ans) &#123; ans = tmp; &#125; &#125; cout &lt;&lt; ans &lt;&lt; endl; //输出结果 &#125; return 0;&#125; 总结 那么本次贪心思想算法分享就到此结束了，我们通过多个例题的学习对于贪婪算法有了更近一步的了解，最重要的是掌握哈夫曼树，0/1背包，最短路和单源最短路径以及两种最小生成树算法的理解与应用，当然拓扑排序和AOV神经网略也需要了解。那么希望你能有所收获😮。"},{"title":"信号量与经典同步问题(1)","path":"/wiki/操作系统笔记/信号量与经典同步问题(1)/index.html","content":"信号量机制 在信号量机制中一个信号量代表一种资源，信号量的值就是这种资源剩余的值，如果信号量的值小于0，说明此时有进程在等待这种资源。P(s)代表申请一个资源s,如果资源不够就阻塞等待，V(s)代表释放一个资源s,如果有进程在等待该资源，则唤醒一个进程。 信号量机制实现进程互斥 首先我们先看一下信号量的结构体 12345//数值型信号量的定义typedef struct &#123; int value;//剩余资源数 struct process *L;//等待队列&#125;semaphore 一般我们如果要借用信号量机制实现进程间的互斥，那么首先毫无疑问需要将并发进程间的关键活动划定为临界区，如各进程对临界资源打印机的访问的代码就应该划分到临界区。然后我们这里初始化一个新的信号量mutex（代表一种新的资源）初始化为1，则进入区P(mutex)就是申请资源，退出区的V(mutex)就是释放资源。所以我们对于不同的临界资源都需要设置各自对应的互斥信号量进行判断。并且P,V操作必须成对出现，缺少P就不能保证临界资源的互斥访问，而缺少V就会导致资源永不释放，等待的进程一直永不被唤醒造成饥饿现象。这样当mutex设置为1时每次都保证了只会有一个进程访问临界资源并且做到了进程互斥的四大原则（“空闲让进”，“忙则等待”，“有限等待”，“让权等待”）。如下： 这样P1,P2之间就通过mutex1和P,V操作实现了并发进行间的互斥，而P3,P4之间通过mutex2和P,V操作也实现了并发进行间的互斥。代码如下： 12345678910111213141516171819202122232425262728semaphore mutex2=1;//初始化信号量semaphore mutex1=2;//初始化信号量P1()&#123; ... P(mutex1)//使用临界资源前需要加锁 critical section;//临界区 V(mutex1);&#125;P2()&#123; ... P(mutex1)//使用临界资源前需要加锁 critical section;//临界区 V(mutex1);&#125;P3()&#123; ... P(mutex2)//使用临界资源前需要加锁 critical section;//临界区 V(mutex2);&#125;P4()&#123; ... P(mutex2)//使用临界资源前需要加锁 critical section;//临界区 V(mutex2);&#125; 实际上上面这种方法也就是PV互斥锁实现进程互斥，这种方法无疑是最优解他做到了四个原则。 信号量实现进程同步 我们前面学到了进程同步它是一种直接限制关系，即一般发生在某个进程P2必须等待进程P1发生以后才可以发生，这种存在先后关系的并发运行就存在进程同步问题。那么这种让本来异步并发的进程互相配合，有序推进就需要信号量机制加以约数实现。 实现方法如下： 分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作（或两句代码） 设置同步信号量S，初始化为0 在“前操作”之后执行V(s) 在“后操作”之前执行P(s) 从上面的操作中我们也可以看出P,V操作一定还是成对出现的但是出现顺序可以发生改变，对于进程互斥是P前V后并且每个进程同时拥有P,V操作，而对于进程同步一般是V前P后，且每个进程只拥有P或者V。 代码如下： 我们还是要先声明信号量但是此时一定要注意是初始化为0： 1semaphore s=0 这样我们可以理解为信号量s代表“某种资源”，刚开始是没有的，而P2需要这种资源才能继续执行，所以他需要等待P1执行完P操作后s++，此时P2才可以继续执行，这种P,V操作就完美实现了进程间的同步。 即如果先执行到了进程1的V(s)操作，那么s++,之后当执行到进程2的P(s)操作时，由于s=1满足条件表示有可用资源，会执行s–，s的值会变回0同时p2进程不会执行block原语而是继续向后执行代码4。 如果先执行到了进程2的P(s)操作，由于s=0,s–后s=-1，此时表示没有可用资源，前面也提到过了当信号量&lt;0表示有进程等待，所以此时进程2执行block原语主动请求阻塞等待。之后当执行到P1的V(s)后s++,使s变回0同时前面也提到过当执行V操作对信号量++的同时还会检查等待队列是够有阻塞进程，如果有就会执行wakeup原语唤醒等待进程，这样P2进程就可以继续执行了。 信号量机制实现前驱关系 进程P1有句代码S1,P2有句代码S2，P3有句代码S3,…，P6有句代码S6，这些代码需要按照如下图的先后顺序执行，其实仔细看对于每一对前驱关系都对应一个信号量一组P,V操作所以前驱关系的子问题就是进程同步。因此对于前驱关系(具有多组进程同步关系的问题)需要为每一对前驱关系都设置一个同步信号量，在“前操作”之后设置相对应的V操作(由于信号量不同，V操作并不相同)同时对于“后操作”之前对应的同步信号量也需要执行P操作(由于信号量的不同，P操作也不相同)。 各进程之间的代码如下： 我们可以画出树状结构来更好的看出前驱关系如下： 总结 生产者-消费者问题 我们首先看一下问题描述 问题描述 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品都会放入缓冲区，而消费者进程每次从缓冲区都取出一个产品使用(这里的&quot;产品&quot;就是一种数据)。所以生产者和消费者共享一个初始为空，大小为n的缓冲区，只有缓冲区没满时生产者才能把产品放入缓冲区，否则就要阻塞等待。只有缓冲区不空时消费者才能从产品中取出产品，否则必须阻塞等待。并且缓冲区是临界资源，需要各进程互斥的访问。 问题分析 我们对于这种问题很容易就能想到刚刚介绍的PV操作实现同步互斥关系。一般对于PV操作解决问题就是分析出题目中的各个进程之间的关系，然后画图确定P,V操作的大致顺序，同时设置信号量(一般都是数值型)进程互斥设置为1就行，而对于同步信号量的处置要根据对应资源的初始值设置。对于生产/消费者问题我们分析一下题目要求： 缓冲区没空的时候消费者可以消费(同步关系) 缓冲区没满的是够生产者才可以生产(同步关系) 进程之前（即生产者-消费者，消费者-消费者）之间都需要互斥访问临界资源缓冲区(互斥关系) 所以我们需要设置三个信号量如下： 1234semaphore mutex=1;//互斥信号量，实现对缓冲区的互斥访问semaphore empty=n;//同步信号量，表示空闲缓冲区的数量，当&lt;=0表示缓冲区满semaphore full=0;//同步信号量，表示产品的数量即非空缓冲区的数量当&lt;=N时表示缓冲区没满 那么我们可以用如下代码实现： 首先无论是哪个进程进入临界资源都要新进行mutex互斥锁判断，然后对于生产者和消费者之间的同步关系分别具有一个P,V同步锁的一部分。一定要记住P操作每次都–，V操作每次都++同时V操作每次还会进行唤醒等待进程的操作。所以一定要理解并不是每次产品者都把缓冲区用产品填满以后才唤醒消费者，而是当生产出了产品就可以唤醒等待的消费者了同时也并不是消费者每次都用空了缓冲区才唤醒生产者，而是只要缓冲区没满就会唤醒生产者，即边生产边消费的现象出现，但是最终边生产边消费的现象会趋于一个稳态： 生产的速度和吃的速度整体看来相当，那么缓冲区既不空也不满整体上看来生产者和消费者都有并发互斥访问临界资源 生产的速度整体上比消费的速度快，最终缓冲区满了以后生产者沉睡并且直至缓冲区再次没满的情况出现前一直沉睡直至消费者消费了产品后再次唤醒生产者 生产的速度整体上慢于消费的速度，那么缓冲区空了以后消费者全部沉睡等待，当生产者再次生产出产品时就会再次唤醒消费者 思考：相邻的P操作能够更改顺序？ 即如下图： 临界区访问互斥锁的P操作和同步信号量检验的P操作进行了交换，此时是先检验能否进入临界资源在检验能否生产或者消费的情况。 我们假设此时缓冲区已经满了，即empty=0,full=n。此时生产者又生产了一个产品按照① 使mutex变为0，然后在执行②，由于此时已经没有空闲缓冲区了，所以生产者被阻塞沉睡，由于生产者阻塞，因此切换回消费者进程，消费者进程执行③，由于mutex=0即生产者还没有释放对临界资源的&quot;锁&quot;，所以生产者就一直沉睡等待与此用时生产者也在沉睡等待消费者消费产品造成了&quot;死锁&quot;现象的出现。 同样的假设缓冲区现在没有产品，即empty=n,full=0。那么此时消费者进入临界区想取出一个产品，此时mutex=0，发现没有产品可以取出了，所以阻塞沉睡切换到生产者进程生产者生产了产品想放入临街资源缓冲区中，但是此时mutex=0消费者还没有释放&quot;锁&quot;所以生产者只能也沉睡等待消费者出来在放入产品，而此时消费者也在等待生产者放入产品也造成了&quot;死锁&quot;现象。 所以我们可以总结出来无论是哪个进程实现互斥的P操作必须放在实现同步的P操作之后。 思考：上图右边的问题：能否把使用产品放到PV操作之前 即如下图： 12345678910consumer()&#123;\twhile(1)&#123; //使用产品 P(mutex); P(full); //从缓冲区取产品 V(mutex); V(empty); &#125;&#125; 想也不要想这种情况会造成一个很离谱的情况就是此时如果缓冲区已但是消费者却可以不经过检验继续先使用产品，但是此时缓冲区已经没产品了他消费的产品从哪里来呢？ 思考：相邻的V操作能够更改顺序？ 事实证明，V操作之间是可以更改顺序的，此时不会造成&quot;死锁&quot;现象仍可以正常执行。 多生产者-多消费者问题 问题描述 桌子上有一只盘子，每次只能向其中放一个水果，爸爸专向盘子中放苹果，妈妈专向盘子放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果，只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果，仅当盘子中有自己需要的水果，儿子或者女儿才可以从盘子中取水果。 问题分析 我们发现有如下几个关系： 盘子需要互斥访问(互斥关系) 只有盘子中为苹果时女儿才取(同步关系) 只有盘子中为橘子时儿子才取(同步关系) 只有盘子为空时爸爸或者妈妈才可以放水果(同步关系) 所以我们第一想法就是设置4个信号量如下： 1234semaphore mutex=1;//实现盘子互斥访问的信号量semaphore apple=0;//盘子中有几个苹果&lt;=0为无苹果semaphore orange=0;//盘子中有几个橘子&lt;=0为无橘子semaphore plate=1;//盘子中还可以放几个水果&lt;=0表示不可以放水果 那么4个进程之间的代码实现如下： 很明显确实实现了题目要求。 思考：可不可以不要互斥信号量？ 即plate互斥信号量删除不用能否满足要求，如下： 我们发现也没有太大的问题，因为此时apple,orange,plate三个信号量永远只有一个会是1也就说明每次都只会有一个进程是非阻塞状态，所以也就只有他可以访问临界区完全不可能出现多个进程用时访问临界资源的情况，所以完全不需要互斥信号量mutex。所以这种方法更好，但是注意仅适用于plate=1的情况，如果一次性可以放入2个或多个水果，即缓冲区容量&gt;1的情况就必须使用mutex互斥信号量了。 思考：为什么缓冲区容量&gt;1时必须使用互斥信号量mutex? 因为此时假设缓冲区容量为2，即盘子可以放2个水果，那么此时假设父亲P(plate)可以访问盘子(此时plate初始值为2，一次P操作plate–=1)，母亲此时也进行P(plate)也可以访问盘子(因为此时plate&gt;0还可以通过检验)此时就出现了两个进程同时访问缓冲区的情况，有可能导致两个进程写入的缓冲区数据相互覆盖。因此当缓冲区大于1的情况时就必须专门设置一个互斥信号量mutex来实现互斥访问了。 总结 对于无论是生产者-消费者问题还是多生产者-多消费者问题最好都加上mutex锁以避免特殊情况出现。"},{"title":"处理机调度","path":"/wiki/操作系统笔记/处理机调度/index.html","content":"处理机调度 基本概念 我们前面说过处理机cpu空闲时会在就绪态进程中挑选一个上cpu执行，这就是调度。当有一堆任务要处理，但由于资源有限，这些事情没有办法同时处理，这就需要某种规则来决定处理这些任务的顺序，这就是“调度”索要研究的问题。在多道程序系统中，进程的数量往往是多于处理机的个数的，这样不可能同时并行地处理各个进程。处理机调度，就是从就绪队列中按照一定的算法选择一个进程并将处理机分配给他使用，以实现进程的并发执行。 调度的三个层次 高级调度（作业调度） 由于内存的空间有限，有时无法将用户提交的所有作业全部放入内存中，因此就需要某种规则来决定将作业调入内存的顺序。高级调度（也叫做作业调度）就是按一定的原则从外存（硬盘等）上处于后备队列的作业中挑选一个（或多个）作业，给他们分配内存等必要资源，一旦进入内存就说明次进程被创建并处于了就绪态，所以需要操作系统创建并分配给其一个PCB，以使他们获得了竞争处理机的权利。 所以高级调度是外存（也叫辅存）与内存之间的调度。每个作业只调入一次，作业调入时会建立相应的PCB，作业调出时才撤销PCB，这也就说明当一个进程处于阻塞态下cpu后仍会存储在内存中随时准备上cpu，而只有当是终止态时才会从内存中取出然后作业调出。高级调度主要是指调入的问题，因为只有调入的时机需要操作系统确定，但调出的时机必然是作业运行结束才掉出。 中级调度（内存调度） 引入了虚拟存储技术后我们知道每次并不是将进程全部的数据放入内存，而是将常用的放入，而可将暂时不能运行的进程调至外存等待，等他重新具备了运行条件且内存又稍有空闲时，再重新调入内存，这么做的目的就是为了提高内存利用率和系统的吞吐量。暂时调到外存等待的进程状态为挂起状态（不是阻塞态），值得注意的是，PCB并不会一起调到外存，而是会常驻在内存中。PCB会记录进程数据在外存中存放的位置，进程状态等信息，操作系统通过内存中的PCB来保持对各个进程的监控和管理，被挂起的进程PCB会被放到挂起队列中。 中级调度（内存调度）就是要决定哪个处于挂起状态的进程重新调入内存，一个进程可能会被多次调出，调入内存，因此中级调度发生的频率要比高级调度更高。 思考：挂起状态在状态转换模型中的位置以及他和阻塞态的区别？ 暂时调到外存等待的进程状态为挂起状态，挂起态又可以进一步分为就绪挂起和阻塞挂起两种状态。所以加上后5状态模型-&gt;7状态模型 低级调度（进程调度） 低级调度（进程调度）其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给他（这个会涉及到很多种调度算法，后面会详细讲解）。进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度，进程调度的频率很高，一般几十毫秒一次。 思考：三种调度的联系与对比 调度名称 要做什么 发生地点 发生频率 对进程状态的影响 高级调度(作业调度) 按照某种规则，从后备队列中选择合适的作业将其调入内存，并为其创建进程 外存-&gt;内存（面向作业） 最低 无-&gt;创建态-&gt;就绪态 中级调度（内存调度） 按照某种规则，从挂起队列中选择合适的进程将其数据调回内存 外存-&gt;内存（面向进程） 中等 挂起态-&gt;就绪态（阻塞挂起-&gt;阻塞态） 低级调度（进程调度） 按照某种规则，从就绪队列中选择一个进程为其分配处理机 内存-&gt;cpu 最高 就绪态-&gt;运行态 总结 进程调度 这里我们详细展开对低级调度或者叫进程调度的详细研究。 进程调度的时机 进程调度就是按照某种算法从就绪队列中选择一个进程为其分配处理机。一般进程调度会发生在以下两种情况，当然，在某些系统中只允许进程主动放弃处理机（即只有上半部分功能），当然也有的系统除了可以进程主动放弃处理机以外，当有更紧急的任务需要处理时，也会强行剥夺该进程的处理机使用权给更加紧急重要的进程使用（被动放弃）。 一般是发生在运行态转换为其他状态，cpu空闲时发生。但是在以下的情况下一般进程调度很难发生 一定要注意第二点，是进程在操作系统内核程序临界区而不是进程自身处于临界区。当进程处于自身临界区时是可以进行处理机调度的。 思考：什么是临界区？什么是临界资源？ 临界资源是一个时间段内只允许一个进程使用的资源，各进程需要互斥地访问临界资源。而临界区就是访问临界资源的那段代码。所以内核程序临界区就是一般用来访问某种内核数据结构的代码，比如访问进程的就绪队列（由个就绪进程的PCB组成）。 之所以此时一般不发生进程调度，是因为如果内核程序还没退出临界区（即临界资源还没解锁） 就进行进程调度，但是进程调度相关的程序也需要访问就绪队列， 但此时就绪队列被锁住了，因此又无法顺利进行进程调度，同时，内核程序临界区访问的临界资源如果不尽快释放的话，极有可能影响到操作系统内核的其他管理工作。因此在访问内核程序临界区期间不能进行调度与切换。但是当在进程处于临界区时是可以进行处理机调度的，例如：在打印机打印完成之前，进程一直处于临界区内，临界资源不会解锁。但打印机又是慢速设备，此时如果一直不允许进程调度的话就会导致CPU一直空闲内核程序临界区访问的临界资源如果不尽快释放的话，极有可能影响到操作系统内核的其他管理工作。因此在访问内核程序临界区期间不能进行调度与切换而普通临界区访问的临界资源不会直接影响操作系统内核的管理工作。因此在访问普通临界区时是可以进行调度和切换的。 进程调度的方式 非剥夺调度方式 又称为非抢占方式，即只允许进程主动放弃处理机（一般是通过系统调用陷入函数发送请求中断该进程），这种方式，在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，知道该进程结束或者主动要求进入阻塞态。这种方式明显不合理，但是实现简单，系统开销小但是无法及时处理紧急任务，一般适用于早期的批处理系统。 剥夺调度方式 又称为抢占方式，当一个进程正在处理机上执行时，如果有一个更重要或者更加紧迫的进程需要使用处理机，则操作系统会立即暂停正在执行的进程，将处理机分配给更加紧迫重要的进程。这种方式优先处理更紧急的进程，也可以实现让各进程按时间片流转执行的功能（通过时钟中断）。适用于分时操作系统，实时操作系统。 进程的切换与过程 思考：狭义的进程调度和进程切换的区别？ 狭义的进程调度就是指从一个就绪队列中选出一个要运行的已就绪的进程（这个进程可以是刚刚被暂停执行的进程或者也可以是另一个进程，而后一种情况就需要进程切换）即仅仅是选择，进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。 广义的进程调度包括选选择一个进程和进程切换两个步骤，进程的切换过程主要完成了： 对原来运行进程各种数据的保存 对新的进程各种数据的恢复（如操作系统根据PCB对程序计数器，程序状态字寄存器PSW，各种段寄存器等处理机现场信息） 所以进程切换是有代价的，因此如果过于频繁的进行进程调度，切换必然会导致整个系统的效率降低，使得系统花费大量时间在进程切换上，而真正用于执行进程的时间减少。 总结 调度算法的评价指标 cpu利用率 因为早期的cpu造价昂贵（说实话现在对于学生来说也得吃好几天土。。），因此人们希望cpu尽可能的多工作，所以就引出了cpu利用率–用来描述cpu忙碌的时间占总时间的比例。 利用率=忙碌的时间/总时间利用率=忙碌的时间/总时间 利用率=忙碌的时间/总时间 一般设备的利用率指的都是cpu利用率，如：某计算机只支持单道程序（单核），某个作业刚开始需要在CPU上运行5秒， 再用打印机打印输出5秒，之后再执行5秒，才能结束。在此过程中， CPU利用率、打印机利用率分别是多少？ 很简单的计算：cpu利用率=5+5/5+5+5=66.6%，同理打印机利用率=33.3%。通常会考察多道程序并发执行的情况，可以使用“甘特图”来辅助计算。 思考：什么是甘特图？ 就是横道图、条状图。其通过条状图来显示项目、进度和其他时间相关的系统进展的内在关系随着时间进展的情况。类似于下图： 系统吞吐量 对于计算机来说，希望能够尽可能用少的时间处理完尽可能多的作业，这就是系统吞吐量–单位时间内完成的作业的数量。 系统吞吐量=总共完成了多少道作业/总共花了多少时间系统吞吐量=总共完成了多少道作业/总共花了多少时间 系统吞吐量=总共完成了多少道作业/总共花了多少时间 例如：某计算机系统处理完10道作业，共花费100秒，则系统吞吐量为？ 10/100=0.1道/秒。 周转时间 对于计算机的用户来说，他最关心的就是自己的作业从提交（注意不是开始运行）到完成花费的时间。周转时间就是指从作业被提交给系统开始（一般是双击应用程序开始）到作业完成为止的这段时间间隔。一般周转时间由四部分组成：作业在外存后备队列上等待作业调度（高级调度）的时间、进程在就绪队列上等待进程调度（低级调度）的时间，进程在cpu上运行的时间、进程等待I/O操作完成（一半是阻塞态或者挂起态）的时间。后三个在一个作业的整个执行过程中，可能发生多次。 （作业）周转时间=作业完成时间−作业提交时间（作业）周转时间=作业完成时间-作业提交时间 （作业）周转时间=作业完成时间−作业提交时间 上面的周转时间是指对于用户来说更加关心自己的单个作业的周转时间，而对于整个操作系统来说，更关系的是系统自身的整体表现即周转时间的平均值。 平均周转时间=各作业周转时间之和/作业数量平均周转时间=各作业周转时间之和/作业数量 平均周转时间=各作业周转时间之和/作业数量 带权周转时间 因为有的作业运行时间长，有的作业运行时间短，因此在周转时间相同的情况下，运行时间不同的作业给用户的感受也是不一样的。可能有的作业虽然运行时间长会导致平均周转时间更大，但是其对用户产生的满意度更高，所以不能操作系统不能仅仅用平均周转时间来衡量，如果只追求平均周转时间短，那岂不是每次都会尽量做运行时间短的任务，但是可能运行时间更长的大型主机游戏对用户的满意度提升更高也就更主要。所以这里引出一个新的概念–带权周转时间。 带权周转时间=作业周转时间/作业实际运行的时间带权周转时间=作业周转时间/作业实际运行的时间 带权周转时间=作业周转时间/作业实际运行的时间 因为一作业周转时间还包括等待时间，所以带权周转时间必然&gt;=1，但是等待时间肯定是越小越好，所以操作系统需要尽量使带权周转时间和周转时间都是越小越好。 平均带权周转时间 当然肯定也会再引进一个平均带权周转时间的概念 平均带权周转时间=各作业的带权周转时间之和/作业数平均带权周转时间=各作业的带权周转时间之和/作业数 平均带权周转时间=各作业的带权周转时间之和/作业数 思考：周转时间和带权周转时间的关系？ 对于周转时间相同的两个作业，实际运行时间更长的作业在相同时间内被服务的时间肯定更多，相应的带权周转时间就更小，用户满意度更高。对于实际运行时间相同的两个作业，周转时间更短的带权周转时间更小，等待时间更短，用户满意度越高。 等待时间 计算机的用户希望自己的作业尽可能少的等待处理机，等待时间就是指进程（或作业）处于等待处理机状态时间（即处于就绪态）之和，等待的时间越长，带权周转时间越大，用户满意度越低。 对于进程来说，等待时间就是指进程建立后等待被服务的时间，在等待/O完成的期间其实进程也是在被服务的，所以不计入等待时间。对于作业来说，不仅要考虑建立进程后的等待时间，还要加上作业在外存后备队列中等待高级调度的时间。 一个作业总共需要被cpu服务多久，被I/O设备服务多久一般是确定不变的，因此调度算法其实只会影响进程/作业的等待时间，当然，和前面的指标类似，也有“平均等待时间”来评价整体性能的。 响应时间 对于计算机用户来说，会希望自己的提交的请求（比如通过键盘输入一个调试指令）尽早地开始被系统服务、回应，响应时间就是指从用户提交到首次产生相应的时间。"},{"title":"基本页式存储管理","path":"/wiki/操作系统笔记/基本页式存储管理/index.html","content":"基本地址变换机构 本节还是讲解基本页式存储管理，在上一节中我们学习了页式存储的地址变换方法，这里我们来理解基本地址变换机构（用于实现逻辑地址到物理地址转换的一组硬件机构）的原理和流程。 页表寄存器 基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。通常我们要设置一个页表寄存器（PTR）存放页表在内存中的起始地址F和页表长度M。这样我们才可以找到页表，进程未执行时，页表的起始地址和页表长度放在进程控制块PCB中，当进程被调度室，操作系统内核会把他们放到页表寄存器。 地址变换过程 我们现在已图示的方法演示，注意这里页面大小是2的整数幂，设页面大小为L，逻辑地址A到物理地址E的变换过程如下： 其实前面都讲过了，这里只是演示一下借助页表寄存器具体的转换流程。理解后不需要死记硬背。这里我们来练习一下：假设页面大小为1KB，页号2对应的内存块号b=8，将逻辑地址A=2500转换为物理地址E。相当于告诉了我们以下有效信息： 系统按字节寻址 页内偏移量占地址的10位 页号2对应页框8 那么我们首先计算页号=2500/1024=2,页内偏移为2500%1024=452。所以物理地址实际上就已经出来了是8*1024+452=8644。 所以在分页存储管理的系统中，只要确定了每个页面的大小，逻辑地址结构就可以啦，因此，页式管理中地址是一维的。即只要给出一个逻辑地址系统就可以自动地算出页号、页内偏移量两个部分，并不需要显示的告诉系统这个逻辑地址中，页内偏移量占多少位。 页表项大小的深究 我们知道页表项所占字节大小是根据最大页号所占的位数确定的并且每个页表项的长度是相同的，页号是“隐含”的。前面我们讲过一个例题：物理内存为4GB，页面大小4KB，我们最终算出来页表项至少要占3个字节也就是24bit。但是实际上一般我们是让页表项占4个字节，即即使我们一直页表项为20bit，3字节就已经可以表示了我们还是宁愿在让他多占一个字节为4字节。 思考：为什么要这样做，有什么意义？ 我们知道页表项会按顺序连续地存放在内存中。那么如果页表在内存中的存放起始地址为X，那么M号页对应的页表项是存放在内存地址为X+3*M的。但是如果此时一个页面大小为4KB，那么每个页框都可以存放4096/3=1365个页表项（因为页表存在内存中，那么显然页表也是按页式存储的，所以页表项也是存在页框中的，只不过这几个页框会相邻这样就实现了连续存储了），但是这个页框还会剩余4096%3=1B页内碎片。这其实内部碎片大小是可以忽略的，但是此时就会导致X+3*M公式不适用了，即整体看来页表项不再是连续存储的了，而是每1365个页表项就间隔1B这可很难受。如下： 所以此时我们发现如果每个页表项按4B存储，那么一个页框就可以放4096/4=1024个页表项，并且刚刚好没有内部页内碎片，这样整体看来页表项就还是连续存储的也就说明此时公式X+3*M是可以适用的，所以明显4B更好，即使这样一个页框所存储的页表项就少了但是不差这一点空间。但是我们要注意不是每次都是4个字节都是刚刚好，根据页框大小的不同我们要动态更新但是原则上就是每次都要使得页面恰好可以装得下整数个页表项。 总结 具有快表的地址变换机构 实际上就是一种在基本地址变换机构的改进版本使得查询速率更快了。 什么是快表（TLB） 快表，又称联想寄存器（TLB,translation lookaside buffer)，是一种访问速度比内存快很多的高速缓存（注意TLB不是内存），用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表（前面说过页表存放在内存中）称为慢表。 地址变换过程（引入快表） 一般访问快表TLB只需要1微秒，而访问内存需要100微秒。现在我们同样以图示演示一下用快表寻找（0,0）（0,4）（0,8）这几个逻辑地址。 我们发现和之前的过程不相同的是在得到页号后不是立刻取内存慢表中查找对应的内存块号，而是先在TLB寻找有没有最近刚刚查找过此页表项，如果有那么就可以直接命中知道内存块号了，这样就加速了查找速度，但是前提是TLB中得有即最近查找过这个表，如果没有那么还是需要去慢表中查找。 思考：两种查找方法的本质区别？ 速度不同那是肯定地了，还有就是访问内存单元的次数也是不同的，对于直接TLB命中的，只需要一次内存单元访问即得到物理地址后访问内存中的存储数据的单元，而如果没有在TLB中命中，那么还需要额外在进行一次在内存中的慢表中查询页表项得到物理块号，所以需要两次内存的访问，当然如果这次未命中，那么查询完此次页表项后会将这个页表项的副本加入到TLB中以便下一次再查找这个页表项时可以命中快速查询。 思考：可以提速多少？ 我们知道由于查询快表的速度比查询页表的速度快很多，所以只要尽可能多的快命中，就可以节省很多时间。由局部性原理（即CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中）一般来说快表的命中率可以达到90%以上。我们以一道例题来计算： 某系统使用基本分页存储管理，并采用了具有快表的基本地址变换机构，访问一次快表耗时1微秒，访问一次内存耗时100微秒。如果快表的命中率为90%，那么访问一个逻辑地址的平均耗时时间为多少？ （1+100）*0.9+（1+100+100）*0.1=111微秒 对于上面的计算可不要轻视，一定要理解透彻，前面是快表命中，需要一次查询快表的时间1微秒+一次内存访问时间（查询数据）100微秒，而对于未命中时也是查询了一次快表1微秒+两次内存访问时间200微秒（一次慢表查询，一次数据访问）。 思考：能否进一步提速？ 可以，对于某些系统来说支持快表和慢表同时查找即两个搜索同时进行，谁先找到就用谁，这样快表找到的时间还是101微秒，但是慢表查询就是200微秒了（因为不查找快表了）这样计算一个逻辑地址平均查找时间为110.9微秒。而如果不采用快表，那么查找一个逻辑地址所用的平均时间为200微秒。显然引入快表以后，访问一个逻辑地址的速度快了一倍。 这里对于两种查询快表的方式进行对比： 思考：如果把所有页表全部放在TLB那么岂不是更快？ 显然不可能，TLB造价高昂，肯定是容量有限不能容下所有页表，所以这种想法目前为止还不可能实现，但是这样就会出现一个问题，当TLB满了以后再添加新的页表项副本时就需要先淘汰一些页表项，这就涉及到了淘汰谁的问题，这里也大有讲究有许多置换算法后面细讲。 局部性原理 时间局部性原理：如果执行了程序的某条指令，那么不久后这条指令很有可能会再次执行，如果某个数据被访问过，那么不久之后这个数据很有可能会再次被访问。（因为程序中存在大量的循环） 空间局部性原理：一旦程序访问了某个存储单元，在不久之后其附近的存储单元也很有可能再次被访问。（因为许多数据在内存中都是连续存放的） 所以对于上节介绍的无快表的基地址变换机构中，每次访问一个逻辑地址，都需要查询内存中的页表。由于局部性原理，可能很多次查到的都是同一个页表项。 总结： 这里我们在学习了机组原理后知道有一个和TLB非常类似的机构叫做Cache实际上两者是由区别的：TLB中只有页表项的副本，而普通Cache中可能会有其他各种数据的副本。但是解决问题的思路是类似的，实战请参考：缓存Cache实验 两级页表 单级页表存在的问题 我们以一个例题为例：某计算即系统按字节寻址，支持32位的逻辑地址，采用分页存储管理，页面大小为4KB，页表项长度为4B。 那么4KB=2^12B，因此页内地址要用12位表示，所以剩余的20位表示页号。因此，该系统中用户进程最多有2^20页。相应的，一个进程的页表，最多会有2^20=1M=1,048,576个页表项，所以一个页表最大需要2^20*4B=2^22B=4M，共需要2^22/2^12=2^10个页框存储该页表。即需要专门给进程分配1024个连续的页框来存放它的页表。 注意：页表的存储方式！ 这里我还是想再谈一谈页表的存储方式，虽然我们知道按照分页存储，数据是可以离散存放的，但是对于页表这一特殊的数据结构在分页内存中存放时还是要连续放的，所以这就要求页框必须是连续的，并且为了地址好查询即X+4*M还尽量要求页框能够放入整数个页表项。 思考：上面的单级页表存储有什么问题？ 页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框 没有必要让整个页表常驻内存，因为局部性原理进程可能一般在一个时间段内只会访问几个特定的相邻的页面。 所以我们想把页表再分页并离散存储，然后在建立一张页表记录各个部分的存放位置，称为页目录表，或称外层页表，或称顶层页表。这就是两级页表甚至多级页表的由来。 两级页表的原理、地址结构 我们先来看一下单机页表时怎么存储的，此时将页表分为了1024个部分即1024个连续页框，每个页框里有1024个页表项如下： 现在我们将这1024个部分也离散存放然后建立一张表格来记录各部分所存储的位置。如下： 此时一级页号（页目录号）有1024项记录的是1024个部分所存储的页框号，然后二级页号对应的是某个页表中的页号（即页号），最后12位还是页内偏移量。例如此时 此时我们发现实际上空间并没有变大，还是只能存储2^20页，但是此时可以不用连续存储了并且最终的计算还是满足X+4*M的公式。但是此时内存里的分布就比较复杂了，原先是某一连续区间里存放的全是页表（里面放的是页表项），然后另外的地方存储着数据单元，但是现在3号存放的是页表（里面对应的是页表项）但是2号页框里面存储的就是数据了，所以数据存储和页表存储夹杂在一起了。并且分成二级发现无论是哪个页表都是最大为1023的数不会再出现1048575这么大的数了就是因为两级导致的拆分。相当于原先的0~1048575的一张大表变成了1024个小页表了每个页表时0~1023并且每个小页表有了编号为0#~1023#。 现在还没有解决页表常驻的问题，所以我们还需要在页目录中添加一栏状态标志位表示此时i#页表是否在内存中如下： 只有在需要访问i#页表时才放入到内存中（虚拟存储技术），当然页目录肯定是得一直在内存中的。如果想访问的页面不在内存中，就是缺页中断了（内中断/异常：自发指令触发，在cpu中发出中断信号）然后将目标页面从外村调入内存（此时不能说是中级调度，因为不是挂起进程进入调入内存而是缺的页表调入）。 思考：之前为什么说当缺页率高时说明内存紧张了？ 毕竟内存有限，如果内存很小时那么每次调入缺的页表同时还需要调出某些页表腾地方，那么老缺页中断就说明没有足够的地方存放被访问页的地方了。 使用多级页表是有没有什么变化？ 我们知道在单级页表时每一个页表项的地址就是起始地址+页号*页表大小，但是当使用多级页表时只有同一张页表中的页表项还使用（因为一张页表内还是连续存储的）但是此时页表间的页表项就不再适用了，因为此时各个页目录表是离散存储的了。 思考：什么时候使用多级页表？ 若分为两级页表后，页表依然很长，那么我们就可以采用更多级页表，一般来说各级页表的大小不能超过一个页面，毕竟页目录最好就放入一个页框中最合适。例如：某系统按字节编址，采用40位逻辑地址，页面大小为4KB，页表项大小为4B，假设采用纯页式存储，则需要几级页表？页内偏移量多少位？ 页面大小=4KB=2^12B，按字节编址所以页内偏移量就是12位。 那么页号所占位数=40-12=28。又因为页面大小为4KB=2^12B,页表项为2^2B，那么每个页面可以放2^10个页表项。因此各级页表最多包含2^10个页表项，需要10位二进制才能映射到2^10个页表项，因此每一级的页表对应页号为10位（可以少但是不要多于10要不就会出现一张表放不下两张表多于的情况，少的话后面就空着呗）。所以需要三级页表，逻辑地址结构如下： 思考：如果就要用两级页表会怎么样？ 按理论你要是非得用也不是不可以，但是此时就会出现一级页号18位即有2^18个二级页表，那么页目录一张放不下，需要1.8个这就很不优雅。所以不推荐。而如果是8,10,10这样分布就很好，一级页号对应有多少个二级页目录一共有2^8个二级页目录，然后二级页号每一个都是一张二级页目录，页目录中的每一项映射着一个三级页表，三级页号表项映射着页号所对应的物理块号。这样一共是有2^28个物理块存储着数据。 思考：为什么不是10,10,8分布？ 这样很不优雅，意味着有2^20个表都是填不满的，虽然对于查找没什么影响，但是页内碎片多，而8,8,10就只有一级页目录有页内碎片。既节省空间还优雅。 思考：两级页表和三级页表查询步骤（没有快表）？ 两级页表： 第一次访存：访问内存中的页目录表 第二次访存：访问内存中的二级页表 第三次访存：访问目标内存单元 三级页表： 第一次访存：访问内存中的一级页目录表 第二次访存：访问内存中的二级页目录表 第三次访存：访问内存中的三级页表 第四次访存：访问目标内存单元 总结 超级重点，必须会计算！"},{"title":"操作系统的运行环境","path":"/wiki/操作系统笔记/操作系统的运行环境/index.html","content":"操作系统的运行机制 预备知识 在学习之前，我们先来回忆一下程序是如何运行的。首先指令是指处理器cpu可以识别、执行的最基本命令。在生活中，很多人习惯将Linux,Windows,MacOS的小黑窗中的命令也称为“指令”，实际上这些是“交互式命令接口”，与本节的“指令”不同，本节中的“指令”是指硬件层机器所能识别的二进制指令（即01串）。 一条高级指令如C,JAVA等都会首先通过编译器翻译为机器能够读懂的二进制指令然后才能被硬件机器识别和执行。高级语言逻辑复杂更符合人类思维，而二进制指令则更对机器的执行友善，简单地01交并补就可以实现高级语言。但是相对应的指令长度和数量也就更多，所以一条高级语言的代码可能会翻译出许多条对应的机器指令（举个例子，实际上通过二进制指令和操作系统的代码实现输出函数printf就已经对于机器来说是一个非常复杂高级的指令了，如果你做过nemu的话会深有体悟）。而cpu就是一条一条的执行二进制指令，当然执行的速度非常快。 内核程序和应用程序 这两个程序有本质上的区别，对于应用程序我们再熟悉不过，普通程序猿写的程序大多都是应用程序，其大部分都是应用于软件层，最终运行在操作系统上。而例如微软、苹果、华为等一些顶级大牛会负责实现操作系统，如果你还记得上节的内容，应该知道操作系统本质上也是一个软件，只是他是连接软件层和硬件层的中间层。这些很多内核程序组成的“操作系统内核”，又叫做内核（kernel)，内核是操作系统最重要的核心部分，也是最接近硬件的部分，可以说，一个操作系统只要有了内核基本上就够了例如Docke仅需要Linux内核，操作系统的内核是实现核心功能的部分，未必拥有操作系统的全部功能，录入图形化接口GUI就不在内核中实现。 特权指令和非特权指令 应用程序使用的都是“非特权指令”，例如加法指令，减法指令等，而操作系统内核作为管理者，就有权有时让cpu执行特权指令，如：内存清零指令，这些指令影响重大，一般会直接影响到操作系统，硬件上的工作，只能由“管理者”–操作系统内核使用。归根对比，应用程序使用的非特权指令权利很小，无权或者不能对操作系统和硬件层产生直接影响，并且一定是需要经过操作系统才能间接使用接口来和硬件层产生关联，而特权指令就是直接更改操作系统代码或者硬件层调度配合工作的代码，不可能暴露给外界以防产生恶意程序入侵破坏设备。在设计cpu时会划分特权指令和非特权指令，因此cpu可以执行一条指令前判断出指令的类型。 内核态和用户态 cpu有两种状态：内核态和用户态。处于内核态时，说明此时正在运行的是内核程序，此时cpu可以执行特权指令（注意是可以，也就是说此时还可以继续执行非特权指令）。而当处于用户态时，说明此时运行的是应用程序，此时只能执行非特权指令。这里用到了一个特殊地寄存器来存储程序状态–程序状态字寄存器（PSW），其中有个二进制位，1表示“内核态”，0表示“用户态”，这样cpu就可以随时判断出此时处于什么状态下。 当然这里有许多别名： 内核态=核心态=管态（即管理状态） 用户态=目态（即只能观看状态） 那么你一定会好奇仅仅用一个PSW就来判断cpu处于什么状态是否过于草率，那么只要更改这个位，岂不是可以按照人为意愿随意更改状态，更可怕的是如果有黑客此时病毒植入，更改了cpu状态然后执行了格式化等指令将系统破坏掉会造成很大的安全隐患，所以这里会有异常中断来避免这种情况，所以PSW不能随意更改，只能由特权指令更改。 这里有一个故事来描述这种情况的应急措施：首先，设备刚刚开机后首先会使cpu处于管态，此时操作系统内核程序先上cpu运行（原因是应用程序需要在操作系统上运行，所以操作系统需要先做准备工作提供接口环境），开机完成后，用户启动某个应用程序，待操作系统内核在合适的时候（准备工作完成）主动（此时处于管态，运行特权指令更改PSW是可以的）让出cpu,让该程序上cpu放入内存后上cpu执行，此时应用程序运行在目态，只能执行非特权指令，当此时有黑客在应用程序中植入一条特权指令（更改PSW）时，企图破坏系统，cpu此时在目态发现要执行的是特权指令（更改PSW）时发现自己是用户态时就会触发异常中断，此时操作系统发现中断信号会立刻夺回cpu的控制权以防有非法指令破坏系统，然后对引发中断的事件进行处理，处理完后在cpu使用权交给应用程序并且此时再次切回目态，这样就保护了系统不会受到入侵破坏了。 思考：内核态和用户态怎样切换 内核态-&gt;用户态：刚刚上面已经讲过了，当cpu处于内核态时可以执行一条特权指令修改PSW的标志位来实现主动切换到目态，这个动作意味着操作系统主动让出cpu的使用权。 用户态-&gt;内核态：任何情况下都不可能通过指令切换回管态，因为PSW只能通过特权指令更改判断位，而此时目态下cpu无权执行特权指令，但是可以通过中断信号引发，硬件自动完成变态过程，触发中断信号意味着操作系统将强行夺取cpu的使用权，因此除了非法使用特权指令以外，还会有许多事件触发中断信号，从而由目态切换到管态，但有一个共性是，但凡需要操作系统介入的地方，都会触发中断信号。 总结 操作系统内核 说了那么多，那么操作系统内核到底是什么，其实内核就是计算机上配置的底层软件，是操作系统最基本，最核心的部分，实现操作系统内核功能的那些程序就是内核程序。如下图： 那么哪些是不属于内核的操作系统的功能呢？例如记事本、任务管理器等设备自带的传说中免费的赠品软件APP，即使没有这些软件，我们仍然可以使用计算机。当然，这些非内核的功能用来推销也是不错哦😹：放松时刻 当然不同厂商对于内核的定义也不同，这里又对内核进行了细分：大内核和微内核。 操作系统的结构和企业的管理问题很相似，内核就是企业的管理层，负责一些重要的核心工作，只有管理层才能执行特权指令，普通员工就只能执行非特权指令。管态和目态之间的切换就相当于普通员工和管理层之间的工作交换。 大内核：企业初创时体量不大，人人都有官，人人皆高层，所以管理层的人会负责大部分的事情，有点事效率高，缺点就是组织结构混乱，难以维护。 微内核：随着企业的体量增大，管理层只负责最核心的一些工作，有点事结构清晰，方便维护，缺点是效率低。 中断和异常 中断的作用 cpu上会运行两种程序，一种是操作系统内核程序（是整个操作系统的管理者），另一种就是应用程序。前面已经基本上知道了中断实际上就是会使cpu由用户态变为内核态，使操作系统重新夺回对cpu的控制权。 在合适的情况操作系统内核会把cpu的使用权主动让给应用程序，而中断就是让操作系统内核夺回cpu使用权的唯一途径。如果没有中断机制，那么一旦cpu开始运行某个应用程序，cpu就会一直运行这个应用程序，那么又何来的并发性呢，所以当切换cpu上的应用程序时就是需要中断信息，使操作系统重新掌权，将cpu使用权让给其他的应用程序，所以中断保证了并发性。 中断的类型 所以中断切换状态是很常见的一种方法，那么根据不同触发的触发中断的情况我们可以分为两类–内中断和外中断。 内中断 内中断与当前执行的指令有关，一般来自cpu的内部，比如发现cpu执行了特殊的特权指令造成的异常或者除0出现计算异常等都是执行的指令自身引发的，这种就成为内中断。当然也不一定指令是出现错误才触发中断，比如应用程序想请求操作系统内核的服务时，此时会执行一个特殊的指令–陷入指令（在Nemu实验中也有，为trap()），此时该指令就会引发一个内部中断信号，也是内中断的一种，这种陷入指令虽然会触发中断，但是此动作意味着应用程序主动的将cpu控制权还给操作系统内核，系统调用就是通过陷入指令完成的。 外中断 外中断与当前的执行无关，不是当前指令引起的中断信号，所以自然不是来自于cpu内部，而是通过内核中某些算法（这些算法来实现任务间合理调度）引起的中断信号。比如内核中的时钟中断，它是由时钟部件发来的中断信号或者是IO设备发起的任务完成的中断信号。 例如时钟算法是用来分配调度任务之间的占用cpu的时间的，我们从上图可以看出时钟计时每50ms会发一个中断信号给cpu,而cpu每次执行完一条指令后都会例行检查是否有外中断信号。当检测到外中断信号时，就会由目态切换到管态。所以回忆之前的知识，可以猜出单批道操作系统的并发性实现即每隔一个时间片切换任务就是通过时钟算法外中断信号引起的。 中断分类的总结 经过上面两个的对比，我们可以看出外中断更符合我们广义上所说的中断，而内中断更多的像是故障，异常终止或者主动陷入，所以大多数的教材和讲义上中断都是特指的外中断，内中断一般称为异常。 中断机制的基本原理 那么对于不同的中断信号，如何知道该进行什么相应操作呢？这时cpu检测到中断信号后，会根据中断信号的类型去查询“中断向量表”，以此来找到相应的中断处理程序在内存中的存放位置。 总结 系统调用 什么是系统调用 我们在前面已经学到了操作系统作为用户和计算机硬件之间的接口，需要向上提供一些简单易用的服务，主要包括命令接口和程序接口。其中程序接口就是由系统调用组成的。例如C库函数中的system()就是一种库函数方法，需要通过程序接口实现。 一般系统调用是操作系统提供给程序猿等编程开发人员使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以通过系统调用来获得操作系统内核的服务。 思考：系统调用和库函数的区别？ 通过上图我们可以看出应用程序一般是直接通过系统调用来请求内核服务的，当然也有一部分是调用库函数时，库函数中需要系统调用来请求内核服务。但是并不是所有的库函数都需要系统调用的，比如“取绝对值”的函数sqrt()只是一个数学操作函数，虽然需要引入cmath库，但是是不需要系统调用的。而“创建一个新文件”局就涉及到了系统调用的库函数。所以一般来说，普通用户是不会手动触发系统调用的，只有编程人员调用库函数和应用程序可能会触发系统调用。 系统调用的必要性 那么为什么要有系统调用呢，即为什么程序需要每次都向内核发送服务请求呢而不是直接自己执行呢？这就涉及到了操作系统的自身的功能–协调分配任务，管理资源。比如两个人的电脑连接着一个打印机，第一个人按下了打印按钮，此时打印机开始打印第一个文件，但是在打印至一半时，第二个人也按下了打印按钮，开始带引他的文件。如果没有系统调用申请内核服务的话，那么两个进程就会互相随意地并发的共享计算机资源，最终造成两个文件混杂在一起的情况。而使用系统调用，触发陷阱发送中断信号请求内核对共享资源的统一的管理，操作系统就会向上提供“系统调用”服务，内核会对这几个进程进行协调处理，使其互相不干扰的并发进行，即在某个进程该工作占用cpu和打印机共享资源时工作，非这个进程阶段就进制此进程占用共享资源，这样就会使得最终的结果互补混杂了。所以系统调用对于共享资源的管理和任务之间的协调调度起着至关重要的作用。 系统调用的分类 应用程序通过系统调用来请求系统的服务，而系统中的各种共享资源都又操作系统内核统一掌管，因此凡是与共享资源有关的操作（如存储分配，I/O操作，文件管理）等，都必须通过系统调用的方式向操作系统内核发出服务请求等待响应，然后又操作系统内核代为完成（所以是在管态进行的分配服务），这样就保证了系统的稳定性与安全性，防止了用户的非法操作。 系统调用的过程 因为系统调用是应用程序主动然爱过出cpu的使用权，使用陷入指令触发的中断信号，所以系统调用一定是内中断。 我们可以看到系统调用时并不是立刻就进行陷入指令，而是首先在目态进行一系列准备工作，比如记录中断地址（毕竟最终操作系统服务完以后还要回到这个地址继续执行），还有传参指令即将系统调用需要的参数存放到制定的寄存器以便操作系统使用，最终才调用陷入指令（此时已经做好了移交cpu的准备工作），然后操作系统掌握cpu使用权（管态）进行服务，完成后最终再返回到中断位置继续执行后面的指令。 总结 操作系统的体系结构 我们通过上图可以看出一个操作系统内核部分和非内核部分可以组装，比如Ubuntu等就是建立在linux基础上再加以非内核功能组装住的操作系统。并且我们也已经知道内核是操作系统最基本，最核心的部分，实现操作系统内核功能的那些程序就是内核程序。并且内核分为了四个部分： 因为其对软硬件的操作程度不同，有区分成了大内核和微内核，我们前面是以企业模型分析了两种内核类别的效率和优缺点。这里我们再以变态次数分析一下，首先我们需要知道应用程序想要请求操作系统的服务时，这个服务会涉及到进程管理，存储管理，设备管理即对硬件操作不是很大的那层（橘色层）。然后在涉及到最接近硬件层的时钟管理，中断处理和原语部分。按照大内核和微内核的定义： 我们可以看出他们两种类型的内核布置造成了不同的变态次数。 对于大内核其认为两层均是内核功能部分，所以这两层都处于管态执行，这样四个功能之间的切换就不会在涉及到变态过程了，唯一造成变态的位置就是应用程序和大内核之间的切换，所以只有2次变态。而对于微内核，其任务进程管理，存储管理和设备管理（橘色层）不属于内核部分，所以此部分还是需要在用户态执行，这样虽然应用程序和橘色层之间不再需要变态了，但是由于这三个操作都是会涉及到时钟管理，中断处理和原语部分，所以每一个都需要经历两次变态，最后总体来看会造成6次变态。而变态的过程是有成本的，要消耗不少的时间，频繁的变态会降低系统的性能，所以这也是大内核效率更高的原因之一。 生活中的系统分类 典型的大内核/宏内核/单内核操作系统：Linux,UNIX 典型的微内核操作系统：Windows NT 总结"},{"title":"同步与互斥","path":"/wiki/操作系统笔记/同步与互斥/index.html","content":"进程同步与进程互斥 进程同步 首先我们在前面已经知道进程具有异步性的特点，异步性是指各进程并发地以各自独立的，不可预知的速度向前推进。而在某些需求上，仅仅实现异步性是不可以的。例如：进程通信中的管道通信，读进程和写进程是并发执行的，由于并发性必然导致异步性，因此“写数据”和“读数据”两个操作虽然根据并发和异步的特点会在一个时间间隔内交叉运行，但是归根结底，“读数据”时必须在“写数据”后面的，所以这里仅仅有异步性是不能满足这个需求的实现的，因为并发异步执行的先后顺序是不确定的。 所以这里我们引入了“进程同步”的概念，它是指为了完成某个任务（如上面的管道通信）而建立的两个或多个进程，这些进程因为需要在某些位置上协调他们的工作次序而产生的限制关系。进程间的直接限制关系主要就是来源于他们之间的相互合作。 进程互斥 进程的“并发”需要“共享”的支持（前面讲过并发和共享相互存在，是操作系统进程的两大基础特性）。那么各个并发执行的进程不可避免的需要共享一些资源（比如内存，又比如打印机、摄像头等I/O设备），所以这里根据同一时间段内能否允许多个进程同时使用这个共享资源将共享细分为两类。 同时共享方式 即系统中的某些共享资源，允许一个时间段内由多个进程“同时”对其进行访问。 互斥共享方式 即系统中的某些共享资源，虽然可以提供给多个进程使用，但是一个时间段内只允许一个进程访问该资源。 我们把一个时间段内只允许一个进程使用的资源称为临界资源（前面也讲过访问临界资源的代码段称为临界区）。许多物理设备（比如摄像头，打印机）都属于临界资源，此外还有许多变量，数据，内存缓冲区等都属于临界资源。对临界资源的访问，必须互斥的进行。互斥，亦称为间接制约关系。 进程互斥是指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源以后，另一个进程才能去访问临界资源。所以互斥共享实际上就要求进程互斥关系。 对临界资源的互斥访问，可以在逻辑上分为如下四个部分： 临界区是进程访问临界资源的代码段，进入区和退出区是负责实现互斥的代码段（后面所讲的互斥锁PV操作代码段就是这两个区内完成），临界区也称为“临界段”。 思考：如果一个进程暂时不能进入临界区，那么该进程一直占用着处理机吗？该进程要是一直进不去临界区怎么办？ 为了实现对临界资源的互斥访问，同时还要保证系统的整体性能，需要遵循以下原则： 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。 忙则等待：当已有进程进入临界区，其他试图进入临界区的进程必须等待。 有限等待：对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饿死）。 让权等待：当进程不能进入临界区，应立即释放处理机，防止进程忙等待。 思考：有限等待和让权等待不矛盾吗？ 可能你会认为一方面保证进程会在优先时间内等待到进入临界区，一方面又说当不能进入临界区就释放处理机，那进程到底等不等？实际上有限等待的意思是保证进程在一段时间后必定会被操作系统提示可以进入临界区，而让权等待的意思是该进程在等待时就不要在这用cpu了，先阻塞或者挂起等待，在有限等待以后在唤醒该进程上cpu然后范文临界资源，所以不矛盾。 总结 进程互斥的软件实现方式 很明显进程互斥有研究的内容，毕竟具体怎样实现互斥的方法有多种，我们一一了解。 思考：进程互斥需要解决的根本问题？ 首先我们先思考一个问题，现在有两个进程A和B并发地运行，如下图： 那么当A上处理机运行使用打印机时，我们知道根据调度算法，一般一个进程会在执行一个时间片（一般现在的操作系统都是MFQSA调度）后，可能并没有执行完，但是也需要下cpu让另一个进程开始执行，此时进程B上cpu后也开始运行使用打印机，这样结果就是A,B的内容混在了一起（这也解释了前面介绍系统调用必要性的例子中打印内容会混合在一起的原因），那么该怎样才能解决这个问题呢？ 单标志法 算法思想：两个进程（注意只适用于两个对象的情况）在访问临界区后会把使用临界区的权限转交给另一个进程，也就是说每个进程进入临界区的权限只能被另一个进程赋予）。代码如下： 首先我们定义一个全局变量turn=0,turn表示当前允许进入临界区的进程号，因为就两个进程，所以0表示允许进程0访问临界资源，1表示允许进程1访问临界资源。 1int turn = 0; 然后进程0的代码如下，这里我们要自己完善进入区和退出区，因为两个进程要互斥访问，所以1能否进入临界区取决于进程0有没有访问完，所以进程0访问完只需通知一下进程1现在可以进入即可，相对应的就是在退出区让turn=1，这样就可以允许进程1在进程0访问完以后进入临界区了。 P0： 12345//如果此时是对方进入回合即turn值为1则一直执行空语句等待while(turn!=0)&#123;&#125;; ----1//进入区critical section； ----2//临界区turn =1; ----3//退出区remainder section ----4//剩余区 相对应的P1访问完临界区后也要告诉P0现在可以访问临界区了，所以turn=0; P1: 12345//如果此时是对方进入回合即turn值为0则一直执行空语句等待while(turn!=1)&#123;&#125;; ----5//进入区critical section； ----6//临界区turn =0; ----7//退出区remainder section ----8//剩余区 这样turn的初始值为0，所以一开始只允许进程0进入临界区，若P1先上的cpu执行到了访问临界区代码，则会一直卡在代码段5，即进入区禁止进入，此时就一直到P1的时间片用完，调度切换到P0上处理机运行，代码1就不会卡在P0，所以P0可以正常访问临界区，此时如果在P0还在访问临界区阶段时间片到了，此时turn还没有更新到1，所以即使切换到P1此时P1还是在等待，直至P0访问完临界资源并更新了turn值以后P1才能进入临界区。 因此，这种算法可以在软件层次上实现“同一时刻最多只允许一个进程访问临界区”。但是貌似有一些小问题，比如只能按照P0-&gt;P1-&gt;P0-&gt;P1…这样的顺序轮流访问，这种必须“轮流访问”的问题是，如果此时允许进入临界区的进程是P0，而P0一直不访问临界区或者根本就不想访问临界区，那么此时虽然临界区是空闲的，但是也不允许P1访问，因此单标志法违背了“空闲让进”原则。并且这种方法对于多个进程的情况会比较复杂。 注意：上方代码的while后面带分号什么意思？ 一定要仔细观察代码，发现是对于P0，当turn!=0时在一直循环while的空语句表示等待，所以P0也可以写成： 1234while(turn!=0); ----1//进入区critical section； ----2//临界区turn =1; ----3//退出区remainder section ----4//剩余区 这个;很致命，一定要透彻理解第一行whlie语句的意义，他是判断是否需要等待，所以这里的判断条件为turn!=0则表示此时如果不是0的回合，那么0代码就一直在while后面的{};语句中执行空语句等待，这里因为{}里面是空语句所以可以省略大括号，P1同上原因。后面也都是这样表示。 双标志先检查法 算法思想：设置一个布尔型数组flag[],数组中各个元素用来标记各进程想进入临界区的意愿，比如&quot;flag[0]=true&quot;表示0号进程P0现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身的对应标志位flag[i]设置为true，之后开始访问临界区。 我们这里还是以进程P0和进程P1为例。首先初始化flag为两位，且一开始都默认为不想访问临界资源。 1bool flag[2]=&#123;false,false&#125;; 然后P0和P1每次访问前都先检查对方是否进入临界区，如果对方不想（即flag=false)那么就将自身的标志位设置为true,这样在自己访问临界资源期间，对方是不能进入的，当访问结束后再将自身的标志位设置为false。 P0： 123456//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[1]); ----1 // 进入区flag[0]=true; ----2//将自身标志位更新为true 进入区critical section ---3//访问临界资源 临界区flag[0]=false ----4//访问完毕，将自身标志位在更新为false 退出区remainder section //剩余区 P1: 123456//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[0]); ----5 //进入区flag[1]=true; ----6//将自身标志位更新为true 进入区critical section ---7//访问临界资源 临界区flag[1]=false ----8//访问完毕，将自身标志位在更新为false 退出区remainder section //剩余区 这个看似完美，实际上比上一个单标志法还不靠谱，他存在一个重大的bug，就是如果按照1-&gt;5-&gt;2-&gt;6-&gt;3-&gt;7的顺序执行，即假设现在flag数组所有位置都为false,即此时临界资源空闲，然后P0执行完允许进入后进入区判断以后突然时间片用完了，那么此时P0该下cpu了并且PCB记录此时状态是被允许进入空闲资源的，然后此时调度切换到P1执行了进入区代码，此时他发现P0的标志位仍然是false呢，所以他也进入，但是就那么巧，此时P1也用完时间片了下cpu前PCB记录此时被允许进入临界资源的状态，然后又切回了P0开始执行临界区，结果此时又用完时间片了此时P0还在临界资源，里面的P0临街资源还没被释放，P1又进来了，此时也可以对临界资源进行读写，完蛋，打印的内容又混在了一起。所以此时违背了“忙则等待”的原则。 思考：能不能优化一下代码避免这种bug? 可以，我们仔细观察，发现出现这种问题主要是因为进入区的“检查”和“上锁”两个操作不是一气呵成的所以会有可能在“检查完”和“上锁前”出现进程切换。所以我们可以更改一下操作顺序，管那么干嘛，先上上锁不让别人进来然后再检查，即更改成如下 双标志后检查法 首先初始化肯定是不变的 1bool flag[2]=&#123;false,false&#125;; 但是此时是先上锁在检查 P0： 123456flag[0]=true; ----1//先上锁 进入区//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[1]); ----2 // 进入区critical section; ----3//临界区flag[0]=fasle; ----4//访问完后解锁 退出区remainder section; P1: 123456flag[1]=true; ----5//先上锁 进入区//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[0]);----6//进入区critical section; ----7//临界区flag[1]=fasle; ----8//访问完后解锁 退出区remainder section; 好像更改完确实不会在发生“忙则不等待”的问题了，但是此时貌似又出问题了，按照1-&gt;5-&gt;2-&gt;6的顺序即进程0想访问临界资源然后上锁了但是在检查前时间片用完了，切换到进程1他也先上锁然后发现0貌似已经上锁了所以就一直停在了代码6直至时间片用完，此时又切换回了进程0，由于进程1并没有检查完发现不能进以后解锁的操作，所以此时进程0也会发现进程1貌似也已经上锁了，所以进程0也一直卡在检查区代码2最终时间片用完，就这样即使空闲资源空闲，但是双方都发现对方上锁了就都一直不进入（其实就是产生了对方正在访问的误会），产生了饥饿现象。所以双标志后检查法不能应用。 思考：难道不能进一步优化双标志位法避免bug? 你可能会想到之所以双方都不进入是因为在检查到对方上锁后自己不能进入后没有解锁的操作，所以可能认为在2和6下方各加上一个若发现对方在就自己解锁的操作。但是你会发现无论这个功能根本实现不了，无论这个解锁操作放在哪里都不太合适仍然会触发更多的bug，所以就不要在尝试优化双标志法了，直接放弃思考一个更好的方法。 Peterson算法 算法思想：结合双标志法和单标志法的思想特点，如果双方都想争着进入临界区，那么就尝试互相退让，作一个有礼貌的进程。 其实实现也很简单就是有添加一个新的参量turn表示优先让哪个进程进入临界区，这样就实现了进程之间的谦让，代码如下： 还是先初始化 12bool flag[2]=&#123;false,false&#125;;//初始化时默认此时双方都不想访问临界资源turn=0;//初始化时默认进程1谦让进程0 P0: 1234567flag[0]=true; ----1//表达自己想进去的意愿上锁 进入区turn=1; -----2//优先让1进程进，即自己谦让有礼貌 进入区//如果此时1也想进入即对方上锁了且自己谦让，那么就循环空语句等待while(flag[1]&amp;&amp;turn==1);----3 //进入区critical section; ----4//临界区flag[0]=false; ----5//访问完了，解锁 退出区remainder section; //剩余区 P1： 1234567flag[1]=true; ----6//表达自己想进去的意愿上锁 进入区turn=0; -----7//优先让0进程进，即自己谦让有礼貌 进入区//如果此时0也想进入即对方上锁了且自己谦让，那么就循环空语句等待while(flag[0]&amp;&amp;turn==0);----3 //进入区critical section; ----4//临界区flag[1]=false; ----5//访问完了，解锁 退出区remainder section; //剩余区 此时进程们都很有礼貌了，每次自己想进去时都会谦让，这是我们在走一次1-&gt;2-&gt;3-&gt;6-&gt;7-&gt;8我们会发现确实做到了“忙则等待”和“空闲让进”并且没有在出现重大致命bug了，但是此种方法也不是太好，首先turn值限制了当涉及到多各进程之间时也很复杂，turn就会变得不那么简单，其次他和前面两种方法一样也没有做到“让权等待”即等待是下处理机，而是一直在循环执行while的空语句所以一直在占用cpu，所以peterson算法虽然比前面的方法好但是也不够好。 总结 进程互斥的硬件实现方法 中断屏蔽方法 利用“开/关中断指令”实现（和原语的实现思想相同，即在某个进程开始访问临界区到结束访问临界区为止都不允许中断，也就不会发生进程切换了因为时钟管理也只是在时间片结束后向cpu发送中断信号但是cpu可以忽视即决定权在cpu手中，这样也就不可能发生两个同时访问临界区的情况了） 优点很明显，简单高效确实实现了进程互斥的所有原则，但是缺点是不适用于多处理机，只适用于操作系统内核进程，不适用于用户进程（因为开/关中断指令都是特权指令，只能运行在内核态，这组指令如果用户可以随意使用会很危险，所以覆盖范围太小） TestAndSet指令 简称TS指令，也有地方成为TestAndSetLock指令，或者TSL指令，TSL是用硬件实现的，执行的过程不允许被中断只能一气呵成（很像原语），这里我们用C语言描述一下逻辑（但是一定要注意是硬件实现的，不是软件实现）。 1234567891011121314//布尔共享变量lock表示当前临界区是否被加锁//true 表示已加锁，false 表示未加锁bool TestAndSet(bool *lock)&#123; bool old; old=*lock;//old用来存放lock原来的值 *lock=true;//无论之前是否已经加锁，现在都将lock设置为true; return old;&#125;//以下是使用TSL指令实现互斥的算法逻辑while(TestAndSet(&amp;lock));//上锁并检查 进入区critical section;//临界区lock=false;//访问完解锁 退出区remainder section;//剩余区代码 实际上TSL就是通过硬件手段强制检查和上锁必须一气呵成执行（主要是因为TSL指令必须一气呵成，而TSL就一次完成上锁和检查），此时如果刚开始lock是false,则TSL返回的old值不满足while循环条件，直接跳过等待循环，进入临界区，如果刚开始lock是true,则执行TSL后old返回的值为true，此时满足while循环条件，会一直循环等待，直至当前访问临界区的进程在退出区进行“解锁”后该进程再访问临界资源。相比软件实现方法，TSL指令把“上锁”和“检查”操作用硬件的方式绑定为一气呵成的原子操作，但是注意他不是真的原语，只是具有原语的特性。 优点是实现简单就可以避免bug，这种无需软件实现方法那样严格检查是否会有逻辑漏洞，适用于多处理机环境，缺点是不满足“让权等待”，一旦无法进入临界区进程就会一直执行循环空语句占用cpu。 Swap指令 有的地方也叫作Exchange指令，或简称XCHG指令，Swap指令也是使用硬件实现的，执行的过程中不允许被打断，只能一气呵成，以下是用C语言描述的逻辑（但是一定要注意是硬件实现的，不是软件实现）。 1234567891011121314151617//Swap指令的作用是交换两个变量的值Swap(bool *a, bool *b)&#123; bool temp; temp=*a; *a=*b; *b=temp&#125;//以下是用Swap指令实现进程互斥的算法逻辑//lock 表示当前临界区是否被加锁bool old=true;while(old==true)&#123; Swap(&amp;lock,&amp;old);&#125;critical section;lock=false;remainder section; 看着有点晕😫，正常。我们来屡一下思路，首先我们有一个地方需要注意，此时的while后面不再是空语句了，而是Swap语句，这也就说明加入while判断条件返回为true即old为true,那么就会一直执行Swap(&amp;lock,&amp;old)交换lock和old值然后在判断，所以知道这一点后我们先假设lock=true的情况，那么此时说明有其他进程正在访问临界资源呢，然后bool设置为true后满足while条件进入循环语句内此时lock和old都是true，所以交换后还会满足while判断条件，所以又交换因此当当前正在访问临界资源的进程没有访问完，lock和old就会一直为true，所以等待的进程就是一直在不断的swap，直到那个进程访问完将lock更改为false,此时在经过1~2次的swap就会出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)此时这个进程就不在等待了出循环开始访问临界资源。而当lock一开始为false即临界资源空闲的情况，那么进入while循环一次后就会出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)的情况所以此时该进程就不需要等待就可以进入了。所以这个指令实现的方法很神奇，他唯一可以进入临界资源的情况就是出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)，当没有出现这个情况时等待的进程也不是一直循环空语句，而是一直在swap(虽然此时lock和old都为true😂),即使初始时临界资源空闲也要执行一次swap，所以无论何种情况，swap至少执行一次。并且转来转去实际上Swap和TSL实现的逻辑思路一模一样。 优点也是实现简单就可以避免bug，这种无需软件实现方法那样严格检查是否会有逻辑漏洞，适用于多处理机环境，缺点是不满足“让权等待”，一旦无法进入临界区进程就会一直循环执行Swap语句占用cpu。 总结"},{"title":"文件共享与保护","path":"/wiki/操作系统笔记/文件共享与保护/index.html","content":"文件共享 操作系统为用户提供文件共享功能，可以让许多个用户共享的使用同一个文件。所以也意味着系统中只有一份文件数据，并且只要某个用户修改了该文件的数据，那么其他用户也可以看到文件数据的变化。如果是多个用户都“复制”了同一个文件，那么系统就会由好几份文件数据，其中一个用户修改了自己的那份文件数据此时并不会其他用户的文件数据造成影响。 基于索引节点的共享方式（硬链接） 我们知道，索引节点是一种文件目录瘦身策略，由于检索文件只需要文件名，所以其他的信息都存放到了索引节点中，这样目录项就只包括文件名和索引节点指针了，如下图： 索引节点中设置了一个链接技术变量count，用于表示链接到本索引节点的用户目录项。如果count=2,说明此时有两个用户目录项都链接到了该索引节点上也就意味着这两个用户共享这个文件。如果某个用户决定删除该文件，那么只需要把用户目录中与该文件对应的目录项删除即可，且索引节点的count值减1。只要count&gt;0，就说明此时还有别的用户要使用这个文件，那么就不能把文件数据删除，否则就会导致目录项中索引节点指针悬空（NULL）。当count==0时就说明没有用户使用这个文件那么就可以删除了，操作系统会负责删除这个文件。 基于符号链的共享方式（软链接） 当User3访问ccc时，操作系统会判断文件ccc属于Link类型文件，那么就会根据其中记录的路径层层查找目录最终找到User1的目录表中的aaa表项，于是就找到了文件1的索引节点。 思考：这种链接方式的一种特点？ 我们发现这种方式的链接会有如下情况发生：当User1的aaa目录项被删除了而此时User3的目录项ccc还没有删除时，那么即使ccc可以指向Link文件2，但是由于User1的aaa不存在了所以不能找到文件1了，所以此时ccc会出现无法找到文件的情况，即User3ccc访问文件是基于User1在存在文件aaa存在的前提下才能实现的。 总结 文件保护 这里我们介绍几种文件保护的具体做法。 口令保护 主要是用于保护文件，设置特殊口令，只有正确才可以访问。所以此时用户访求文件时必须提供正确的口令，口令一般会存放在文件对应的FCB活索引节点中，用户访问文件前需要输入口令，然后操作系统将口令和FCB中的口令做对比，如果正确则允许用户访问文件（那么FCB中的口令肯定是不允许普通用户随意获得的）。这种方式优点是保存口令的空间开销不多，验证口令的时间开销也很小，但是缺点是正确的口令存放在系统内部不够安全。 加密保护 使用某个密码对文件进行加密，在访问时需要提供正确的密码才可以进行正确的解密。那么密码肯定是有多种的，我们以一个最简单的加密算法–异或加密为例。假设用于加密/解密的密码为01001，那么： 上面这种方法确实做到了加密的作用，并且优点是保密性强，不需要在系统中存放正确的密码，缺点是编码/译码（加密/解密）需要花费一定的时间。 访问控制 为每个文件的FCB（或者索引节点）中增加一个访问控制表（Access-Control List,ACL),该表记录各个用户可以对文件执行那些操作。 精简的访问列表就是：以组为单位，标记各组用户可以对文件执行那些操作。如下表： 当某用户想要访问文件时，系统会检查该用户所属的分组是否有相应的访问权限。所以一般重要的OS内核文件肯定是不允许用户访问的即使是操作者。 总结 磁盘的结构 磁盘、磁道、扇区 磁盘的表面由一些磁性物质组成，可以用来存储二进制数据，所以磁盘不能被刮坏。这里我们讲解一下一个磁盘的具体结构术语。 上图就是一个磁盘，他会被等大分为许多扇形，每一个扇形就是一个磁盘块（前面讲过磁盘块存储的数据大小相同），这里的一圈就是磁道，越靠近内侧数据的密度就越大。 磁盘读/写数据方法 我们知道磁盘在被访问时会一直转动，所以就会一直切换不同的扇区即磁盘块，而右边的磁头就是从磁盘上滑过，但是他只会从里到外滑动，不会旋转转动，这样他想在某个扇区（磁盘块）进行数据的读写只需要等到磁盘转到指定扇区即可，即磁头主要是负责切换磁道。 盘面、柱面 为了高效，一般一个盘片的两面均可以存放数据，所以会有许多盘面。所以每一个盘面均对应着一个滑过的磁头，但是磁头是连在一起的所以共进退。这也就意味着一次只能有一个磁头到达他想要到达的位置对应着的就是（柱面号，盘面号，扇区号），柱面号就是规定了磁头将要访问的磁道，而盘面号规定的是此时是哪一个磁头访问这个柱面磁道的数据，扇区号就是访问盘面的哪一个扇面，其他的磁头如果没有到达所要访问的位置也只能等待。 思考：为什么磁头要设计成这样？ 当然我也想过每个磁头可以不用共进退，各自访问他们想要去的位置这样岂不是更加读写高效，但是貌似实现起来也更复杂，并且我们也知道磁盘一转很快的，实际上磁头读写的速度非常快，上面这种已经可以高效实现磁盘的读写操作了。 磁盘的物理地址 其实我们上面已经介绍过来，可以用(柱面号，盘面号，扇区号)来定位任意一个磁盘块，在文件的物理结构中，我们经常提到文件数据存放在外存中的几号块，这个块号就是对应着一个具体的物理地址所以可以转换成（柱面号，盘面号，扇区号）的地址形式。 可根据该地址读取一个块： 根据柱面号移动磁臂，让磁头指向指定柱面（柱面号的作用） 激活指定盘面对应的磁头（盘面号的作用） 磁盘旋转的过程中，当指定的扇区划过时，磁头进行数据的读写，如果一次没有完成可以再等磁盘转过时进行直至完成数据的读/写（扇区号的作用） 磁盘的分类 此时图二的下方也是有许多磁头的只是没画出来，实际上这两种各有利弊，第一个磁臂需要频繁移动来切换磁道，而第二个磁头太多。 总结"},{"title":"早期分配管理方式","path":"/wiki/操作系统笔记/早期分配管理方式/index.html","content":"连续分配管理方式 这里我们讲一讲内存空间的分配方式，分为连续分配管理方式和非连续分配管理方式，我们首先学习连续分配管理方式。 连续分配顾名思义就是为用户进程分配的必须是一个连续的内存空间，这里有三种连续分配方式如下： 单一连续分配 在单一连续分配方式中，内存被分为系统区和用户区。系统区通常位于内存的低地址部分，用于存放操作系统相关数据，而用户区存放用户进程相关数据。内存只有一道用户程序，用户程序独占整个用户区空间。 这种方式优点是实现简单，没有外部碎片，可以采用覆盖技术扩充内存，不一定需要采取内存保护（例如早期的PC操作系统MS-DOS）。但是缺点是只能用于单用户，单任务的操作系统中（这显然不适合并发进程），并且有内部碎片，存储器利用率极低。 思考：什么是内、外部碎片，有什么区别？ 我们先给出定义： 外部碎片是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。外部碎片是处于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或者其他原因，使得系统无法满足当前申请。多道可变连续分配只有外部碎片。 内部碎片就是已被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间。内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程不能使用这个存储块。而在进程占有这块存储块时，系统无法利用它。知道进程释放他，或进程结束，系统才有可能利用这个存储块。 所以内外碎片本质区别就是是否已经属于某个被分配的进程。并且外部碎片在操作系统的调整下可以消除，而内部碎片操作系统无权调配管理，只能等待被分配进程结束。 这里我们举一个例子来形象介绍，假设现在有1,2,3,4,5,6六个仓库，当1,2,3,4,5已填满后，4清仓了，那么此时空仓库有4,6，此时来了一批货物大小为2个仓库刚好满足4,6容量之和，但是货物要去连续存储，此时4,6无法使用并且4,6不属于任何一个货物所以4,6形成的就是外部碎片。而现在假设六个仓库都是空的，并且要求货物最小分配空间为间，所以一个仓库只能装一种货物，那么现在有一批2.5间容量的货物装载1-3号仓库，那么3号仓库只装了半间，但是此时再有别的货物也不能装入3号仓库并且此时3号仓库属于第一批货物，并且管理员也不能调整再使用3号仓库了，那么3号仓库剩余的空部分就是内部碎片。–大佬博客 按照上面的介绍我们知道了单一连续分配不会产生外部碎片的原因了，并且这种分配管理方式不用想也知道肯定会产生很大的内部碎片，所以不合理。 固定分区分配 20世纪60年代支持多道程序的系统出现后，为了能在内存中装入多道程序并且这些程序之前互不干扰，于是将整个用户控件划分为若干个固定大小的分区，在每个分区中只装入一道作业，这样就形成了最早的。最简单的一种可运行多道程序的内存管理方式，但是显然这种固定大小分区的分配方式很不合理，于是又出现了分区大小不等的分配方式。 分区大小相等：缺乏灵活性，但是很适用于一台计算机控制多个相同对象的场合（比如：钢铁厂有n个相同的炼钢炉，就可以把内存分为n个大小相等的区域存放n个炼钢炉控制程序） 分区大小不等：增加了灵活性，可以满足不同大小的进程需求，根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区，适量中等区，少量大分区）。 思考：那我们如何知道某个分区i的具体大小是多少？ 所以我们需要建立一个数据结构–分区说明表来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小，起始地址，状态（是否已分配）。如下： 当用户程序要装入内存时，由操作系统内核程序根据用户程序的大小检索检索表，从中找到一个满足大小的，未分配的分区，将之分配给该程序，然后修改状态为“已分配”。 这种固定分区分配优点是实现简单，无外部碎片（因为可以调整消除）缺点是当用户程序太大时，可能所有的分区都不能满足需求，此时就不得不采取覆盖技术来解决但是这又会降低性能，并且这种方法肯定是会产生内部碎片的，内存利用率低（无论是大小固定还是大小不等的分区分配方式）。 动态分区分配 动态分区分配又称为可变分区分配，这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的，（比如：假设某计算机的内存大小为64MB，系统区8MB，用户区56MB…） 很明显这种方法肯定是没有内部碎片的，解决了固定分区分配的缺陷。 思考：系统需要用什么样的数据结构记录内存的使用情况？ 其实和固定分区分配中分区不等大小的方法一样，也是建立表或者链来记录呗，如下： 当然名字还是得换一换的，实际上思路是异曲同工的。一定要注意此时只需要记录空闲连续分配区间的大小和起始地址就可以了。。 思考：当很多个空闲分区都能满足需求时选择哪个分区进行分配？ 如在上图中的空闲区域情况时，又来了一个进程5（之所以没有进程1,2,3可能是挂起或者运行完成释放了）大小为4MB，此时所有分区都满足，那么如何分配呢？ 这里我们有以下几种情况（后面会细讲）： 用最大的分区进行分配 用最小的分区进行分配（比较符合正常思维） 用地址最低的部分进行分配 把一个新作业装入内存时，须按照一定的动态分区分配算法，从空闲分区表（或空闲分区链）中选出一个分区分配给该作业。由于分配算法对系统性能会有很大的影响，因此人们研究后发明了几种动态分区分配算法（后面讲）。 思考：如何进行分区的分配和回收？ 空闲分区分配 首先看分配，这个简单，如果分配后某个分区刚刚好被占据了那么这个表项直接删除就好了。如下图： 5号进程放在了3号空闲分区刚好占满，那么删除3号表项即可。 如果空闲分区分配一定空间后没有被占满，那么就要更新分区大小和起始地址了，如下图： 5号进程放在了1号分区并且从1号分区的头部开始放，那么1号分区并未占满，此时就要更新1号分区，起始地址+4变为12同时大小-4变为16。 分区回收 分区的回收涉及的问题较多，这里我们逐一讨论 情况1：回收区的后面有一个相邻的空闲分区 例如下图： 此时要回收进程4了，那么很明显回收区后面相邻连着空闲分区1，那么此时只需要将后面的空闲分区更新起始地址-4同时分区大小+4就好。这个是两个相邻的空闲分区的合并。 情况2：回收区的前面有一个相邻的空闲分区 例如下图： 进程3完成后回收，此时回收区与前面的2号空闲分区所以合并更新2号分区的分区大小+18=28即可，起始地址此时是不需要变得。 情况3：回收区的前、后各有一个相邻的空闲分区 如下图： 此时比较复杂，需要将回收区和后相邻分配去全部加入到前相邻分配区，此时如上面的进程4被回收，那么回收区+后相邻空闲区的总大小为14都加到前相邻空闲分配区1中，所以此时1号空闲分配区大小为34，同时起始地址还是不变，然后还要将后相邻空闲分区删除表项，即2号分区变为了原先的3号分区。 情况4：回收区的前、后都没有相邻的空闲分区 如下图： 我们可以看到此时如果进程2回收，那么新的回收区就成为了一个新的最靠近低地址的空闲分区，所以加入一个新表项这里是1号分区大小为进程大小14，同时起始地址是28。 我们可以看出动态分区不会有内部碎片，但是会有外部碎片。如果内存中空闲空间的总和本来可以满足某进程的需求，但由于进程需要的是一部分连续的内存空间，因此这些“碎片”不能满足进程的需求，可以通过紧凑（拼凑，Compaction)技术来解决外部碎片。紧凑技术就是操作系统不时地对进程进行移动和整理来达到将几个外部碎片凑成一片连续的分区这需要动态重定位寄存器的支持。 总结 动态分区分配算法 接着前面的思考问题，我们来思考一下对于具有许多个空闲分区都可以容下进程数据时我们应该使用哪种策略选取分区。 首次适应算法 顾名思义，该算法的思想就是每次都从低地址开始查找，找到第一个能满足大小的空闲分区。实现方法就是空闲分区以地址递增的次序排列，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小满足要求的第一个空闲分区。如下图： 那么很明显5号进程会放在1号空闲分区，6号进程会放到2号分区。这种算法没有什么问题，但是缺陷是可能前面有一个非常大的空闲分区可以放入很多很小的进程数据，但是后面有刚刚好可以放进该进程的大小的空闲分区，这样大的空闲分区会优先被使用，最终造成许多小的空闲分区，再来大的进程就放不下了。同时会导致许多小的空闲分区在低地址处排列，每次分配查找还要再经过这些分区，增加了查找的开销。 最佳适应算法 算法思想是由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因为为了保证当大进程到来时也能有连续的大片空间，可以尽可能多地留下大片的空闲区，所以优先使用更小的空闲区，这样就弥补了首次适应算法的缺点。实现方法是空闲分区按容量递增次序链接，每次分配内存时顺序查找空闲分区链（或空闲分区表）找到大小能满足要求的第一个空闲分区也就是最小的可以容纳该进程的空闲分区（符合人类思维，尽可能不浪费的多放） 加入现在有一个进程6那么显然要放到2号分区这样2号分区就只剩下1MB了就要同时更新到表或链的最前面。我们发现这种方法的缺陷是每次都选更小的分区放最后只会导致很多外部碎片。 最坏适应算法 又称最大适应算法，就是为了解决最佳适应算法的问题而产生的，为了避免留下太多的外部碎片，优先使用最大的连续空闲区，这样分配后剩下的空闲区就不会太小，更方便使用。实现也很简单就是按照容量递减次序排列，每次分配也是顺序查找找到大小能满足要求的第一个空闲分区。 其实我们发现对于首次适应算法如果恰巧大的分区在前面，小的分区在后面，那么实际上就和最适应算法你一样了，所以最坏适应算法的缺陷就是大分区快速被消耗，再来大进程放不下了。 邻近适应算法 弥补首次适应算法的查找开销大的缺陷，这个算法思想是每次都从上次查找结束的位置开始向两侧检索就能解决上述问题，哪侧先找到大小合适的就放下该进程，所以是双向链表。 首次适应算法每次都要从头查找，每次都必须需要先检索低地址的小分区。但是这种规则决定了当低地址有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会有可能把高地址部分的大分区空闲出来，所以首次适应算法有可能会出现最坏适应算法的缺点即外部碎片多但同时也可能出现最佳适应算法的优点即合理利用空间。 而邻近适应算法的规则可能导致无论低地址，高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大小分区更可能被使用，划分为许多小分区，最后导致无大分区可用，所以综合四种算法来看，首次适应算法的效果反而更好。 思考：四种分配算法的异同？ 算法 算法思想 分区排列顺序 优点 缺点 首次适应 从头到尾找合适的分区 空闲分区以地址递增次序排列 综合性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排列 可能会出现低地址处许多非常小的空闲分区加大查找开销 最佳使用 优先使用更小的分区以保留更大的分区 空闲分区以容量递增次序排列 会有更多的大分区被保留下来，更能满足大进程的需求 会产生很多太小的、难以利用的碎片导致查找算法开销大，回收分区后可能需要对空闲分区队列重新排序 最坏适应 优先使用更大的分区，以防止产生太小的不可用的碎片 空闲分区以容量递减次序排列 可以减少难以利用的小碎片（外部碎片） 大分区容易被用完，不利于大进程，算法开销大（最后也会造成许多小分区导致查找开销大） 邻近适应 由首次适应算法演变而来，每次从上次查找结束为止开始查找 空闲分区以地址递增次序排列（可排列成循环链表） 不用每次都从低地址的小分区开始检索，算法开销小 会使高地址的大分区也被用完 基本分页存储管理的基本概念 我们先看一个图： 我们可以看出此节我们就开始讲解非连续分配管理方式了，这里只是一种一个小部分而已。非连续分配就是为用户进程分配的可以是一些分散的内存空间。 地址空间 我们先回忆一下什么是地址空间，我们知道地址分为两种逻辑地址（相对地址）和物理地址（绝对地址）两者有一定的映射关系。 但是我们发现这种存储只能连续存储，这很不方便，所以引出了分页存储的概念。 分页存储 我们将内存空间分为一个个大小相等的分区（比如每个分区为4KB），那么每个内存分区就是一个“页框”（页框=页帧=物理块=物理页面）。每个页框都有一个编号，即“页框号“（页框号=页帧号=内存块号=物理块号=物理页号），页框从0开始编号。 将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分称为一个“页”或“页面”。每个页面也有一个编号，即“页号”，页号也是从0开始。 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，可以放到不相邻的各个页框中。 注意进程的最后一个页面可能没有一个页框那么大，也就是说分页存储有可能产生内部碎片，因此页框不能设置的太大，否则可能产生过大的内部碎片造成浪费。 思考：固定分区分配（分区大小相等）和分页存储的区别？ 我们第一想法一定是这个和分区大小相等的固定分区分配好像，实际上思路就是差不多的，只不过是前者是一个小空间里放一个作业，所以作业/进程还是连续分配的，并且分区大小无论是多大都有可能会放不下更大的进程并且内部碎片会很大，而现在分页存储类似于将作业分块离散存储在许多的小分区中，所以作业/进程本身是不连续的且相应的无论作业/进程多大理论上都可以放下（只不过是会分成许多页面存储在许多页框中)并且内部碎片在一定的页框大小时是很小可控的。 思考：那么我们怎么知道每个页面存放在了内存的那个页框中呢？ 所以我们同样需要建表来说明–页表 页表 每个进程都会被分为许多页面存放在许多同样数量的页框中，所以每个进程都要有一张的页表，所以页面一般存放在PCB中，所以页表会一直在内存中（毕竟PCB是一直在内存中）直至该进程销毁。 所以一个进程对应一个页表，进程的每个页面对应一个页表项，每个页表项由“页号”和“块号”组成。页表记录着进程页面和实际存放的页框之间的映射关系。每个页表项的长度是相同的。 思考：每个页表项多大？占几个字节？ 首先我们要走出误区，表项的个数只是和页面页框数量一样，但是大小不同，页框大小和页表表项没有直接关系，我们先看一下两者的区别。页框是存储数据的单位，而页表表项是存储页框号和页面号的单位。所以页框大小是人为划分的，但是一旦内存大小和页框大小确定了，那么页表表项也就确定了。比如下题： 假设某个系统物理内存大小为4GB，页面大小是4KB，则每个页表项至少应该为多少字节？ 首先内存大小为4GB也就是2^32字节，页面大小实际上等于页框大小，所以页面页框的大小都是4KB=2^12字节，所以一共可以有2^32/2^12=2^20个页框(页面当然也就是2^20个），编号为0~2^20-1，所以一共会有2^20个页表项并且编号至少需要20bit来表示，又因为一个字节为8bit,多以至少需要3个字节来表示。所以一个页表项为3B，一个页框或页面为4KB。 并且页表项肯定是连续的，假设页表中的页表项从地址为X的地方开始连续存放，那么第i号页表项的地址就是X+3*i,同时第i个页面的存储地址就是第i号页表项中所对应的块号。并且我们发现页号是隐含的，所以页号不占用存储空间，一个页表项所占空间就是块号所占的空间，页号就好像数组的键值一样是隐含不占用空间的。 并且还要注意，块号记录的不是页框的起始地址，而只是页框号，又因为0号页框号的起始地址就是0，所以j号内存块的起始地址就是j*内存块大小。 思考：如何实现地址的转换？ 我们回忆一下在连续存储时，操作系统有三种策略实现地址转换（绝对装入，静态重定位，动态重定位)。现在是分页离散存储，我们如何找到逻辑地址所对应的物理地址呢？我们知道虽然各个页面是离散存放的，但是页面内部是连续存放的。 所以如果想要访问逻辑地址A需要以下步骤： 确定逻辑地址A对应的“页号”P 找到P号页面在内存中的起始地址（需要查页表找到内存块号j,起始地址就是j*内存块大小) 确定逻辑地址A的“页内偏移量”W 逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W 逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W 思考：如何确定逻辑地址对应的页号和页内偏移量？ 我们以一道例题来讲解：假设在某个计算机系统中，页面大小时50B，某进程逻辑地址空间大小为200B，则逻辑地址110对应的页号、页内偏移量是多少？ 页号=逻辑地址/页面长度（取除法的整数部分） 页内偏移量=逻辑地址%页面长度（取除法的余数部分） 所以上面的题页面号=110/50=2，页内偏移量=110%50=10，所以逻辑地址可以拆分为页号和页内偏移量来表示。接下来我们去页表中寻找页号2所对应的块号j,那么物理地址就是j*50+10。这里我们是用十进制表示的，但是我们知道对于计算机来说，他的操作都是二进制串进行操作，现在我们还是按照这个思路来看一下二进制的表示： 在计算机内部，地址用二进制表示，如果页面大小刚好是2的整数幂，则计算机硬件可以很快就把逻辑地址拆分成页号和页内偏移量，这样自然转换到物理地址也就更快了。如果是2的整数幂，那么假设每个页面的大小为2^K字节，那么用二进制表示逻辑地址时，逻辑地址01串的末尾K为就是页内偏移量，其余部分就是页号。如下： 我们可以看出页面大小为2^12B，所以末尾12位就是黑色部分就是页内偏移量，同时红色的20位就是页号了。 这样我们可以就轻松的对逻辑地址进行拆分转换成物理地址了。又因为内存块的大小=页面大小，且块的起始地址就是页内偏移量为0的地址，所以各个块的地址可以表示为： 同样对于物理地址，假设现在我们通过查询页表得到1号页面存放在了9（1001）号内存块，那么 我们发现前面红色部分就是9的二进制串即内存块号 思考：二进制串中物理地址和逻辑地址的异同点？ 我们仔细观察发现逻辑地址和物理地址的表示公式都是如下（前提：页面大小是2的整数幂）： 逻辑地址=页面号+页内偏移量逻辑地址=页面号+页内偏移量 逻辑地址=页面号+页内偏移量 物理地址=页框号+页内偏移量物理地址=页框号+页内偏移量 物理地址=页框号+页内偏移量 所以假设现在页面大小为4KB=2^12B=4096B。那么4097的页号就是1，页内偏移量为1，所以逻辑地址二进制串为 并且通过查表得知1号页面存放在9号页框，那么物理地址就是 总结：页面大小刚好是2的整数幂的好处就是 逻辑地址的拆分更加迅速–如果每个页面大小为2^KB，用二进制表示逻辑地址，则末尾K为就是页内偏移量，其余部分就是页号。因此，如果让每个页面的大小为2的整数幂，计算机硬件就可以很方便地得出一个逻辑地址对应的页号和页内偏移量，而无需进行除法操作，从而提升了运行速度。 物理地址的计算更加迅速–根据逻辑地址得到的页号，查询页表找到对应存放的页框号，将二进制表示的内存块号和页内偏移量拼接起来，就可以得到最终的物理地址。 逻辑地址结构 实际上通过上面的例题我们已经掌握了逻辑地址的结构和应用，这里再给出严格定义，分页存储管理的逻辑地址结构如下图： 地址结构包括两个部分：前一部分为页号P，后一部分为页内偏移量W。在上图所示的例子中，地址为32位，其中0~11号为“页内偏移量”，或称“页内地址”，12~31位为“页号”。 如果有K位表示“页内偏移量”，则说明该系统中一个页面的大小是2^K个内存单元。如果有M位表示“页号”，则说明在该系统中，一个进程最多允许有2^M个页面。所以页面大小&lt;–&gt;页内偏移量位数。 思考：页面大小一般设为什么数比较好？ 当然就是2的整数幂啦，因为这样地址转换快，这也是现代操作系统大多的做法。当然考研的题中有些奇葩题（为了考而考）会出现页面大小不是2的整数幂的情况，那就只能按照最原始的公式计算了页号=逻辑地址/页面长度（取除法的整数部分），页内偏移量=逻辑地址%页面长度（取除法的余数部分）。 思考：从上面的结构中我们能否看出一些页号和页内偏移量的规律？ 我们可以易知页号简介反映了页框的数量，页内偏移量简介反应了一个页框的大小。那么当一个页框很大时，页内偏移量也就大，K值也就大，那么所占的地址位数也就多，那么相应的页号所占位数32-K也就越小代表着此时页号就下了，也就说明页框数量变少了，其实这很正常，毕竟空间就那么大，一个存储单元变大了，相应的存储单元数量自然就少了。 总结"},{"title":"文件存储与基本操作","path":"/wiki/操作系统笔记/文件存储与基本操作/index.html","content":"文件的物理结构 文件块，磁盘块 外存中的文件存储方式我们前面提到过实际上和内存中的分页存储类似，磁盘中的存储单元也会被分为一个个“块/磁盘块/物理块”，甚至在许多操作系统中，磁盘块的大小和内存块，页面的大小是相同的。 所以I/O操作的时间开销较大，一般要避免I/O操作（例如内存中页面调度优先淘汰干净页面以避免写回）或者降低I/O的操作次数例如上面讲到的PCB索引节点机制。因为在外存中也是分成一个个外存块，所以文件的逻辑地址也是逻辑块号+块内地址拼接的形式。用户给出的是逻辑地址而操作系统转换为物理地址进行映射。 连续分配 连续分配要求每个文件在磁盘上占有一组连续的块。如下图： 并且对应的文件目录中也需要记录起始块号，占据的块的长度： 并且由于逻辑地址-&gt;物理地址的方法相似，所以当用户给出逻辑块号后，只需要操作系统根据目录项FCB找到对应的物理块号=起始块号+逻辑块号即可，然后在检验合法后在拼接上块内地址即可完成，因此连续分配支持顺序访问和直接访问（随机访问）。 思考：连续分配存储的好处？ 当读取一个磁盘块时，需要移动磁头。那么访问的磁盘块距离越远，移动磁头所需要的的时间也就越长。所以连续分配时块号相邻，那么文件再顺序读/写时速度最快。 思考：连续分配的缺点是什么？ 我们考虑一种情况，比如下图： A此时是占用了连续的3个黄色的磁盘块，但是现在A要进行拓展，需要在增加一个磁盘块并且由于要连续存储，因此此时A放不下了，又因为后面的连续块都已经被橙色所占用，所以A只能全部迁移到绿色区域。这无疑会造成很大的开销。所以物理上采用连续分配的文件不方便拓展。 并且还会造成如上图的情况，这是连续分配存储的共性问题，大量的外部碎片会降低空间的利用率，当然那我们同样可以使用紧凑技术来处理碎片，但是很明显会有大量的开销。 链接分配 隐式链接 为了解决上面的外部碎片问题，我们采用链接分配磁盘块，这里先给出隐式链接的方法，还是如上图，我们此时把文件离散存储并记录起始块号和结束块号（中间块号不记录），每一个中间块都有一个尾指针指向下一个存储文件信息的磁盘块并且对用户开放，这样就不要紧凑技术仍然可以充分利用外部碎片了。如下图： 并且貌似文件拓展也就不是什么难事了所以不会有外部碎片，但是此时却产生了另一个缺点。 思考：这种链接方法的缺陷？ 我们发现此时实际上并不是连续存储了，那么就产生了非连续存储的一个常见问题，就是假设现在用户要访问逻辑块号i，那么操作系统找到对应的FCB然后从起始块开始一个一个查找直至找到所需块号，这样假设要读入逻辑块号i，那么需要i+1次磁盘I/O。这种采用隐式链接的方法，只支持顺序访问，不支持随机访问，查找效率低。另外，指向下一个盘块的指针也需要移动很长距离的磁头，时间开销较大。 显式链接 为了解决上面所遇到的问题，可以把用于链接文件各物理块的指针显式的存放在一个表中，即文件分配表（FAT,File Allocation Table)。同样目录中只需要记录起始块号即可，会另有FAT用来存储这些指针如下： 此时我们为每一个磁盘设置一张FAT，开机时，将FAT放入内存并常驻内存。因为此时按物理块号递增排列，所以物理块号可以隐含不需要占用额外的空间。 此时我们在观察目录表和FAT可以轻松得知文件aaa的磁盘块有2-&gt;5-&gt;0-&gt;1，bbb的文件一次存放在4-&gt;23-&gt;3中。此时如果我们得到了逻辑块号i，那么找到其实块号，如果i&gt;0,则查询内存中的文件分配表FAT，往后查找第i个物理块号即可。所以此时逻辑块号转换成物理块号不需要再进行读磁盘操作。 所以采用显式链接方式的文件，支持顺序访问，也支持随机访问（想访问i号逻辑块时，并不需要依次访问之前的0~i-1号逻辑块），由于块号的转换也不需要访问磁盘，所以相比于隐式链接来说，显式链接访问速度更快。并且显式链接也不会产生外部碎片，可以很方便的进行文件的拓展。 索引分配 这就是分页存储思想在外存中的应用，索引分配允许文件离散的分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表记录了文件的各个逻辑块对应的物理块（索引表的功能类似于内存管理中的页表–建立逻辑页面到物理页之间的映射关系）。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。 假设某个新创建的文件aaa的数据依次存放在磁盘块2-&gt;5-&gt;13-&gt;9,7号磁盘块作为aaa的索引块，即7号块存放aaa的索引表存放aaa文件的逻辑块号与物理块号的映射关系。所以我们注意到与FAT不同，索引分配中，索引表是一个文件对应一张。 同样我们也涉及到索引表项的字节大小的问题，我们假设磁盘总容量为1TB=2^40B，磁盘块大小为1KB，那么总共有2^30个磁盘块，所以索引表项即可以用4B来表示磁盘块号（同样我们也争取凑成2的整数次幂），因此索引表的逻辑块号也是可以隐含的。 所以，索引分配中逻辑块-&gt;物理块的转换就是通过查表得知，并且索引分配也是可以支持随机访问的，稳健拓展同样容易实现（只需要给文件分配一个空闲块，并增加一个索引表项即可）但是索引表需要占用一定的空间。 思考：一个磁盘块装不下文件的整张索引表时，此时如何解决？ 假设如果每个磁盘块1KB，一个索引表项4B，那么一个磁盘块只能存放256个索引项，但是如果一个文件的大小超过了256块，那么很明显此时一个磁盘块装不下文件的整张索引表，该怎么办。我们有以下几种解决策略： 链接方案 如果索引表太大，一个索引块放不下，那么可以将多个索引块链接起来存放。如下： 看似问题有效解决了，但是考虑一种情况：假设磁盘块大小为1KB，一个索引表项占4B，则一个磁盘块只能存放256个索引项。如果一个文件大小为256*256KB=64MB，那么这个文件一共需要256*256块,也就是256个索引块来存储，那么如果真的是按照链接形式存放，如果想要访问最后一个索引块就需要先将前面的255个全部访问一遍，这样顺序查找时间开销太大。 多层索引 建立多层索引（类似于多级页表），是第一层索引块指向第二层索引块，还可根据需要再建立第三层，第四层索引块。 如果采用这种二层索引，那么该文件的最大程度可以到达64MB，并且还可以根据逻辑块号算出应该查找索引表中的哪个表项。例如现在要查找1026号逻辑块： 1026/256=4,1026%256=2。所以先将第一层索引表调入内存，查询4号表项，然后在对应的二级索引表调入内存，再查询二级索引表的2号表项即可知道1026号逻辑块存放的磁盘块号了。这样访问数据块，需要3从I/O操作，那块采用K级索引结构，且顶级索引表未调入内存（一定要注意，一般顶级索引表常驻内存），那么访问一个数据块只需要K+1次读磁盘操作。同理如果是三层索引，那么文件最大长度就是256*256*256KB=16GB,并且查找到一个物理块需要4次磁盘读操作。 混合索引 多种索引分配方式的结合。例如：一个文件的顶级索引表中，既包含了直接地址索引（直接指向数据块），又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表）。 这样需要经常被访问的就放在直接地址索引，对于不经常使用的放在多级地址索引，高效同时长度拓展的也很大。非常合理，同时我们也可以进行文件的大小估计。例如上图中的最大文件长度就是65800KB，其实计算和多级索引类似。 三种索引分配的总结 索引策略 策略规则 缺点 链接方案 一个索引块装不下可以多个索引块链接存放 I/O次数过多，查找效率极低 多层索引 建立多级索引表，类似于多级页表 即便是小文件也需要K+1次读磁盘 混合索引 多种索引方式的结合，既有直接地址索引也有多级间接索引 对于小文件访问次数少，查找高效 ❗超级重点：一定要回根据多层索引和混合索引的结构（各级索引表必须放在一个磁盘块中）计算文件的最大长度，公式是： 个数∗索引块的大小个数*索引块的大小 个数∗索引块的大小 要回分析所需要的读磁盘次数，并且一定要注意题目条件–顶级索引块是否已经掉入内存。 总结 分配方式 怎样实现 目录项内容 优点 缺点 顺序分配 为文件分配的块必须是连续的磁盘块 起始块号、文件长度 顺序存取速度快，支持随机访问 会产生碎片，不利于文件拓展 链接分配（隐式链接） 除文件的最后一个盘块之外，每个盘块中都存有指向下一个盘块的指针 起始块号，结束块号 可解决碎片问题，外存利用率高，文件拓展实现方便 只能顺序访问，不能随机访问 链接分配（显式链接） 建立一张文件分配表FAT显式记录盘块的先后关系（开机后FAT常驻内存） 起始块号 除了拥有隐式链接的优点之外，还可以通过查询内存中的FAT实现随机访问 FAT需要占用一定的存储空间 索引分配 为文件数据块建立索引表，索引表存储在索引块中，如果文件太大，可采用链接方案，多层索引或者混合索引策略 链接方案记录第一个索引块的块号，多层/混合索引记录的是顶级索引块的块号 支持随机访问，易于实现文件的拓展 索引表需占用一定的存储空间，访问数据块前需要先读入索引块。如果采用的是链接方案，查找索引块时可能需要很多次读磁盘操作 混淆点：什么是支持随机访问？ 假设现在这个文件的逻辑结构是“顺序文件”，并且是定长记录，每个记录的长度是16B，那么i号记录的逻辑地址是多少？（从0开始编号） 每块大小为1KB，定长记录时16B，所以一各磁盘块可以存放64个记录，则： “文件的某种逻辑结构支持随机存取/随机访问”是指：采用这种逻辑结构的文件，可以根据记录号直接算出该记录对应的逻辑地址（逻辑块号，块内地址）。 文件存储空间管理 存储空间的划分与初始化 安装windows操作系统的时候必须经历的步骤–为磁盘分区（C盘，D盘等）。 存储空间管理–空闲表法 空闲表法主要适用于连续分配方式，这里是用一张空闲盘块表进行对空闲物理块的记录，如下： 如何分配磁盘块：其实和内存管理的动态分区分配很相似，为一个文件分配连续的存储空间，同样可以采用首次适应，最佳适应，最坏适应等算法来决定为文件配到那个区。 所以毋庸置疑回收磁盘块时肯定是情况也类似有以下几种情况： 回收区的前后都没有相邻空闲区 回收区的前后都是空闲区 回收区前面是空闲区 回收区后面是空闲区 所以我们也需要注意合并的问题。 存储空间管理–空闲表链法 空闲盘块链 操作系统保存着链头，链尾指针。分配时如果要申请K个盘块，那从链头开始依次摘下K个盘块分配，并修改空闲链的链头指针。回收时回收的盘块挂到链尾，并修改空闲链的链尾指针。这种方法适用于离散分配的物理结构，为文件分配多个盘块时可能要重复多次操作。 空闲盘区链 操作系统保存着链头，链尾指针。 分配时若某文件申请K个盘块，则可以采用首次适应，最佳适应等算法，从链头开始检索，按照算法规则找到一个大小符合要求的空闲盘区， 分配给文件。若没有合适的连续空闲块，也可以 将不同盘区的盘块同时分配给一个文件，注意分配后可能要修改相应的链指针、盘区大小等数据。 回收时若回收区和某个空闲盘区相邻，则需要将回收区合并到空闲盘区中。若回收区没有和 任何空闲区相邻，将回收区作为单独的一个空闲盘区挂到链尾。 这种方法离散分配和连续分配都适用，为一个文件分配多个盘块时效率更高。 存储空间管理–位示图法 其实就类似于矩阵存储，但是又不是完全一样，如下图： 这是磁盘的情况，那么我们可以列出一种特殊的矩阵形式，如下： 他是由字号和位号来表示的，因为这个矩阵时16列，所以一个字号就是代表几个16，而位号就是几个1，优点类似于满16进1的表示意味。 位示图：每个二进制位对应一个盘块，在本例中，“0”代表空闲，“1”代表盘块已分配。位示图一般用连续的“字”来表示，如本例题中一个字的字长是16，字中的每一位对应一个盘块。因此可以用（字号，位号）对应一个盘块号。当然有的题目中也描述为（行号，列号）。但是总之就是要自己会推算出每个盘块的空闲状态。这里主要要注意开头的号码是0还是1千万要注意一个字是多少位。 (字号,位号)=(i,j)的二进制位对应的盘块号b=n∗i+j(字号,位号)=(i,j)的二进制位对应的盘块号b=n*i+j (字号,位号)=(i,j)的二进制位对应的盘块号b=n∗i+j 所以如下图我们可以推出： 同理我们也可以一直盘块号反推出字号和位号 b号盘对应的字号i=b/nb号盘对应的字号i=b/n b号盘对应的字号i=b/n b号盘块对应的位号j=b%nb号盘块对应的位号j=b\\%n b号盘块对应的位号j=b%n 所以我们可以反推出： 所以分配时：若分配需要K个块， ①顺序扫描位示图，找到K个相邻或不相邻 的“0” ②根据字号、位号算出对应的盘块号，将相应盘块分配给文件 ③将相应位设置为“1” 回收时： ①根据回收的盘块号计算出对应的字号、位号 ②将相应二进 制位设为“0” 存储空间管理–成组链接法 空闲表法和空闲链表法都不适用于大型文件系统，因为空闲表或者空闲链表会过大。所以UNIX系统采用了成组链接法对磁盘空闲块进行管理。 文件卷的目录区中专门有一个磁盘块为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。 超级块记录的是下一组的空闲块数，然后底下表示的就是空闲块号，并且这些空闲块不是连续的，而是离散存储使用指针相连的，这里只是为了方便表示。所以现在上图中的情况是表示超级块表示下一组有100个空闲块分别是201~300号同时发现300号，即此时300号是空的，但是同时300号有表示下一组有100个空闲块分别是301~400号，同时400号表示下一组7801~7900是空闲块，但是当遇到-1表示这个是空闲块的末尾了即使空闲块此时显示一个正整数但是此时也表示没有空闲块了。 思考：如何分配空闲块？ 我们现在假设需要给一个空闲块分配，那么首先检查第一个分组的块数是否满足。发现1&lt;100所以第一组就可以满足，然后分配第一组中的一个空闲块并修改数据即可。所以加入一个后变成： 此时第一个超级块变成了99，同时201~300号中有一个变成了非空闲块。一定要注意即使此时300上面显示下一组的空闲块数说明他是一个空闲块但是他仍然自身还是一个空闲块。 现在我们假设要分配100个空闲块，那么显然此时第一组刚好放下，所以201~300全部填满都变成了非空闲块，但是此时300底下也有一组空闲块为301~400所以此时不能放在300底下了赋值到超级块底下如下： 所以超级块第一个位置是400，直接指向400开头的组，所以此时超级块底下为400，7801~7900。 思考：如何回收非空闲块？ 因为每组就只能100（一般是规定好的最大值），那么此时下图中： 超级块此时是99表示下一组有99个空闲块，还可以回收一个，所以回收的如果刚好1个那么就放到第一组的末尾。但是如果此时要回收100个，那么就会超了，所以要新建一组来存放空闲块，并且组头用来标记下一组的空闲块数，如下图： 那么此时组成的100个空闲块的一组就组成一个新组并且300中的400指向之前的400开头的组，那么此时超级块就表示第一个组只有1个空闲块了。 对于成组链接法不要求掌握，确实不太好描述和理解。主要是知道超级块是一切的起点然后同时记录着下一组的空闲块数就好。我讲的不太好，可以参考这篇博客大佬博客 总结 文件的基本操作 这里我们学习基本功能的具体实现方法，了解即可 创建文件 需要调用Create系统调用，主要需要提供以下几个参数： 文件所需要的外存空间大小（如：一个盘块，即1KB）。 文件存放的路径(“D:/Demo”) 文件名（这个地方默认为&quot;新建文本文档.txt&quot;) 操作系统在进行Create系统调用时，主要进行了两件事： 在外存中找到文件所需的空间（结合上小节学习的空闲链表法，位示图等） 根据文件存放的路径的信息找到该目录对应的目录文件（此处就是D:/Demo目录)，在目录中创建该文件对应的目录项。目录项中包含了文件名、文件在外存中的存放位置信息。 删除文件 进行Delete系统调用，需要以下几个参数： 文件存放路径（D:/Demo ） 文件名（test.txt） 操作系统在处理Delete系统调用时，主要做了几件事： 根据文件存放路径找到对应的目录文件，从目录中找到文件名对应的目录项 根据该目录项记录的文件在外存中的存放位置。文件信息大小等回收文件占用的磁盘块。（同样的，回收时也需要根据空闲链表，空闲表，位示图等策略回收） 从目录表中删除文件对应的目录项 打开文件 在很多操作系统中，在对文件进行操作之前，需要用户使用Open系统调用打开文件，需要提供以下几个参数： 文件存放路径（D:/Demo） 文件名（test.txt) 要对文件的操作类型（如：r只读，rw读写等） 操作系统需要处理Open系统调用时，主要做一下几件事： 根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项，并检查该用户是否有指定的操作权限。 将目录项复制到内存中的“打开文件表”中，并将对应表目的编号返还给用户，之后用户再使用打开文件表的编号来指明要操作的文件。 思考：一共有多少个打开文件表？ 每个进程会对应着自己的一个打开文件表，同时系统也还拥有一张系统的打开文件表： 关闭文件 与打开文件相反，操作也类似。 一定不要忘记最后一步的系统打开文件表项的操作。 读文件 进程使用read系统调用完成读操作，需要指明是哪个文件（在支持“打开文件”的操作系统中，只需要指明文件在打开文件表中的索引值就行了），还需要指明要读入的数据大小、读入的数据的存放位置。 操作系统在处理read系统调用时，会从读指针指向的外存中，将用户指定大小的数据读入到内存的指定存放位置。 写文件 进程使用write系统调用完成写操作，需要指明是哪个文件（在支持“打开文件”操作系统中，只需要提供文件在打开文件表中的索引号即可），还需要指明要写出多少数据，写回外存的数据的存放位置。 操作系统在处理write系统调用时，会从用户指定的内存区域，将指定大小的数据写回写指针指向的外存。 思考：读写操作的细节？ 读操作是数据进入内存，写操作是写回外存，并且读/写指针都是指向的外存，一定要注意。 总结 实际上当遇到文件重名时，系统会请求用户端能否使用(1)(2)后缀表示或者用户端更改文件名。"},{"title":"段页式管理与虚拟内存概念","path":"/wiki/操作系统笔记/段页式管理与虚拟内存概念/index.html","content":"基本分段存储管理 分段 实际上类似于分页管理中的“分页”思想。我们先看一下分段的定义。 地址空间：按照程序自身的逻辑关系将程序划分为若干个段，每个段都有一个段名（在低级语言中，程序猿使用段名来编程），每段从0开始编制。而分段的内存分配规则就是：以段为单位进行分配，每个段在内存占据连续空间，但各个段可以离散存储不相邻，所以大小也是可以不相等的（不像分页必须规定固定大小的页帧）。 思考：为什么要引进分段的概念？ 我们熟悉的数据段，代码段都是分段的概念，那么分段和分页的区别是什么呢，又为什么要引入分段的概念呢？我们思考分页的存储方式，他是直接将进程按照固定大小切成许多小部分存到了不同的页。但是这里会涉及到一个尴尬的问题，就是大部分页要不存的全是代码，要不存的全是数据，但是总是会有那么几个页且在了数据和代码的交界处，这样这个页就会同时存储着数据和代码的混合体，这种页对于系统管理当然是没有问题的，但是对于编程人员来说就会可读性很差，不友好，导致用户编程不方便。按照人类的正常思维，最好将程序的不同的种类分段，这一段全存储数据，这一段全存储数据等等这样就会对人类可读友好。所以引进了段的概念。即分页是按照物理大小划分，分段是按照逻辑功能模块划分。 那么分段系统中同样有逻辑地址此时的逻辑地址是由段号（段名）和段内地址（段内偏移量）组成，如下： 段号决定每个进程最多可以分为几个段，而段内偏移量决定了每个段的最大长度是多少。如上图这样的32位划分，那么如果系统是按照字节编址，那么段号16位，因此程序最多可以分为2^16=64K个段，段内地址为16位，因此每个段最大长度为2^16=64KB。 同样的和分页查找地址类似，段中的某一个地址也是根据段号+段内偏移量找到具体的位置，如下： 那么 段号一般是用[]包裹，然后根据逻辑地址和段号就可以求得段内偏移量同样也需要段表查找到段的物理起始地址然后就可以找到真正的物理地址进行相应的读/写操作了(实际上和分页存储的查找方式是一样的)。 段表 问题：程序会被分为许多个段，各段离散地装入内存中，为了保证程序能正常运行，就必须从物理内存中找到各个逻辑段的存放位置。因此同样需要建立一张段映射表简称“段表”。 不同的是此时段表没有块号而是改为基址，并且有新添加了一栏段长，这是因为分段存储中段的大小长度不固定而导致的。所以物理块的起始地址也就不能使用X+4*M这种来计算了。 这里有几个要注意的点： 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称“基址”）和段的长度 各个段表项的长度是相同的。例如：某系统按照字节寻址，采用分段存储管理，逻辑地址结构为（段号16位，段内地址16位），因此使用16位即可表示最大段长。物理内存大小为4GB（可以用32位表示整个物理内存）。因此可以让每个段表项占16+32=48位，即6B。由于段表项长度相同，因此段号是可以隐含的，不占存储空间。若段表其实地址为,。则K号段对应的段表项存放的地址为M+K*6。 思考：分段存储和大小不等的固定分区分配的区别？ 我们知道在讲解分页时我们对比了分页和固定大小的固定分区分配两者的区别。这里我们同样来区分以下分段和大小不等的固定分区分配的区别。大小不等的固定分区分配是将内存块分成大小不等的一个个小空间，每个空间存放一个作业/进程，各个空间之间的进程/作业互不干扰。但是分段存储是将进程首先分成许多个大小长度不固定的块然后离散存储到物理块的不同位置处。这就是区别。 思考：此时我们是不是也需要考虑页表项凑成刚好被放入整数个时的字节大小问题？ 答案是不用的，我们思考以下问什么，对于分页存储每一个存储单元是固定大小的，所以需要连续存储时就是选取相邻连续的页帧凑成的，只有刚好恰好装满整数个时才能实现页表项之间的连续。但是现在段存储长度是可以改变的，所以就是页表项有多少，段的大小就是多少不需要再去凑了，毕竟段表肯定也是以段的方式存储到物理内存的（此时我们不讨论段页式存储，就仅仅是纯页式存储或纯段式存储） 思考：有没有可能有多级段表？ 应该是没有的，毕竟之所以有多级页表是因为页完全不需要连续，可以在离散的基础上再次离散，但是段就是按照逻辑模块进行划分的最小单元了，在离散逻辑模块就不连续了。所以应该是没有多级段表的。 地址变换 同样的我们也讨论以下如何实现逻辑地址到物理地址的转换。此时就没有什么“相除取页号，取余得偏移量”的步骤了，段式存储最大的特点就是在指令中直接就指出了段号和逻辑地址，那么直接就可以求得段内偏移然后查表就可以了。即少了求段号的一步（段号一般用[]包裹）。 同样的此时在二进制串中的转换方法是不变的，还是后K位表示偏移量，剩下的位数表示段号，然后根据段号查表找到基址，那么物理地址就是基址+段内偏移量。多简单，都不用像页式存储那样还得得到块号自己算物理起始地址，此时段式存储直接就可以根据表得到基址。 具体的变换演示如图： 我们一定要注意此时还多了一个步骤就是步骤4需要进行检查段内偏移量是否越界了。这个可千万不要忘记。所以也是需要进行两次访存一次是查表，一次是访问数据。 分段、分页管理的对比 我们从以下几个角度探讨： 角度1：划分单位 页是信息的物理单位，分页的主要目的是为了实现离散存储，提高内存的利用率（内部碎片很少）。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。 段是信息的逻辑单位，分段的主要目的是更好的满足用户需求，一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显示的给段名。 角度2：单位大小 页的大小固定由系统决定 段的长度不固定，决定于用户编写的程序 角度3：地址空间 分页的用户进程地址空间是一维的，程序猿只需要给出一个记忆符即可表示一个地址 分段的用户进程地址空间是二维的，程序猿在标识一个地址时，既要给出段名，也要给出段内地址。 角度4：信息的共享与保护 分段比分页更容易实现信息的共享和保护。不能被修改的代码成为纯代码或可重入代码（不属于临界资源），这样的代码是可以共享的。可修改的代码是不能共享的（比如，有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致） 思考：如何使得某个段是临界资源可以被共享？ 很简单，就是使表项的基址指向同一个段即可： 而页不是按照逻辑模块划分的，这就很难实现共享。因为假设一个函数模块被放在了两个页A,B，那么如果想让这个函数模块被共享，那么就需要A,B页都是可以允许共享的，但是如果此时A只有一半存的是函数模块，另一半存的是不允许共享的资源，那么显然现在A就很难实现共享，那么这个函数模块就也不能被共享了，这种冲突就造成了分页很难实现共享，同时风险也就更大。 角度5：访存流程 对于分页存储（单级页表）：第一次访存–查内存中的页表，第二次访存–访问目标内存单元。总共两次访存。 对于分段存储：第一次访存–查内存中的段表，第二次访存–访问目标内存单元。总共两次访存。 并且分页和分段都可以引入快表机构，这样近期访问过得表项再次被访问时就只需要访存一次了。 总结 段页式管理方式 前面我们一直都是讲解的纯分页式管理或者纯段式管理，那么能不能同时集合两者的优点，这就出现了段页式管理方式。 分页、分段的优缺点 存储方式 优点 缺点 分页管理 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 不方便按照逻辑模块实现信息的共享和保护 分段管理 很方便按照逻辑模块实现信息的共享和保护 如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生很大的外部碎片（当然可以使用“紧凑”技术来解决，但是时间开销大） 分段+分页=段页式管理 我们前面说过页可以再分页，但是段不能再分段，但是我们可以用分段后在分页的方式存储，这样逻辑模块功能划分的优点保存的同时也可以将较大的段离散存储。所以首先要知道段页式存储一定是先分段再分页并且是对相同的段分页。如下： 段页式管理的逻辑地址结构 那块此时逻辑地址的结构也是变化的，我们此时会将逻辑地址变为如下： 此时就没有段内偏移量了，“分段”对用户是可见的，程序猿编程时需要显式地给出段号、段内地址。而将各段“分页”对用户是不可见的，系统会根据内地址自动划分页号和页内偏移量来具体存储段的位置。因此段页式管理的地址结构也是二维的。 段号的位数决定了每个进程可以最多被分成几个段，页号位数决定了每个段可以最多被分成几个页，而页内偏移量决定了页面大小和内存块大小（当然如果是多级页表存储，页号还可以分成许多多级页号更复杂）。 例如上图中的结构如果系统是按字节寻址的，那段号占16位因此该系统中，每个进程最多有2^16=64个段，而页号占4位，因此每个段最多被分为2^4=16页，页内偏移量是12位，因此每个页面/内存块大小为2^12=4096=4KB。 段表、页表 显然此时段表和页表也是有变化的，如下图： 此时每个段对应一个段表项，每个段表项由段号，页表长度（实际上就是段长度），页表存放块号（可以算出页表其实地址）组成。每个段表项长度相同，段号是隐含的。所以段表变化很大，页表基本上不变。每个页表对应一个页表项，每个页表项由页号和页面存放的内存块号组成。每个页表项长度相同，页号是隐含的。当然对于页表为了连续存储公式计算方便，最好还是一个页帧可以放入整数个页表项。 地址变换 注意此时一般来说就需要三次访存了，一次查段表，二次查页表，三次访存目标内存单元。当然如果加入了快表，那就只需要一次访存就是访存目标内存单元。 总结 虚拟内存的基本概念 这部分主要谈论内存管理中内存空间的扩充部分。我们之前已经讲过覆盖和交换技术了，那么这次来讲一讲虚拟存储技术（在中级调度中有过应用）。 传统存储管理方式的特征与缺点 所以我们之前讲的都是属于传统存储管理的部分。缺点是长期占用内存，所以可以使用虚拟存储技术解决。在传统的存储管理方式中有以下特点： 一次性：作业必须一次性全部装入内存才能开始运行。这会造成两个问题：一是作业很大时不能全部装入内存导致大作业无法运行，二是当大作业要求运行时，由于内存无法容纳所有作业，因此只能有少量作业能运行，导致多道程序并发度降低。 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分就可以正常运行了，这就导致内存中会驻留大量的，暂时用不到的数据，浪费了宝贵的内存资源。 而以上的缺点我们都可以使用虚拟存储技术来解决。 局部性原理 我们之前已经讲过局部性原理了，实际上虚拟存储技术就应用了局部性原理的思想，已知的应用有快表机构就是将常访问的页表项副本放到更快速访问的TLB中，这种高速缓冲技术的思想就是利用了局部性原理，将近期频繁访问到的数据放到更高速的存储器中，暂时用不到的就放在更低速的存储器中。 虚拟内存的定义和特征 基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。（覆盖技术的思想） 如果内存空间不够，由操作系统将内存中暂时用不到的信息换出到外存。（交换技术的思想） 在操作系统的管理下，在用户看来似乎有一个比实大的多的内存，这就是虚拟内存。（操作系统虚拟性的体现） 思考：覆盖技术，交换技术，虚拟存储技术的区别？ 我们可以发现实际上虚拟内存的出现就是虚拟存储技术的具体应用，而且思想貌似就是覆盖交换技术，实际上他们的思路就是一样的，只是作用的单位不同。覆盖技术和交换技术都是对于进程来说的，而虚拟内存是对内存中的数据信息块进行管理。 易混淆知识点： 虚拟内存的最大容量是由计算机的地址结构（CPU寻址范围）确定的 虚拟内存的实际容量=min(内存和外存容量之和，CPU寻址范围) 例如：某计算机地址结构为32位，按字节编址，内存大小为512MB，外存大小为2GB。 那么虚拟内存的最大容量就是2^32B=4GB（虚拟出来的），但是虚拟内存的实际容量就是min(2^32B,512MB+2GB)=2GB+512MB 思考：虚拟内存的特征？ 虚拟内存凭借虚拟存储技术有以下三个特点： 多次性：无需在作业运行时一次性全部装入内存，而是允许分成多次调入内存 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量远大于实际容量。 虚拟内存技术的应用条件 虚拟内存技术允许一个作业多次调入内存，如果是采用的连续分配方式很明显不方便，所以虚拟内存的实现方式需要建立在离散分配的内存管理方式基础上。 但是区别于传统的离散分配存储管理，虚拟内存不是一次性装入全部，所以才会像之前所说的出现缺页中断等现象，此时就需要请求调入内存了，所以在虚拟内存技术中很明显会频繁的发生&quot;请求&quot;所以在虚拟内存技术下的存储方式叫做 所以主要区别就是在程序执行过程中，当所访问的信息不在内存时，有操作系统负责将所需要的信息从外存调入到内存中，然后继续执行程序。若内存空间不够了，就由操作系统将内存中暂时不需要的信息换出到外存。所以操作系统需提供请求页面功能和页面置换功能，当然后面会讲解页面置换算法决定具体该将那个信息暂时调出内存。 总结"},{"title":"文件系统基础与目录","path":"/wiki/操作系统笔记/文件系统基础与目录/index.html","content":"初识文件管理 那么我们现在要了解一席文件内部的数据的组织方式与文件之间的组织方式。并且思考从下往上看OS是提供哪些服务方便用户、应用程序使用文件，而从上往下看文件数据又要怎么存放到外存（磁盘）的问题。 文件属性（文件构成） 文件名：由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。 标识符：一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用来区分各文件的一种内部名称（同样的，操作系统为各个进程是通过PID来识别的）。 类型：文件的类型 位置：文件存放的路径（让用户使用），在外存中地址（操作系统使用，对用户不可见） 大小：文件的大小 创建时间，上次修改时间，文件所有者信息等 保护信息：对文件进行保护的访问控制信息 文件内部的组织方式 无结构文件：如文件文件，就是一些由二进制或者字符流组成，又称“流式文件” 有结构文件：如数据库表，由一组相似的记录组成，又称&quot;记录式文件&quot;，这里要注意记录是一组相关数据项的集合，而数据项才是文件系统中最基本的数据单位。 文件之间的组织组织方式 实际上就是通过目录来实现分层，这里的层最好不要太少（这样会造成目录下文件密度过大），同时也不要太多，否则分层太多，搜索查找文件时间开销大。 思考：文件夹是有结构文件吗？ 当然是，用过电脑的都知道文件夹可以以文件项排列各文件的详细信息，很明显每一个文件此时都是一个记录，而每一个文件的具体文件名，大小，创建时间等就是文件夹这一个记录式文件的数据项。 OS向上提供的服务 创建文件：可以“创建文件”，点击新建后，图形化交互进程在背后使用“create系统调用” 删除文件：可以“删除文件”，点击删除操作之后，图形化交互进程通过操作系统提供的“删除文件”功能，即delete系统调用，将文件数据从外存中删除 读文件：将文件数据从外存中读入内存，这样才能让CPU处理，使用的是read系统调用 写文件：将更改过的数据写回外存，使用的是write系统调用 打开文件：读/写之前需要打开文件 关闭文件：读/写文件结束之后需要关闭文件 基本上更多复杂的功能都是通过上面的基本功能组合实现的。 文件如何存放至外存 我们发现其实这个就是分页存储的思想，所以外存中与内存一样也是分成一个一个存储单元然后将文件切割离散存储，当然如果文件特别小，那么一个存储单元就可以放下整个文件，所以明显外存中也会有内部碎片。 思考：这里我们思考是不是外存中也会有连续存储的方式？ 肯定是有的，这里也有固定分区分配的存储思想和分页存储思想两种方式存储文件。 操作系统需要完成的其他文件管理的操作 文件共享：使多个用户共享一个文件 文件保护：保证不同的用户对文件有不同的操作权限 总结 大部分都是概念性知识点，记住即可 文件的逻辑结构 类似于数据结构的“逻辑结构”和“物理结构”，如线性表就是一种逻辑结构，在用户看来，线性表就是一组有先后顺序的元素序列。而线性表这种逻辑结构可以通过许多种物理结构实现，不如顺序表和链表均可以，顺序表是元素在逻辑和物理上都是连续相邻的，而链表是物理上不相邻但是逻辑上相邻的数据结构。所以顺序表的线性表可以随机访问，而链表形式的线性表就不可以了。所以算法的具体实现与逻辑结构和物理结构都有关（文件也是一样，文件操作的具体实现和文件的逻辑结构，物理结构有关) 无结构文件 首先无结构文件前面也提到过了就是“流式文件”是一组二进制或者字符流，所以没有明显的结构，也就不用讨论“逻辑结构”的问题。 有结构文件 前言：记录的分类 记录式文件，每条记录都是由若干个数据项组成的集合。一般来说，每一条记录的一个数据项都是一个关键字（可以作文识别不同记录的ID）。 根据各条记录的长度我们可以将记录分为定长记录和可变长记录： 定长记录：一般每条记录的长度是必须等长的，每一个数据项所在位置也都是相同不变的。 可变长记录：数据项的长度不一定相同因此记录的长度也是各不相同的，甚至某一个数据项没有是可以删掉的即下图中如果无特长可以直接删掉。 顺序文件 文件中的记录一个一个的地顺序排列（逻辑上），记录可以是定长或者变长的。各个记录在物理上可以是顺序存储或者链式存储。 根据记录之间的顺序是否与关键字有关我们分成： 思考：加入现在知道文件的起始位置，那种文件可以快速找到第i个记录的位置？那种文件又可以找到某个关键字对应的记录的位置？ 首先链式存储肯定是不可能实现随机随机存放的，所以每次都需要从头开始查找这样很难快速找到第i个文件的位置。所以快速查找只能在顺序存储中，又由于可变长记录长度不相同不能使用X+i*M的连续查找公式所以也不能和实现快速查找，所以只有定长记录的顺序存储才可以实现，同时只有采用顺序结构即存储的顺序和关键字有关的才可以找到关键字对应的记录的位置。 很明显从上图我们就可以看出可变长记录不能随机存取的原因了，由于长度不同，连续查找公式是不能使用的。定长记录的顺序文件，如果采用物理上的顺序存储那么就可以实现随机存取。如果还能保证记录的顺序结构那么就可以关键字快速检索了。一般上，考试题中的“顺序文件”指的是逻辑结构和物理结构上都是顺序存储的文件。所以顺序文件一般如果不说都是默认定长记录所以可以随机存放，但是缺点是增加/删除一个记录就很复杂，需要整体记录前移或者后移，但是如果是串结构那么就相对简单。 索引文件 对于很多场景都需要快速查找都第i个记录的位置，但是又是可变长记录文件，那么这时就需要索引文件的逻辑结构形式，即建立一张索引表，每个索引表都有唯一的索引号，长度m(毕竟是可变长的需要记录)以及一个指针ptr指向文件再外存中存放的地址，所以索引文件在结构上还顺序的，但是物理结构上是可以离散存储的，当然如果你非得在物理结构上也顺序存储也可以。 其实感觉就是分页存储的思想，只不过那个是讨论内存存放时提出的方法，现在这种思想应用在了文件管理上，实际上思想类似。索引表本身是定长记录的顺序文件（这里指的是物理结构上也顺序存储，否则不能实现随机存取），因此可以快速找到第i个文件的索引项。并且可以在索引表中以关键字作为索引号内容，若按照关键字顺序排列，那么还可以实现按照关键字折半查找。这是我们在尝试删除/增加一个记录时就是对索引表进行修改。因为索引表有很快的检索速度，所以主要用于对信息处理的及时性要求很高的场合。并且，可以用不同的数据项建立很多个索引表，如：学生信息表可以用关键字“学号”“姓名”都各建立一张索引表。这样就可以根据不同的关键字检索文件了。 索引顺序文件 我们思考一个问题，每个记录都会对应一个索引表项，因此索引表可能会非常巨大。比如：文件的每个记录平均只占8B，而每个索引表项占32个文件，那么索引表都要比文件本身还要大4倍，这样就降低了空间利用率。所以提出了索引顺序文件。 我们可以看出索引顺序文件的索引项不需要按关键字顺序排列，这样就极大方便新表项的插入，同时在上图中我们发现学生记录按照学生的姓名开头字母进行分组，每一个分组就是一个顺序文件，分组内的记录不需要按关键字排序。索引顺序文件就是索引文件和顺序文件思想的结合。索引顺序文件同样会为每个文件建立一个索引表，但是不是每一个记录对应一个索引表项，而是每一组数据对应一个索引表项。然后每一组文件中顺序存储，这样就大大瘦身了。 思考：三种文件的区别？ 顺序文件就是顺序存放，那么查找时如果是不定长就只能逐一查找并且顺序存放不好增删所以出现索引文件每一个记录对应索引表一定长个表项，索引表是物理顺序存放那么查找时就可以很快找到并且增删只需要修改索引表项，但是空间会很大毕竟索引表项和文件各占用很大的空间，所以索引顺序文件是将整个文件组按某些标准分成许多组然后为每个组建立一个索引表这样就实现了瘦身。 思考：用这种索引顺序策略能否解决不定长记录的顺序文件检索速度慢的问题？ 我们假设现在有一个10000个记录的顺序文件（不定长记录的物理结构顺序存储的顺序文件），那么如果根据关键字检索文件，只能从头开始顺序查找，平均需要查找5000个记录。 如果是索引文件，虽然表项定长，但是索引文件只是在已知起始地址查找第i个文件时加快了速度，现在是要查找某个关键字的搜索，那么也只能从头开始顺序查找，所以最终也是5000次平均查找。 如果使用的是索引顺序文件结构，可以把10000个记录分成100组每组100个记录，那么先顺序查找索引表找到分组（共100个分组，所以平均需要查找50次）然后找到分组后再在分组中顺序查找记录也是平均需要50次，那么最终只需要100次。很明显确实相较于顺序文件和索引文件有了检索速度的提升。 思考：但是如果现在是10^6的记录怎么办？ 我们发现如果是10^6个记录，那么此时索引顺序文件的查找次数还是很大，所以此时多建几层次级索引表就好了（毕竟每建一层索引表理论上会减少查找没有必要的多组文件），所以此时就是多级索引顺序文件如下： 此时对于一个10^6记录的文件(注意还是可变长记录文件），可以先为该文件建立一张低级索引表，每100个记录为一组，所以总共会有10000个表项，即10000个定长的表项，然后再把这10000个定长记录再次分组为每组100个再为其建立顶级索引表，那么顶级索引表就有100个定长表项。 这里有个公式：N个记录的文件建立K级索引，则最优的分组是每组N^(1/K+1)个记录。这样检索一个记录的平均查找次数是 (N1/K+1/2)∗(K+1)(N^{1/K+1}/2)*(K+1) (N1/K+1/2)∗(K+1) 次，例如上面我们分成了2级，那么每组就是(10^6)^1/3=100个记录，并且平均查找次数就是（100/2)*(2+1)=150次。 总结 文件目录 文件控制块 思考当我们双击照片这个文件夹后OS是如何找到文件夹下的文件和显示到我们屏幕上的呢？ 实际上此时是借助文件控制块实现的，我们双击“照片”后，操作系统会在这个目录表中找到关键字“照片”对应的目录项（也就是记录，毕竟记录就是存得许多不同的数据项也就是关键字），然后从外存中将“照片”目录的信息读入内存，于是“照片”目录中的内容就可以显示出来了。所以我们所说的目录实际上就是一个索引表。 那么目录文件中每一条记录实际上就是一个文件控制(FCB),FCB实现了文件名和文件之间的映射，使得用户(用户程序)可以实现“按名存取”。FCB的有序集合就成为“文件目录”，一个FCB就是一个文件目录项。FCB中包含了一个文件的基本信息，存取控制信息使用信息等。当然最重要的就是文件名和文件存放的物理位置。 那么通过文件控制块FCB我们可以实现哪些功能呢？ 搜索：当用户使用一个文件时，系统根据文件名搜索目录，找到该文件对应的目录项。 创建文件：当创建一个文件时，需要在所属的目录中增加一个记录项。 删除文件：当删除一个文件时，需要在目录中删除相应的目录项。 显示目录：用户可以请求显示目录的内容，如显示该目录中的所有文件及相应的属性。 修改目录：某些文件属性保存在目录中，因为这些属性变化时需要修改相应的目录项（如：文件重命名等）。 目录结构 单机目录结构 早期的操作系统不支持多级目录，所以整个系统只建立一张目录表，每个文件占据一个目录项，单机目录实现“按名存取”，不允许有任何文件重名。在创建一个文件时，需要先检查目录中有没有重名文件，只有确定不重名后才能建立文件，并将新文件对应的目录项插入到目录表中。 很显然，不适合多用户(这里的用户值得是多程序,应用软件)操作系统。想一想也知道现在的应用程序肯定都有许多重名文件例如：data,dist.source,js等 两级目录结构 早期的多用户操作系统采用两级目录结构，分为主目录(MFD,Master File Directory)和用户文件目录(UFD,User File Directory)。 此时就允许有重名文件了只要不在一个FCB下，但是此时还是不够灵活，毕竟用户文件夹可能也需要有自己的目录，所以就有了多级目录结构。 多级目录结构 又称树形目录结构，灵活高效，解决了上面两种目录结构的缺陷。 此时因为有许多可能重名的文件但是他们所在的位置是不同的，所以要访问某个文件时要用文件路径标识文件，文件路径是一个字符串。各级目录之间用&quot;/&quot;隔开，从根目录出发的就是绝对路径，从当前位置或者当前位置的父目录出发就是相对路径。例如：./就是相对路径表示从现在的位置出发，…/是从当前位置的父文件开始出发明显也是相对路径，但是…/或者/就是根目录出发就是绝对路径了。 思考：为什么要用相对路径？ 考虑一个问题现在我们要对某个文件夹下的许多文件进行操作，那么如果使用绝对路径，那么每一次都要输入很长的根目录路径明显低效，而如果此时使用相对路径./就很方便简洁。同时不仅仅是为了输入简便，如果我们使用绝对路径，那每一次都需要从根目录开始逐一从外存读入对应的目录表，然后在找到该文件夹下的文件，而是用相对路径就可以直接一次性将这个文件夹读入内存然后访问文件。可以见到，在引入“当前目录”和“相对路径”以后，磁盘的I/O次数减少了，这样就提升了访问文件的效率。所以相对路径是常用的文件路径方式，当然对于某些特殊的情况是必须使用绝对路径的。 所以树形目录结构不仅可以很方便的对文件进行分类，层次结构清晰，而且也能够更加有效的进行文件的管理和保护。但是树形结构不便于实现文件的共享，所以提出了“无环图目录结构”。 无环图目录结构 可以用不同的文件名指向一个文件，甚至可以指向同一个目录（共享一个目录下的所有内容）。需要为每一个共享节点设置一个共享计数器，用于记录此时有多少个地方在共享该节点。用户提出删除节点的请求时，只是删除该用户FCB、并且使共享计数器减1，并不会直接删除共享节点。直至共享计数器为0时，才删除节点。 我们发现共享文件不是赋值文件。在共享文件中，由于各用户指向的都是同一个文件，因此只要其中一个用户修改了文件数据，其他所有用户都可以看到文件数据的变化。 FCB的改进 我们之前进行的瘦身策略，实际上是对目录项进行分组然后多级索引表的存储，但是对于同一个目录下的目录项最好是对应一个目录表，那么该怎样实现瘦身呢？我们可以对FCB进行修改，毕竟查找时只是按照“文件名”进行查找，只有文件名匹配才能读出文件的信息，所以可以考虑让目录表瘦身吗，如下： 瘦身前： 瘦身后： 思考：好处是什么？ 假设一个FCB是64B，磁盘块大小为1KB=2^10B，那么每个盘块只能存放16个FCB，如果一个文件目录中共有640个目录项，那么需要占640/16=40个盘块。因此按照某文件名检索目录平均需要查找320个目录项，平均需要启动磁盘20次（每次磁盘I/O读入一块）。但是如果瘦身后即使用索引节点机制那么文件名占14B，索引节点指针占2B，一个FCB只占用16B，那么一个盘就可以放64个目录项，那么按文件名目录平均只需要读入320/64=5个磁盘块。显然这就大大提升了文件检索速度。 只有找到文件名对应的目录项才会将索引节点放到内存中，索引节点中记录了文件的各种信息，包括在文件再外存中的位置，根据“存放位置”即可找到文件。存放在外存中的索引节点就叫做“磁盘索引节点”而当索引节点放入到内存后就称为“内存索引节点”。相比之下内存索引节点需要增加一些信息，比如：文件是否被修改，此时有几个进程正在访问该文件等。 总结"},{"title":"磁盘","path":"/wiki/操作系统笔记/磁盘/index.html","content":"磁盘调度算法 显然对于一个磁盘数据的读/写序列（中途可能会更新）使用不同的调度算法会产生不同的效率，这里我们也探讨一下几种不同算法的性能，那么指标肯定就是时间了所以我们先介绍几个指标概念然后介绍调度算法。 一次磁盘读/写操作需要的时间 寻道时间Ts 寻道时间Ts：又称为寻找时间，在读/写操作之前，将磁头移动到指定磁道所花费的时间。 启动磁头臂是需要时间的。假设耗时为s。 移动磁头也是需要时间的，假设磁头均匀移动，每跨越一个磁道耗时为m，总共需要跨越n条磁道，则： Ts=s+m∗nT_s=s+m*n Ts​=s+m∗n 现在的硬盘移动一个磁道大约需要0.2ms,磁臂启动时间约为2ms。 延迟时间Tn 延迟时间Tn:通过旋转磁盘，使磁头定位到目标扇区所需要的时间。设磁盘转速为r(单位:转/s，转/min)，那么平均所要的延迟时间为 Tn=(1/2)∗(1/r)=1/2rT_n=(1/2)*(1/r)=1/2r Tn​=(1/2)∗(1/r)=1/2r 1/r就是转一圈所需要的时间，找到目标扇区平均需要转半圈，因此再乘1/2，硬盘的典型转速为5400转/min，或者7200转/min。 传输时间Tt 传输时间Tt:从磁盘读出或向磁盘写入数据所经历的时间，假设磁盘转速为r，此次读/写的字节数为b，每个磁道上的字节数为N，则： Tt=(1/r)∗(b/N)=b/rNT_t=(1/r)*(b/N)=b/rN Tt​=(1/r)∗(b/N)=b/rN 每个磁道可存N字节的数据，因此b字节的数据需要b/N个磁道才能存储，而读/写一个磁道所需要的时间刚好又是一圈所需要的时间1/r。 总的平均时间Ta Ta=Ts+Tn+Tt=s+m*n+1/2r+b/rN 延迟时间Tn和传输时间Tt都与磁盘的转速有关，且为线性关系，而转速是硬件的固有属性，因此操作系统无法优化延迟时间和传输时间。 先来先服务算法（FCFS) 根据进程请求访问磁盘的先后顺序进行调度。例如：假设磁头的初始位置为100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道，那么按照FCFS的规则，按照请求的顺序，磁头需要一次移动到55、58、39、18、90、160、150、38、184号磁道。 磁头一共移动了45+3+19+21+72+70+10+112+146=498个磁道。响应一个请求平均需要移动489/9=55.3个磁道。（平均寻找长度）。 优点：公平，如果请求访问的磁道比较集中的话，算法还可以。 缺点：如果有大量进程竞争使用磁盘，请求访问的磁道很分散，那么FCFS在性能上很差，寻到时间长。 最短寻找时间优先（SSTF） SSTF算法优先处理的是离当前磁头最近的磁道，可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短。其实就是贪心思想，贪心解未必是最优解。 例如：假设磁头的初始位置为100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道： 磁头总共移动了(100-18)+(184-18)=248个磁道，响应一个请求平均移动248/9=27.5个磁道（平均寻道长度） 优点：性能好，平均寻道时间短 缺点：可能产生饥饿现象 扫描算法（SCAN） SSTF产生饥饿的原因是磁头有可能会在一个小区域内来回的移动，为了防止这个问题，可以规定，只有磁头移动到最外侧的磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。这就是扫描算法（SCAN）的思想。由于磁头移动方式很像电梯，因此也叫电梯算法。 假设某磁道为0~200号，磁头的初始位置是100号，此时磁头正在往磁道号增大的方向移动，那么此时有多个进程的请求访问：55、58、39、18、90、160、150、38、184号磁道。 一定要注意必须移动到磁道最边缘处才可以更改移动方向即使没有请求访问最边缘磁道也要经过。 磁头总共移动了（200-100）+（200-18）=282个磁道，响应一个请求平均需要282/9=31.3个磁道（平均寻道长度）。 优点：性能好，平均寻道时间短，不会产生饥饿现象 缺点：①只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求之后就不需要再往右移动磁头了。②SCAN算法对于各个位置磁道的响应频率不均匀（如：假设此时磁头正在向右移动，且刚处理过90号磁道，那么下次处理90号磁道的请求就需要等磁头移动很长一段距离，而相应了184号磁道的请求之后，很快又可以再次相应184号磁道的请求了） LOOK调度算法 扫描算法（SCAN）：只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求之后就不需要再往右移动磁头了。LOOK算法就是为了解决这个问题，如果在磁头移动方向上没有别的请求，就可以立即改变磁头移动方向。（边移动边观察，因此叫LOOK） 假设某磁道的磁盘为0~200号，磁头的初始位置为100号磁道，且此时磁头正在往磁道号增大的方向移动，有多个进程先后陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 那么响应一个请求平均寻道长度为250/9=27.5磁道 优点：比起SCAN算法来，不需要每次都移动到最外侧或最内侧时才改变磁头方向，使寻道时间进一步缩短。 缺点：只解决了SCAN算法的缺点1，响应频率还是不均匀。 循环扫描算法（C-SCAN） SCAN算法对于各个位置磁道的响应频率不平均，而C-SCAN就是解决了这个问题。规定只有磁头向右移动或者向左移动时才可以处理磁道访问请求，而返回时直接快速移动到起始端中间返回过程不做任何请求任务。 假设某磁盘的磁道为0~200号，磁头的初始位置为100号磁道，且此时磁头正在向磁道号增大的方向移动，那么有多个进程陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 优点：比起SCAN算法，对于各个位置的响应频率很平均 缺点：只解决了SCAN算法的缺点2，但是还是只有到达最边缘的磁道才可以返回到起始端。 C-LOOK调度算法 C-SCAN算法的主要缺点是只有到达最边缘的磁道才可以返回到起始端，但是我们也可以模仿LOOK算法边移动边观察，当后面没有更大的请求磁道号时就不用再移动到最边缘了，直接返回到起始端节省开销。 假设某磁盘的磁道为0~200号，磁头的初始位置为100号磁道，且此时磁头正在向磁道号增大的方向移动，那么有多个进程陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 优点：比起C-SCAN算法来，不需要每次移动到最外侧或者最内侧才改变刺头方向，同时响应频率也很均匀。 缺点：也不算是缺点，就是没必要，因为边移动边观察看似节省开销了实际上实现起来开销也不必C-SCAN小多少。 总结 减少延迟时间的方法 我们知道延迟时间就是磁头等待到目标扇区的时间，那么磁盘扇区的不同排列方式也会对延迟时间造成影响。 如果排列如下： 那么假设现在要连续读取橙色区域的2,3,4区域，那么磁头读取一块的内容（也就是一个扇区的内容后）需要一小段的处理时间，而此时盘片还在不停地旋转。因此如果2,3号扇区相邻着排列，则读完2号扇区后无法连续不断的读入3号扇区。必须等待盘片继续旋转，3号扇区再次滑过磁头，才可以完成扇区读入。所以我们可以得到如下结论：磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，那么读入几个连续的逻辑扇区，可能需要很长的延迟时间。 减少延迟的方法：交替编号 很明显，此时采用交替编号后，逻辑相邻的磁盘块物理结构上并不是相邻的，这样可以使读取连续的逻辑扇区所需要的延迟时间更小。 磁盘结构的设计 我们思考一个问题，为什么在设计磁盘的物理地址时使用的表示方法为（柱面号，盘面号，扇区号）而不是（盘面号，柱面号，扇区号）？这里的原因如下： 假设现在某个磁盘有8个柱面即8个磁道（且最内侧磁道编号为0），4个盘面，8个扇区。那么可以用3个二进制位表示柱面，2个二进制位表示盘面，3个二进制位表示扇区。 那么如果物理地址是（盘面号，柱面号，扇区号）来表示，那么如果现在需要连续读入物理地址（00,000,000）~（00,001,111）的扇区。那么（00,000，000）~（00,000,111）转两圈即可读完，之后在读取物理地址相邻的区域即（00,001,000）~（00,001,111）的时候需要启动磁头臂，将磁头移动到下一个磁道。 而如果是物理地址结构为（柱面号，盘面号，扇区号），且需要连续读入物理地址为（000,00,000）~（000,01,111）的扇区时，由于都在柱面为000的位置，所以不需要移动磁臂，只是在读入(000,01,000)~(000,01,111)时需要激活1号盘面的磁头即可。所以如果是（盘面，柱面，扇区）这种物理地址结构读入连续的物理地址时也需要不断的移动磁头，但是如果是（柱面，盘面，扇区）时就只需要激活不同盘面的磁头即可，无需移动磁臂，这样可以减少磁头移动消耗的时间。 减少延迟的方法：错位命名 如果按照上面这样命名，即不同盘面的相对位置处编号相同，那么假设要连续读入物理地址为(000,00,000)~(000,01,111)时当读取完磁盘块（000,00,111）之后需要短暂的时间处理，而盘面又在不停地旋转，那么当（000,01,000）第一次滑过1号盘面的磁头下方时，并不能读取数据，只能再等扇区再次滑过磁头。所以我们可以错位命名如下： 即此时的两个盘面相对位置处的编号都有错位。那么就可以做到当读取完磁盘块（000,00,111）之后，还有一段时间处理，当（000,01,000）第一次滑过1号盘面的磁头下方时，就可以直接读取数据了，从而减少了延迟时间。 思考：交替编号和错位命名的区别？ 首先交替编号和错位命名是两种策略，他们相互配合减少了磁盘读/写的时间开销。交替编号是针对某一个盘面的编号来说的，使得每一个盘面的编号的交替的。而错位命名是针对的不同盘面之间编号的，使得每一个盘面编号相同的扇区在不同的相对位置，使得切换盘面有一定的时间缓冲可以立刻读取下一个相邻的物理地址。 总结 磁盘的管理 磁盘初始化 分为如下几个步骤： 进行低级格式化（物理格式化），将磁盘的各个磁道划分为扇区。一个扇区通常可分为头、数据区域（如512B大小）、尾三个部分组成。管理扇区包括各种数据结构一般存放在头、尾两个部分，包括扇区校验码（如奇偶校验码，CRC循环冗长验证码等，校验码用于校验扇区中的数据是否发生错误） 将磁盘分区，每个分区由若干柱面组成（即分为C,D,E盘等） 我们可以看出越靠近里面的盘数据密度也就越大。 进行逻辑格式化，创建文件系统。包括创建文件系统的根目录，初始化存储空间管理所用的数据结构（如位示图法、空闲分区表等） 引导块 计算机在开机时需要进行一系列初始化工作，这些初始化工作通过执行初始化程序（自举程序）完成的。 初始化程序可以放在ROM中（只读存储器）中，ROM中的数据在出厂时就写入了，并且以后就不可以修改了（ROM一般是出厂时就集成在主板上）。 思考：自举程序放在ROM中存在什么问题？ 我们发现当需要更新自举程序时就会很不方便，因为ROM中的数据结构无法更改。所以我们需要解决此问题。 我们可以考虑不将自举程序放入ROM，而是在ROM中存放很小的“自举装入程序”，开机时计算机先运行“自举装入程序”，通过执行该程序就可以找到引导块，并将完整的“自举程序”读入内存，完成初始化。而完整的自举程序放在了磁盘的启动块（即引导块/启动分区）上，启动块位于磁盘的固定位置。拥有启动分区的磁盘称为启动磁盘或系统磁盘（一般我们的计算机中都是C盘）。 坏块的管理 对于简单的磁盘，可以在逻辑格式化时（建立文件系统时）对整个磁盘进行坏块检查，标明那些是坏扇区比如在FAT表上标明（在这种方式中，坏块对操作系统不透明）。对于复杂的磁盘，磁盘控制器（磁盘设备内部的一个硬件部位）会维持一个坏块链表。在磁盘出厂前进行低级格式化（物理格式化）时就将坏块链进行初始化。当然也可以保留一些备用扇区用于替换坏块。这种方案称为扇区备用，且这种处理方式中，坏块对操作系统透明。我们这里介绍几种策略： RAID0 RAID0又称为Stripe或者Striping,他代表着所有RAID级别中最高性能的存储性能。RAID0的原理就是把连续的数据分散到多个磁盘上存取，这样当系统有数据请求时就可以多个磁盘并行的执行，每一个磁盘运行属于它自己的那部分数据请求。这种并行操作请求的方法显著提高了存储性能。并且磁盘的读/写操作也会提高，假设RAID0将某一个请求分成了三个部分，那么每个磁盘只运行自己的那部分任务，那么理论上运行速度会提升为原来的3倍，但是由于总线带宽等影响，会低于理论值，但是也明显提升了速度。 虽然优点显著：读写，存储性能极高，但是缺点是不提供数据冗余，一旦用户数据损坏，损坏的数据将不能再恢复。所以RAID0中只要有一个硬盘损坏，整个RAID0设备都不能使用，所以可维护性极差。 磁盘空间使用率：100%，故成本最低。 读性能：N*单块磁盘的读性能 写性能：N*单块磁盘的写性能 冗余：无，任何一块磁盘损坏都将导致数据不可用 RAID1 其实就是镜像备份了，这样就实现了数据冗余，在成对的独立磁盘上产生互相备份的数据。当原始数据繁忙时，可以镜像拷贝读取数据，所以读取性能提高了。并且由于每一个盘都有镜像备份，所以磁盘阵列中单位成本很高。但是也提供了数据的安全性和可用性，当一个磁盘损坏失效，系统可以快速切换到备份的镜像磁盘上读写，不会立刻停止工作。当然两个都损坏了也是无法工作的，但概率太小。所以RAID1中总是有一个保持完整数据的备份盘，可靠性更好。 细节：读写数据的区别？ 一定要注意RAID1中读只能在一个磁盘上进行，即要不在DRIVE1BlockX读，要不在DRIVE2BlockX读,只是在DRIVE1BlockX忙碌时暂时无法提供读数据的时候，DRIVE2BlockX可以替DRIVE1BlockX提供读，但是总体上看只能一个盘提供，所以读的时候是不能并行执行的。而写磁盘的时候可以并行的对两个磁盘进行写，毕竟他们的数据应该是一样的（备份盘和原盘数据必须一致），但是虽然是并行写操作，但是因为要比较硬盘中的数据，所以写数据性能还是比单块磁盘慢。 磁盘空间使用率：50%，故成本最高。 读性能：只能在一个磁盘上读取，取决于磁盘中较快的那块盘 写性能：两块磁盘都要写入，虽然是并行写入，但因为要比对，故性能单块磁盘慢 冗余：只要系统中任何一对镜像盘中有一块磁盘可以使用，甚至可以在一半数量的硬盘出现问题时系统都可以正常运行 RAID10 其实可以看出特点，就是RAID1和RAID0的组合，对于整体来看组合是RAID0而局部看来每一个不分都是RAID1这样的好处是，整体上的读写性能很好，并且也不容易损坏因为每一个部分都有备份盘即使损坏了也可以立刻用备份盘替换。 磁盘空间利用率：50% 读性能：N/2*单块硬盘的读性能 写性能：N/2*单块硬盘的写性能 冗余：只要一对镜像盘中有一块磁盘可以使用就没问题 思考：为什么不是RAID01组合？ 即整体看来是RAID1，而局部看来每个部分都是RAID0我们发现整体看性能写很慢，读还可以，但是只要有2个局部损坏任意一个分盘都是整体都不能在使用了，性能一般且成本昂贵不易于维护😅。所以这个组合不适用。 RAID5 RAID 5是RAID 0和RAID 1的折中方案。RAID 5具有和RAID0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID5的磁盘空间利用率要比RAID 1高，存储成本相对较低，是目前运用较多的一种解决方案。当然我们发现每一组类型的盘都有一个备份盘随时准备顶替损坏的磁盘工作，并且备份盘每一个都分布在不同的disk上，而相应的有备份盘的disk就么有哪一种类的工作原盘。这样既便于维护整体性能也还不错，当有一个盘损坏时也可以继续工作，当然仅限于坏掉一个，当再坏掉一个或者备份盘先坏掉此时又有盘坏掉时也是会停止工作的。 磁盘空间利用率：(N-1)/N，即只浪费一块磁盘用于奇偶校验 读性能：(n-1)*单块磁盘的读性能，接近RAID0的读性能。 写性能：比单块磁盘的写性能要差 冗余：只允许一块磁盘损坏 以上内容来自大佬博客 总结"},{"title":"管程与死锁","path":"/wiki/操作系统笔记/管程与死锁/index.html","content":"管程 这部分仅是了解内容，当做拓展就好 为什么引入管程 在提出信号量后我们确实可以借用信号量+PV操作实现进程互斥关系但是我们发现这对编程人员极其不友好，编写程序困难，易出错。如下图： 我们知道这种P操作顺序错误会造成死锁，但是在编程中我们确实需要时刻注意P,V操作的顺序，这非常困难，所以能不能设计一个机制，让程序猿写程序时不需要关心复杂的PV操作，让写代码更轻松呢？可以，1973年，Brinch Hanson首次在程序设计语言（Pascal)中引入了&quot;管程&quot;的概念–一种高级同步机制，自此我们不需要在关心复杂P,V操作了，而是由编译器负责实现各进程的互斥进入管程操作。 管程的定义和基本特征 管程实际上就是一种特殊地软件模块，由这些部分组成： 局部于管程的共享数据结构说明 对该数据结构进行操作的一组过程(实际上就是函数) 对局部于管程的共享数据设置初始值的语句 管程有一个名字 管程的基本特征： 局部于管程的数据只能被局部于管程的过程(就是函数)所访问 一个进程只有通过调用管程内的过程(实际上就是函数)才能进入管程访问共享数据 每次仅允许一个进程在管程内执行某个内部过程(就是函数) 所以我们知道管程有自己的内部局部变量和函数以及一个管程名字，管程一次性只允许一个进程执行管程内函数并且管程内的数据只能被局部于管程的函数访问这样就实现了进程之间的互斥，即管程的函数封装了具体的操作，并且凭借每次只有一个进程能够调用管程函数来修改管程内的数据(实际就是信号量)。这样我们就不需要经常关注PV操作了。 如下是一个应用： 用管程解决生产者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//定义管程数据结构为ProducerConsumermonitor ProducerConsumer //管程内数据实际上就是信号量 //解决同步问题 condition full,empty;\tint count=0;//缓冲区内产品数\t//第一个管程内部函数\t//把产品放入到缓冲区\tvoid insert(Item item)&#123; if(count==N)//缓冲区已满 wait(full)//阻塞等待 count++;//否则产品数加一 insert_item(item);//缓冲区放进一个产品 if(count==1) //此时缓冲区不空了唤醒wait(empty) signal(empty) &#125;\t//第二个管程内函数\t//从缓冲区取产品\tItem remove()&#123; //缓冲区是空的 if(count==0) wait(empty)//阻塞等待 count--;//否则产品数减一 if(count==N-1) //此时缓冲区不满了唤醒wait(full) signal(full); return remove_item();//取出产品 &#125;end monitor;//结束管程定义//生产者进程producer()&#123; while(1)&#123; item=生产一个产品; //调用管程函数进行放入产品操作 ProducerConsumer.insert(item); &#125;&#125;//消费者进程consumer()&#123; while(1)&#123; //调用管程函数进行取出产品操作 ProducerConsumer.remove(); //消费产品item &#125;&#125; 我们发现管程只是保证每次都只有一个进程进行操作的互斥关系，具体的同步关系还是需要我们在管程内自己实现代码逻辑，并且这种封装管程内函数然后暴露给其他进程调用来操作内部数据的方式就是典型的“封装”思想。 引入管程的目的无非就是要更方便的实现进程互斥和同步。所以原理如下： 需要在管程中定义共享数据(如生产者-消费者问题中的缓冲区) 需要在管程中定义用于访问这些共享数据的&quot;入口&quot;–其实就是一些封装函数(如生产者-消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品) 只有通过这些特定的&quot;入口&quot;才能访问共享数据 管程中有很多&quot;入口&quot;，但是每次只能开放一个&quot;入口&quot;，并且只能让一个进程或线程进入(如生产者-消费者问题中，各进程需要互斥的访问共享缓冲区，管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。注意：这种互斥特性是由编译器负责实现的，程序猿不用关心，但是互斥关系还是需要程序猿自己实现) 可在管程中设置条件变量(实际上就是信号量)+等待/唤醒操作以解决同步问题，可以让一个进程或者线程在条件变量上等待(此时，该进程应先释放管程的使用权，也就是让出&quot;入口&quot;)，可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。 程序猿可以用某种特殊的语法定义一个管程（比如：monitor ProducerConsumer…end monitor)之后其他程序猿就可以使用这个管程提供的特定&quot;入口&quot;很方便的使用实现进程同步/互斥了。 JAVA中类似于管程的机制 JAVA中，如果使用synchronized来描述一个函数，那么这个函数同一时间段内只能被一个线程调用。 如下： 12345678static class monitor&#123; private Item buffer[]=new Item[N]; private int count=0; public synchronized void insert(Item item)&#123; .... &#125;&#125; 如上每次都只允许一个线程进入insert函数，如果多个线程同时调用insert函数则后来者需要排队等待。 总结 死锁 什么是死锁 其实我们在前面已经不止一次提到“死锁”的概念了，例如刚刚讲到的哲学家问题中同时都先拿左筷子再拿右筷子就会导致死锁现象出现。这里每个人都占有一个资源同时又在等待另一个人手里的资源的情况就是“死锁”这里我们给出严格的定义：在并发环境下，各种进程因争夺资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是&quot;死锁&quot;。发生死锁后若无外力干涉，这些进程都将无法向前推进。 思考：死锁，饥饿，死循环有什么区别？ 死锁：各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。比如：SPF算法中，若有源源不断的短进程到来，则长进程一直得不到处理机，从而发生长进程“饥饿”。 死循环：某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序猿故意设计的（比如while(1)）。 共同点 区别 死锁 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 死锁一定是“循环等待对方手里的资源”而导致的，因此如果有死锁现象，那么至少有两个或两个以上的进程同时发生死锁。另外，发生死锁的进程一定处于阻塞态。 饥饿 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 可能只有一个进程发生饥饿，发生饥饿的进程既可能是阻塞态（如长期得不到需要的I/O设备），也可能是就绪态（长期得不到处理机）。 死循环 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 可能只有一个进程发生死循环，死循环的进程可以上处理机运行（可以是运行态），只不过无法像期待的那样顺利推进，思索和饥饿问题是由于操作系统分配资源的策略不合理导致的，而死循环是由代码逻辑的错误导致的。死锁和饥饿是管理者（操作系统）的问题，死循环是被管理者的问题。 死锁产生的必要条件 产生死锁必须同时满足以下四个条件，只要其中任意一个条件不成立，死锁就不会发生。 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家问题的筷子，打印机等I/O设备）。像内存，扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）。 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源的请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。 所以我们完全可以参照哲学家问题的死锁情况推出这四个条件，并且还可以知道发生死锁时一定是有循环等待，但是发生循环等待时未必死锁（循环等待是死锁的必要不充分条件）。当然如果同类资源数大于1，则即使有循环等待，也未必发生死锁，但如果系统中每类资源都只有一个，那循环等待就是死锁的充要条件了。 什么时候发生死锁 对系统资源的竞争，各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源(cpu)的竞争是不会引起死锁的。 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如：并发执行的进程P1，P2分别申请占有了资源R1,R2，之后进程P1有紧接着申请资源R2，而进程P2又申请资源R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁。 信号量的使用不当也会造成死锁，如生产者-消费者问题中实现互斥的P操作在实现同步操作P之前，就有可能会发生死锁。（我们可以把互斥信号量和同步信号量也看做是一种抽象的系统资源） 总之对不可剥夺的资源的不合理分配就可能会导致死锁。 死锁的处理策略 预防死锁。破坏死锁产生的四个必要条件中的一个或多个 避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁（银行家算法） 死锁的检测和接触、允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后才去某种措施解除死锁。 前面的两种方法都是不允许死锁发生，最后一种是允许死锁发生。 总结 死锁的处理策略 那么接下来我们就逐一讲解一下死锁处理的三条策略。 预防死锁 破坏互斥条件 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁 如果我们把只能互斥使用的资源改造为允许共享使用，那么系统就不会再进入死锁状态了，比如：SPOOLing技术。操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备，比如用SPOOLing技术将打印机改造成共享设备。 这个策略的缺点是并不是所有的资源都可以改造成共享使用的设备，并且为了系统的安全，很多地方还必须保护这种互斥性，因此很多时候无法破坏互斥条件。 破坏不剥夺条件 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 我们可以采用以下两种方案破坏不剥夺条件 方案1：当某个进程请求新的资源得不到满足时，他必须立即释放保持所有的资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。 方案2：当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用） 这种策略的缺点是： 实现起来复杂无论是方案1还是方案2 释放已获得的资源可能会造成前一阶段的工作的失效，因此这种方法一般适用于易保存和恢复状态的资源，如cpu。（有PCB记录信息的好处） 反复地申请和释放资源会增加系统开销，降低系统吞吐量。 如果采用方案1，意味着只要暂时得不到某个资源，之前获得的那些资源都要放弃，以后再重新申请，如果一直放生这样的情况，就会导致进程饥饿。 破坏请求和保持条件 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 可以采用静态分配方法，即进程在运行前一次申请完他所需要的全部资源，在它的资源未满足之前，不让他投入运行，一旦投入运行，这个资源就一直归他所有，该进程就不会再请求别的任何资源了。 该策略实现起来简单，但也有明显的缺点：有些资源可能只需要很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，资源利用率低，另外该策略也会导致某些进程饥饿。 破坏循环等待条件 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。 我们可以采用顺序资源分配法，首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完。 思考：什么原理破坏了循环等待条件？ 一个进程只有已经占有小编号的资源时，才有资格申请更大编号的资源，按照此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而就破坏了循环等待链也就不会再出现循环等待的现象了。 我们假设现在有10个资源，编号1~10。 该策略的缺点： 不方便增加新的设备，因为可能需要重新分配所有的编号 进程实际使用资源的顺序可能和编号递增顺序不一致，可能会导致资源浪费 必须按照规定次序申请资源，用户编程麻烦 总结 避免死锁 避免死锁就是利用银行家算法避免系统处于不安全状态，那么首先我们先了解一下一个定义 安全序列，不安全序列，安全状态，不安全状态 我们以一个投资的例子来分析介绍，假设你是一位成功的银行家，手里拥有100亿资金，有三个企业借贷，分别是B,A,T三个公司： B表示最多会借70亿 A表示最多会借40亿 T表示最多会借50亿 然而有个不成文规定，如果你借给企业的钱总数达不到企业提出的最大要求那么值钱借给企业的钱就都拿不回来了。刚开始B,A,T三个企业分别借了20,10,30亿，如下： 此时我们手里还剩下40亿，此时A又提出要借款20亿，那么我们能否借给A呢？ 思考：如果借给A会有三家公司的钱都要不回来的风险吗？ 我们思考，此时借给A20亿，如下: 那么此时我们手中还剩下20亿，此时如果按照T-&gt;B-&gt;A或者A-&gt;T-&gt;B的顺序追债是可以把之前借的钱都要回来的，所以此时没有三家公司的钱都要不回来的风险，所以此时是安全的，我们可以借给A20亿。 思考：能否举出一个三家公司的钱都要不回来的情况吗？ 很简单，假设此时我们手上还有40亿，此时B也要借钱借30亿，那么此时如果我们借出去，如下图： 那么此时我们手中还剩下10亿，我们发现此时就不安全了，因为三家公司的钱我们都要不回来了。所以此时就是不安全的，我们不能再借给B30亿了。 根据上面的例子我们知道所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成，只要能找出一个安全序列，系统就是安全的，当然安全序列可能有多个。 如果分配了资源之后，系统找不出任何一个安全序列，系统就进入了不安全状态，这也就意味着之后可能所有进程都无法顺利的执行下去了，当然如果有进程提前归还了一些资源（比如A先归还了10亿，那么手里有20亿按照T-&gt;B-&gt;A），那么系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。 如果系统处于安全状态，就一定不会发生死锁。如果系统进入了不安全状态也未必就一定发生死锁，只是有死锁的风险，但是如果死锁了那么一定是在不安全状态下发生的。因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求，这也是“银行家算法”的核心思想。 银行家算法 银行家算法是荷兰学者Dijkstra为银行设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。后来这种算法被用在操作系统中用于避免死锁。 核心思想和刚刚的借贷案例相同就是在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态，如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。 思考：对于多种资源的情况，如何实现银行家算法？ 我们思考在BAT借贷的例子中只有一种类型的资源–钱，但是在实际的计算机系统中会有多种多样的资源，应该怎么把算法拓展为多种资源的情况呢？这里我们可以把单维的数字拓展为多维的向量，比如：系统中有5个进程P0~P4，3中资源R0~R2，初始数量为(10,5,7)，则某一时刻的情况可用下表方式表示： 对于上面的例子我们分析一下能否安全。首先第一次分配后剩余的资源数如下表： 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P1 (3,2,2) (2,0,0) (1,2,2) P2 (9,0,2) (3,0,2) (6,0,0) P3 (2,2,2) (2,1,1) (0,1,1) P4 (4,3,3) (0,0,2) (4,3,1) 此时我们还剩下（3,3,2）的资源在手里，那么此时系统是否处于安全状态？ 我们先检查（3,3,2）此时可以满足那些进程的需求，很明显现在满足P1,P3： 假设我们先把P1收回，此时应该是按照下面的公式更新已有资源 if(已有的资源&gt;最多还会需求)then{已有资源=已有资源+已分配资源}if(已有的资源&gt;最多还会需求)\\\\ then\\{ 已有资源=已有资源+已分配资源 \\} if(已有的资源&gt;最多还会需求)then{已有资源=已有资源+已分配资源} 所以我们收回P1后，已有资源更新为(3,3,2)+(2,0,0)=(5,3,2),剩余的进程资源表变为 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P2 (9,0,2) (3,0,2) (6,0,0) P3 (2,2,2) (2,1,1) (0,1,1) P4 (4,3,3) (0,0,2) (4,3,1) 此时满足收回条件的有P3,P1，我们假设先收回P3，那么现有资源为(5,3,2)+(2,1,1)=(7,4,3)，表更新为 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P2 (9,0,2) (3,0,2) (6,0,0) P4 (4,3,3) (0,0,2) (4,3,1) 此时全部进程都满足收回条件了，那肯定是先收回那个都可以了，所以只要是P1-&gt;P3开头的序列就一定是安全序列，所以操作系统处于安全状态，当然也不是只有P1-&gt;P3开头的是安全序列，同理P3-&gt;P1同样是安全序列，总之只要找到一条安全序列就是安全状态所以此时不会发生死锁。 以此类推，共5次循环检查即可将5个进程都加入安全序列，最终得到一个安全序列。这种算法成为安全性算法，可以很方便的使用代码实现以上流程，每一轮都从编号较小的进程开始检查。这里主要是要牢记已有资源的更新公式！ 思考:银行家算法的定义？ 假设系统有n个进程，m中资源，每个进程在运行前先声明对各种资源的最大需求数，则可以用一个n*m的矩阵（可以用二维数组实现）表示所有进程对各种资源的最大需求数。不妨称为最大需求矩阵Max,Max[i,j]=K表示进程Pi最多需要K个资源Rj,同理，系统可以使用一个n*m的分配矩阵Allocation表示对所有进程的资源分配情况，Max-Allocation=Need矩阵，表示各进程最多还需要多少各类资源。另外还要用一个长度为m的一维数组Available表示当前系统还有多少可用资源。某进程Pi向系统申请资源，可用一个长度为m的一维数组Requesti表示本次申请的各种资源量。 可用银行家算法预判本次分配是否会导致系统进入不安全状态： 如果 Requesti[j]&lt;=Need[i,j](0&lt;=j&lt;=m)Request_i[j]&lt;=Need[i,j](0&lt;=j&lt;=m) Requesti​[j]&lt;=Need[i,j](0&lt;=j&lt;=m) 便转向2，否则认为出错 如果 Requesti[j]&lt;=Available[j](0&lt;=j&lt;=m)Request_i[j]&lt;=Available[j](0&lt;=j&lt;=m) Requesti​[j]&lt;=Available[j](0&lt;=j&lt;=m) 便转向3，否则表示尚无足够资源，Pi必须等待 系统试探着把资源分配给Pi,并修改相应的数据（并非真的分配，修改数值只是为了做预判）： Available=Available−RequestiAvailable=Available-Request_i Available=Available−Requesti​ Allocation[i,j]=Allocation[i,j]+Requesti[j]Allocation[i,j]=Allocation[i,j]+Request_i[j] Allocation[i,j]=Allocation[i,j]+Requesti​[j] Need[i,j]=Need[i,j]−Requesti[j]Need[i,j]=Need[i,j]-Request_i[j] Need[i,j]=Need[i,j]−Requesti​[j] 操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式分配，否则，恢复相应数据，让进程阻塞等待。 总结 死锁的检测和解除 死锁的检测和解除一大特点就是他允许死锁的发生然后检测到死锁后用一些方法解除死锁。所以首先我们需要能够检测出死锁。 死锁的检测 为了能够对系统是否已发生了死锁进行检测，必须： 用某种数据结构来保存资源的请求和分配信息 提供一种算法，利用上述信息来检测系统是否已进入死锁状态 我们一般可以用资源分配图来保存资源的请求和分配信息，有以下两点两边的定义： 如果系统中剩余的可用资源数足够满足进程的需求，那么这个进程暂时是不用阻塞的，可以顺利执行，如果这个进程执行结束了把资源归还给系统，就可能使某些正在等待资源的进程被激活，并顺利的执行下去。相应的，这些被激活的进程执行完了之后又会归还一些资源，这样可能又会激活另外一些阻塞的进程。 按照上面的过程叙述，我们知道对于资源分配图，每一个边对应一个圆的资源节点，如果最终能够消除所有边（优先消除绿边然后再消除蓝边），就称这个图是可完全简化的，此时一定没有发生死锁（相当于能找到一个安全序列）。如果最终不能消除所有变，那么此时就是发生了死锁，最终还连着的边的那些进程就是处于死锁状态的进程。 检测算法： 在资源分配图中，找出既不阻塞又不是孤点的进程Pi(即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如上图中R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配边，使之成为孤立的节点。在上图中P1是满足这一条件的进程节点，于是P1的所有边消去。 进程Pi所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程，在下图中，P2就满足这样的条件，根据1的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的。 死锁的解除 一旦检测出死锁的发生，就应该立即解除死锁，注意并不是系统中的所有进程都是死锁状态，而是用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程。解除死锁的方法有： 资源剥夺法：挂起（暂时放到外存）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程，但是应防止被挂起的进程长时间得不到资源而饥饿。 撤销进程法：也叫终止进程法，顾名思义，强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大，因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑还得从头再来。 进程回退法：让一个或多个死锁进程回退到足以避免死锁的地步，这就要求系统要记录进程的历时信息，设置还原点。 总结"},{"title":"经典同步问题(2)","path":"/wiki/操作系统笔记/经典同步问题(2)/index.html","content":"吸烟者问题 问题描述 假设有一个系统有三个抽烟者进程和一个供应者进程，每个抽烟者不停地卷烟并抽掉他，但是要卷烟起并抽掉一只烟需要有三种材料：烟草，纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限的提供这三种材料但是每一次供应者只在桌子上放两种材料，而拥有剩余那种材料的抽烟者才能卷一根并抽掉他，并给供应者一个信号告诉完成了，此时供应者就会将另外两种材料放在桌子上一直重复使得三个抽烟者进程可以轮流的抽烟。 问题分析 我们分析一下题意不难发现这是一个生产者对应多个消费者的问题，并且特殊地是这个生产者可以生产多种产品，如上图： 生产者可以生产三种产品分别是： 纸+胶水 烟草+胶水 烟草+纸 而消费者各自有不同的产品需求分别对应消费生产者的三种产品同时这样看来实际上还是缓冲区只能容下一个产品，并且一次性只能有一个进程访问缓冲区，所以事件关系如下： 桌子上有组合1的产品-&gt;第一个抽烟者取走东西抽烟(同步关系) 桌子上有组合2的产品-&gt;第二个抽烟者取走东西抽烟(同步关系) 桌子上有组合3的产品-&gt;第三个抽烟者取走东西抽烟(同步关系) 抽烟者发出完成信号-&gt;供应者将下一种产品组合放到桌子上(同步关系) 各进程互斥访问临界资源–桌子(互斥关系) 思考：需要设置，互斥信号量吗？ 前面我们提到过对于一个临界资源并且每次都只有一个同步信号量为1的情况可以不设置互斥信号量，此问题也可以不设置互斥信号量。 代码如下： 首先声明信号量其次声明索引值i用来判断供应者该提供那种产品了 12345semaphore offer1=0;//桌子上组合1的数量semaphore offer2=0;//桌子上组合2的数量semaphore offer3=0;//桌子上组合3的数量semaphore finish=0;//抽烟是否完成int i=0;//用于实现&quot;三个抽烟者轮流抽烟&quot; 供应者代码： 123456789101112131415161718provider()&#123; while(1)&#123; if(i==0)&#123; //将组合1的产品放到桌子上 V(offer1); &#125; else if(i==1)&#123; //将组合2的产品放到桌子上 V(offer2); &#125; else if(i==2)&#123; //将组合3的产品放到桌子上 V(offer3); &#125; i=(i+1)%3; P(finish); &#125;&#125; 抽烟者代码： 思考：为什么这次供应者的P操作放到了后面？ 因为初始化时finishi为0，而桌子上一开始是没有组合产品的，所以供应者现需要进行一次产品放置，所以此时P操作放在了最后面实际上就等于放在了下一次循环的开头，如果初始化时finish为1那么P操作就应该放在最前面。并且对于这种可以生产多个产品的供应者一定注意V操作对应着不同事件下。 读者-写者问题 问题描述 有读者和写者两组并发进程，共享一个文件，当两个或两个以上的读进程用时访问共享数据时不会产生副作用，但若某个写进程和其他进程(读进程或者写进程)同时访问共享数据时则可能导致数据不一致的错误，因此要求： 允许多个读者进程同时对文件进行读操作 只允许一个写者往文件中写信息 任一一个写者在完成写操作之前不允许其他的读者或者写者工作 写者操作执行写操作之前需要保证已有的读者和写着进程全部已经退出共享文件 注意：这里和生产-消费者最大的不同是共享数据不会被取走所以共享资源不会减少甚至清空，因此多个读者可以同时访问共享数据。 问题分析 首先我们知道无论是写进程-写进程之间还是写进程-读进程之间都是互斥访问共享文件的。而读进程-读进程之间是不互斥的。所以我们首先肯定是需要设置一个互斥变量rw用来保证写-写，写-读之前互斥，同时为了记录此时正在有几个读进程执行我们设置一个参量count用来记录读进程个数，这样我们知道只有count==0时此时写进程才可以进行写操作，当count&gt;0时说明还有读操作进行，每次新加入一个读进程count就++，每次退出一个读进程count–，只有count==0时说明此时没有读进程才能进行写操作。所以我们的代码如下： 首先声明一个互斥信号量和一个记录参量： 12semaphore rw=1;//实现对共享文件的互斥访问int count=0;//记录当前有几个进程在访问文件 那么写进程代码： 1234567writer()&#123; while(1)&#123; P(rw);//写之前“加锁” write....//进入共享区域进行写操作 V(rw);//退出共享区域并“解锁” &#125;&#125; 一个读进程 12345678910111213reader()&#123; while(1)&#123; if(count==0)&#123;//如果是第一个读进程那么需要进行判断&quot;上锁&quot; P(rw);//&quot;上锁&quot; &#125; count++;//读进程个数加一 read....//进入共享区域进行读操作 count--;//读完，退出读进程个数减一 if(count==0)&#123;//如果是最后一个读进程那么退出前解锁 V(rw);//&quot;解锁&quot; &#125; &#125;&#125; 思考：为什么对于读进程只有count==0时进行PV操作？ 我们思考，rw实际上是一个用来使得写-写和写-读之间互斥的信号量，所以对于每一个写进程都需要进行P,V操作保证每次共享区域都只有自己一个写进程。而对于读者进程来说，如果他是第一个要进入共享区域的进程，那么他唯一需要做的就是保证此时共享区域里面没有写进程即可，即使里面已经有读进程了没关系因为他们之间不是互斥的。所以对于count!=的读进程来说他不需要进行P操作检验就可以直接进入共享区域因为此时说明共享区域里面有读进程且没有写进程，同理对于退出也是，只有自己是最后一个读进程退出时才需要解锁否则其他读进程直接退出即可。 思考：上面的代码有没有什么问题？ 我们想一下，如果此时已经有一个读进程进入共享文件区域了，那么毫无疑问rw=0已经上锁了，此时如果又来了一个读进程我们知道由于count!=0他是不用经过P操作检查就可以直接进入共享区域的，但是我们现在就想对这个后来的读进程进行P操作检查，那么肯定他是通不过的，所以对于第一个if语句的作用除了要做到让第一个读进程上锁同时还要做到避免让其他后来的读进程被P操作检查因为一旦检查他们都是不可能进入的，但是现在上面的if语句操作代码有bug做不到第二个作用。原因如下：我们考虑现在有两个读进程在并发执行此时count==0，好巧不巧第一个读进程刚刚通过if(count==0)的检验还没来得及进行P上锁时间片用完了切换到了第二个读进程他也恰巧刚刚通过if(count==0)的检验也要进行P操作，此时说明这两个读进程都要进行P操作检查此时第二个进程的时间片也用完了有切换到了第一个进程第一个进程此时rw=1可以进入他通过了P操作检查并将rw设置为了0，此时他又用完时间片了切换到进程2PCB状态信息记录着他也要经过P检查，但是此时rw=0!完了第二个度进程是进不去的他过不了P进程的检查所以就一直阻塞到本轮所有的读进程结束才能进入。此时很明显是有问题的，if语句没有做到后来的读进程不用P操作检查。同理对于第二个if操作也会有问题，仔细想想就知道会造成最后一个进程还没有离开共享资源区，倒数第二个离开的进程就已经解锁了，这也很致命，所以我们需要对两个If语句进行优化。 思考：如何优化两个if语句？ 分析易知此时会发生这种bug是因为此时的if判断语句和后面的操作语句不想P,V操作可以做到检查和操作一气呵成的原子性特点，所以我们需要借助P,V做到if语句判断和操作一气呵成，因此我们可以再设置一个互斥信号量来实现各读进程对count的访问是互斥的。所以优化后的代码如下： 我们需要再声明一个互斥信号量： 1semaphore mutex=1;//用于保证对count变量的互斥访问 读进程的代码： 1234567891011121314151617reader()&#123;\twhile(1)&#123; P(mutex);//对count访问上锁 if(count==0)&#123;//如果是第一个读进程那么需要进行判断&quot;上锁&quot; P(rw);//&quot;上锁&quot; &#125; count++;//访问的进程加一 V(mutex);//对count访问解锁 read... P(mutex);//对count访问上锁 count--;//对count访问解锁 if(count==0)&#123;//如果是最后一个读进程退出那么退出前需要解锁 V(rw);//“解锁” &#125; V(mutex);//对count访问解锁 &#125;&#125; 思考：上面的代码还有什么问题？ 我们再仔细想一想，貌似这种代码还是有一个缺陷，我们想每次中途都可以来新的读进程并且如果已知读进程个数不是0那么rw就一直不解锁，也就意味着只要有读进程正在读并且此时又来了新的读进程，那么写进程就得已知阻塞等到所有的读进程全部读完并且没有再来新的读进程，此时rw解锁后写进程才能继续写，这很容易就造成写进程饥饿（即已知有新的读进程源源不断的断断续续的来）。所以上面这种算法是读进程优先的，所以我们需要优化一下代码，即不允许读进程一直插队，当写进程正在等待前面的读进程时新来的读进程只能排在正在的写进程后面等待下一轮的读进程。所以事先代码如下，可能有点不太好理解： 首先还是需要声明信号量，此时还要在上面的基础上在新添加一个信号量w用于实现“写优先”如下： 这样上面加粗部分的就是新家的互斥信号锁，我们来分析以下为什么加上了这个信号量就避免了写进程饥饿。假设现在来了一个读进程R1，他将w上锁然后进行count++和rw上锁等功能，然后在解锁w,此时来了一个写进程W1，他可以通过w的P检验并上锁，此时他还不能通过rw的P操作，因为R1还没有解锁，此时W1在阻塞等待，此时又来了一个读进程R2如果按照上面原先的读者优先算法读进程可以立即进入共享区域执行读操作，但是此时他因为不能通过w的P操作（因为此时W1没有解w锁）所以R2也只能阻塞等待，当R1读完退出临界资源后将rw解锁此时W1可以进行写操作了，此时R2正在阻塞等待W1完成，只有当写进程完成并解锁w后R2才可以开始访问共享文件。我们发现从原来的R1-W1-&gt;R1-R2-W1变成了R1-W1-&gt;R1-W1-R2即读进程不能随意插队了也就是读写进程公平等待了避免了写进程饥饿的风险。 总结一下我们发现实际上上面这种算法并不是&quot;写优先&quot;算法，他只是做到了保证读进程和写进程公平排队而已。所以有的教材也把这种算法叫做&quot;读写公平法&quot;。 总结：各个信号量的作用？ 我们一定要理解上面的代码衍生过程这样才可以深刻记忆各个信号量之间的作用。 rw-保证写写，写读的互斥访问 metux-保证读进程互斥访问count w-保证读写公平排队 十分注意count不是信号量他只是一个记录读进程数量的参量。 哲学家进餐问题 问题描述 一张圆桌上面坐着5名哲学家，每两个哲学家之间的桌子上摆着一个筷子，桌子的中间是一碗米饭，哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人，只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根拿起）。如果筷子已经在他人手上时，则需要等待。解饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。 问题分析 从上面的描述中我们可以知道其实筷子就好像临界资源，每次都只允许一位哲学家进程访问，所以毋庸置疑这是互斥关系。5位哲学家与左右相邻对其中间的筷子是互斥访问的，但是这个不同于之前的生产者-消费者问题或者多生产者-多消费者问题亦或是吸烟者问题，此时一个进程需要同时访问两个临界资源。如何避免临界资源分配不当造成的死锁现象是哲学家问题的关键所在。 这里我们先设置互斥信号量，定义互斥信号量数组chopsticks[5]={1,1,1,1,1}（互斥信号量初始化为1）用于实现对5个筷子的互斥访问。并对哲学家按照0~4编号，同时哲学家i左边的筷子编号为i，右边的筷子编号为(i+1)%5。 思考：同时先左后右可取吗？ 即每一个哲学家都是先尝试拿左边的筷子然后在尝试拿到右边的筷子，如果拿不到就放下筷子。此时代码如下： 123456789101112semaphore chopsticks[5]=&#123;1,1,1,1,1&#125;;pi()&#123; while(1)&#123; P(chopsticks[i])//拿左 P(chopsticks[(i+1)%5])//拿右 eat... V(chopsticks[i])//放左 V(chopsticks[(i+1)%5])//放右 think... &#125;&#125; 很明显这种方法不妥当，会造成死锁最终谁也吃不上饭。因为当所有人都拿起左边的筷子时所有哲学家都不可能能拿到右边的筷子，所以所有哲学家最终都放下筷子重新再按照此方法尝试下去，最终谁也吃不上饭。这种循环等待右边的人放下筷子(阻塞)就是造成&quot;死锁&quot;的原因。 思考：加上某些条件可以避免死锁吗？ 可以我们尝试每次都只限制至多4名哲学家同时吃饭，这样就会由5双筷子4个人分，至少保证了有一名哲学家可以吃饭，不会在造成死锁现象。但是貌似效率太低，究其原因是虽然某些哲学家不能吃上饭但是还是会拿起一根筷子占为己有进行尝试。即某些进程明明已经不可能访问到临界资源了却还是占用了一部分临界资源。我们最好能够避免不能立刻执行的进程占用临界资源。 思考：加上某些条件可以避免进程占用不必要的临界资源？ 我们可以要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家正相反。这样可以保证当相邻的奇偶数号哲学家都想吃饭时，只会有一个哲学家获得第一个筷子，而另一名哲学家连第一个临街资源都没有获得就阻塞了，这样就避免了占有一支后再等待另一支的情况了。 思考：还有没有其他方法？ 归根结底上面的方法都是在还没能确保能获得全部临界资源时就拿起了部分临界资源然后再尝试获取另一部分临界资源，这样就可能会造成大家都拿到了一部分临界资源然后等待。所以我们可以规定只有进程一次性可以获得全部临界资源才执行即仅当一个哲学家左右两支筷子都可以使用时才允许他抓起来。这种方法貌似最合适代码如下： 123456789101112131415semaphore chopsticks[5]=&#123;1,1,1,1,1&#125;;semaphore mutex=1;//互斥的拿筷子pi()&#123; while(1)&#123; P(mutex); P(chopsticks[i])//拿左 P(chopsticks[(i+1)%5])//拿右 V(mutex); eat... V(chopsticks[i])//放左 V(chopsticks[(i+1)%5])//放右 think... &#125;&#125; 我们对比之前的发现只是在取筷子时加上了互斥锁，这样各个哲学家拿筷子这件事必须是互斥进行的，这样就保证了即使一个哲学家在拿筷子时如果拿到一半被阻塞了，也不会有别的哲学家会继续尝试拿筷子，这样的话，当前正在吃饭的哲学家放下筷子后，被阻塞的哲学家就可以获得等待的筷子了。我们发现这种方法虽然可以避免死锁，但是貌似和上面的思路不太一样，实际上他并没有真正的实现满足有两个筷子的哲学家尝试吃饭，而是保证了每次都只允许一名哲学家尝试拿筷子，如果他能一次性拿齐两双就吃饭如果拿不齐就阻塞等待，并且在他等待期间其他哲学家也禁止尝试拿筷子，必须等到这个阻塞的哲学家能够拿齐筷子吃饭后其他哲学家才可以尝试。这样的方法可以至少保证有一个哲学家能够进餐同时最好情况还可以有两名哲学家同时进餐。 思考：上面的方法有没有什么瑕疵？ 我们发现上面这种方法并不能保证只有两边的筷子都可用湿才允许哲学家拿起筷子。例如： 此时1号哲学家已经尝试拿齐了右边筷子(2号筷子)，但是由于0号此时在吃饭所以1号筷子不能拿齐，所以此时1号哲学家不拿起筷子进入阻塞等待，而此时虽然2号哲学家可以同时拿齐2,3号筷子，但是由于mutex此时在1号筷子处为1，其他哲学家此时都不能拿筷子，所以2号哲学家此时虽然可以同时拿齐两双筷子但是却没有资格去尝试拿，而1号哲学家虽然不能用时拿齐两双筷子但是他却可以等待0号进程吃完然后拿齐1,2号筷子吃饭。 思考：三种方法哪种更好? 对于上面所说的三种方法： 每次最多允许4名哲学家拿筷子 奇偶号哲学家反方向拿筷子 互斥锁保证每次一个哲学家拿筷子(两个筷子都能拿才有资格拿筷子) 实际上没有好坏之分，都是最好情况为同时2名哲学家进餐，对于多个进程访问临界资源并且一个进程需要同时访问两个临界资源的变式题参考哲学家问题。 各种问题总结 问题类型 生产者-消费者问题：一个临界资源，两个进程互斥访问，互斥+同步关系 多生产者-多消费者问题：一个临界资源，多个进程互斥访问，互斥+同步关系 吸烟者问题：一个临界资源，一个生产者-多个消费者问题，互斥+同步关系 读者-写者问题:一个临界资源，部分进程互斥访问，互斥+同步关系同时有优先级问题 哲学家进餐问题：多个临界资源，进程需要两个临界资源，纯互斥关系"},{"title":"缓冲区&结束语","path":"/wiki/操作系统笔记/缓冲区&结束语/index.html","content":"缓冲区管理 这节接上一张仍然是核心子系统的功能实现，本节是缓冲区管理。 什么是缓冲区 缓冲区我们并不陌生，机组原理中讲过的cache还有操作系统中讲述的高速缓冲tlb都是以中国缓冲区，他们都是一个存储区域，可以由专门的硬件寄存器组成，也可以利用内存作为缓冲区。使用硬件作为缓冲区的成本较高，容量也较小，一般仅用于对速度要求非常高的场合（如存储器管理中的联想寄存器TLB,由于对页表的访问频繁，因此使用速度很快的联想寄存器来存放页表项的副本）。一般情况下，更过的是利用内存部分空间作为缓冲区，“设备独立性软件的缓冲区管理就是要组织管理好这些缓冲区。 这里我们将详细讲述“内存作为缓冲区”的知识点。首先我们先要了解一下缓冲区的作用： 缓和cpu和I/O设备之间速度不匹配的矛盾。 减少对cpu的中断频率，放宽对cpu中断响应时间的限制。 解决数据颗粒度不匹配的问题，例如输出进程每次可以生成一块数据，但是I/O设备每次只能输出一个字符。 提高cpu和I/O设备之间的并行性。 这里我们介绍几种缓冲区管理策略 单缓冲 假设某用户进程请求某种块设备读入若干块的数据，如果采用单缓冲的策略，操作系统会在主存中为其分配一个缓冲区（如果题目中没有特别说明，一个缓冲区的大小就是一个块）。 此时当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出，当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满以后，才可以把缓冲区数据传出。其实特别类似于管道机制 如上图，块设备数据-&gt;缓冲区用时短于cpu处理数据的时间，因此读入的时间更快，那么一段时间后缓冲区就会被充满数据，此时就不能再继续输入数据了，需要等待cpu一直工作到缓冲区为空时才可以继续块设备数据-&gt;缓冲区。所以处理一块数据的平均用时=C+M。 当T&gt;C时，那么cpu处理速度更快，反而不会是的缓冲区被充满，所以此时处理一块数据的平均用时=T+M。所以无论是哪种情况，永远是取速度慢的，所以采用单缓冲策略时，处理一块数据平均耗时Mx(C,T)+M。 双缓冲 假设某用户进程请求某块设备读入若干块的数据。如果采用双缓冲的策略，操作系统会在主存中为其分配两个缓冲区（如果题目中没有说明，一个缓冲区的大小就是一块）。那么此时设备对于将数据写入缓冲区1,2的速度相同并且缓冲区-&gt;工作区的速度相同的。那么此时假设初始状态为：工作区空，其中的一个缓冲区满，另一个缓冲区空。 那么如果T&gt;M+C,此时即设备将数据填满空数据区2时，另一个数据区1已经全部移到工作区并且被cpu处理完了，那么每次都是设备-&gt;缓冲区的速度慢，所以处理一块数据的平均时间就是T。 如果此时T&lt;M=c，那么也就是当满缓冲区1数据移到工作区且被cpu处理完之前，另一个空的缓冲区2已经被填满了，那么此时处理一块数据的平均时间就是M+C。并且在双缓冲策略中，我们发现缓冲区1和缓冲区2是交替进行两个任务：①空的时候就是被设备数据填充②满的时候就是将数据转移到工作区。相应频率是相同的，不会出现一个缓冲区一直空，一个缓冲区一直满的情况，因为两个任务并行进行。所以在双缓冲策略中，处理一个数据块的平均时间为Max(T,M+C)。 使用单/双缓冲在通信时的区别 两台机器之间，可以配置缓冲区用于数据的发送和接受。 当采用单缓冲的时候，显然两个相互通信的机器只设置单缓冲区，那么在任一时刻只能实现数据的单向传输。显然效率并不高。所以一般使用双缓冲策略比较好： 此时两个相互通信的机器设置双缓冲时，则同一时刻可以实现双向的数据传输。我们对比发现实际上管道通信就是一种利用单缓冲区的方法，所以一个管道通信只能实现单一方向的数据传输，而如果想实现双向数据传输，就必须建立两个管道。 循环缓冲区 将过个大小相等的缓冲区链接成一个循环队列。下图中，绿色表示空缓冲区，橙色代表已充满数据的缓冲区。 缓冲池 缓冲池由系统中的共用的缓冲区组成，这些缓冲区按使用状况可以分为：空缓冲队列，装满输入数据的缓冲队列（输入队列），装满输出数据的缓冲队列（输出队列）。另外，根据一个缓冲区在实际运算中扮演的功能不同，又设置了四种工作缓冲区（全部都是以缓冲池的视角命名的）： 用于收容输入数据的工作缓冲区（hin）：存储的是要输入到用户进程的数据，但是要暂时存放到缓冲池，完成的是设备输入数据-&gt;缓冲区 用于提取输入数据的工作缓冲区（sin)：存储的是要输入到用户进程的数据，并且是要离开缓冲池，完成的是缓冲池的输入数据-&gt;用户进程 用于收容输出数据的工作缓冲区（hout)：存储的是要输出到设备的数据，但是要暂时存放到缓冲池，完成的是用户进程输出数据-&gt;缓冲区 用于提取输出数据的工作缓冲区（sout）：存储的是要输出到设备的数据，并且是要离开缓冲池，完成的是缓冲池的输出数据-&gt;设备 总结 结尾语 历时半个月，我终于完成了408–操作系统一周目的学习，20天的熬夜学习换来了丰富的回报，独自一人在图书馆中爆肝王道笔记的场景历历在目，相信经过这次学习更加坚定了长时间战线学习的信念👊，接下来敬请期待我的计算机组成原理学习笔记。–2021.1.18"},{"title":"进程调度算法","path":"/wiki/操作系统笔记/进程调度算法/index.html","content":"调度算法 先来先服务（FCFS) 先来先服务算法（First Come First Serve)强调公平性，按照进程先来先服务的思想调度，在作业调度时，考虑的是那个作业先到达后备队列，用于进程调度的时候，考虑的是哪个进程先到达就绪队列。是一种非抢占式的算法，即不会有进程中途插队的情况出现。 例如各进程到达就绪队列的时间、需要的运行时间如下表所示，如果使用FCFS算法来调度进程，那么下列的各进程的等待时间，平均等待时间，周转时间，平均周转时间和带权周转时间与平均带权周转时间各是多少？ 首先周转时间=完成时间-到达时间，带权周转时间=周转时间/运行时间，等待时间=周转时间-运行时间。按照先来先服务的算法调度，那么就是根据到达的先后顺序调度，当然也就是等待时间越久（说明来的越早）的进程优先得到服务。所以调度的顺序就是P1-&gt;P2-&gt;P3-&gt;P4。如下图： P1先执行，即到达就先运行，运行7个时间单位，在P1运行途中P2，P3和P4实际上已经都到达了就绪队列了，但是P1执行完，P2等待时间肯定是最久的，所以他执行，然后P3,P4。所以周转时间=完成时间-到达时间可以算出各个进程的周转时间如下表： 进程 到达时间 完成时间 周转时间 1 0 7 7 2 2 11 9 3 4 12 8 4 5 16 11 然后计算带权周转时间如下表： 进程 周转时间 运行时间 带权周转时间 1 7 7 1 2 9 4 2.25 3 8 1 8 4 11 4 2.75 等待时间如下表: 进程 周转时间 运行时间 等待时间 1 7 7 0 2 9 4 5 3 8 1 7 4 11 4 7 所以平均周转时间=(7+8+9+11)/4=8.75，平均带权周转时间=(1+2.25+8+2.75)/4=3.5,平均等待时间=(0+5+7+7)/4=4.75，注意本题的进程都是纯计算的进程，一个进程到达要么在等待，要么在运行，如果是又有计算，又有I/O操作的进程，那么其等待时间就是周转时间-运行时间-I/O操作时间（本题不考虑这种情况）。我们通过上面的3个表可以看出当带权周转时间大的时候说明等待时间所占整个的周准事件比例也就越大，所以使用户的满意度也就降低了，并且这种FCFS算法很明显很不合理，对于某些运行时间非常短的且来的较晚的进程，如果其前面具有一个周转时间非常大的进程时，就会出现长时间的等待从而造成带权周转时间很大，从整体来看，也会影响到平均带权周转时间较大（当然FCFS不会造成平均周转时间大），并且这种算法当面对突发紧迫重要的进程任务时也不能及时处理，所以现代的操作系统是不采取这种调度算法的，这种算法对长作业有利，但是对于短作业不利，当然这种算法也不会造成饥饿现象。 思考：什么是饥饿？ 可以理解为排队买东西，老是有人中间插队造成后面的排队的人迟迟无法得到需求。进程亦是如此，当前面的进程总是出现插队现象，就会造成后面的进程一直长时间无法得到相应造成饥饿现象，当然FCFS虽然不合理，但是总是能得到服务的，所以不会造成饥饿现象，而接下来介绍的算法就有可能造成饥饿现象。 短作业优先（SJF） 短作业优先（Shortest Job Fiirst)追求最少的等待时间，最少的平均周转时间，最少的平均带权周转时间，既然FCFS会造成运行时间的短作业长时间等待，那么我就每次都让运行时间短的短作业先进行服务，长时间的大作业多等待一会也不会造成非常离谱的带权周转时间。这种短作业进程优先服务的进程调度算法也是非抢占式的算法，但是也有抢占式的算法例如最短剩余时间优先算法（SRTN,Shortest Remaining Time Next),但是SJF算法有可能会导致饥饿现象。 思考：SJF和SPF的区别？ SJF是对于作业调度（即高级调度）的短作业优先算法，所以叫Shortest Job First而SPF是对于进程调度（低级调度）的短作业优先算法，所以叫做Shortest Process First。 思考:什么是抢占式算法？什么是非抢占式算法？ 你可能会疑惑到SJF里可能会出现晚到但是先执行的情况出现，难道还不是抢占式算法？这里的抢占式是指某个任务在运行过程中还没有运行完时被剥夺cpu占用权，使另一个进程开始在cpu上运行。而SJF虽然会每次都挑选就绪队列中运行时间最短的短作业，但也是一定保证这个任务一次性执行完。所以SJF和FCFS都是非抢占式，而SRTN就是抢占式了，他每次都会实时监视计算那个任务有最短剩余时时间谁就上cpu及时前一个任务还没有执行完也要下cpu等待，当然当这个任务又可以上cpu时还是可以继续执行没完成的部分，不需要重新开始，即PCB会帮助记录状态信息以便恢复，一般SRTN又称作具有抢占式的短作业优先进程调度算法。 接下来，我们也计算一个SJF的题，为了更好的理解抢占式，我们做的是具有抢占式的短作业优先算法题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用抢占式的短作业优先调度算法， 计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。 所以实际上做的是SRTN的算法题。 最短剩余时间算法：每当有进程加入到进程就绪队列时就需要进行调度即使现在还有任务在cpu上运行，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则新进程抢占cpu，当前运行进程在PCB记录相关信息后让出cpu重新回到就绪队列等待直至其又是最短剩余时间的作业时在上cpu。同时，当然运行任务结束后还要执行调度。 如下图： 需要注意的是，每次当有新进程到达时就绪队列都会改变，按照上述的规则进行检查。所以每次到达新进程时都要格外注意计算剩余时间。如上，在0-2时只有进程1，所以其先执行，但是当来到时刻2，插入一个新的作业2，他的剩余时间为4(因为还没有执行过，所以剩余运行时间=运行时间)，而此时作业1还有5的运行时间比作业2长，所以虽然作业1没有运行完也要下cpu,作业2抢占cpu。 所以可以用下表表示整个过程Pi(remain time): 0时刻（P1到达）：P1（7），7上cpu执行。 2时刻（P2到达）：P1（5），P2（4），2上cpu执行 4时刻（P3到达）：P1（5），P2（2），P3（1），3上cpu执行 5时刻（P3完成且P4到达）：P1（5），P2（2），P4（4），2上cpu执行 7时刻（P2完成）：P1（5），P4（4），4上cpu执行 11时刻（P4完成且只剩下1）：P1（5），1上cpu执行 16时刻，所有进程完成，调度算法结束。 我们同样计算一下周转时间： 进程 到达时间 完成时间 周转时间 1 0 16 16 2 2 7 5 3 4 5 1 4 5 11 6 带权周转时间： 进程 周转时间 运行时间 带权周转时间 1 16 7 2.28 2 5 4 1.25 3 1 1 1 4 6 4 1.5 等待时间： 进程 周转时间 运行时间 等待时间 1 16 7 9 2 5 4 1 3 1 1 0 4 6 4 2 所以平均周转时间=(16+5+1+6)/4=7,平均带权周转时间=(2.28+1.25+1+1.5)/4=1.50,平均等待时间=(9+1+0+2)/4=3。我们发现对于短作业优先，其平均的指标要明显低于FCFS算法，同时我们这里给出非抢占式的SJF算法的平均指标： 调度算法 平均周转时间 平均带权周转时间 平均等待时间 SJF 8 2.56 4 SRNT 7 1.5 3 我们会发现抢占式的短作业优先算法比非抢占式的短作业优先算法的平均指标更小，也就意味着平均性能更好。 注意：小细节 如果题目中并未特别说明，所提到的“短作业/进程优先算法”默认都是非抢占式的即SJF。 很多的教材上都会说“SJF调度算法的平均等待时间，平均周转时间”最少，严格来说，这个表述是错误的，不严谨的。之前的例子已经表明，最短剩余时间优先算法（即抢占式的短作业优先算法）还要更少。应该再加上“在所有进程同时可运行时，采用SJF调度算法的平均等待时间，平均周转时间最少”或者“在所有进程几乎同时到达时，采用SJF调度算法的平均等待时间和平均周转时间最少”。否则在判断题中如果未加上上面的条件，那么SRNT是平均等待时间，平均周转时间最少的。 平均等待时间最短未必平均带权周转时间最短，毕竟后者同时由运行时间和周转时间决定。但是一般来说平均等待时间和平均带权周转时间正相关，即平均等待时间较小一般平均带权周转时间也不会太大。 短作业优先调度平均等待时间和平均周转时间短显而易见，但是却不公平，这种进程调度算法对短作业有利，但是对长作业不利，很有可能造成饥饿现象，即在排队过程中总是出现短作业，这样就会一直插队造成长作业一直等待不能得到相应的饥饿现象。 思考：有没有一种较为中和的算法，不会产生过于极端的情况？ 仔细对比发现FCFS和SJF都是很大几率出现较为极端的情况的，前者会对短作业不友好且平均性能不好，后者对长作业不友好，虽然平均性能不错，但是却会造成饥饿现象，那么我们可以发明一种更平和的算法，牺牲部分平均性能，但是对于长短作业都有所考虑，且不会造成饥饿的算法–高响应比优先算法。 高响应比优先算法（HRRN） 高响应比优先算法（Highest Response Ratio Next)要综合考虑作业/进程的等待时间和要求服务的时间，这里我们首先需要引入一个新的概念–响应比 响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1 响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1 要求服务时间就是运行时间，所以可以看出响应比一定是&gt;=1的，自HRRN算法中每次调度时都会计算各个作业/进程的响应比并且选择响应比最高的作业/进程服务。仔细思考响应比我们会发现等待时间更长且运行时间更短的作业/进程会优先选择，这样就实现了既不会让短作业等待也太长时间也不会让短作业永远最先被服务，相应的，也就实现了不会让长作业等待太长时间，折中了SJF和FCFS的优点，并且这种算法也是非抢占式的，只有在该作业/进程运行完毕或者中途主动放弃时才会触发调度，才需要即需要计算响应比，很显然这种算法不会产生饥饿现象。 下面我们还是对于上面的那4个任务按照HRRN算法调度计算： 每次调度时我们都计算响应比，并选择响应比高的上cpu 0时刻：只有P1到达了就绪队列，P1上处理机 7时刻：P1完成，就绪队列中有P2，P3,P4，P2的响应比为((5+4)/4=2.25),P3的响应比为((3+1)/1=4),P4的响应比为((2+4)/4=1.5)，显然选择3，虽然2和4都是一样的运行时间，但是2等待时间更长响应比也就越高。 8时刻：P3完成，此时剩下P2和P4，刚刚就算过两个任务的运行时间一样，经过相同的等待时间，P2还是比P4等待的时间长，所以2上cpu（不信可以计算响应比）。 12时刻：P2完成，还剩下P4，4上cpu 16时刻：所有任务完成，调度算法结束。 我们同样计算一下平均性能，首先计算周转时间 进程 完成时间 到达时间 周转时间 1 7 0 7 2 12 2 10 3 8 4 4 4 16 5 11 带权周转时间 进程 周转时间 运行时间 带权周转时间 1 7 7 1 2 10 4 2.5 3 4 1 4 4 11 4 2.75 等待时间 进程 周转时间 运行时间 等待时间 1 7 7 0 2 10 4 6 3 4 1 3 4 11 4 7 所以平均周转时间=(7+10+4+11)/4=8,平均带权周转时间=(1+2.5+4+2.75)/4=2.56，平均等待时间=(0+6+3+7)/4=4 前三种算法的总结 首先我们对比一下平均性能 算法 平均周转时间 平均带权周转时间 平均等待时间 FCFS 8.75 3.5 4.75 SJF 8 2.56 4 SRNT 7 1.5 3 RHHN 8 2.56 4 我们发现FCFS确实平均性能有点拉胯，而SJF和SRNT虽然平均性能优秀但是饥饿现象导致也不太好，而RHHN不但没有饥饿现象，而且平均性能也较好甚至这题的情况下平均性能和SJF一样优秀，所以RHHN整体应该较为出色，但是每次都要计算响应比又加大了计算开销。 这几种算法主要关心的是对用户的公平性，平均周转时间和平均等待时间等平均性能的指标，但是并不关心响应时间，前面我们也提高到过平均性能一般是操作系统关心的，但是用户关心的是自己的任务能否更快完成，所以上面这几种方法对于用户来说交互性很糟糕，因此这三种算法一般适用于早期的批处理系统，当然FCFS现在也扮演着某些情况的重要角色。但是接下来我们在介绍几种更适合于交互式系统的调度算法。并且要注意上面的这几种算法对于高级调用和低级调用均可以采用。 时间片轮转（RR） 不陌生呀，前面介绍操作系统发展史时分时系统就是时候用的这个时间片从而大幅推进了系统的发展，那么接下来我们就详细了解一下时间片轮转调度算法。时间片轮转（RR,Round-Robin)公平的，轮流的为各个进程服务，让每一个进程在一定的时间间隔内都可以得到相应。按照各进程到达就绪队列的顺序，轮流的让各个进程执行一个时间片（如100ms）。若进程未能在一个时间片内执行完，则剥夺处理机（外中断），将进程重新放到就绪队列队尾重新排列。并且注意此时的时间片轮转只能适用于低级调度（进程调度），因为作业只有放入内存建立了相应的进程后才能分配给处理机时间片，所以高级调度不适用。很明显，RR是一种抢占式的进程调度算法，计时装备由时钟装置完成，到达一个时间片后，就由时钟中断来通知cpu时间已到。因为各个进程都会得到相应，所以不会造成饥饿现象。 例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用时间片轮转调度算法，分析时间片大小分别为2,5时的进程情况。 时间片轮转算法轮流让就绪队列中的进程依次执行一个时间片（每次选择的都是排在就绪队列队头的进程）按照上表，就绪队列如下： 假设现在时间片为2那么 0时刻（P1(5)）：0时刻只有p1到达就绪队列，让P1上处理机运行一个时间片。 2时刻（P2(4)-&gt;P1(3）:2时刻P2到达就绪队列，P1运行完一个时间片，被剥夺处理机，重新放到队尾，此时2排在了队头，因此2上处理机（注意：此时P1由于运行完一个时间片刚下处理机，然后此时插进入了P2，那么默认他是排在刚刚完成的P1的前面即P2插入队尾紧接着P1插入队尾）。 4时刻（P1(3)-&gt;P3(1)-&gt;P2(2)）：4时刻，P3到达，先插到队尾，紧接着P2下处理机也插到队尾，此时又轮到P1上处理机。 5时刻（P3(1)-&gt;P2(2)-&gt;P4(6)）：5时刻，时间片还没结束，此时P4先任务插到末尾，由于一个时间片还没结束，所以此时1任务还在cpu上执行。 6时刻（P3(1)-&gt;P2(2)-&gt;P4(6)-&gt;P1(1)）：6时刻，P1时间片用完，下处理机，重新回到就绪队列的末尾，发生调度，3上处理机。 7时刻（P2(2)-&gt;P4(6)-&gt;P1(1)）：虽然P3的时间片还没用完，但是由于此时P3只需要一个时间，所以7时刻它运行完主动放弃了cpu，因此也发生调度，队头进程2上处理机。 9时刻（P4(6)-&gt;P1(1)）：进程2时间片用完，并且刚好运行结束，发生调度，P4上处理机。 11时刻（P1(1)-&gt;P4(4)）：P4时间片用完，重新回到就读队列队尾，队头任务1上处理机。 12时刻（P4(4)）:此时虽然时间片还有，但是1已运行完，主动放弃处理机，此时只剩下了P4，4上处理机。 14时刻（）：就绪队列为空，P4接着上cpu执行。 16时刻：所有进程运行结束，调度算法结束。 对于时间片5和上面类似，可以自己尝试。 这种RR算法更注重的是响应时间，因而不计算周转时间，一般来说，设计RR算法目的就是要让响应时间合适，即时间片要让切换进程的开销占比不超过10%。比如一个系统中有10个进程在并发执行，如果时间片为1s,则一个进程被相应的时间可能至少需要9s,也就是说用户在自己进程的时间片外通过键盘发出调试命令，可能需要等待9秒才能被系统响应（当然，如果实在自己的时间片内就会被立即响应）。这样时间片的大小也要制定合适，如果太大了，使得每一个任务都可以在 一个时间片内就完成，则时间片轮转调度算法就退化为FCFS算法了，并且会增大进程的响应时间。如果太小的话，进程调度、切换有时间代价（保存、恢复运行环境），因此如果时间片太小会导致花费大量的时间来处理进程切换，从而导致实际用于进程执行的时间比例也减小了。 优先级调度算法（PSA) 优先级调度算法（PSA,Priority Scheduling Algorithm)的提出就是为了适应随着现代计算机的发展，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序的情况。每个作业/进程都有各自的优先级，调度时永远选择优先级最高的作业/进程，这种算法即可用于作业调度，也可用于进程调度，甚至，还会用于之后学习的I/O调度。PSA同时具有抢占式和非抢占式的两种情况，但是面对实际情况，一般的PSA都是抢占式的，非抢占式的实现简单，但是实际应用意义不太大。 思考:抢占式和非抢占式的PSA区别？ 非抢占式的PSA需要在进程主动放弃处理机时进行调度，仍然没能有效解决实现紧急重要任务的初衷问题，而抢占式就是可以在就绪队列变化时检查是否产生了更高的优先级的任务，则进行抢占式切换所以肯定也是外中断了。 我们先来看一下非抢占式的PSA：各进程到达就绪队列的时间，需要运行的时间，进程优先数如下表所示（优先数越大，优先级越高） 非抢占式PSA每次调度选择当前已经到达且优先级最高的进程，当前进程主动放弃处理机时发生调度。 0时刻（P1）：只有P1到达，P1上处理机。 7时刻（P2,P3,P4）：P1运行完成放弃处理机，其余的三个进程都已经到达，选择优先级最高的P3上处理机。 8时刻（P2,P4）：P3完成，P2,P4优先级相同，则等待时间更长的（更早到达就绪队列的）先上，所以P2上处理机。 12时刻（P4）：P2完成，就绪队列只剩下P4,P4上处理机。 16时刻（）：P4完成，没有任务了，算法结束。 同样的我们在采取抢占式的PSA对上面的进程表进行调度： 抢占式的PSA永远要保证运行着的是优先级最高的任务，如果新到的任务优先级比正在运行的优先级高，则抢占，如果相同，则仍然等待（毕竟人家先到的）。 0时刻（P1）：只有P1到达，P1上处理机。 2时刻（P2）：P2到达就绪队列，发现此时P2优先级更高，虽然P1还在运行，抢占，P2上处理机，P1回到就绪队列。 4时刻（P1,P3）：P3到达，优先级比P2还高，虽然P2还在运行，抢占，P3上处理机，P2回到就绪队列。 5时刻（P1,P2,P4）：P3完成了，主动释放处理机，同时，P4也到达，由于P2比P4更先进入就绪队列，所以2上处理机。 7时刻（P1,P4）：P2完成，就绪队列只剩下P1,P4且P4优先级高，P4上处理机。 11时刻（P1）：P4完成，P1上处理机。 16时刻（）：P1完成，所有进程均已运行完，算法结束。 并且在PSA中就绪队列未必就只有一个，可以按照不同的优先级来组织，另外，也可以吧优先级高的进程排在更靠近队头的位置（使用优先级队列）。并且我们又跟据优先级是否动态改变分为了静态优先级和动态优先级两种。 静态优先级：创建进程时优先级确定，之后不发生改变。动态优先级：创建进程时有一个初始值，之后会根据情况动态地调整优先级。 一般系统进程优先级是高于用户进程的，前台进程优先级高于后台进程，操作系统更偏好I/O型进程（或者称为I/O繁忙性进程），这样I/O设备和cpu可以并行工作（注意不是并发）。如果优先让I/O繁忙型进程优先运行的话，则越有可能让I/O设备尽早的投入工作，则资源利用率、系统吞吐量也就会得到提升。因此与I/O型进程相对立的就是计算型进程（或者称为cpu繁忙型进程）。 思考：为什么要存在动态优先级PSA？ 可以从追求公平，提升资源利用率等角度考虑，如果某进程在就绪队列中等待了很长的时间则可以适当的提高其优先级，如果某进程长时间的占用处理机运行了很长时间，则可适当的降低其优先级，如果一个进程频繁的进行I/O操作，则可适当的提升其优先级。并且仔细思考，对于静态优先级的PSA，如果每次就绪队列中都会出现新的优先级高于进程P的进程，那么P就会长时间无法得到相应，造成饥饿现象的出现，所以动态优先级的PSA也可有效避免饥饿现象。 在PSA算法中用优先级区分紧急程度，重要程度，适用于实时操作系统，可灵活的调整对各个作业/进程的偏好程度。缺点是对于静态优先级的PSA可能会造成饥饿。 思考：有没有更好的算法? 思考我们已经介绍过得算法貌似都有自己的优缺点，FCFS公平但平均性能不好，SJF短作业永远优先平均性能优秀但是容易饥饿，高响应RHHN比虽然这种了FCFS和SJF但是对于用户交互糟糕且计算开销大，时间片RR虽然各进程相应但是应急能力一般，优先级PSA灵活调整各种进程服务的机会但是静态优先级易饥饿动态优先级实现较为复杂，所以有没有一种更好的这种考虑以上所有算法优点的同时缺点又不是那么明显的算法？有–多级反馈队列调度算法。 多级反馈队列调度算法（MFQSA） 多级队列反馈队列调度算法（Multilevel Feedback Queue Scheduling Algorithm）综合了上面算法的优点，他是设置多级就绪队列，各级队列优先级从高到低，时间片从小到大，新进程到达时先进入第1级队列队尾，按照FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进入下一个队列的队尾，在等待FCFS分配时间片，如果已经到达了最下级的队列还没执行完就重新放回该队列的队尾（所以永远是以非递增的顺序向低级队列插入），只有当第k级队列为空时，才会为k+1级队头的进程分配时间片用于进程调度。所以从整体来看，各个队列之间有静态PSA的特点，对于某一个队列里的进程又有RR的特点，同时从某个进程来看又有动态PSA和FCFS的特点，真实太妙了。当然这个算法也是抢占式的算法，即在k即队列的进程运行过程中(此时1~k-1级队列应该都已经为空)，若更上级的队列（1~k-1级)中又进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回k级队列的队尾。 例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用MFQSA算法，分析运行情况。 0时刻：只有P1，P1上处理机运行一个时间片，下处理机。 1时刻：P2到达，P1还未能在一个时间1的情况下运行完，P1移动至第二队列，开始执行P2，P2上处理机。 2时刻：P2执行完一个时间片1，也没能执行完，所以也插到队列2，此时队列1空了，开始给队列2分发时间片。此时1先到的队列2，所以P1先执行，再次上cpu 4时刻：P1又执行完一个时间片2，此时还是没能执行完，插到队列3队尾，发现队列2还没空还有P2，P2上处理机。 5时刻：此时P2在cpu上执行了时间片2的一半，还没运行完，但是来了新任务3插入到了队列1末尾，此时队列1不是空的，抢占，2下cpu重新插回到队列2末尾。 6时刻：P3执行了一个时间片1执行完了，下cpu，不用在插入到队列2了，此时队列2的P2重新上cpu。 8时刻：P2又运行完了一个时间片2，此时P2完成，不需要在插到队列3了，此时队列1,2都空了，只剩下了队列3的P1，P1上cpu 12时刻：P1又执行完了一个时间片4，此时已经完成了7/8，还差1，所以重新插回到队列3的队尾，此时队列3只有P1，所以P1又上cpu 13时刻：P1运行完成，所有进程都结束，算法结束。 MFQSA对各类的进程都相对公平（FCFS的优点），每个进程到达都可以很快得到相应（RR的优点），短进程只用较少的时间就可以完成（SPF的优点），不必事先估计进程的运行时间（避免用户作假），可灵活的调整各类进程的偏好程度，比如cpu密集型进程，I/O密集型进程（拓展：MFQSA可将因I/O而阻塞的进程重新放回到原队列，这样I/O型进程就可以保持较高的优先级），唯一的缺点就是还是有可能造成饥饿现象的，但是概率不会像SPF那么大。 后三种算法的总结 比起早期的批处理操作系统来说，由于计算机的造价大幅下降，因此之后的交互式的操作系统（包括分时操作系统和实时操作系统等）更注重系统的响应时间、公平性和平衡性等指标。而这后面的这几种算法能较好的满足交互式系统的需求，因此这三种算法适用于交互式系统。（比如UNIX使用的就是多级反馈队列调度算法）。 总结 经过上面的6个算法的介绍，我们对各个算法都有了一定的了解，并且最好是记住英文缩写名字，因为考试有时候只给英文要对其有印象。前面三种要熟练掌握计算指标的方法，后面的三种方法要可以熟练表述运行过程并且了解优缺点，尤其是最后的MFQSA。这里我列出以下注意点总结希望你可以有所收获。 抢占!=饥饿，对于抢占式动态PSA算法不会造成饥饿。 RR和MFQSA不适用于作业调度（高级调度），因为时间片的原因必须进入内存分配成进程后才能实现。 等待时间最大!=带权周转时间最大，只是成正相关。 有可能造成饥饿的算法：SJF,SPF,SRTN,抢占式的静态PSA和MFQSA。 交互式糟糕的算法：FCFS,SJF,HRRN，交互式好的算法：RR,PSA,MFQSA"},{"title":"虚拟内存管理","path":"/wiki/操作系统笔记/虚拟内存管理/index.html","content":"请求式分页管理方式 前面我们介绍了虚拟内存，并且介绍了请求式管理的由来，那么接下来就详细介绍一下请求式分页管理方式。请求分页存储管理与基本分页存储管理的主要区别是在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息调入内存（这里操作系统要提供请求调页功能把缺失页面从外存调入内存）后继续执行程序。如果内存空间不足，由操作系统负责将内存中暂时用不到的信息换出到外存。（操作系统要提供页面置换的功能，将暂时用不到的页面换出外存).这里会涉及到页面机制，缺页中断机构和地址变换机构，我们在下面一一进行介绍。 页表机构 与基本分页管理相比，请求分页管理中，为了实现“请求调页”，操作系统需要知道每个页面是够已经掉入内存，如果还没有调入内存，那么也需要知道该页面在外存中存放的位置。并且当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面（页面置换算法），有的页面没有被修改过，就不用再浪费时间写回外存。有的页面修改过，需要将外存中的旧数据覆盖，因此操作系统需要记录各个页面是否被修改的信息。如下： 从上图我们可以看出请求分页存储管理的页表中存储了所有的页表，即使没有放入到内存中页记录在一个页表项。例如x现在就没有在内存中。 缺页中断机构 假设现在某进程要使访问的逻辑地址为（页号，页内偏移量）=（0，1024），那么经过查表发现此时0号页不在页表中，所以产生一个缺页中断，然后然后由操作系统对缺页中断进行处理。首先是将缺页的进程阻塞，然后放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。如果内存中还有空闲块，那么就为进程分配一个空闲块，将所缺页面装入该快，并修改页表中相应的页表项。 如上图就是将0号页表项内存块号修改为a并且状态为1，并且还要将x号块内的页面装入内存中去： 思考：如果内存块此时是满的怎么办？ 那么就会调用页面置换算法将一些符合调出条件的页面写回外存，所以只有内存满的时候才会触发调换算法（其实很容易理解，写回外存肯定是有时间开销的，所以只有满的时候迫不得已了才会增加时间开销为新来的页腾地儿），类似的实际上TLB等快表也有这个调出暂时长时间不命中的页表项的算法。并且如果内存满了，调出某个页面时，如果这个页面在内存期间被修改过，那么需要将其写回外存覆盖旧数据，否则未修改过的页面就不用了写回外存了，直接淘汰掉就好。毕竟外存块x处还存有旧数据的页，所以我们也可以看出调入是从外存快复制一份页面进入内存块，调出的意思是从内存淘汰的意思，当修改过的时候，这个被淘汰的页面还肩负着通知外存块更新数据的使命所以还需要写回外存（当然肯定是有额外的时间开销的），当没有被修改过（不意味着没被使用，可能在内存期间一直在在被读也发挥作用了）那么就直接扔出内存即可。 思考：缺页中断属于内中断的哪一类？ 我们知道缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断。一条指令在执行期间，可能会产生多次缺页中断（如copy A to B,即将逻辑地址A的数据复制到逻辑地址B，而A,B属于不同的页面，就可能产生两次中断，即A的页不在内存中，B的页也不再内存中，可能会产生两次中断）。 我们可以看出缺页中断属于内中断中的故障，但是是可以被程序处理恢复的。 地址变换机构 因为不能保证逻辑地址访问的页在内存中，所以我们首先是需要确定页是否在页表中，如果不在还需要调入页面并修改表项，当然如果内存满了，那么还需要页面置换。所以新增的步骤有： 当然后面的步骤就是根据页号找到内存块号了，然后拼接物理地址最后再访问目标内存单元。 这里我们尤其要注意TLB的机制，他只存放现在在内存中的刚刚被访问过得页表项，所以TLB里的页一定是存在的。 这里面的一些小细节直接用图片给出，这里我们一定要注意绿框中的提示要点。我们可以看出当产生缺页中断时换出旧页面并调入新的页面到内存块后发生了几个重要的事件： 快表直接加上新的表项 不是直接通过慢表拼接出了物理地址然后访存，而是又重新来了一遍这次快表命中了，然后通过快表拼接出了物理地址进行访存。 思考：为什么没有查慢表和查快表一起进行？ 可以，但是没必要，因为此时慢表大概率会慢于快表（如果不是还要TLB作甚）并且查慢表还会出现缺页中断，并行查询也快不了多少。 思考：为什么当有缺页中断时会通过快表命中？ 这就是进程中断的原理了，当在某一个指令处中断时如果进程阻塞了PCB会记录上次停止的位置，然后当进程再次执行时PCB会恢复到上一次停止的指令处然后重新执行中断的指令（大部分情况下），所以此时还会再执行一遍这个指令的逻辑地址但是此时就会通过快表命中了。 总结 页面置换算法 这部分超级重要，我会做适当的扩充，毕竟王道讲的实在是太少了。一定要透彻了解并且会计算。首先我们明确一个目的，由于页面的换入换出需要磁盘I/O，会有较大的开销，因此优秀的页面置换算法应该追求更少的缺页率。 最佳置换算法（OPT） 也叫作最优置换算法（OPT,Optimal):每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样就可以保证最低的缺页率。这里我们知道肯定是最理想的情况，因为这个算法要求我们需要提前知道未来这个所要被调出的页面就是最长时间或者永久不可能再被使用的页面，但是未来不可预测，所以这个算法实际中不可能实现，但是我们需要学习算法思想（毕竟万一未来我们量子预测到未来这个算法那不就可以实现了吗😝） 例题：假设系统为某进程分配了三个内存块，并考虑有以下页面号引用串（会依次访问这些页面）：7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1 那么最终的过程如下： 首先不用想，第一次填入时肯定都是缺页的（这个很重要容易被忽视）所以内存块填入7,0,1就先缺页3次，然后接下来到2，我们需要调出一个页面，此时我们看一下未来的访页顺序发现7最长时间不会被访问了，所以调出7接入2又缺页1次，继续执行到3发现又该调出了，还是看未来的顺序，调出1,…一直这样看未来顺序调出页面最终缺页率还是可观的才45%。这里我们可以看出缺页率的计算公式： 缺页率=缺页中断次数/页面引用次数缺页率=缺页中断次数/页面引用次数 缺页率=缺页中断次数/页面引用次数 最近未使用页面置换算法（NRU） 最近未使用页面置换算法（Not Recently Used)和OPT很相似，既然我不能知道未来的顺序，那么我就往回看，根据经验分析和局部性原理我们知道如果一个页面很久没有被是用来，那么大概率他就会很长时间或者不会再被使用了（根据历史经验推测未来），所以我们每次都选择调出最近未使用的页面。这里我们的做法如下： 当一个页面被访问(读)时设置R(read)位，页面被写入(修改)时设置M(modificate)位。 当启动一个进程时，它的所有页面的两个位都由操作系统初始化为0，R会被定期地（比如在每次时钟中断时）清零以区别最近没有被访问和被访问的页面。 那么当发生缺页中段时就会检查页面，其中页面可以分为4类： 第0类：没有被访问也没有被修改过的页面（R=M=0) 第1类：没有被访问但是已被修改过的页面（R=0,M=1） 第2类：已被访问过但是没有被修改过的页面（R=1,M=0） 第3类：已经被访问过并且也被修改过的页面（R=M=1） 每次都是从类编号小的非空类中随机挑选一个页面淘汰。 思考：问什么第2类比第3类优先被淘汰？ 首先请读一下算法名字，他强调的就是最近未使用，所以重在根据是否最近被访问过来决定页面的重要性，所以2类先被淘汰，毕竟在一个时间嘀嗒中（大约20ms）淘汰一个没有被访问过的已被修改过的页面比淘汰一个被频繁使用的“干净”（没被修改过）的页面好，所以是否“干净”（即是够被修改过）只是一个次级判断条件。其实NRU这种算法优点就是易于理解和有效实现并且虽然性能不是最好的但是已经够用了。 先进先出页面置换算法（FIFO） 同样借鉴了NRU的思路，既然每次都淘汰最近未被使用的页面，那么大多数情况先来的一般会在内存中待较长的时间，根据时间局部性原理，一般他就是那个最近未被使用的页面。所以FIFO算法就是每次选择淘汰的页面是最早进入内存的页面。 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列（FIFO队列），需要换出页面时就选择队头页面即可。所以队列的最大长度取决于操作系统为进程分配了多少个内存块。 例题： 缺页率=9/12=75%,说实话优点小高。那么你一定想到了如果多分几个内存块是不是缺页次数会变得更少，答案是未必，如下： 缺页率=10/12=83%缺页率反而更大了。只有FIFO会产生这种Belady异常现象，所以FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律是不适应的，因为先进入的页面也有可能经常被访问，所以算法性能差，不推荐使用。 第二次机会页面置换算法（SC） 第二次机会页面置换算法（Second Chance)是对FIFO算法进行的一种优化改进。修改的思路其实很简单，就是避免将最先进来的页面却被访问的页面优先调出，所以只需要设置一位R位，如果是0那么这个页面就是既老还没有被使用，可以直接置换掉。如果是1那么就说明这个页面虽然老但是被访问过，所以将R为置为0然后把这个页面放到队尾修改装入的时间就好像它刚被装入一样（即拥有了第二次机会），然后继续搜索队头直至R=0的页面换出。 第二次机会算法就是在寻找一个最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，即队列中所有的页面R都是1了，那么这个算法就是纯FIFO算法了，所以为了避免这种情况此时操作系统会一个接一个地将每一个页面都移动到队尾并将R设置为0。最后又回到原来的表头页面并且此时R位都是0，因此这个页面会被淘汰，所以这个算法总是可以结束不会出现死循环的。 思考：NRU和SC都有R位有什么区别？ NRU和SC的R位都是被访问的意思，但是NRU的R位是最近被访问的概念，而SC的R为只是表示被访问过的意思，所以NRU需要一个时间嘀嗒来设置R在一个时间段后清零，而SC就不需要只是当队列全是1时所有页面都在绕一圈然后R都变为0。 时钟页面置换算法（CLOCK） 对第二次机会算法的改进，我们发现第二次机会算法总是需要在链表中移动页面，这很低效没必要。所以更好的做法是把所有的页面都保存在一个类似钟面的环形链表中，一个表指针指向最老的页面（即最先进入内存的页面）。当发生缺页中断时，首先检查指针指向的页面，如果R位是0，那么就淘汰该页面，并把新的页面插入到这个位置，然后把表指针移到下一个页面，如果R位是1就将R位置为0然后检验下一个位置，重复这个过程一直到找到一个R位为0的页面为止。当所有的R位都是1时，则指针转一圈将所有的页面的R位都清为0。 我们发现实际上CLOCK算法和SC算法思想一模一样，只不过是换了一个数据结构来减少操作的开销。并且我们发现简单的CLOCK算法选择淘汰一个页面最多经过两轮扫描。 思考：能否进一步优化CLOCK算法？ 我们发现NRU不止讨论了是否最近被访问过的问题，还加了一个是否被修改过的判断指标，当都没有被访问时优先会淘汰没有被修改过的页面，这是因为毕竟修改过的页面被淘汰时还需要写回外存有更大的开销不如再等一等万一他一会被访问了不就不用写回外存了嘛。所以优先淘汰的是R=M=0的，那么CLOCK算法也可以借鉴这种思想。 改进型的时钟置换算法（CLOCK v2.0) 因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件均相同时，应该优先淘汰没有被修改过得页面，避免I/O操作。这就是改进型的时钟置换算法的思想。所以也是有下面这四类： 第0类：没有被访问也没有被修改过的页面（R=M=0) 第1类：没有被访问但是已被修改过的页面（R=0,M=1） 第2类：已被访问过但是没有被修改过的页面（R=1,M=0） 第3类：已经被访问过并且也被修改过的页面（R=M=1） 页面的状态用（R,M）表示，所以（1,1）表示最近被访问过且被修改过。 算法规则：将所有可能被置换的页面排成一个钟面型的循环队列。 第一轮：从当前位置开始扫描到第一个（0,0)的帧用于替换，本轮扫描结束。 第二轮：前提是第一轮扫描失败（即没有(0,0)），那么重新扫描，查找第一个（0,1)的帧用于替换。本轮会将所有扫描过得帧访问位设置为0（即第二轮扫描后（1,0)-&gt;(0,0),(1,1)-&gt;(0,1)。 第三轮：前提是第二轮扫描失败（即没有(0,0)和（0,1)），那么重新扫描，查找第一个（0,0）（此时的(0,0)是原先的(1,0)）的帧用于替换。本轮不修改任何标志位。 第四轮：前提是第三轮扫描失败（即没有(0,0),(0,1)和(1,0)），那么重新扫描，查找第一个（0,1)（此时的(0,1)是原先的(1,1)）的帧用于替换。并且此轮一定会扫描成功。 由于第二轮已经将所有的访问位设置为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型CLOCK算法选择一个淘汰页面最多会进行四轮扫描。 思考：改进型CLOCK和CLOCK最大的区别是什么？ 我们仔细对比一下两者的算法思想，我们发现虽然都是使用类似钟的循环队列数据结构，但是算法思想却截然不同，对于简单的CLOCK使用的是SC的思想，而改进型的时钟页面置换算法使用的是NRU+CS的算法思想但是更贴向NRU。 最近最少使用页面置换算法（LRU） 最近最少使用页面置换算法（LRU，Least Recently Used）：每次淘汰的页面是最近最久未使用的页面。 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t，当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。很明显这个非常的科学。 我们以一道例题讲解，假设某系统为某进程分配了4个内存块，并考虑到有以下页面号引用串：1,8,1,7,8,2,7,1,8,3,8,2,1,3,1,7,1,3,7 缺页率=6/20=33%很小。在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号。在逆向扫描过程中最后一个出现的页号就是要淘汰的页面。我们发现这个方法太好啦，就用这个吧，但是实际上这个算法不常见，因为需要专门的硬件支持且实现困难，开销极大。 最不常用页面置换算法（NFU） 最不常用页面置换算法（NFU,Not Frequently Used）:用一个软件模拟LRU，该算法将每个页面与一个软件计数器相关联，计数器的初始值为0，每次时钟中断时，由操作系统扫描内存中的所有页面，将每个页面的R位（他是0或1）加到计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。当发生缺页中断时，则置换计数器上数值最小的页面。 我们发现NFU不忘记任何事情，比如一个页面之前被频繁访问，导致这个计数器很大，但是后来不访问他了，但是由于计数器的值太大，他也一直不会被置换出去，这个缺点太严重，所以也不推荐。 老化算法 老化算法是对NFU算法的修改，其修改包括两个部分，首先，在R位被加进之前将计数器（二进制数）右移一位（相当于除以2）然后将新来的R位的数加在计数器的最左端的位（即次数最大最优决定权）。这样老化算法的计数器中只有有限位数，如果时钟滴答是20ms,8位一般足够了，加入一个页面160ms都没有被访问过，那么他很有可能就不重要了。 工作集页面置换算法(WS) 在讲解算法的实现之前，我们先了解一下几个概念： 思考：什么是工作集？ 工作集：一个进程当前正在使用的页面的集合称为工作集 思考：什么是颠簸现象？ 颠簸现象：程序每执行几条指令就产生一次缺页中断 思考：什么是请求调页？颠簸现象什么时候频繁出现？ 请求调页：在单纯的分页系统中，刚启动进程时，在内存中是没有页面的，所以当cpu尝试读取第一条指令时就会产生一次缺页中断，使操作系统装入含有第一条指令的页面，其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间后，该进程需要的大部分页面都已经在内存中了，进程开始在较少缺页中断的情况下运行 思考：怎么解决程序初期运行的颠簸现象？ 有不少分页系统会设法跟踪进程的工作集，以确保进程运行以前，他的工作集就已经在内存中了，这样运行初期就不会频繁发生颠簸了。这种方法就叫做工作集模型，大大减少了缺页中断率。在进程前装入其工作集页面也称为预先调页。所以工作集随着时间变化的。 实际上大多数的程序会任意访问一小部分页面，工作集缓慢变化。当程序重新开始时，就有可能根据它上次结束时的工作集对要用到的页面作一个合理的推测，预先调页就是在程序IXUS运行之前预先装入推测的工作集的页面。 思考：纯分页式管理的工作集和请求式分页管理的工作集的区别？ 那么按照以前的方法定义工作集为前1000万次内存访问所使用过的页面的集合，那么现在在请求式分页管理中就应该定义为过去10ms中的内存访问所用到的页面的集合。这样的模型更合适和容易实现。并且要注意每个进程都只会计算自己执行的时间，所以当一个进程在T时刻开始然后在T+100ms的时间段内使用了40ms的CPU，那么对于工作集来说就是40ms。一个程序从他开始执行到当前所实际使用处理机的时间总数就是当前实际运行时间。我们通过这个近似的方法定义进程的工作集就是在过去的t秒实际运行时间中他所访问过的页面的集合。 那么现在我们再来探讨下基于工作集的页面置换算法：就是找出一个不在进程工作集中的页面淘汰他。 每个表项至少要包含两条信息： 上次使用该页面的近似时间 最近是否访问过的R位 过程如下： 扫描所有的页面检查R位。 如果R==1：那么设置上次使用时间为当前实际时间，以表示缺页中断时该页面正在被使用 如果R==0&amp;&amp;生存时间&gt;t:那么表示最近没有被访问过且已经不再工作集了，那么就移除这个页面，用新的页面置换它。扫描会继续进行以更新剩余的表项。所以这次扫描后所有不在工作集的页面都会被淘汰掉。 如果R==0&amp;&amp;生存时间&lt;=t:那么表示这个页面没有被访问过但是却还在工作集中，那么就记录下最长生存时间（就是当前时间-最早被使用时间即已经在呆工作集中的时间）。如果最后没有找到任何一个可以淘汰的即所有页面都是1情况除了现在被扫描的这个页面那么就淘汰这个页面，如果有多个3这种情况的即（1,3都有的情况）那么就淘汰生存时间最长的。如果最终所有页面都是1的情况（包括现在被扫描的这个也是1的情况）那么虽然都满足无需淘汰的条件，但是总是得出去一个，那么就尽可能随机淘汰一个“干净”（没有被修改过的）页面这样就无需进行I/O操作了节省开销。 总结 以上涵盖了大部分置换算法，这里列表总结 页面置换算法 算法规则 优点 缺点 最佳置换算法（OPT） 优先淘汰最长时间内不会被访问到的页面 缺页率小，性能最好 预测未来，无法实现 最近未使用置换算法（NRU） 优先淘汰最近未被访问且干净的页面（需要R,M） 性能优秀，实现简便 ———— 先进先出置换算法（FIFO） 优先淘汰最先进入内存的页面 实现简单 性能差，与规律相悖，可能出现Belady异常 第二次机会置换算法（SC) FIFO改良版，对于最近被访问过得放到队尾获得第二次机会 合理，性能适中 链表操作复杂 时钟置换算法（CLOCK） SC的时钟循环链表形式，规则同上 合理，性能适中 未考虑干净页面的I/O开销 改进型的时钟置换算法（CLOCK v2.0) 和NRU思路规则相似使用的是时钟循环链表形式 合理，性能适中，考虑了I/O开销 有时候扫描次数有点多 最近最少使用页面置换算法（LRU） 每次都淘汰上一次被访问时间最早的页 性能好，科学合理 实现复杂，需要特殊地硬件支持，开销大 最不常用页面置换算法（NFU） 计数器记录R的和来表示被访问频率，每次淘汰访问频率小的页面 实现简单 之前访问频率大但是最近不怎么访问的页面迟迟不能被置换 老化算法 NFU改良版 实现适中，性能适中 ———— 工作集算法（WS） 每次都淘汰不在工作集的或者在工作集时间最长的干净的页面 实现适中，性能适中 ———— 页面分配策略 页面分配、置换策略 驻留集 指请求分页存储管理中给进程分配的物理块的集合。在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。如果驻留集太大，就失去了虚拟存储技术的应用意义，导致多道程序并发度下降，资源利用率降低。如果驻留集太小，会导致缺页颠簸，系统需要花费大量时间处理缺页。所以驻留集的大小要合适。 我们考虑一个极端的情况，如果一个进程共有100个页，那么如果驻留集大小为100，那么进程可以全部放入内存运行期间也就不会再发生缺页了，如果驻留集为1，则进程运行期间必定会频繁的缺页。 页面分配策略 固定分配：操作系统为每个进程分配一组固定数目的物理块，在运行期间各个进程的驻留集大小不变。 可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即驻留集大小动态变化。 页面置换策略 局部置换：发生缺页时只能选进程自己的物理块进行置换。 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。 思考：分配策略和置换策略的关系？ 固定分配局部置换：系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。这种策略缺点是很难在刚开始就确定应该为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小，优先级，或是根据程序猿给出的参数来确定为一个进程分配的内存块数） 可变分配全局置换：刚开始为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某个进程发生缺页时，从空闲物理块中取出一块分配给该进程，如果已经没有空闲物理块了，则可以选择一个未锁定的页面换出外存（注意，并不是所有的页面都可以换出外存，比如系统会锁定一些页面，这些页面中的内容不能置出外存比如重要的内核数据等），再将物理块分配给缺页的进程。如果采取这种策略，那么只要进程发生缺页，都将先获得空闲的物理块，只有空闲物理块也没有的时候系统会调出一些其他进程未锁定的页面（这个页可能是任何一个进程的页），然后将腾出的物理块分配给这个缺页的进程。因此这个被选中的进程拥有的物理块会减少，缺页率会增加。 可变分配局部置换：刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。 思考：可变分配全局置换和可变分配局部置换的区别？ 可变分配全局置换是只要缺页系统就会给他分配新的物理块。 可变分配局部置换是根据发生缺页的频率动态增加或减少进程的物理块直至频率趋于稳定。 调入页面的时机 预调页策略 根据局部性原理（主要是空间局部性原理），一次调入若干个相邻的页面可能比一次调入一个页面更加高效。但是如果预先调入的页面大多数没有被访问，那么就会低效。因此可以预测不久之后可能访问到的页面，将他们预先调入内存，但是目前预测成功概率为50%。所以这种策略主要用于进程的首次调入，由程序猿指出应该调入那些部分。 请求调页策略 进程在运行期间发现缺页时才将页面调入内存。这种策略调入的页面一定会被访问，但是每次只能调入一页，而且每次调入都要磁盘I/O操作，所以开销大。 调入页面的区域 当系统拥有足够的对换区空间： 那么页面的调入和调出都是内存和对换区之间进行，这样可以保证页面的调入和调出速度很快，在进程运行前，需要将进程相关的数据从文件区复制到对换区。 当系统缺少足够的对换区空间： 凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的 部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。 独特的UNIX方式： 运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。 颠簸(抖动)现象 刚刚换出的页面马上又换入内存，刚刚换入的内存又要换出内存，这种频繁的页面调度行为就是颠簸或抖动。产生的原因是划分给进程的驻留集太小。 工作集 驻留集：在请求分页存储管理中给进程分配的物理块的集合。 工作集：在某段时间内，进程实际访问页面的集合。 所以工作集大小可能会小于窗口尺寸，系统会根据工作集大小和窗口尺寸的关系动态更改驻留集。比如某个进程的窗口尺寸为5，但是一段时间的检测发现进程的工作集一般最大就是3，那么物理块大小更改为3即可满足需要。所以一般驻留集的大小不能小于工作集的大小，否则就会导致进程运行过程中频繁缺页。 总结"},{"title":"设备独立性软件","path":"/wiki/操作系统笔记/设备独立性软件/index.html","content":"I/O软件层次结构 从上图我们可以从总体上看出一个I/O设备相应请求时的全过程，分别经过了以下几个过程。 用户层软件 用户层软件实现了与用户交互的接口，用户可以直接使用该层提供的、与I/O操作相关的库函数对设备进行操作。比如库函数提供的printf()函数，他会被翻译成等价的write系统调用，用户层软件会在系统调用时填入相应参数，这样就可以通过系统调用的方式实现I/O请求。 windows操作系统会向外提供一系列系统调用，但是由于系统调用的格式严格，使用麻烦，所以在用户层上封装了一系列更加方便的库函数接口供用户使用就比如C库等。 设备独立性软件 又称为设备无关性软件，因为与设备的硬件特性无关的功能几乎都在这一层实现。他有以下几个功能： 向上层提供一些统一的调用接口（如read/write系统调用） 原理类似于文件保护，设备被看成是一种特殊的文件，不同用户对各个文件的访问权限不一样。同理也就实现了对设备的访问权限不同，保护设备不会被恶意文件修改 差错处理，设备独立性软件需要对一些设备的错误进行处理。 设备的分配与回收 数据缓冲区的管理，可以通过缓冲技术屏蔽设备之间数据交换单位大小和传输速度的差异 建立逻辑设备名到物理设备名的映射关系，根据设备类型选择调用相应的驱动程序。用户和用户层软件发出I/O操作相关系统调用的时，需要指明此次要操作的I/O设备的逻辑设备名。设备独立性软件通过“逻辑设备表（LUT，Logical Unit Table）”来确定逻辑设备对应的物理设备，并且找到该设备对应的设备驱动程序。 操作系统可以采用两种方式管理逻辑设备表LUT： ①整个系统就设置一张LUT，这就意味着所有用户不能使用相同的逻辑设备名，因此这种方式只适用于单用户操作系统。 ②为每一个用户都设置一个LUT，这样各个用户使用的逻辑设备名可以重复，适用于多用户操作系统，系统在用户登录时为其建立一个用户管理进程，而LUT就存放在用户管理进程的PCB中。 思考：为什么不同的设备需要不同的设备驱动程序？ 我们前面提到过，不同的厂商提供的设备信号规则不同，有的厂商对于生产的设备0代表空闲1代表忙碌，但是有的厂商生产的设备0代表忙碌1代表空闲。所以根据不同的信号需要正确识别信息，而这些不同设备的内部硬件特性只有厂商才知道，所以厂商需要提供与设备的对应的驱动程序，这样cpu才能够正确执行驱动程序的指令序列，来完成设置设备寄存器，检查设备状态等工作。（如果你不能够理解，那么就以这个例子为比喻：你通过介绍人录用了一个外国小伙当你的公司总监，但是你们之间的语言不通所以你无法知道他所返还的信息，所以介绍人在介绍外国小伙的同时还需要提供一个中间翻译即设备驱动程序，他能够为你们两个之间的信息交流提供翻译桥梁）。 设备驱动程序 设备驱动程序主要负责对硬件设备的具体控制，将上层发出的一系列命令（如read/write)转换成特定设备“能够听懂”的一系列指令操作，包括设置设备寄存器，检查设备状态等。不同的I/O设备有不同的硬件特性，具体细节只有设备的厂家才知道，因此厂家需要根据设备的硬件特性设计并提供相应的设备驱动程序。 中断处理程序 当I/O任务完成后，I/O控制器会发送一个中断信号，系统会根据中断信号类型找到相对应的中断处理程序并执行。中断处理程序的流程如下： 所以我们以一个I/O请求任务为例分别经过一下啊几个阶段才能够完成这次任务相应： 用户通过用户层软件提供的库函数发出的I/O请求 用户层软件通过“系统调用”请求设备独立性软件层的服务 驱动程序向I/O控制器发出具体命令 等待I/O设备完成的进程应该被阻塞，因此需要进程切换，而进程切换必然需要中断处理 总结 I/O软件各个层次之间的顺序要理解，要能够推理判断出某个处理属于哪个层次，通常直接涉及到硬件具体细节。且和中断无关的操作肯定是在设备驱动程序层完成的，没有涉及到硬件。对各个设备都需要进行的管理工作都是在设备独立性软件层完成的。 I/O核心子系统 I/O核心子系统是属于操作系统内核的一部分，所以肯定涉及到了调度，设备保护还有互斥等问题，下面就详细介绍这几种功能的具体实现 功能所属层次 我们知道这些功能都是由I/O核心子系统实现的，并且I/O核心子系统是由设备独立性软件、设备驱动程序、中断处理程序三个层次组成的，所以理论上这些功能肯定都是属于这三个层次。 但是实际上假脱机技术即SPOOLING技术（前面讲过是一种解决死锁的方法，即让个进程都产生这个临界区是自己的从而实现临界资源共享打破互斥条件来解决死锁）需要请求“磁盘设备”的设备独立性软件的服务，因此一般来说假脱机技术是在用户软件成实现的，但是408大纲又将假脱机技术归为了“I/O核心子系统”的功能，所以这里我们也认为假脱机技术是I/O核心子系统的功能。 I/O调度 与进程调度类似，I/O之间肯定也是需要有调度算法的，毕竟I/O设备就那么多，进程之间肯定是需要等待轮流使用I/O设备的。我们这里实际上已经学过了一些I/O调度算法，比如磁盘调度算法(FIFO算法，最短寻道优先算法，SCAN算法，C-SCAN算法， LOOK算法，C-LOOK算法等)。当多个磁盘I/O请求到来时，用某种调度算法确定满足I/O请求的顺序。同理打印机等设备肯定也有类似的FIFO，优先级算法，短作业优先等算法来确定I/O调度顺序。 设备保护 操作系统需要实现文件保护功能，不同的用户对各个文件有不同的访问权限（如：只读、读和写等）在UNIX系统中，设备被看作是一种特殊的文件，每个设备也会有对应的FCB（文件控制块，存储文件在磁盘中的相关信息）。当影虎情趣访问某个设备时，系统会根据FCB中记录的信息来判断该用户是否有相关的访问权限，以此实现“设备保护”的功能。 总结 这里只是介绍了部分简单的功能，下面将逐一介绍比较复杂的功能。 假脱机技术（SPOOLING技术） 产生的原因 在手工操作阶段主机直接从I/O设备获得数据，由于设备速度慢，主机速度快，人际速度矛盾明显，主机需要浪费很多时间来等待设备。而在批处理阶段，就引入了假脱机技术，缓解了cpu与慢速I/O设备之间的速度矛盾，另一方面，即使cpu在忙碌，也可以提前将数据输入到磁带，技术速度慢的输出设备正在忙碌，也可以提前将数据输出到磁带。 输入井和输出井 假脱机技术又称为&quot;SPOOLING技术&quot;，使用软件方式模拟脱机技术，SPOOLING系统的组成如下： 这样主机就不在需要长时间等待输入了，而是直接从磁盘即输入井中拿取数据，而慢速的技术输入就是将数据放入到磁盘中，这样就类似于吃自助餐，服务员（用户层软件）将数据直接提前放到餐台（磁盘）上，而餐客（设备）需要数据时就直接从餐台上拿取相应的数据了，输出亦是如此，这样就减少了长时间的数据等待时间了。 输入/输出缓冲区 实际上就是上面所讲的餐台。 共享打印机原理 这个就是我们之前讲的实现数据区共享以防止死锁的技术应用。 独占式设备：只允许各个进程串行使用设备，一段时间内只可以满足一个进程的请求。 共享设备：允许多个进程“同时”使用设备（宏观上是同时使用，实际上微观上是交替使用，即并发使用）可以满足多个进程的使用请求。 当多个用户进程提出要输出打印的请求时，系统会答应他们的请求，但是并不是真正把打印机分配给他们，而是由假脱机管理进程为每个进程做两件事： 在磁盘输出井中为每一个进程分配一个空闲缓冲区（也就是说，这个缓冲区是在磁盘上的），并将要打印的数据送入其中。 为用户进程申请一张空白的打印请求表，并将用户的打印请求填入表中（其实就是用来说明用户的答应数据存放位置等信息的），再将该表挂载到假脱机文件队列上。 当打印机空闲时，输出进程会从文件队列的队头取出一张打印请求表，并且根据表中的要求将要打印的数据从输出井传送到输出缓冲区，在输出到打印机进行打印。用这种方式可依次处理完全部的打印任务。 因此假脱机文件队列实际上就是打印任务队列，假脱机技术(SPOOLING技术)可以把一台物理设备虚拟成逻辑上的多台设备，可将独占式设备改造成共享设备。 总结 设备的分配与回收 设备分配时应考虑的因素 设备的固有属性可以分为三种： 独占设备：一个时段只能分配给一个进程（如打印机） 共享设备：可同时分配给多个进程使用（如磁盘），各进程往往是宏观上同时共享使用设备，而微观上是交替使用，即并发性的特点。 虚拟设备：采用SPOOLING技术将独占设备改造成虚拟的共享设备，可同时分配给多个进程使用（如采用SPOOLING技术实现的共享打印机） 设备的分配算法：FIFO,优先级算法，短作业优先SJF等。 从进程的安全性上考虑，设备分配有两种方式： 安全分配方式：为进程分配一个设备后就将进程阻塞，本次I/O完成后才将进程唤醒。这样一个时间段内每个进程只能使用一个设备，优点是破坏了请求和保持条件，不会死锁，缺点是对于一个进程来说，cpu和I/O设备只能串行工作，效率较低。 不安全分配方式:进程发出I/O请求后，系统为其分配I/O设备，进程可以继续执行，之后还可以发出新的I/O请求，只要某个I/O请求得不到满足时才将进程阻塞。这样一个进程可以同时使用多个不同的I/O设备，优点是进程的计算任务和I/O任务可以并行处理，是进程迅速推进，缺点是有可能发生死锁（死锁避免，死锁的检测和解除来解决此问题）。 静态分配和动态分配 静态分配：进程运行前为其分配全部所需资源，运行结束后归还资源，破坏了请求和保持条件，不会发生死锁。 动态分配：进程运行期间动态申请设备资源，但是可能会发生死锁。 设备分配管理中的数据结构 一个管道可以控制多个设备控制器，每个设备控制器可以控制多个设备。其中每个层次都会有自己的信息表如下： 设备控制表（DCT） 在进程管理中我们知道系统会根据阻塞原因的不同，将进程PCB挂到不同的阻塞队列中。因此设备队列的队首指针指向的一定是因为等待这个设备而导致阻塞的PCB队列。 控制器控制表（COCT） 每个设备控制器都会对应着一张COCT，操作系统会根据COCT的信息对控制器进行操作和管理。 通道控制表（CHCT） 每一个通道也都会对应着一个CHCT，操作系统会根据CHCT的信息对通道进行操作和管理。 系统设备表（SDT） 记录了系统中全部设备的情况，每一个设备对应一个表目。 设备分配的步骤 根据进程请求的物理设备名查找SDT（注意物理设备名是进程请求分配设备时提供的参数） 根据SDT找到DCT，若设备忙碌则将进程挂到设备等待队列中，不忙碌则将设备分配给进程 根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列，不忙碌则将控制器分配给进程。 根据COCT找到CHCT，若通道忙碌则将进程PCB挂到控制器等待队列，不忙碌则将通道分配给进程。 只有设备、控制器、通道三者都分配成功时，这次设备分配才算成功，之后便可以启动I/O设备进行数据传送了。 有没有什么缺陷？如何解决？ 有，我们发现进程请求时需要提供“物理设备名”，但是底层细节对用户不透明，不方便编程，因此如果一旦换了物理设备，那么这个程序就无法运行了，并且如果进程请求的物理设备正在忙碌，那么即使系统中还有同类型的设备，这个进程也会阻塞等待。改进方法就是建立逻辑设备和物理设备之间的映射机制，用户编程时只需提供逻辑设备名。 设备分配步骤的改进 根据进程请求的逻辑设备名查找SDT（注意物理设备名是进程请求分配设备时提供的参数） 根据SDT找到DCT，若设备忙碌则将进程挂到设备等待队列中，不忙碌则将设备分配给进程 根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列，不忙碌则将控制器分配给进程。 根据COCT找到CHCT，若通道忙碌则将进程PCB挂到控制器等待队列，不忙碌则将通道分配给进程。 逻辑设备表LUT建立了逻辑设备名和物理设备名之间的映射关系，当某个用户进程第一次使用设备时使用逻辑设备名向操作系统发出请求，操作系统会根据用户进程指定的设备类型（逻辑设备名）查找系统设备表，找到一个空闲设备分配给进程，并在LUT中增加相应表项。如果之后用户进程再次通过相同的逻辑设备名请求使用设备，则操作系统会通过LUT表即可知道用户进程实际要使用的是哪个物理设备了，并且也能知道该设备的驱动程序入口地址了。但是我们前面也讨论过：如果整个系统就一张LUT，那么各个用户所使用的逻辑设备名不允许重复，适用于单用户操作系统，而每个用户都拥有一种LUT，那么不同用户的设备逻辑名可以重复，使用于多用户操作系统。 总结"},{"title":"存储器与CPU连接","path":"/wiki/计算机组成原理笔记/存储器与CPU连接/index.html","content":"主存储器与CPU的连接原理 主存储器通过数据总线、地址总线和控制总线（读/写）和CPU相连 数据总线的位数与工作频率的乘积正比于数据传输率 地址总线的位数决定了可寻址的最大内存空间 控制总线指出总线周期的类型和本次输入/输出操作完成的时间 主存容量的扩展 单个存储芯片的容量肯定是有限的，他在字数或者字长方面与实际存储器的要求都有一定的差距，因此我们需要在字和位两方面进行扩展来满足实际存储器的要求。通常的方法有位扩展法，字扩展法和字位同时扩展法来扩展主存容量。 在学习这些内容前，我们先来了解一下为何要进行字、位扩展以及扩展的特点。我们前面学习了存储器的容量表示是XB×Y位。也就是说寻址范围是0~2^X，每一次输出的数据位数是Y位。但是在实际应用中，可能会出现需要4KB×16位的存储器，然而我们只有1KB×8位的存储器，那么寻址范围太小不够4KB，且一次性输出的数据位数是8位少于16位，那么此时地址线和数据线与存储芯片的型号就有矛盾了，所以我们需要将这有限个存储芯片以一定的方式组合扩展成4KB×16位。其中数据线位数应该总是等于一次输出的数据位数也就是等于扩展后的存储芯片位数。地址线至少能够表示组合扩展后存储芯片的寻址范围，但是可能会大于这个范围，因为部分地址线会成为片选信号线。 位扩展法 那么我们首先来学习以下位扩展，顾名思义，仅仅是需要扩展位数。CPU的数据线数与存储芯片的数据位数不相等，此时必须对存储芯片进行位扩展，方法很简单，就是用多个存储器件组合对数据字长进行扩充，增加存储字长即可，使得一次输出的数据尾位数等于数据线数。比如，现在我们要使用8个8K×1位的存储芯片组合进行位扩展成一个8K×8位的存储器件。如下图组合： 首先我们讲解一下上图，A0~A12表示的是地址线（Address)，D0~D7是数据线（Data)。那么很明显一个存储芯片一次性只能输出一位数据，并且寻址范围仅是8K，而现在我们要求寻址范围不变仍是8K，但是一次性输出的数据必须是8位（和数据线数相等）。那么很容易想到，我们只需要每次输出数据的时候，每一个存储芯片都贡献一位，这样组合出来就是一个8位数据了，所以每一个RAM芯片都连接一个不同的数据线，而这8个RAM芯片肯定是同时工作的，即要输出必定同时输出各贡献一位数据。所以8片RAM芯片的地址线A12~A0，非CS,非WE都连在一起，即他们同时控制着这8片芯片的工作方式。 所以我们可以总结出在采用位扩展时，各芯片连接地址线的方式相同（每一个芯片都同时连接着A12~A0来表示4K的寻址范围)，但是连接数据线的方式不同（各连接一个不同的数据线,输出数据时各贡献1位数据）。 字扩展法 字扩展是指增加存储器字的数量，而位数不变，即仅增大寻址范围。比如现在我们要用4个16K×8位的存储芯片组成一个64K×8位存储器件。此时已经满足了每一个存储芯片即可输出与数据总线位数相同的数据了。但是要用这4个芯片（寻址范围都是0~2^14-1)组合扩展成一个寻址范围为0~2^16-1的存储器件。组合方式如下： 此时芯片的地址线，控制线，读写控制线相应并联，而不再是串联统一由一个信号管理了。我们可以看出每一个芯片还是都连接着A13~A0地址线来表示自己的16K寻址范围，但是此时A15A14却和译码器相连接用来传送片选信号（顾名思义，就是选择哪一个存储芯片工作的信号)。那么此时我们就可以用一下方式来实现寻址范围（字）扩展： 第一片芯片工作时满足A15A14=00，所以寻址范围是0000000000000000-0011111111111111 第二片芯片工作时满足A15A14=01，所以寻址范围是0100000000000000-0111111111111111 第三片芯片工作时满足A15A14=10，所以寻址范围是1000000000000000-1011111111111111 第四片芯片工作时满足A15A14=11，所以寻址范围是1100000000000000-1111111111111111 所以我们可以看出译码器可以用A1514来控制片选信号从而选择每次工作时由哪一个芯片工作，并且最终的地址拼接着A15A14也就变成了16位即寻址范围扩大了，但是从每一个芯片的视角来看，他们的寻址范围并没有变化只是起始地址不再都从0开始了而已。每一个芯片都同时连接着D7~D08个数据线，所以每一次只有一个芯片工作，他一次性就输出了满足数据线位数的8位数据。 采用字扩展时，各芯片连接地址的方式相同（都是同时连接着A0~15，一次性接受16位地址），连接数据线的方式也是相同的（都连接着D7~D0，一次性输出8位数据）。但在某一个时刻只需选中一个芯片，所以通过片选信号非CS或采用译码器设计连接到相应的芯片）。 字位同时扩展法 既然有字扩展和位扩展，那么就肯定还有更加复杂的组合扩展方法即字位同时扩展。这种方法既增加存储字的数量，又增加存储字长。比如用8片16K×4位的RAM芯片组合扩展成一个64K×8位的存储器。那么组合方式如下： 即8个芯片每两个芯片采用位扩展组合成4个16K×8位的芯片，这4个组合芯片再采用字扩展扩展成64K×8位的芯片。所以A15A14仍然是片选信号，4个16K×8位组合芯片每次只只有一个工作，但是这个组合芯片的两个16K×4位存储芯片总是要同时工作的，一个输出数据的前4位，一个输出数据的后4位从而拼接组合成一个8位的数据。 所以采用字位同时扩展时，各芯片连接地址线的方式相同（都是连接着A15~A0)，但是连接数据线的方式不同（每一个存储芯片都只连接4个数据线），而且需要通过片选信好非CS或采用译码器设计连接到相应的芯片。 总结 扩展方式 目的 方法 位扩展 增长存储字长 各芯片串联地址线，并联数据线 字扩展 扩大寻址范围 各芯片并联地址线，串联数据线 字位同时扩展 既增长存储字长，又扩大寻址范围 各芯片并联地址线，并联数据线 存储芯片的地址分配和片选 前面我们学习了片选信号可以控制不同的存储芯片工作，下面我们就来细分以下不同的片选信号产生方式。首先我们要知道CPU要想实现对存储芯片的访问，首先要选择存储芯片，即进行片选，然后为选中的芯片依地址码选择相对应的存储单元，以进行数据的存取，即进行字选。片内的字选通常是由CPU传出的N条地址线完成的，地址线直接接到所有存储芯片的地址输入端（N由片内存储量2^N决定）。所以我们不关注由地址直接决定的片内字选，而是学习一下片选信号的产生方法。 线选法 线选法用除片内寻址的高位地址线（或经反相器）分别接至各个存储芯片的片选端，当某地址线信息为“0”位时，就选中与之对应的存储芯片。这些片选地址每次寻址时只能有一位有效，不允许多位有效，这样就能保证每次只选中一个芯片（或芯片组）。假设4片2K×8位存储芯片用线选法构成8K×8位存储器，各芯片的片选信号如下表 芯片 A14~A11 0# 1110 1# 1101 2# 1011 3# 0111 4个芯片，所以需要额外的四个高位地址线来表示片选信号，一般都是1表示不工作，当第i位为0时就表示选中第i个芯片工作，比如上表中A11这个最低位为0就表示0号芯片工作，1101就是2号芯片。而片内字选的地址码就是A10~A0用于寻址。 很明显这种方法优点是线路简单，不需要地址译码器。但是缺点却也很大，首先地址空间不连续了，1110是1号芯片地址的高位部分，但是3号芯片高位地址部分反而是小的0111，这不好表示地址连续。并且选片的地址线必须分时为低电平（否则不能工作，即每位表示一个芯片的编号，每次只能有一位为0来表示选中一个芯片0）。这种方法不能充分利用系统的存储空间，造成地址资源的浪费。比如现在有4位高位地址，明明可以有2^4=16中组合方案，但是却只能用来控制4个芯片即只能使用其中的4中组合方案来表示片选信号。当芯片很多时，这种方法弊端太大。 译码片选法 译码片选法就是解决上面线选法的局限性的，他可以充分利用剩余的高位地址线。比如8片8K×8位的存储芯片组成64K×8位存储器（地址线16位，数据线8位），需要8个片选信号，若采用线选法，除去用于片内寻址的13位地址线，还额外需要8个地址线来表示8个片选信号。但是现在仅余下3个地址线了即只有3位可以表示片选信号了。此时使用译码片选法，即用一片74LS138作为地址译码器，则A15A14A13=000时选中第一片，A15A14A13=001时选中第二片，以此类推，3位8种组合刚好可以表示8个芯片的片选信好，充分利用了系统的存储空间。 总结 片选信号产生方法 特点 片选信号数量 优缺点 线选法 n个位中只有一个为0 n位n个片选信号 线路简单，但是利用率低，寻址空间不连续 译码片选法 n个位中不同的组合都是一种片选信号 n位2^n个片选信号 虽然复杂，但是存储空间利用率高，寻址空间连续 存储器与CPU的连接 合理选择存储芯片 要组成一个主存系统，选择存储芯片是第一步，主要指存储芯片的类型（RAM或者ROM）和数量的选择。通常选用ROM存放系统程序，标准子程序和各类程序（因为不易修改且断电后不易丢失），RAM则是为用户编程而设置的。此外，在考虑芯片数量时，要尽量是连线简单，方便。 地址线的连接 存储芯片的容量不同，其地址线数也不同，CPU的地址线往往比存储芯片的地址线数要多，因为部分地址线需要和译码器组合来控制片选信号的产生。通常是将CPU的地址线的低位和存储芯片的地址线相连，以选择芯片的某一单元（字选），这部分的译码是由芯片的片内逻辑完成的。而CPU地址线的高位则在扩充存储芯片时使用，用来选择存储芯片（片选），这部分译码由外接译码器逻辑完成。 例如CPU地址线为16位，即A15~A0，1K×4位的存储芯片仅有10根地址线，那么此时CPU的低地址位A9~A0与存储芯片的地址线A9~A0相连。 数据线的连接 CPU的数据线往往与存储芯片的数据线不一定相等，在相等时直接连接即可，如果不相等必须使用存储芯片位扩展，使得其数据位数和CPU的数据线数相等。 读/写命令的连接 CPU读/写命令线一般可直接与存储芯片读/写控制端相连，通常高电平为读，低电平为写。有些CPU读写命令线是分开的（读为非RD，写为非WE，均为低电平有效），此时CPU的读命令线应与存储芯片的允许读控制端相连，而CPU的写命令线则应与存储芯片的允许写控制端相连。 片选线的连接 片选线的连接是CPU与存储芯片连接的关键。存储器由许多存储芯片叠加而成，哪一片被选中完全取决于该存储芯片的片选控制端非CS是否能接收到来自CPU的片选有效信号。 片选有效信号与CPU的访存控制信号非MREQ（低电平有效）有关，因为只有当CPU要求访存时，才要求选中存储芯片。若CPU访问I/O，则非MREQ为高，表示CPU不需要访存，不要求存储器工作。 例题 设CPU有16根地址线，8根数据线，并且用非MREQ作为访存控制信号（低电平有效），用非WR作为读/写控制信号（高电平为读，低电平为写）。现在有下列存储芯片：1K×4位RAM，4K×8位RAM，8K×8位RAM，2K×8位ROM，4K×8位ROM，8K×8位ROM以及74LS138译码器和各种门电路。画出CPU与存储器的连接图。要求主存地址空间分配的6000H~67FFH是系统程序区，6800H~6BFFH为用户程序区。 首先我们需要确定系统程序区使用ROM，用户程序区使用RAM，所以ROM和RAM芯片都要选择。然后我们确定存储器数据线尾数应扩展为8位。然后我们来查看所选芯片的寻址范围。 首先是6000H~67FFH之间的寻址空间范围是800H=2K。所以需要一片1K×8位的ROM。ROM地址线11根。然后是6800H~6BFFH之间的寻址空间范围是400H=1K，所以需要一片1K×8位的RAM。发现没有1K×8位的RAM芯片，所以使用两个1K×4位的RAM芯片进行位扩展。RAM地址线10根。然后我们发现CPU的总地址线是16根，不满足为每一个存储器都分配全部的地址线，所以ROM存储器和由两个RAM组成的存储器要并联组成字扩展，所以他们需要连接一个译码器。并且此时我们观察一下地址范围： {6000H∼67FFH:0110000000000000∼01110011111111116800H∼6BFFH:0110100000000000∼0110101111111111\\begin{cases} 6000H\\sim67FFH:0110000000000000\\sim0111001111111111\\\\ 6800H\\sim6BFFH:0110100000000000\\sim0110101111111111 \\end{cases} {6000H∼67FFH:0110000000000000∼01110011111111116800H∼6BFFH:0110100000000000∼0110101111111111​ 我们知道ROM存储器的地址码需要用到A0~A10，RAM存储器的地址码需要用到A0~A9。所以A11~A15可以用来当做片选信号线。所以地址的高5位是片选信号位，而对于ROM存储器，剩下的11位刚好全部用来表示字选的片内地址码即可。而对于RAM存储器低10位就已经可以用来表示字选的片内地址码了，第6位不会使用到，所以一直是0，如下： 所以当红框内的是100即十进制为4时就是ROM地址，如果红框内是101即十进制为5且第11位A10不会用到永为0那么就是RAM地址（两个条件需要同时成立，所以需要一个5&amp;！0，所以使用的是与非门）。又因为高两位用不到因为都是01没有区分作用，所以片选信号只需要A13A12A11即可。所以连接图如下： 我们观察上图果然A0~A9作为了RAM的地址线，同时两个RAM芯片是位扩展的方式，同时A0~A10作为了ROM的地址线，又因为地址线有共享部分，所以两个存储器芯片组最终并联字扩展，一次只能有一个工作，A13A12A11连接着译码器的CBA三位片选信号位同时A15A14没用到。非MREQ控制线也连接上了，同时数据线数和存储器的线数也相等了。"},{"title":"存储器概述","path":"/wiki/计算机组成原理笔记/存储器概述/index.html","content":"存储器简介 我们之前学习到冯诺依曼体系中的五大重要部件：输入设备，输出设备，运算器，控制器，存储器。上一节我们学习的算术逻辑单元是运算器的一小部分，这里我们详细学习一下存储器。 存储器的分类 存储器只是一个总名称，其种类繁多有许多种，首先我们可以按照几个不同的角度将存储器分类。 按在计算机中的作用（层次）分类 主存储器：又称为主存，内存，用来存放计算机运行期间所需的大量程序和数据，CPU可以直接对齐进行访问，他也可以和告诉缓存cache以及辅助存储设备交换数据。特点是容量小，存取速度较快，每位价格高。 辅助存储器：又称为辅存，外存，是后援存储器，用来存放当前暂时用不到的数据和程序，以及一些永久性保存的信息，他不能够直接和CPU进行信息交换。特点是容量大，存取速度慢，单位成本低。 高速缓冲器：又简称为cache，位于主存和CPU之间，用来存放正在执行的程序段和数据段，以便CPU能够高速使用。cache的存取速度可与CPU相匹配速度最快，但是容量小，价格高昂。目前的高档计算机都会将它们制作在CPU中。 按存储介质分类 存储器可以分为磁表面存储器（磁带，磁盘）、磁心存储器半导体存储器（MOS型存储器，双极型存储器）和光存储器（光盘）。 按存取方式分类 随机存储器（RAM）：存储器的每一个存储单元都可以将内容随机存取，而且存取的时间与存储单元的物理位置无关。优点是读写方便，使用灵活，主要用于主存或告诉缓冲存储器。RAM又分为静态RAM（以触发器原理寄存信息）和动态RAM（以电容充电原理寄存信息）。但是断电内容会丢失。 只读存储器（ROM）：存储器的内容只能随机读入不能写入，信息一旦写入存储器就固定不变，即使断电，内容也不会丢失。因此，通常用它存放固定不变的程序，常数和汉字字库，甚至用于操作系统的固化。他和随机存储器共同作为主存的一部分，统一构成主存的地址域。 思考：RAM和ROM存储方式？ 我们可以大胆猜测，由于它们都是随机存取，并且和物理位置无关，那么就和索引表式的离散存储方法很相似。所以应该会有一个存储数据单元的索引表，这样随机存取就实现了与物理位置无关的特点了。 补充：ROM派生存储器是可以写入的 由ROM派生出的存储器也包含可反复重写的类型，ROM和RAM的存取方式都是随机存取。并且要注意广义上的ROM已可通过电擦除等方式进行写入了，“只读”的概念并未保留，但是仍然保留了断电内容保留、随机存取的特性。仅仅是可以通过一些特定的方法可以进行更改内容了而已，其写入速度比读取速度慢的多。 串行访问存储器：顾名思义，对存储单元进行读/写操作时，需要按照其物理地址的先后顺序寻址，包括顺序存取存储器（如磁带）和直接存取存储器（如磁盘）。 思考：顺序存取存储器和直接存取存储器的区别？ 顺序存取存储器的内容只能够按某种顺序存取，存取的时间长短与信息在存储体上的物理位置相关，其特点是存取速度慢。直接存取存储器既不像RAM那样随机的访问任何一个存储单元，又不像顺序存储器那样完全按顺序存取，而是介于两者之间。存取信息时现寻找整个存储器的某个小区域（例如磁道上的磁道），再在小区域内顺序查找。 按信息的可保存性分类 易失性存储器：断电后，存储信息即消失的存储器，例如RAM。 非易失性存储器：断电后信息仍然保持的存储器，例如ROM、磁表面存储器和光存储器。 破坏性读入存储器：其某个存储单元的信息被读入时，原存储信息被破坏，因为存储单元信息会被破坏，所以每一次读出操作后，必须紧接一个再生的操作，以便恢复被破坏的信息。 非坏性读入存储器：其某个存储单元的信息被读入时，原存储信息不会被破坏。 存储器的性能指标 存储器有三个重要的性能指标，分别是存储容量 ，单位成本和存储速度。这三个指标相互制约，设计一个优秀的存储器就是要使这三个指标尽可能都同时更好。 存储容量 存储容量=存储字数×字长（如1M×8位）存储容量=存储字数×字长（如1M×8位） 存储容量=存储字数×字长（如1M×8位） 1B=8bit,其中存储字数是存储器的地址空间大小，字长表示的是一次存取操作的数据量。所以存储容量表示的就是存储器存储数据的位数大小。 单位成本 单位价格=总成本/总容量单位价格=总成本/总容量 单位价格=总成本/总容量 就是造价成本，要保证一位的成本尽可能的小。 存储速度 数据传输率=数据的宽度/存储周期数据传输率=数据的宽度/存储周期 数据传输率=数据的宽度/存储周期 这里我们介绍几个重要的时间指标： 存取时间Ta：存取时间是指从启动一次存储器操作到完成该操作所经历的时间，分为读入时间和写入时间。所以这个时间表示的仅仅是数据读取/写入操作的时间。 存取周期Tm：存储周期又称为读写周期或访问周期，它是指存储器进行一次完整的读写操作所需要的全部时间，即连续两次独立访问存储器操作（读或写操作）之间所需的最小时间间隔。 主存宽带Bm：主存宽带又称为数据传输率，表示每秒从主存进出信息的最大数量。单位是字/秒、字节/秒，或者位/秒。 思考：存取时间和存取周期的区别？ 存取时间不等于存取周期，通常存取周期大于存取时间，这是因为任何一个存储器，在读写操作之后一定还需要一段时间恢复内部状态，这段时间我们成为恢复时间。对于破坏性读出的存储器，存取周期往往比存取时间大得多，甚至存取周期是存取时间的两倍之大。因为存储器中的信息读出后需要迅速进行再生。 总结 存储器的层次化结构 为了解决存储系统大容量、高速度、低成本3个相互制约的矛盾。在计算机系统中，通常采用多级存储结构来存储信息。如下图： 在图中越靠上的部分造价越高，容量越小但是同时存取速度就越快，CPU的访问频率就越大。CPU,Cache,主存和辅存组成了最经典的三级存储系统结构如下图： 存储系统的层次结构主要体现在“Cache-主存”层次和“主存-辅存”层次。前者是为了解决CPU和主存的速度不匹配问题而产生的，后者则是为了解决存储系统容量问题的。在存储体系中，Cache,主存可以和CPU直接进行信息交换，而辅存中的信息需要先导入都主存以后才可以被cpu进行存取访问。 存储器层次结构的主要思想就是上一层的存储器作为低一层存储器的高速缓存。从CPU的角度看，“Cache-主存”层次的数据存取速度接近于Cache，容量和位价都接近于主存。从“主存-辅存”层次分析，其速度接近于主存，容量和位价接近于辅存。这样就缓解了速度，容量和位价三者的制约关系了，现代计算机系统几乎采用的都是这种三级存储系统，需要注意，主存和Cache之间的数据调动都是由硬件自动完成的，对所有程序员都是透明的，而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，只是对应用程序员透明。在“主存-辅存”这次层次的不断发展中，逐渐形成了虚拟存储系统，在这个系统中程序员变成的范围与虚拟存储器的地址空间相对应，远大于实际物理地址范围。对于具有虚拟存储器的计算机系统而言，编程可用地址空间远大于主存空间。 思考：上层内容与下层内容的关系？ 在&quot;Cache-主存&quot;和“主存-辅存”层次中，上一层的内容一定是来自与下一层的内容副本，所以Cache（或主存）中的内容只是主存（或辅存）中内容的一部分。越到底层，数据存储范围越大，而越到上层，存储的数据范围越小。 总结"},{"title":"主存储器","path":"/wiki/计算机组成原理笔记/主存储器/index.html","content":"易失性半导体随机存储器 主存储器由DRAM实现，靠近处理器的那一层（Cache)是由SRAM实现的，这两种半导体随机存储器都属于易失性存储器，只要电源被切断了，那么原来保存的信息便会丢失。DRAM的位成本低于SRAM，速度也慢于SRAM，主要原因是制造DRAM需要更多硅。而ROM属于非易失性存储器。ROM我们后面详细介绍，我们先来学习一下易失性存储器DRAM和SRAM的工作原理。 SRAM工作原理 我们通常把一个存放二进制位的物理器件称为存储元，他是存储器的最基本的构件。地址码相同的多个存储元构成一个存储单元。若干个存储单元就构成了存储体。 静态随机存储器SRAM的存储元是用双稳态触发器（六晶体管MOS）来记忆信息的，因此即使信息被读出以后，他仍然能够保持其原状态而不需要再生，所以是非破坏性读出。SRAM的存取速度快符合高速缓存Cache的要求，但是集成度低，功耗大，所以一般来组成高速缓冲存储器。 DRAM的工作原理 和SRAM的存储原理不同，动态随机存储器DRAM是利用存储元电路中栅极电容上的电荷来存储信息的，DRAM的基本存储元通常只会使用一个晶体管（注意SRAM一个存储元是使用的六晶体管），所以它比SRAM的密度要高很多。DRAM采用地址复用技术，地址线是原来的1/2，且地址线信号分行、列两次传送。 思考：什么是地址复用技术？ 地址复用技术只适用于DRAM，不适用于SRAM，地址复用技术的目的就是为了减少地址线的数量，便于增加DRAM的集成度。地址复用技术的本质就是分两次送行地址和列地址，因为半导体存储芯片的核心存储矩阵是采用行列地址交叉确定存储单元的，而SRAM需要一次性传入行列地址，假设行列地址一共需要40根地址线，那么SRAM需要至少40根地址线才可以完成一个存储单元的查找读取，而DRAM可以先传入行地址，再传入列地址，因而只需要20根即可。这样就减少了地址线的数量，SRAM和DRAM有许多不同，这个技术也是导致不同的原因之一。 相比于SRAM，DRAM具有容易集成，位价低，容量大和功耗小的优点，但是DRAM比SRAM存取速度要慢， ，一般用来组成大容量主存系统。 DRAM的刷新方式 DRAM电容上的电荷一般只能维持1~2ms,因此即使电源不断电，信息也会自动消失，所以每隔一段时间必须刷新，通常取2ms,这个时间称为刷新周期。常用的刷新方式有3种：集中刷新，分散刷新和异步刷新。 集中刷新：在一段刷新周期内，利用一段固定的时间，依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为“死时间”，又称访存“死区”。集中刷新的优点是读写操作时不受刷新工作的影响，因此系统的存取速度较高，缺点是在集中刷新期间不能访问存储器。例如有128行且每行刷新时间是0.5μs，那么每隔2ms就要占用一段固定时间64μs对128行统一进行刷新。 分散刷新：把对每行的刷新分散到各个工作周期中。一个存储器的系统工作周期分为两部分：前半部分用于正常读、写或保持，后半部分用于刷新某一行。这种刷新方式增加了系统的存取周期，如存储芯片的存取周期为0.5μs,但是系统的存取周期却为1μs（因为还包括了行刷新时间）。很明显分散刷新的优点是没有死区，缺点是加长了系统的存取周期，降低了整机的速度。即128行某一行被读取后就要立刻进行未检查的一行刷新操作，所以每隔128次读取操作就可以刷新完所有行一遍，此时刷新周期不再是2ms而是128μs。虽然整体上刷新周期减少了，但是每一行的刷新时间都增大为了1μs。 异步刷新：异步刷新结合了前面两种方法，它既可缩短“死时间”，又能充分利用最大刷新间隔为2ms的特点。具体做法是将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求。这样可以避免CPU连续等待过程时间，而且减少了刷新次数，从根本上提升了整机的工作效率。即128行，那么2ms/128=15.6μs，每隔15.6μs就进行一次刷新一行且每一行的刷新时间就是0.5s即此时相对于每一行来说是集中刷新而相对整体是分散刷新。 如果将刷新安排在不需要访问存储器的移码阶段，那么就既不会加长存取周期，又不会产生“死时间”了。这是分散刷新方式的发展，也称为“透明刷新”。 思考：三种方法的总结？ 刷新方式 刷新周期 一行的刷新时间 某一行何时刷新 死区 所有行刷新一遍的时间和 集中刷新 2ms 0.5μs 64μs来集中刷新所有行 有 64μs 分散刷新 128μs 1μs 进行一次存取操作后刷新一行 无 128μs 异步刷新 2ms 0.5μs 每隔15.6μs刷新一行 有 64μs 思考：刷新和存取的关系？ 前面也讲过了刷新和存取并不能并行发生，即刷新就不能存取，所以刷新时间就是死时间，刷新与存取很相似，他也是选中一行，这期间片选线，地址线和地址译码器全部占用，只是不同于存取没有输入和输出。所以刷新时间一般和存取时间相同因此存取时间也是0.5μs。集中刷新有64μs刷新时间也就是64μs的死时间。而分散刷新是将刷新放到了存取的后面，所以不会占用存取时间，所以无死时间。而异步刷新虽然集成了两者的优点，但是也是又死时间的，因为异步刷新每个15.6μs产生的某一行的刷新时间0.5μs就是死时间。 思考：刷新周期和所有行刷新时间和的区别？ 刷新周期是指每隔多少时间后所有的行都刷新了一遍，这其中还包括了其他操作的时间。而所有行刷新时间和是仅仅将所有的行刷新时间累加。 思考：DRAM刷新的补充？ 我们要注意上面所讲的刷新仅仅是为了维持存储单元存储的信息不变，这对于内存厂商来说并不难实现，只要在隔多少时间后进行刷新就好了。但是同时还要注意当DRAM某一个存储单元被信息访存后不仅仅要进行保存内容不变的刷新，还需要再刷新一遍因为主存的读取操作是破坏性的，需要再生存储数据。所以DRAM读取操作后可能某一行需要两次刷新一次是维持自身电荷稳定，还有一次是存储信息的再生刷新，而SRAM是非破坏性读取，永远也不需要刷新。 DRAM的刷新需要注意一下问题： 刷新对CPU是透明的，即刷新不依赖于外部的访问，是特定时间自动刷新的。 动态RAM的刷新单位是行，因此刷新操作时仅需要行地址，即刷新行即可。而SRAM不需要这些操作。 刷新操作类似于读操作，但又有所不同。刷新操作仅给栅极电容补充电荷，不需要信息输出。另外刷新时不需要选片，即整个存储器的所有芯片同时被刷新。 一定要区分维持自身信息的刷新和读取后刷新的目的是不同的。 我们一定要注意易失性存储器和刷新的区别。易失性存储器是指断电后数据丢失，SRAM和DRAM都满足断电内容消失。但是需要定时刷新只有DRAM，而SRAM不需要。究其原因是SRAM是使用双稳态触发器来记忆信息的，而DRAM使用的是栅极电容发上的电荷，电荷会逐渐减少，所以需要定时补充。 SRAM与DRAM的总结 SRAM(静态) DRAM（动态） 存储信息 双稳态触发器 电容 破坏性读出 否 是 读取特点 读：“查看”触发器状态写：改变触发器状态 读出后需要重新充电（破坏性读取）读：连接电容，检测电流变化写：给电容充/放电 需要刷新 否 是（一种刷新是用来维持电荷稳定，还有一种是破坏性读取后存储数据再生） 送行列地址 同时送 分两次送 运行速度 快 慢 集成度 低（6个逻辑元件组成） 高（1个或3个逻辑元件构成） 发热量 大 小 存储成本 高 低 存储作用 常用Cache 常用作主存 存储器的读、写周期 RAM的读周期 从给出有效地址开始，到读出所选中单元的内容并在外部数据总线上稳定地出现所需要的时间，称为读出时间(tA)。地址片选信息号非CS必须保持到数据稳定输出（注意不是必须为高/低电位，而是只要稳定即可），tCO为片选信息号的保持时间，在读周期写命令信号非WE必须为高电平。RAM芯片的读周期时序图如下： 一定要注意读周期tRC与读出时间tA是不同的，读周期tRC表示存储芯片进行两次连续读操作时必须间隔的时间，他总是大于等于读出时间。即读周期是从地址有效一直到地址失效的过程，而读出时间仅仅是地址有效到内容稳定出现到数据总线的时间，所以读周期更加长。在读周期中包括了数据有效到数据稳定的过程，而读出时间仅仅有数据有效时间，因为到了数据稳定读出时间就停止了。 RAM的写周期 要实现写操作，要求片选信号非CS和写命令信号WE都必须为低电平，为了使数据总线上的信息能够可靠的写入存储器，要求非CS信号和非WE信号相“与”的宽度至少为tW（即相较时间，也是写数据时间）。具体的写操作时序图如下： 为了保证在地址变化期间不会发生错误写入而破坏存储器的内容，非WE信号在地址变化期间必须保持高电位。为了保证有效数据的可靠写入，地址有效时间至少应为tWC=tAW+tW+tWR即整个写周期地址都要有效。为了保证在非WE和非CS变为无效前能够把数据可靠的写入，要求写入的数据必须在tDW以前在数据总线上已经稳定。 非易失性半导体存储器 RAM和ROM都是支持随机存取的存储器，其中SRAM和DRAM均是易失性半导体存储器。而ROM是一旦有了信息，那么就不能轻易改变，即使断电了也不会丢失信息，他在计算机中是只供读出的存储器，ROM有两个优点： 结构简单，位密度比可读写存储器的高 具有非易失性，所以可靠性高 ROM同样也有许多类型，我们一一了解即可： ROM分类 根据制造工艺的不同，ROM可以分为掩模式只读存储器（MROM)、一次可编程只读存储器（PROM)、可擦除可编程只读存储器（EPROM)、闪速存储器（Flash Memory)和固态硬盘（Solid State Drives)。 掩模式只读存储器 MROM的内容由半导体制造商按用户提出的要求在芯片的生产过程中直接写入，写入以后任何人都无法改变其内容。优点是可靠性高，集成度高，价格便宜，缺点是灵活性差。 一次可编程只读存储器 PROM是可以实现一次性变成的只读存储器，允许用户利用专门的设备（编程器）写入自己的程序，一旦写入，内容就无法改变。 可擦除可编程只读存储器 EPROM不仅可以由用户利用编程器写入信息，而且可以对内容进行多次修改。需要修改EPROM内容时，先将全部内容擦除，然后编程。EPROM又可以分为两种，紫外线擦除（UEPROM)和电擦除（E2PROM)。EPROM虽然既可以读又可以写，但是不能取代RAM，因为EPROM的编程次数有限且写入时间长。 闪速存储器（Flash Memory) 闪速存储器是在EPROM与E2PROM的基础上发展而来，主要特点是既可以在不加电情况下长期保存信息，又能在线进行快速擦除与重写。闪速存储器既有EPROM的价格便宜，集成度高的优点，又有E2PROM电擦除可重写的特点，且擦除重写的速度快。 固态硬盘 基于闪存的固态硬盘是固态电子存储芯片阵列制成的硬盘，由控制单元和存储单元（FLASH芯片)组成。保留了闪速存储器长期保存信息、快速擦除和重写的特性。对比传统硬盘具有读写速度快、低功耗的特性、缺点是价格高昂。 思考：ROM是非破坏性读出吗？ 很明显ROM是非破坏性读出的方式进行工作的，因为再生数据就是重写数据，而ROM一般是不能进行数据写修改的。一般ROM用来存储固定不修改的数据和程序的，例如Apple II或者IBM PC XT/AT等早期个人电脑的开机程序（操作系统）或是其他各种微电脑系统中的韧体所使用的硬件都是ROM。 总结 主存储器的基本组成 下面我们来从整体学习一下一个主存信息存储，读取的操作过程。下图是主存储器（Main Memory,MM)的基本组成框图，其中由许多个存储0或1的记忆单元（也称为存储元件）构成的存储矩阵（也称存储体）是存储器的核心部件。记忆单元是具有两种稳态的能表示二进制0和1的物理器件。为了存取存储体中的信息，必须对存储单元进行编号（也称为编址）。编制单位是指具有相同地址的那些存储元件构成一个单位，可以按照字节编址，也可以按字编址。现代计算机常使用字节编址方式，此时存储体内的一个地址中有一个字节。 指令执行过程中需要访问主存，CPU首先会把访问存储单元的地址送到MAR中，然后通过地址线（注意是单向的，MDR-&gt;地址寄存器）将主存地址送到主存中的地址寄存器，以便地址编码器进行译码选中相应的存储单元，同时CPU将读写信号通过控制线送到主存中读写控制电路。如果是写操作，那么将信号写入选中的存储单元，如果是读操作，那么主存读出选中存储单元的内容送到数据线，然后送到MDR中。数据线的宽度和MDR的宽度相同，地址线的宽度和MAR宽度相同。上图中数据线是64位，所以在按字节编址方式下，每次最多可以存取8个单元的内容。地址线的位数决定了主存地址空间的最大可寻址范围。例如上图中地址线是36位，所以寻址范围是0~2^36-1。数据线和地址线共同反应存储体的最大容量，上图中最大容量是2^36*64位。 总结"},{"title":"数制与编码规则","path":"/wiki/计算机组成原理笔记/数制与编码规则/index.html","content":"计算机系统中的数制 进位计数法 我们在计算时都使用的是进位计数法，即数制相加到最大值时要进一位。这里我们最熟悉的就是十进制的进位了。但是在计算机系统中我们使用的是机器语言，所以是二进制的进位计数。如下： 进制 可以使用的数 10的表示方法 二进制 0,1 1010 四进制 0,1,2,3 22 八进制 0,1,2,3,4,5,6,7 12 十进制 0,1,2,3,4,5,6,7,8,9 10 十六进制 0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F A 思考：为什么要采用二进制，他有什么特点？ 二进制只有0/1位，方便对应到物理器件的状态，如通电/断点，或者高电位/低电位。并且我们发现每个数的位可以对应一个可以使用的符号，比如二进制每一位只能用0或者1，而16进制每一位都有15中可能的符号，基数小的进制很长，比如在二进制中表示一个数时通常需要很多位，而十六进制基数很大，所以就很短。但是运算时，二进制只有与，非，或，异或四中运算情况，而对于更大的进制比如十进制都有100以上的运算情况，很明显二进制虽然长了一点，但是运算起来更加简便，计算性能也就更高，所以计算机采用的是二进制。 进制转换 其他进制转10进制 那么接下来我们来看一下如何实现进制转换，这里我们先来具体了解一下一个进制是如何表示一个数的，实际上符号位的数值是系数，他所在的位数表示的是位权，比如： 二进制：101.1=1∗22+0∗21+1∗20+1∗2−1=5.5二进制：101.1=1*2^2+0*2^1+1*2^0+1*2^{-1}=5.5 二进制：101.1=1∗22+0∗21+1∗20+1∗2−1=5.5 四进制：11.2=1∗41+1∗40+2∗4−1=5.5四进制：11.2=1*4^1+1*4^0+2*4^{-1}=5.5 四进制：11.2=1∗41+1∗40+2∗4−1=5.5 八进制：5.4=5∗80+4∗8−1=5.5八进制：5.4=5*8^0+4*8^{-1}=5.5 八进制：5.4=5∗80+4∗8−1=5.5 十进制：5.5=5∗100+5∗10−1=5.5十进制：5.5=5*10^0+5*10^{-1}=5.5 十进制：5.5=5∗100+5∗10−1=5.5 十六进制：5.8=5∗160+8∗16−1=5.5十六进制：5.8=5*16^0+8*16^{-1}=5.5 十六进制：5.8=5∗160+8∗16−1=5.5 这里一定要注意小数点后面的位权分别是-1,-2,-3…，前面的位权是0,1,2,3…并且我们发现确实101.1中的’1’,‘0’,‘1’,'1’1’都是系数，他们所在的数值串的位置决定了他们的位权。那么我们现在会将各种进制转换成了10进制了，但是如果我们想要将10进制转换成其他进制怎么做呢？这里我们回忆一下初中学过的连除法。 10进制转其他进制 我们一定要注意连除法对于小数点前的数是除到商为0在停止，并且最后是倒序着将余数排列成串，小数点后的数是不断乘，直到小数点后面全零，然后顺序着将小数点前面的数排列成串在拼接。比如： 将23.25转换成二进制，那么转换方法如下： 同理如果要转换成4进制，那么就是不断除以4和不断乘4，如果是8进制就是不断除以8和不断乘8。 其他进制转其他进制 这个办法就比较麻烦啦，我比如四进制的11.2转换到二进制，那么就只能先将四进制的11.2转换成十进制的5.5，然后再转换成二进制的101.1了。即上面两种方法的总和使用，关键就是以10进制为跳板。并且无论是哪种进制转换，重点要掌握小数的转换方法。 或者使用如下方法：n进制就是位一组表示一个数，比如： 因为四进制一位等于二进制的两位，所以二进制串中从低位（靠近小数点）开始每两个组成一个数就是四进制的数，如果位数不足就补零。比如八进制和16进制，都是从靠近小数点的地方开始组合，到两边时位数不够了就要补零来凑。 真值和机器数 实际上数还有正负之分，所以一般要去一个符号位来表示正负，0表示正数，1表示负数： 所以15的机器数应该是01111也写成0,1111，这个都好只是用来隔开符号位的，实际上在机器中并不存在，-8就要写成11000。而对于一个二进制数到底是解码成一个纯正整数还是负数就要看变量是如何声明的了。比如11000如果看成是一个纯正整数unsign int 那么就是+24，如果是一个负数那么就是-8。 BCD码 我们发现实际上对于计算机一般的计算就是将我们输入的十进制的数转换成二进制计算然后在输出十进制的形式，所以大部分的计算都在二进制和十进制中发生，所以我们需要一种更好的二进制与10进制的转换表示方式，既能够快速方便计算机处理又可以方便于人类理解，所以产生了BCD码。如下： BCD码规定了各位的权值不再是2^n-1，而是特定的4个位为一组表示一个十进制数，这个四个位权从高到低排列是8,4,2,1。什么意思呢？查看下表： 0 1 2 3 4 5 6 7 8 9 0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 那么根据BCD码的计算规则，我们可以得到以上的表中数值对应的BCD码是这样产生的 1=0∗8+0∗4+0∗2+0∗1=11=0*8+0*4+0*2+0*1=1 1=0∗8+0∗4+0∗2+0∗1=1 8=1∗8+0∗4+0∗2+0∗1=88=1*8+0*4+0*2+0*1=8 8=1∗8+0∗4+0∗2+0∗1=8 并且当1+8时上面的BCD码也可以正确表示 1+8=0001+1000=1001=8∗1+0∗4+0∗2+1∗1=91+8=0001+1000=1001=8*1+0*4+0*2+1*1=9 1+8=0001+1000=1001=8∗1+0∗4+0∗2+1∗1=9 这样的方法既能够方便计算机计算，同时我们也可以轻松的通过二进制串读出具体的数值。但是我们知道BCD码规定是4位组合成一个十进制数，但是我们知道在二进制的4位组合下可以有16中组合，即还有6中冗余无效的二进制串： 10 11 12 13 14 15 1010 1011 1100 1101 1110 1111 上面这六个是非法无意义的BCD码，规定当相加后的串落入以下区间时，就要加上0110产生的新BCD码为结果，既保证了不能一次性用四位二进制串表示10以上的数，这样BCD码中的四位二进制位总是对应着一个十进制0~9的数，就符合人类思维了。所以： 我们发现当5+8用BCD计算后结果为1101落入了非法映射中（即虽然确实此时读还是能读出13，但是表示是非法的，因为我们规定一个四位组合只能表示0~9）所以，加上一个0110，这样1101+0110=10011，我们在从地位划分四个四个组合就是0001和0011也就是13。这就是BCD码的表示方法，这种方法比较常见，需要牢记。同时还有余3码和2421码等，可以了解即可。 计算机系统中的编码 字符与字符串的ASCII码 最常见的就是表示字符和字符串的ASCII码了，他将每一个键盘上的字符都对应着一个可以用7位二进制编码表示的数。如下: 其中我们可以将128个字符划分一下区域： 可印刷字符 32~126 数字 48（011 0000）~57（011 1001） 注意：这里去掉高三位后面四位其实就是0~9的二进制表示 大写字母 65（100 0001）~90（101 1010） 小写字母 97（110 0001）~122（111 1010） 我们这里熟背0对应的ASCII码是48，A对应的是65，a对应的是97。我们要回推算不同字母或者数字的ASCII码，比如我们已知A的ASCII码是65，那么字符‘H’存放在了某存储单元M中，那么M中存放的内容是什么？ 我们可以确定M中存放的是H的ASCII码，而我们又知道了A的ASCII码是65，H是第八个字母，所以H的ASCII码为65+(8-1)=72=1001000所以M中存放的内容是0100 1000。这里一定注意存储单元的内容都是按字节存储，所以必须是Byte的整数倍，也就是必须是8位的整数倍表示，所以这里应该用八位表示。 大端模式和小端模式 我们这里在讨论一下字符串的字符存储模式，大端模式就是存储单元内先存储高位字节，后存储低位字节的顺序，即我们正常的理解的顺序存储，比如假设我们现在有一个存储区，他的每个存储单元可以放4B，那么IF_A&gt;B_THEN_READ©_这句话存储后就是这样： 就是从左往右，高位存高位字节，低位存低位字节。对应的ASCII码就是： 但是如果是小端模式，那么就是存储单元内先存储低位字节，后存储高位字节的顺序，即每个存储单元（4个格，这一行）都是倒着存的，如下： 每一行都是从右往左，从存储单元低位到高位分别存储字符的高位到低位。 奇偶校验码 就是将校验码分为有效信息位和奇偶校验位，奇校验码就是要保证校验码中1的个数为奇数，而偶校验码就是要保证校验码中1的个数为偶数： 比如上图中的1001101的奇校验就是奇偶校验位上要加上一个1使得整体的1的个数是奇数，而偶校验就是要在1001101前面加上一个0这样保证了整体1的个数是偶数个。这种方法有两种可供选择的校验规律，一般是用来检验信息位的奇数位是否出错，但是无法纠正错误，因为只是知道1的个数不对，具体哪里错了无从得知，常用于检验存储器数据的检查和传输数据的检查。但是局限性较强，所以一般使用更好的方法。重点掌握奇校验码和偶校验码的求解。 海明校验码 海明校验码更加科学，他实际上就是一种特殊地组合方式使得可以组成多组奇偶校验码组，从而可以既能发现错误，同时还可以根据海明码得知是第几位出错从而完成检验以及纠正的功能，具体为什么这样做，我现在还没想明白，但是不影响我们解题。这里就介绍以下方法。 首先回忆之前的奇偶校验我们知道一般设置一位（1bit）的校验位即可，但是这里我们需要要求信息为和校验位满足一个要求： 确定海明码的位数 实际上就是确定信息为何校验位是否满足一个可以组成海明码的条件关系，假设现在这个海明码有n个信息为，k个校验位，那么必须满足下面的条件才可以形成用来校验的海明码： n+k&lt;=2k−1或者也可以表示为2k&gt;=n+k+1n+k&lt;=2^k-1或者也可以表示为2^k&gt;=n+k+1 n+k&lt;=2k−1或者也可以表示为2k&gt;=n+k+1 我们来简单理解一下这个式子以便加深印象，2^k表示的是加上了k个校验码后最多可以检验出多少种错误情况，而n+k+1表示的是在一个n+k位的组合海明码会可以形成n+k+1中形式，那么也就是说n+k位的海明码可能有n+k个错误情况以及1中正确情况，而我们的校验码可以检验的最多情况是2^k，所以当且仅当2^k&gt;=n+k+1时这个n+k位的海明码可以利用这k各校验位查找出自己的所有错误情况并表示出来。 满足了上面这个式子以后说明我们现在可以进行组装海明码了。那么接下来我们进行组装 确定校验位的位置分布 接下来我们需要组装校验位和信息位了，我们需要确定校验位要放在哪里。我们这里假设信息位D4D3D2D1是1010，然后校验位是P3P2P1，我们需要将P3,P2,P1插入到信息位D4D3D2D1中来组成一个海明码H7H6H5H4H3H2H1。那么对于Pi位的校验位，他要放在海明码中的第2^i-1处。即 Hi=P2i−1H_i=P_{2^{i-1}} Hi​=P2i−1​ 所以对于上面的n=4,k=3，且信息位是1010，我们组成海明码时，P3要放到H4，P2要放到H2，P1要放到H1处，所以其他的剩余Hi处放信息位，所以最终组成的海明码应该如下： 接下来我们还需要确定校验位应该填写什么值。 分组以形成校验关系（确定个校验位的数值） 这里的分组很简单，我们要保证一个数据为Di要由多个校验位P1,P2,P3的几个组合形式来校验，其中到底每一个Di选那几个校验组合检验我们只需要满足被校验的信息位的海明位号等于校验该信息位的各校验位的海明位之和。比如对于1010我们已经确定的海明位： 我们可以看出对于D1他的海明位是H3所以选择了P2（海明位是H2)和P1（海明位是H1）的组合，因为H3=H2+H1。D2的校验组合就是P3P1等等。然后我们将这些组合竖着分组，分成1,2,3组（这里的组数一定&gt;=校验位数的） 那么检验位P1就是需要第一组的数据位进行异或取值，异或就是相同取0，不同取1，所以 P1=D1⊕D2⊕D4=0⊕1⊕1=0P_1=D_1⊕D_2⊕D_4=0⊕1⊕1=0 P1​=D1​⊕D2​⊕D4​=0⊕1⊕1=0 P2=D1⊕D3⊕D4=0⊕0⊕1=1P_2=D_1⊕D_3⊕D_4=0⊕0⊕1=1 P2​=D1​⊕D3​⊕D4​=0⊕0⊕1=1 P3=D2⊕D3⊕D4=1⊕0⊕1=0P_3=D_2⊕D_3⊕D_4=1⊕0⊕1=0 P3​=D2​⊕D3​⊕D4​=1⊕0⊕1=0 所以各个校验位的值就都填写出来了，这样我们就写出了1010的海明码是 H7 H6 H5 H4 H3 H2 H1 D4 D3 D2 P3 D1 P2 P1 1 0 1 0 0 1 0 海明码的校验原理 那么我们是如何进行对海明码的检验的呢？怎样通过海明码来检验信息位是否正确？如果不正确又是如何知道第几位出错了呢？ 我们知道此时1010正确的海明码就应该是1010010，即如果信息位正确恰好有 S1=P1⊕D1⊕D2⊕D4=0S_1=P_1⊕D_1⊕D_2⊕D_4=0 S1​=P1​⊕D1​⊕D2​⊕D4​=0 S2=P2⊕D1⊕D3⊕D4=0S_2=P_2⊕D_1⊕D_3⊕D_4=0 S2​=P2​⊕D1​⊕D3​⊕D4​=0 S3=P3⊕D2⊕D3⊕D4=0S_3=P_3⊕D_2⊕D_3⊕D_4=0 S3​=P3​⊕D2​⊕D3​⊕D4​=0 即此时S3S2S1刚刚好是000（想想也知道P1,P2,P3都是由正确的D1,D2,D3,D4组合异或出来的，所以如果反过来D1,D2,D3,D4没有错误，那么刚好此时校验位和信息位异或出来的结果相同即S1就是P1⊕P1=0，所以只有正确时才能为0）。那么如果海明码不正确，比如检测出来的S3S2S1=001,那么就说明1010的海明码有错误并且海明码的第001=1位有错误，取反就可以纠正错误了，再比如S3S2S1=101，那么就说明H5错误，需要取反纠正即可。为了验证表示的位置确实是错误的，我们假设对应的1010的海明码我们接受的是1010000，那么此时S2就会报错为1，即此时S3S2S1=010说明H2错误，我们发现此时确实是H2错误了。 最后我们再来思考一下k和n需要满足的关系，我们就不难发现了此时如果满足2^k&gt;=n+k+1,那么刚好任何一个有错误的位都可以由k位二进制串标志出错误的位置。即如上面k=3时最多可以表示8个位置，而海明码刚好就是有0~7八个位置，所以任何一个错误都可以由k位二进制串S3S2S1表示出来，并且由于海明码也是二进制码，所以只有0/1两种可能的值，所以一旦某个位置出错误了说明只要取反就一定是正确的数值了。这种海明码校验明显更加科学高效，是一种较为广泛的校验方法。 循环冗余检验码（CRC) 循环冗余检验码最终实现的目的和海明检验码是一样的，需要技能查找到错误，并且同时还能得知错误的位置进行修正。其思路如下： 首先它不同于海明码，不是将校验位插入到信息位当中，而是将所有的校验位放到信息位的后面组成CRC码。 确定CRC位数 实际上就是确定在K个信息位后面插入的校验位数R是多少，这个R与接收端和发送端约定好的一个多项式G(x)的最高位有关，如对于 G(x)=x3+x2+1G(x)=x^3+x^2+1 G(x)=x3+x2+1 那么R就是最高项的次数值，这里R就是3，最终的CRC码应该是一个长度为N=K+R的码，所以CRC码又称为（N,K）码。那么接下来我们需要求解校验位的值 确定校验位的数值 由于校验位都是拼接在信息位后面如下： 所以也就没有确定校验位一说了，直接求解各个校验位的数值即可了，这里我们以信息码为101001为例讲解，我们约定生产多项式G(x)=x^3+x^2+1，那么R=3，接下来我们需要求解3个校验位的数值，我们先假设校验码是000，然后拼接到信息码后面，所以组成了一个长度为K+3的码就是101001000，我们将这码称之为被除数，这个步骤叫做移位（实际上就是将信息码左移了R位），同时根据G(x)我们取每一个x的系数，所以取出来的码就是1101因为 1101=1∗x3+1∗x2+0∗x1+1∗x0=G(x)=x3+x2+11101=1*x^3+1*x^2+0*x1+1*x^0=G(x)=x^3+x^2+1 1101=1∗x3+1∗x2+0∗x1+1∗x0=G(x)=x3+x2+1 我们将1101称之为除数，那么接下来求解校验码就是将被除数不断地进行对除数的模2除法。 思考：什么是模2除法？ 我们规定：模2加法和模2减法的结果是相同的，都是做异或运算。模2除法和算术除法类似，但是对于每一次的减法都要使用模2减法，并且结果不影响其他2位，也不允许借位，步骤如下： 用除数对被除数进行最高位做模2减，不借位 除数右移一位，如果余数最高位是1，那么就商1，即对余数做除数的模2减法。如果余数最高位是0，那么就商0，除数继续右移一位。 循环直到余数位数小于除数时，该余数就是最终的余数，也就是校验码了。 比如我们现在求解101001的校验码，所以就是除数1101对被除数101001000进行模2除法如下图： 我们来就提分析一下这个模2除的过程： 这样我们就得到了校验码是001，所以101001的CRC码就是101001001。 CRC的检验原理 检验原理实际上就是对接收到的CRC码进行模2除，如果刚好可以整除即余数为0说明CRC码正确，否则得到的余数就是错误的位置的二进制表示。比如对于101001的一个CRC码是101001011，那么通过不断的进行1101（这个是G(x)约定的除数）的模2除法最终会得到余数是010，即第010=2位错误，一定要注意无论是海明码还是CRC码，他们的排列都是从右往左数错误的位置，即CRC码的排列方式也是C9C8C7C6C5C4C3C2C1,所以错误的位置是C2，即从右往左数的第二位，查看确实是这个错误了，取反即可纠正错误。 CRC码和海明码两种码效果相同无优劣之分，都是对于接收到的数据进行检验。 总结"},{"title":"算术逻辑单元ALU","path":"/wiki/计算机组成原理笔记/算术逻辑单元ALU/index.html","content":"算术逻辑单元（ALU） 在前面我们讲过计算机五大组件之一的运算器，其中，他的组成如下： 其中这个ALU就是运算器的核心元件，算术逻辑单元，它主要的功能是： 算术运算：加、减、乘、除等 逻辑运算：与、或、非、异或等 辅助功能：移位、求补等 他的工作流程如下： 就是传入两个或者多个操作数，然后通过运算指令译码产生的信号进行算数逻辑运算，然后输出运算结果，这里的具体工作原理和结构组成，我们以经典的4位ALU芯片（74181）为例进行学习。74181的结构如下： 74181能执行16种逻辑运算和16中算术运算，可工作于正/负逻辑操作方式下，所以刚好可以用电流的两种状态代表两种运算状态，所以这里的M位是用来区分进行的是逻辑运算还是算术运算的，M=0表示算术运算，M=1表示逻辑运算。其中剩余的S0~S3是表示具体的算术运算或者逻辑运算的位，比如在M=1,S3~S0-1001时，是在做逻辑运算A⊕B。 74181是4位并行加法器（并行就是同时进行，OS中有细讲），其4位进行位也是同时产生的，所以如果我们使用4片74181芯片可以组成一个16位的ALU。但是如果是串接，那么虽然片内进位是快速的，但是片间进位却仍然是逐片传递的，即组内并行，但是组间串行，因此总的形成时间还是很慢，其具体放的演示如下： 那么我们肯定是要优化合作组成的结构来加快运算速度。 我们可以把16位ALU的每4位作为一组，即将74181和74182芯片（先行进位芯片）配合，用类似位间快速进位的方法来实现16位ALU（4片ALU组成），则能得到16位的两级先行进位ALU，即组内并行，组件并行。如下： 其实说白了就是每一个4位ALU看成是一位，这样4个组间进位就可以看成是74182的4个位间进位了。也就是形成了一个两级进位，这样就实现了组内并行，组间并行的进位ALU了。和74181类似的片位式芯片的还有Am2901,这个芯片也是4位并行加法器，可以和先行进位芯片Am2902配合，而此芯片还有16个16位寄存器，因此也称为是片位式运算器。 数字电路基础知识 我们在讲解具体如何通过电路来实现算术逻辑运算之前，先来学习一下数字电路的基础知识。 基本逻辑 在电路逻辑表示中，我们通常将断电称为0，通电称为1，即： 首先我们来学习以下基本的逻辑运算符号： 与运算 其逻辑表达式如下 Y是A与B的结果：Y=A⋅BY是A与B的结果：Y=A·B Y是A与B的结果：Y=A⋅B 他的电路表示为： 我们在物理电路中学过，此时是串联电路，如果想要Y通电（即真值为1），那么A,B必须都通电（即A，B真值都为1）才可以，所以真值表为： A B Y 0 0 0 0 1 0 1 0 0 1 1 1 他的电路符号是： 或运算 其逻辑表达式如下： Y是A或B的结果：Y=A+BY是A或B的结果：Y=A+B Y是A或B的结果：Y=A+B 他的电路表示为： 此时要想Y通电，只要满足至少A,B有一个通电（至少A,B有一个真值为1）即可。所以真值表如下： A B Y 0 0 0 0 1 1 1 0 1 1 1 1 他的电路符号是： 非运算 其逻辑表达式为： Y是非A的结果：Y=A‾Y是非A的结果：Y=\\overline{A} Y是非A的结果：Y=A 他的电路表示为： 所以当A为断点（即A真值为0）时，Y通电，所以真值表如下： A Y 0 1 1 0 他的电路符号是： 复合逻辑 上面就是借用电路的串联，并联，短路三种形式实现的简单的逻辑运算，当然是用复合电路我们也可以实现复杂的复合逻辑运算如下： 与非运算 其逻辑表达式为： Y是A与非B的结果：Y=A⋅B‾=A‾+B‾Y是A与非B的结果：Y=\\overline{A·B}=\\overline{A}+\\overline{B} Y是A与非B的结果：Y=A⋅B=A+B 他的电路不好直接通过复合拼接表示，一般借用了半导体，所以就不给出电路图了。我们来看一下真值表： A B Y 0 0 1 0 1 1 1 0 1 1 1 0 电路符号是： 注意他和与门不一样，前面有个小圆圈。 或非运算 其逻辑表达式为： Y是A或非B的结果：Y=A+B‾=A‾⋅B‾Y是A或非B的结果：Y=\\overline{A+B}=\\overline{A}·\\overline{B} Y是A或非B的结果：Y=A+B​=A⋅B 其真值表如下： A B Y 0 0 1 0 1 0 1 0 0 1 1 0 电路符号是： 异或运算 其逻辑表达式为： Y是A异或B的结果：Y=A⊕BY是A异或B的结果：Y=A⊕B Y是A异或B的结果：Y=A⊕B 其真值表为： A B Y 0 0 0 0 1 1 1 0 1 1 1 0 他的电路符号是： 对于异或运算，我们不太好记忆规律，可以通过下图记忆： 所以只有0和1时异或才能使得低位为1，也就是相同为0，不同为1。 同或运算 这里我们再来了解一个很特殊的逻辑运算同或运算，其逻辑表达式如下： Y是A同或B的结果：Y=A⊙BY是A同或B的结果：Y=A⊙B Y是A同或B的结果：Y=A⊙B 他的真值表如下： A B Y 0 0 1 0 1 0 1 0 0 1 1 1 实际上我们看完真值表，发现只不过是和异或相反了，现在是相同取1，不同取0了， 所以结果总是异或的非。 电路符号： 加法器 我们回忆一下前面讲的运算器中的算术逻辑单元ALU并联系之前所学的各种算术逻辑运算的实现原理，我们很容易就可以知道所有的运算实际上最终都可以转换成加法。所以可以见到ALU中最重要的部件就是加法器，所以ALU才会出现复杂的进位问题，那么接下来我们就详细学习一下几种加法器。 一位全加器 一位全加器（FA）顾名思义模拟的就是一个位的加法，所以会涉及到两个问题： 本位最终是填写0还是填写1 向自己的高位是进位1还是进位0（即不进位） 而能决定这两个问题就是两个操作数的位以及自己的低位产生的进位，所以输入有三个值，而输出有两个值分别是（假设我们现在讨论第i位的加法） {Ai:操作数A的第i位数值Bi:操作数B的第i位数值Ci−1:Ai−1和Bi−1相加产生的向结果i位进位数值Ci:Ai和Bi相加产生的向结果i+1位进位的数值Si:答案的第i位数值\\begin{cases} A_i:操作数A的第i位数值\\\\ B_i:操作数B的第i位数值\\\\ C_{i-1}:A_{i-1}和B_{i-1}相加产生的向结果i位进位数值\\\\ C_i:A_i和B_i相加产生的向结果i+1位进位的数值\\\\ S_i:答案的第i位数值 \\end{cases} ⎩⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎧​Ai​:操作数A的第i位数值Bi​:操作数B的第i位数值Ci−1​:Ai−1​和Bi−1​相加产生的向结果i位进位数值Ci​:Ai​和Bi​相加产生的向结果i+1位进位的数值Si​:答案的第i位数值​ 所以我们需要给出根据上面3个输入来计算出下面两个输出的方法： 这里我们首先给出Si（又称为本位和）的逻辑表达式为： Si=Ai⊕Bi⊕CiS_i=A_i⊕B_i⊕C_i Si​=Ai​⊕Bi​⊕Ci​ 根据上面表达式我们很轻松就可以推断出有以下结论：当这三个位有奇数个1时，本位和数值就是1，否则就是0，这和二进制加法的规律相同。所以我们知道对于一位加法，是使用异或运算来模拟的。 思考：为什么公加法式如上，异或运算为什么可以来模拟本位加法？ 你可能会有点小疑惑上面是如何模拟的，所以就有了这个解答，一定要透彻理解。我们以一个例子来讲解： 我们发现对于上面的公式就是模拟的上图的这三种情况的运算，其中三个输入一目了然，他们很显然一同决定了本位和与进位数值，那么确实当三个输入有奇数个1时就是本位和为1，否则为0。并且使用异或运算就刚好符合加法的规律。 接下来我们再给出进位的逻辑表达式： Ci=Ai⋅Bi+(Ai⊕Bi)⋅CiC_i=A_i·B_i+(A_i⊕B_i)·C_i Ci​=Ai​⋅Bi​+(Ai​⊕Bi​)⋅Ci​ 好家伙，可是够复杂，别慌我们先解读一下这个式子。很显然Ci若要为1，可以有以下几种情况： {情况1：Ai与Bi都是1情况2：Ai和Bi的有一个为1同时Ci也是1\\begin{cases} 情况1：A_i与B_i都是1\\\\ 情况2：A_i和B_i的有一个为1同时C_i也是1 \\end{cases} {情况1：Ai​与Bi​都是1情况2：Ai​和Bi​的有一个为1同时Ci​也是1​ 我们思考一下这两种情况只要有一种情况出现那么Ci就会为1，而他刚好也是符合加法运算的规律的，我们看一下下图就是两个情况演示： 我们发现情况1Ci-1实际上已经不决定是否产生进位1了，因为Ai和Bi之和就已经决定了必须产生进位了，此时Ci-1只是决定本位和是1还是0了。而对于情况2Ci-1为1才使得决定了最终第i位要想第i+1高位产生进位1。 所以上面两个公式完美模拟实现了一位的加法，所以这就是一位全加器的功能原理，那么我们就可以给出他的电路逻辑结构了： 串行加法器 在串行加法器中，只有一个全加器，所以一次只能够进行一个位的加法运算，因此若操作数长n位，那么加法就要分n次进行，每次产生一个位的和，并且串行逐位的送回寄存器。进位触发器用来存储进位信号，以便参与下一次的运算。因为只需要一个一位全加器即可，所以串行加法器具有器件少，成本低的优点，但是运算速度缓慢，常用于某些低速的专用计算器。 并行加法器 很显然，并行加法器就是解决串行加法器计算过慢问题的。并行加法器一般是由多个一位全加器组成，其位数和机器的字长相同，各个位数据同时运算。并行计算器可同时对数据的各位相加，但是存在一个加法的最长运算时间问题，我们思考一下原因，虽然操作数的各位是提供的，但是我们知道对于一个位的计算除了需要两个操作数以外，还需要一个从低位传进来的进位信号，其数值也会影响本位和以及向高位的进位输出。因此并行加法器的最长运算时间主要是由进位信号的传递时间决定的，计算时间远远要短于进位信号的传递时间。因此提高并行加法器速度的关键就是尽量要加快进位的产生和传递的速度。并行加法器的产生个传递如下： 并行加法器中的每个全加器都有一个从低位送进来的进位输入和一个传送给高位的进位输出。通常将传递进位信号的逻辑线路连接起来构成的进位网络称为进位链。进位表达式如下： Ci=Gi+PiCi−1(Gi=1或者PiCi−1=1时，Ci=1)C_i=G_i+P_iC_{i-1}(G_i=1或者P_iC_{i-1}=1时，C_i=1) Ci​=Gi​+Pi​Ci−1​(Gi​=1或者Pi​Ci−1​=1时，Ci​=1) 并且有 {Gi=AiBi:进位产生函数Pi=Ai⊕Bi：进位传递函数\\begin{cases}G_i=A_iB_i:进位产生函数\\\\P_i=A_i⊕B_i：进位传递函数\\end{cases} {Gi​=Ai​Bi​:进位产生函数Pi​=Ai​⊕Bi​：进位传递函数​ 我们分析一下上面的式子，发现这就是一位全加器进位表达式，只不过换了一下形式而已。因为Ai和Bi都为1时，就已经可以肯定会向高位产生一个进位信号1了，所以Gi被称为进位产生函数，而PiCi-1均为1时，就要求低位向本位传递的进位信号为1时才可以使本位向高位传递一个进位信号1，所以Pi被称为进位传递函数。那么并行加法器的进位通常可以分为以下两种： 串行进位 很好理解，就是将n各一位全加器串接起来，就可以进行两个n位数的相加，这种加法器称为串行进位的并行加法器。如下图： 那么每级进位直接依赖于前一级的进位，即进位信号时逐级形成的。那么就有以下推导： C1=A1B1+(A1⊕B1)C0C_1=A_1B_1+(A_1⊕B_1)C_0 C1​=A1​B1​+(A1​⊕B1​)C0​ C2=A2B2+(A2⊕B2)C1C_2=A_2B_2+(A_2⊕B_2)C_1 C2​=A2​B2​+(A2​⊕B2​)C1​ ...... ... Cn=AnBn+(An⊕Bn)Cn−1C_n=A_nB_n+(A_n⊕B_n)C_n-1 Cn​=An​Bn​+(An​⊕Bn​)Cn​−1 所以，低位运算产生的进位所需要的时间会影响至最高位运算的时间，所以并行加法器的最长运算时间主要是由进位信号的传递时间决定的，位数越多延迟时间越长，而全加器本身的求和延迟是次要因素，所以加快进位信号产生和传递的速度是关键。 并行进位 我们思考一下串行进位信号产生和传递速度慢的原因，主要是因为第i位的进位信号是Ci-1，所以需要等待Ci-1完成才可以进行，所以导致了延迟时间积累到了高位。而并行进位尝试解决了这一困局，并行进位又称为先行进位，同时进位，其特点是各级进位信号同时产生，而不再是像串行进位那样需要逐级等待了。所以采用并行进位的方案可以进一步提高进位产生和传递的速度，即将各级低位产生的本级G和P信号一次同时传递到高位，那么并行进位是如何做到的呢？我们将上面的式子进行拆解： C1=G1+P1C0C_1=G_1+P_1C_0 C1​=G1​+P1​C0​ C2=G2+P2C1=G2+P2G1+P2P1C0C_2=G_2+P_2C_1=G_2+P_2G_1+P_2P_1C_0 C2​=G2​+P2​C1​=G2​+P2​G1​+P2​P1​C0​ C3=G3+P3C2=G3+P3G2+P3P2G1+P3P2P1C0C_3=G_3+P_3C_2=G_3+P_3G_2+P_3P_2G_1+P_3P_2P_1C_0 C3​=G3​+P3​C2​=G3​+P3​G2​+P3​P2​G1​+P3​P2​P1​C0​ 我们不难发现，实际上所有进位信号Ci都可以拆分成C0的多项式，所以所有位的进位输出信号实际上仅有Gi,Pi,C0决定，而不依赖于其低位的进位输入Ci-1，因此各个进位可以并行同时产生和传递。 这种进位方式很显然很快速，与字长无关，但是局限性是随着加法器位数的增加，Ci的逻辑表达式会变得越来越长，输入变量会越来越多，使得计算电路泰国复杂。所以采用并行进位不现实。所以我们还需要改进，这里又有两种改进方法： 单级先行进位方式 即我们退求其次，不要求全部并行进位了，以16位为例。我们不再尝试16位同时进位的纯并行进位方式，而是先将16位划分成4个组，每一个组是一个4位加法器，这一组内是并行进位同时产生进位，而这4个组之间使用的是串行进位，这样，就不会导致高位的计算逻辑过于复杂，同时也保证了计算性能的优化，其结构图如下： 注意这个图和上面的纯串行进位的并行加法器是有区别的，这里的每一个加法器不再是一位全加器FA，而是4位CLA加法器。此时是组内并行，组间串行。我们从低位到高位将4个组编号成1~4，那么对于1号CLA，根据C0同时产生C3,C2,C1然后计算输出C4,2号CLA会根据C4同时并行产生C7,C6,C5，然后计算输出C8，以此类推。 多级先行进位方式 我们还是将其16位分成4个组，每个组是4位CLA加法器，但是此时我们将这四个4位加法器不串接，而是再次使用并行进位的方式连接，这样就形成了两级并行进位的计算方式。如下图： 此时是组内并行，组间也并行。我们从低位到高位将4个组编号成1~4，那么1号CLA的进位输出C4可以改写成 C4=G4+P4G3+P4P3G2+P4P3P2G1+P4P3P2P1C0=G1∗+P1∗C0C_4=G_4+P_4G_3+P_4P_3G_2+P_4P_3P_2G_1+P_4P_3P_2P_1C_0=G_1^*+P_1^*C_0 C4​=G4​+P4​G3​+P4​P3​G2​+P4​P3​P2​G1​+P4​P3​P2​P1​C0​=G1∗​+P1∗​C0​ 其中 Gi∗是组内进位产生函数,Pi∗是组进位传递函数G_i^*是组内进位产生函数,P_i^*是组进位传递函数 Gi∗​是组内进位产生函数,Pi∗​是组进位传递函数 这两个函数至于Pi,Gi有关，而与进位信号C无直接联系。所以以此类推我们可以推出： C8=G2∗+P2∗C4=G2∗+P2∗G1∗+P2∗P1∗C0C_8=G_2^*+P_2^*C_4=G_2^*+P_2^*G_1^*+P_2^*P_1^*C_0 C8​=G2∗​+P2∗​C4​=G2∗​+P2∗​G1∗​+P2∗​P1∗​C0​ C12=G3∗+P3∗C8=G3∗+P3∗G2∗+P3P2∗G1∗+P3∗P2∗P1∗C0C_{12}=G_3^*+P_3^*C_8=G_3^*+P_3^*G_2^*+P_3P_2^*G_1^*+P_3^*P_2^*P_1^*C_0 C12​=G3∗​+P3∗​C8​=G3∗​+P3∗​G2∗​+P3​P2∗​G1∗​+P3∗​P2∗​P1∗​C0​ 以此类推，但是这种方法需要对CLA进行改进，此时4个4位加法器都不再计算C4,C8,C12了。 第一组内根据C0同时产生G1*,P1*,C3,C2,C1,不产生C4。 第二组内根据C4同时产生G2*,P2*,C7,C6,C5,不产生C8。 第三组内根据C8同时产生G3*,P3*,C11,C10,C9,不产生C12。 第四组内根据C12同时产生G4*,P14*,C15,C14,C13,不产生C16。 那么各组所需要的的C0,C4,C8,C12怎么得来呢？因为他们不能从低位获得进位信号，此时我们就引入了CLA电路，即上面最长的那个，而4位的加法器改名为了BCLA。那么此时CLA可以根据BCLA提供的不同的Gi*,Pi*以及上面推出的公式，用C0并行同时计算出来个BCLA所需要的C4,C8,C12，所以两个并行加法同时进行的，就很强。 思考：两个不同优化改进方式的异同点？ 改进方法名称 进位方式 结构特点 每一个组加法器输入的数据 每一个组加法器输出的数据 单级先行进位 组内并行，组件串行 多个分加法器串接 只需要一个从低位传来的Ci-1 向高位输出一个传递的进位信号Ci-1 多级先行进位 组内并行，组件并行 多个分加法器串接，同时还需要一个额外的CLA电路 只需要一个来自CLA辅助电路的Ci-1 向辅助电路CLA传递Gi*和Pi*以及Ci-1 单级先行进位改进方法是牺牲了部分计算速度，但是大大降低了计算逻辑，同时造价也简单。而多级先行进位改进方法没有牺牲计算速度，但是需要加入一个辅助电路CLA来帮助计算复杂的逻辑运算，造价较高。 思考：算术逻辑单元的计算方式 我们学完了计算方式再来思考一下之前讲到的算术逻辑单元的计算方式，我们不难看出实际上算术逻辑单元采用的就是这两种改进版的并行进位计算方法，而都没有使用串行进位计算方法。 总结"},{"title":"计算机系统概述","path":"/wiki/计算机组成原理笔记/计算机系统概述/index.html","content":"什么是计算机系统组成原理 计算机组成原理的学习 顾名思义，计算机组成原理知识点可以用三部分概括，首先是介绍什么是计算机，然后是计算机的组成，最终再是计算机各个部分的构成原理，知识点由浅入深，由易到难。 各个部分各占1/3板块，我们需要全部熟练掌握，只有理解了最底层的构成原理以及各个板块之间的组成配合方法，才能够深刻理解计算机组成原理的知识点。 所以我们主要学习： 基本计算机部件的结构和组织方式 基本运算的操作原理 基本部件和单元的设计思想 计算机系统简介 我们很容易就可以将计算机系统划分成两部分： 上面是所有计算机都有的共性特征，即软件和硬件相互配合形成才能组成计算机系统，这是区别于操作系统的一大特点，操作系统只是软件。 计算机发展历程 第一代计算机 电子管时代（1946-1957），由电子管组成的电子数字计算机：ENIC横空出世，虽然确实能够进行计算，但是使用的是二进制机器语言，占地面积很大约170平方米，耗电量巨大。 第二代计算机 晶体管计算机时代来临（1958-1964），使用的是面向过程的程序设计语言：FOTRAN，有了操作系统雏形。相较于电子管更叫精巧高效。 第三代计算机 中小规模集成电路时代（1965-1971），此时高级语言迅速发展，开始有了分时操作系统。OS中介绍过分时操作系统他是一个RR时间片轮转执行的操作系统的计算机，对于每一个用户都分配一定的时间片进行运行。 第四代计算机 大规模，超大规模集成电路时代（1971-至今），此时产生了微处理器，并且还产生了许多高级的系统概念：并行，流水线，高速缓存，虚拟存储器等。 计算机硬件发展总结 发展阶段 时间 逻辑元件 速度（次/秒） 内存 外存 第一代 1946-1957 电子管 几千-几万 汞延迟线、磁鼓 穿孔卡片，纸袋 第二代 1958-1964 晶体管 几万-几十万 磁芯存储器 磁带 第三代 1964-1971 中小规模集成电路 几十万-几百万 半导体存储器 磁带、磁盘 第四代 1971-至今 大规模，超大规模集成电路 上千万-万亿 半导体存储器 磁盘、磁带、光盘、半导体存储器 这里我们一定要注意之前所讲的各种计算器的组成原件都是逻辑元件，即用来实现逻辑运算的元件。 计算机编程语言的发展？ 我们前面介绍了各个时代计算器所使用的编程语言的不同，大体上编程语言可以分类为： 这个在OS中也有所介绍，但是这里要注意在高级语言翻译成机器语言之前，还有一个步骤是先编译译成汇编语言，汇编语言是一种助记符，我们并不陌生，在做计算机系统实验时会经常看到。前面是不同汇编指令的名称，后面两项一般是操作数或者寄存器等。这里要注意是通过编译程序将高级语言先编译成汇编语言，然后再通过汇编程序将汇编语言汇编成机器语言，计算机才能够识别指令并进行执行，并且一条高级语言通常会编译成多行汇编语言，一条汇编指令又会翻译成多条机器语言指令。 思考：微处理器的发展？ 我们前面讲到在大规模集成电路的第四代计算器时代出现了微处理器硬件，其发展历程如下，主要是机器字长的增加： 其中机器字长的意思是计算机执行一次整数运算所能处理的二进制位数，我们可以看到随着计算机的发展，机器字长再逐渐增长，这个无疑会表示更大的数，更长的地址，也就同时增大了计算机的空间和计算能力，所以计算机的发展不仅仅是由软件推进，硬件部分的发展也可以大幅提升计算机的性能。我们这里对于80386微处理器的计算机不能再熟悉了，他是最经典的32位微处理器计算机，在我们的nemu实验中，就是再借鉴80386的计算机来进行的。 摩尔定律 伴随着计算机硬件的发展，摩尔提出了一个非常有趣的理论：集成电路上可容纳的晶体管数目，约每隔18个月便会增加一倍，整体性能也会提升一倍。这个定律揭示了信息技术进步的速度之快。 我们可以看到半导体存储器的单芯片容量在迅速增大，从1KB-&gt;4KB-&gt;16KB-&gt;64KB-&gt;256KB-&gt;1MB-&gt;4MB-&gt;16MB-&gt;64MB-&gt;256MB-&gt;1GB，每次提升都在2^10量级以上。 计算机发展方向 角度一：体型 在计算机的发展历程中，逐渐两极分化为两个类型，一种是体型小，便捷可携带但是计算性能较小的微型计算机，例如：手机、PAD、私人电脑等，另一种是体型较大的巨型服务器计算机，其计算性能可观，通常可以集成并并行完成许多任务。再细分可以分为：巨型机，大型机，中型机，小型机，微型机，单片机。 角度二：硬件组成 电子模拟计算机、电子数字计算机等，主要区别是逻辑元件的功能原理不同 角度三：服务对象的不同 通用计算机和专用计算机，通用计算机一般是大型的服务器，而专用计算机就是每个人自己的Laptop等。 角度四：指令和数据流 单指令流&amp;单数据流（SISD）：冯诺依曼体系结构 经典的五大基础硬件：输入设备，输出设备，存储器，运算器和控制器。 单指令流&amp;多数据流（SIMD）：阵列处理器、向量处理器 多指令流&amp;单数据流（MISD）：实际上不存在，因为在单数据流的条件下，多数据流没有实际应用意义。 多指令流&amp;多数据流（MIMD）：多处理器，多计算机 很明显这种多核的计算机可以并行执行多个进程，性能更高，但是也较为昂贵，耗能大。 计算机硬件的基本组成 接下来我们就来讲一讲计算机硬件的基本组成，这里主要介绍冯诺依曼这一经典的组成方式，基本上现代计算器的硬件组成仍然沿用的是冯诺依曼体系。 冯诺依曼计算机 上图就是冯诺依曼体系的简化图，其中有以下几大特点： 计算机硬件系统由输入设备，输出设备，存储器，运算器和控制器5大部件组成 指令和数据以同等的地位存于存储器中，并且可以按地址寻访 存储程序：将指令以代码的形式事先输入到计算机主存储器中，然后按其在存储器中的首地址执行程序的第一条指令，以后就按照该程序的规定顺序执行其他指令直至程序执行结束。 指令和数据都是使用二进制代码表示 指令由操作码和地址码组成，操作码用来表示操作的性质，地址用来表示操作数在存储器中的位置，比如LOAD A,16等 指令在存储器内按顺序存放，通常，指令是顺序执行的，在特定条件下，可以根据运算结果或根据设定的条件改变执行顺序，最经典的就是if-else判断语句的跳转。 早期的冯诺依曼机以运算器为中心，输入/输出设备通过运算器和存储器传送数据。 当然根据计算机的功能不同，会将冯诺依曼的体系进行略微的调整，比如： 不同的设备侧重的硬件也不相同，比如： 但是总体来看，基本上沿用的都是冯诺依曼的经典组成结构。 总结 计算机的功能部件 这里我们逐一对各个部件的原理进行介绍来进一步了解计算机的5大部件 存储器 在一个计算机中，有两处存储数据的地方，和运算器控制器直接进行数据交换的是主存储器为主的主存又称为内存，而还有一部分数据是先存放在外存又称为辅存的地方，一般是暂时不会用到的数据，当使用时是先将数据从外存中调入到内存中再进行运算。外存可以是外设的辅助存储器，磁盘等。 从上图我们不难看出一个数据的访问过程，大部分数据都是存放到了存储体内，当访问这个数据时，实现调用访问指令找到他的存储地址，这个地址就存放在了地址寄存器（MAR)中，通过地址进行访存获得这个数据值然后存储到数据寄存器(MDR)中方便使用。并且一个数据并不是一个十进制的数存放，而是许许多多个0/1位组成表示，通常0/1串的长度是根据机器字长决定的，那么通过译码器可以将二进制串表示的数据翻译成10进制等其他进制的数据。 思考：为什么要用二进制表示？ 首先最主要的就是由计算机的硬件特性决定的，我们知道一个电位通常可以用两个状态来表示，通电和断点，那么刚好可以用1和0来表示，再无第三个状态，所以使用二进制表示契合硬件的特点，同时二进制数据存储虽然可能长度较长，但是同时也意味着计算效率的高效，无论是多么复杂的计算方法，都可以最终拆解为交并异或等基本的二进制操作，这些基础操作运算效率更高，实现简单，所以使用二进制的方式来存储数据。 通常一个数是由固定的位表示的，MAR用于寻址访存，其位数就对应着存储单元的个数。每一位都可以有两种情况0或者1，所以8位存储字就是可以表示0~2^8-1范围的数，存储性能非常可观。MDR数据寄存器的位数一般和存储字长相等，一般是字节的二次幂的整数倍。并且虽然这里介绍是MAR和MDR都是在存储器中，但是在现在的CPU中，MAR和MDR通常都是存在于CPU中的，不难理解，这样的方法数据交流更加利于寄存器和cpu,性能更高。这里一定要注意一个存储单元就是一字节，存储单元中的一个通电元件就是一位，所以假设存储单元是8位，n个存储单元表示的空间就是2^n*8bit=2^nB。 并且MDR是应用于数据交流的总线，是双向的，而MAR是地址总线，一般是访存时的地址，很明显是单向的。cpu通过两个寄存器和指令，译码驱动等部件，实现了和主存之间的读写操作。 运算器，控制器 运算器，控制器一起组成了cpu核心处理器的功能，其中运算器顾名思义肯定是进行运算的，数学运算方式加、减、乘、除还有逻辑运算或、与、非、异或等。如下： 加 减 乘 除 ACC 被加数，和 被减数，差 乘积高位 被除数、余数 MQ 乘数、乘积地位 商 X 加数 减数 被乘数 除数 上面的ACC是累加器，MQ是乘商寄存器，X是操作数寄存器，这三个元件是组成运算器必须的部件。PSW我们知道是程序状态寄存器来表示这个指令或者这个程序是否越权限执行了。ALU是算术逻辑单元，当然运算器中肯定还有许多通用寄存器来存储中间结果的。 控制器是协调各个部件、功能单元配合工作的。他的构成如下： 其中CU是控制单元，IR是指令寄存器存储当前执行的指令，而RC是程序计数器，就是存储下一个指令的地址，实际上就是在IR基础上加一表示下一条指令（这是因为指令通常是顺序存储的）。 所以我们知道cpu同时集成了运算和调度控制各任务执行的功能，是计算机的核心部件。 I/O设备 输入输出设备，都是相对于计算机来说的，所以键盘，鼠标等是输入设备，显示屏，打印机等是输出设备，里面也有自己相对应的独立软件，和驱动软件来完成指令的翻译，执行以及向cpu报告状态信息等，所以同时也听从于cpu的指令调度。 计算机系统多层次结构 我们知道硬件是提供底层服务环境的，软件是在硬件支持下进行运行的。并且操作系统等系统软件是最接近硬件层次的第一层软件，他们会涉及到许多有关硬件的功能。同时根据硬件的状态向上层的应用软件提供接口等服务环境: 所以上层软件会使用高级开发语言，相应的程序先翻译成汇编语言，然后再翻译成传统机器，硬件所能执行的二进制代码，最终再由硬件直接进行微指令的执行： 我们同样将这个语言翻译的过程进行层次划分如下： 一般将二进制代码的部分分为硬件层次，其他为软件层次。这里如何理解汇编语言是一种助记符呢？我们在做过nemu实验后知道实际上log.txt打印的就是我们规定输出的汇编语言，他已经被翻译成了一种对应着机器语言执行序列的方式了，但是不是给硬件机械设备用的，而是方便于我们设计人员了解程序走向，设计程序的助记符，我们可以通过汇编语言向上了解软件程序的运行原理，同时也可以向下掌握硬件系统的工作原理。 计算机的性能指标 最后我们再来简单讲解一下如何评判一个计算机的性能？我们可以从两个角度出发： 容量 毫无以为，计算机的容量至关重要，我们知道在8位数据时代，存储的数据范围很有限，伴随着信息的增大，我们需要扩大数据空间了，所以增大了机器字长，16位，32位再到如今的64位，可以看出，容量毫无疑问会影响到我们计算机的工作性能。 当然伴随着技术的发展，我们也不仅仅局限于扩大机器字长来增大计算机的存储性能了，虚拟存储技术，动态分配都可以让我们充分利用优先的存储空间来存储更多的数据。这里我们只需要记住系统最大的容量计算公式 总容量=存储单元个数Byte=存储单元个数×存储字长bit/8总容量=存储单元个数Byte=存储单元个数×存储字长bit/8 总容量=存储单元个数Byte=存储单元个数×存储字长bit/8 速度 另一方面，毫无疑问，计算机的工作速度也非常重要，执行一个任务我们肯定是需要在保证精度准确的情况下执行的越迅速越好。我们通常用时钟周期来表示一个单位时间长度，那么一条指令的耗时就是数个时钟周期，即（CPI是平均执行周期数，又称为计算机执行一条指令所需的时钟周期数） 单条指令耗时=CPI∗CPU时钟周期单条指令耗时=CPI*CPU时钟周期 单条指令耗时=CPI∗CPU时钟周期 所以我们可以重新定义一下机器字长，机器字长是计算机进行一次整数运算所能处理的二进制数据的位数 假设每次只能处理一个二进制位，那么可以通过编程8条指令完成对8位数据的运算：指令1，指令2……指令8。那么 CPU的执行时间（这个数据运算耗时）=指令1耗时+指令2耗时+……指令8耗时=（指令1的CPI+指令2的CPI+……+指令8的CPI）×CPU时钟周期=平均CPI×指令条数×CPU时钟周期。 同时还有几个可以表示运算速度的指标： 数据通路宽度：数据总线一次所能并行传送信息的位数 吞吐量：指系统在单位时间内处理请求的数量，他取决于信息能够多快的输入内存，cpu能够多快的取指令，数据能多快的从内存取出或存入，以及所得结果能够多快的从内存送给一台外部设备。这些步骤中的每一步都关系到主存，因此，系统吞吐量主要取决于主存的存取周期。 响应时间：指从用户向计算机发送一个请求，到系统对该请求做出相应并且获得它所需要的结果的等待时间。通常包括CPU时间（运行一个程序所花费的时间）与等待时间（用于磁盘访问、存储器访问、I/O操作、操作系统开销等时间）。 MIPS(每秒执行多少百万条指令) MIPS=指令条数/(执行时间×106)=主频/CPIMIPS=指令条数/(执行时间×10^6)=主频/CPI MIPS=指令条数/(执行时间×106)=主频/CPI MFLOPS(每秒执行多少百万次浮点运算) MFLOPS=浮点操作次数/(执行时间×106)MFLOPS=浮点操作次数/(执行时间×10^6) MFLOPS=浮点操作次数/(执行时间×106) GFLOPS(每秒执行多少十亿次浮点操作) GFLOPS=浮点数操作次数/(执行时间×109)GFLOPS=浮点数操作次数/(执行时间×10^9) GFLOPS=浮点数操作次数/(执行时间×109) TFLOPS(每秒执行多少十万亿次浮点运算) TFLOPS=浮点数操作次数/(执行时间×1012)TFLOPS=浮点数操作次数/(执行时间×10^{12}) TFLOPS=浮点数操作次数/(执行时间×1012) 总结 计算机系统概述总结"},{"title":"高性能存储器","path":"/wiki/计算机组成原理笔记/高性能存储器/index.html","content":"双端口RAM 为了提高CPU访问存储器的速度，可以采用双端口存储器、多模块存储器等技术，它们同属并行技术，前者为空间并行，后者为时间并行，这里我们先来学习双端口存储器。 双端口RAM是指同一个存储器有左、右两个独立的端口，分别具有两组相互独立的地址线、数据线和读写控制线，允许两个独立的控制器同时异步地访问存储单元，如下图所示。 很明显当两个端口的地址不同时，在两个端口上进行读写操作一定不会产生冲突。但是，两个端口同时存取存储器的同一地址单元时，会因数据冲突造成数据存储或读取错误。两个端口对同一主存操作有以下4中情况： 两个端口对不同时对同一地址单元存取数据（无冲突） 两个端口同时对同一地址单元读出数据（无冲突） 两个端口同时对同一地址单元写入数据（存取数据）（有冲突） 两个端口同时对同一地址单元，一个写入数据，另一个读出数据（有冲突） 因此后两者对同一地址单元的操作会有冲突（情况3写错误，情况4读错误），此时操作就不能并行进行。我们要避免后两者情况，做法是设置忙信号为0，由判断逻辑决定暂时关闭一个端口（即被延时进行），未被关闭的端口正常访问，被关闭的端口延长一个很短的时间段后再访问。 多模块存储器 提高CPU访存速度，常采用多模块存储器，常用的有单体多字存储器和多体低位交叉存储器。CPU的速度比存储器的的快，因此如果一条一条指令的读取，会有很长的等待时间，因此考虑同时从存储器中取出n条指令，就可以充分利用CPU资源，提高运行速度，多体交叉存储器就是基于这种思想提出的。 单体多字存储器 单体多字系统的特点是存储器只有一个存储体，每个存储单元存储m个字，总线宽度也为m个字，这样一次访问一个存储单元就相当于并行读出m个字，因此地址必须顺序排列并处于同一存储单元。 单体多字存储系统在一个存取周期内，从同一地址取出m条指令，然后将指令逐条送至CPU执行，每隔1/m存取周期，CPU向主存存取一条指令。显然这增大了存储器的带宽，提高了单体存储器的工作速度。 但是缺点是指令和数据必须是连续存放的，一旦遇到了转移指令，或者操作数不能连续存放，这种方法的效果就很不明显。 多体并行存储器 多体并行存储器由多体模块组成，每一个模块都有相同的容量和存取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。他们既能并行工作，又可以交叉工作。 多体并行存储器又分为高位交叉编址（顺序方式）和低位交叉编址（交叉方式）两种。 高位交叉编址 高位交叉编址中高位地址表示体号（即模块号），低位地址为体内地址（即模块内偏移地址）。如下图： 存储器共有4个模块M0~M3，每个模块都有n个单元，各模块地址的范围如图中所示。那么在高位交叉编址方式下，总是把低位的体内地址送到由高位体号决定的模块内进行译码。访问一个连续主存块时，总是先在一个模块内访问，等到该模块访问完才可以转到下一个模块访问，CPU总是按顺序访问存储模块，存储模块不能被同时并行访问，因而不能提高存储器的吞吐率。我们来思考一下上面这种方式的运行特点： 首先我们知道地址是连续的，所以地址应该为00001,00010,00100…~01001，前两位是高位体号，后三位是体内地址。那么对于每一个地址的读取都是先看体号再根据体内地址进行一个存储单元的存取。那么也就是说对于上面的地址，依次是先将M0模块内的每一个存储单元进行顺序的存取以后才开始对M1进行存储单元的存取，同样M1内的所有存储单元全部存取完以后才会进行M2的。并且此时模块内没有并行进行，即每一次只有一个模块在进行对存储单元的存取。我们假设对于任何一个模块内的存取单元的存取周期都是T，那么对于任何一个模块内，都是顺序对存储单元进行存取，所以任意一个模块的存取时间是nT,又因为有4个模块，所以上图的4个模块全部执行完需要4nT。因为此时任意一个存储单元只存储一个字，所以我们可以知道对于顺序方式读取m个字需要顺序访问m个存储单元，所以时间是mT。 一定要注意模块内的地址是连续的，存取方式仍是串行的，因此这种存储器仍然是顺序存储器。 低位交叉编址 低位地址为体号，高位地址是体内地址。如下图： 那么此时每个模块按“模m”交叉编址，即模块号=单元地址%m，假定有m个模块，每个模块有k个单元，则0,m,…,(k-1)m单元位于M0，第1,m+1,…,(k-1)m+1单元位于M1，以此类推。 在低位交叉编址方式下，总是把高位的体内地址送到由低位体号确定的模块内进行译码。程序连续存放在相邻模块中，因此采用此编址方式的存储器为交叉存储器。采用低位交叉编址后，可在不改变每个模块存取周期的前提下，采用流水线的方式并行存取，提高存储器的带宽。原理如下： 设模块字长等于数据总线宽度，模块存取一个字的存取周期为T，总线传送周期为r，那么我们知道这种方式的存取，不是一次性将一个模块全部操作完，而是先将各个模块的相对同位置的体内偏移进行操作，所以每一次存取操作都会切换模块及为M0M1M2M3M0M1M2M3这种方式，所以当M0得到了数据总线传来的数据就可以自己进行相对应的存取操作了时间为T，而此时存取操作不会停止等待，因为他可以立刻切换到下一个模块，对下一个模块的存储单元进行操作，只是需要等待下一个数据从数据总线传来的时间r,所以会延迟一个r，所以对于一个T，可以包括许多个r。我们定义m=T/r,m称为交叉存取度。每次经过r时间延迟后启动下一个模块，交叉存储器要求其模块数必须大于等于m,这样就可以保证启动某模块后经过m×r的时间后会再次启动该模块时，其上次的存取操作已经完成（这样就实现了流水线不间断）。所以存取m个字所需要的时间就大大缩短成了T+(m-1)r比高位交叉编址的mT快了许多。 究其原因是因为此时多个模块可以并行执行存取操作了，如上图一个T，4个模块都可以开始进行自己的任务了，而无需待前者必须完成操作才能开始，这就是流水线原理。 思考：流水线时间图一定是上面的样子吗？ 不一定，上面这个刚好是m=T/r=C（C时正整数）时的图，当m小于T/r时会出现第一个模块还没有执行完就又轮到第一个模块进行下一个数据的操作了，那么就需要有等待了。即上图中的W4灰块左移一点点即为这种情况。当m大于T/r时，那么第一个模块执行完以后还需要再等待一小段时间才会再次轮到他工作。即为上图中的W4灰块右移一点点的情况。所以当m=T/r=C时是最理想的流水线情况，如果不能做到，那么有一小段时间延迟也没有关系。 例题 设存储容量为32个字，字长为64位，模块数m=4，分别采用顺序方式和交叉方式进行组织。存储周期T=200ns,数据总线宽度为64位，总线传输周期r=50ns。在连续读出4个字的情况下，求顺序存储器和交叉存储器各自的带宽。 首先无论是哪种存储方式读出m=4个字的信息总量都是 q=64位×4=256位q=64位×4=256位 q=64位×4=256位 顺序存储器连续读出4个字所需要的时间是 t1=mT=4×200ns=800ns=8×10−7st_1=mT=4×200ns=800ns=8×10^{-7}s t1​=mT=4×200ns=800ns=8×10−7s 而交叉存储器读出4个字所需要的时间是 t2=T+(m−1)r=200ns+3×50ns=350ns=35×10−8st_2=T+(m-1)r=200ns+3×50ns=350ns=35×10^{-8}s t2​=T+(m−1)r=200ns+3×50ns=350ns=35×10−8s 所以带宽分别是 {顺序存储器：W1=q/t1=256/(8×10−7)=32×107b/s交叉存储器：W2=q/t2=256/(35×10−8)=73×107b/s\\begin{cases}顺序存储器：W_1=q/t_1=256/(8×10^{-7})=32×10^7b/s\\\\交叉存储器：W_2=q/t_2=256/(35×10^{-8})=73×10^7b/s\\end{cases} {顺序存储器：W1​=q/t1​=256/(8×10−7)=32×107b/s交叉存储器：W2​=q/t2​=256/(35×10−8)=73×107b/s​ 所以交叉存储器的带宽更大，效率更高。一个存储周期内，交叉存储器可以提供的数据量为单个模块的m倍。 总结"},{"title":"定点数的表示与运算","path":"/wiki/计算机组成原理笔记/定点数的表示与运算/index.html","content":"定点数的表示 无符号数 无符号数就是我们通常所说的非负数，所以整个机器字长的全部二进制位都为数值位，没有符号位，所以无法表示负数，相当于数的绝对值。例如： 这里要记住一个小知识点，一个数值串后面是B表示二进制，D表示十进制,H表示十六进制。所以对于n位机器字长，无符号数可以表示的数量是2^n个数： 例如对于8位机器字长的计算机，他可以表示的无符号数范围是： 所以n位无符号数表示的范围是：0~2^n-1。 有符号数 有符号数即会最高位符号位来决定数值的正负，0是正数，1是负数。并且有符号数的机器表示会有多种形式如原码、补码、反码和移码。为了对上面四中形式进行区分，我们规定用X表示真值： [X]原表示原码，[X]补表示补码，[X]反表示反码，[X]移表示移码[X]_原表示原码，[X]_补表示补码，[X]_反表示反码，[X]_移表示移码 [X]原​表示原码，[X]补​表示补码，[X]反​表示反码，[X]移​表示移码 并且有符号数表示的数值数量和无符号数相同都是2^n个，但是表示的范围是不同的，对于一个n位机器字长的计算机，他能表示的有符号数的范围是-(2^n-1)~2^n-1。 定点表示 那么无符号数和有符号数和定点表示有什么关系？我们知道在机器的数值表示中，为了能够表示小数，我们通常会有一个小数点位置，那么根据这个小数点位置是否固定不变，我们将数划分成了定点表示和浮点表示两种形式。而一般对于一个实数，通常使用的都是定点表示，所以使用定点表示的整数我们称之为定点整数，小数称之为定点小数。那么这里我们就详细就讲解一下定点表示。 定点表示中小数点是事先约定好位置固定不变的，不再使用’.'表示了。这里我们分别看一下定点小数和定点整数的表示方法。 定点小数 约定小数点位置在符号位之后，有效值位最高位之前，那么后面的位权分别是2^(-1),2^(-2)等。如下图： 这里我们一定要区分一个概念，机器里的小数真的就只是小数点后面的数值，例如3.14虽然是小数，但是在机器中3看为整数又称为纯整数，0.14才看为一个真正的小数又称为纯小数。所以对于一个定点小数默认为就是有符号数，所以对于一个数值有效位n位的定点小数(x1~xn)。可以表示的范围是 当x0=0,x1~xn均是1时是最大值，真值就是1-2^(-n)。 当x0=1,x1~xn均是1时是原码所能表示的最小值，真值是-(1-2^(-n))。 此时存储解码时默认就全部是按照小数的位权进行解码： 那么我们如何知道对于一个二进制数值串要按照定点小数进行解码呢？可以根据参量之前的声明格式得知。 定点整数 其实定点整数就是我们广泛所指的纯整数，因为纯整数没有小数部分，所以小数点就固定在有效数值位最后一位即可。解码时位权全部按照2^0,2^1,2^2赋值即可。比如： 我们发现同样是对于011进行计算真值，但是此时由于要按照定点整数计算，所以计算处的真值就是+3D了。那么定点整数同样是有符号数，所以可以表示的范围是： 原码、补码、反码、移码 原码 原码就是我们最常见的二进制数值表示法，由最高位符号位以及有效数值位组成，符号位决定数值的正负，有效数值位表示的是数值的绝对值。 对于纯小数的原码，我们规定求解原码规则如下： [X]原={x0&lt;=x&lt;11−x=1+∣x∣−1&lt;x&lt;=0[X]_原=\\begin{cases} x&amp;0&lt;=x&lt;1\\\\ 1-x=1+|x|&amp;-1&lt;x&lt;=0 \\end{cases} [X]原​={x1−x=1+∣x∣​0&lt;=x&lt;1−1&lt;x&lt;=0​ 对于纯整数的原码，我们规定规则如下“ [X]原={0,x0&lt;=x&lt;2n2n−x=2n+∣x∣−2n&lt;x&lt;=0[X]_原=\\begin{cases} 0,x&amp;0&lt;=x&lt;2^n\\\\ 2^n-x=2^n+|x|&amp;-2^n&lt;x&lt;=0 \\end{cases} [X]原​={0,x2n−x=2n+∣x∣​0&lt;=x&lt;2n−2n&lt;x&lt;=0​ 一定要注意对于机器字长更长的，位数不全的时候要补0，但是对于小数是在有效数值位后面补0，而对于纯整数是在符号位和有效数值位中间补0。 并且在原码中，真值0有正零和负零两种形式，即[+0]原=00000,[-0]原=10000。 补码 我们发现在原码的加减计算时很复杂，尤其是在两个不同符号数的加法或者两个相同符号数的减法时，需要用绝对值大的数减去绝对值小的数，然后最后还要给结果选择合适的符号，这很麻烦，所以引入了补码。补码的加减运算全部都是采用加法运算并且结果正确。 对于纯小数的补码，我们规定规则如下： 我们发现了如下规律： [X]原−&gt;[X]补{如果是正数，则不变如果是负数，符号位不变，数值位取反加一[X]_原-&gt;[X]_补\\begin{cases} 如果是正数，则不变\\\\ 如果是负数，符号位不变，数值位取反加一 \\end{cases} [X]原​−&gt;[X]补​{如果是正数，则不变如果是负数，符号位不变，数值位取反加一​ [X]补−&gt;[−X]补：连同符号位整体取反加一[X]_补-&gt;[-X]_补：连同符号位整体取反加一 [X]补​−&gt;[−X]补​：连同符号位整体取反加一 比如上面的x2=-0.1001的原码是1,1001000，那么他的补码就是符号位不变，数值位取反再加一即可得1,0111000。又因为x2和x1是正负数，所以x2的补码也可以由x1的补码推得，即x1的补码是0,1001000，所以x2的补码就是x1的补码整体取反加一得1,1001000。 对于纯整数的补码，我们规定规则如下： 同样也是遵循上面的规律： [X]原−&gt;[X]补{如果是正数，则不变如果是负数，符号位不变，数值位取反加一[X]_原-&gt;[X]_补\\begin{cases} 如果是正数，则不变\\\\ 如果是负数，符号位不变，数值位取反加一 \\end{cases} [X]原​−&gt;[X]补​{如果是正数，则不变如果是负数，符号位不变，数值位取反加一​ [X]补−&gt;[−X]补：连同符号位整体取反加一[X]_补-&gt;[-X]_补：连同符号位整体取反加一 [X]补​−&gt;[−X]补​：连同符号位整体取反加一 思考：为什么对于补码，会比原码多表示一个数，那个数的由来是什么? 我们知道对于位数确定的数值串，表示的数值数量是固定的，就是2^n中排列组合，那么和原码比，为什么补码会多表示一个数？实际上是因为在原码中0,0000和1,0000都表示0，即一个0的情况占据了两种数值串，然而在补码中，0就一种表示方法，[+0]补=[-0]补=0,0000（因为+0的补码就是+0的原码0,0000，所以根据补码的规律，-0的补码就是+0的补码整体取反加一为10,0000，但是此时我们知道溢出了，丢弃最高位就是0,0000所以补码中0的表示情况就只有0,0000）也就是说，此时在补码中空出了一种情况1,0000按照补码的解码规则，在小数中他表示的是-1，在整数中他表示的是-2^n。 反码 我们知道由原码到补码的过程是取反加一，而作为中间过渡结果，取反后的表示就是反码表示。 对于纯小数的反码，我们规定规则如下： 满足以下规律： [X]原−&gt;[X]反{对于正数,[X]原=[X]反，即无变化对于负数，原码符号不变，数值部分按位取反[X]_原-&gt;[X]_反\\begin{cases} 对于正数,[X]_原=[X]_反，即无变化\\\\ 对于负数，原码符号不变，数值部分按位取反 \\end{cases} [X]原​−&gt;[X]反​{对于正数,[X]原​=[X]反​，即无变化对于负数，原码符号不变，数值部分按位取反​ 我们发现实际上和由原码转换成补码的过程相比就少了一个加一而已。并且上面的规则同样适用于反码转换成原码。 和原码表示的数值数量一样。 对于纯整数的反码，我们规定规则如下： 满足以下规律： [X]原−&gt;[X]反{对于正数,[X]原=[X]反，即无变化对于负数，原码符号不变，数值部分按位取反[X]_原-&gt;[X]_反\\begin{cases} 对于正数,[X]_原=[X]_反，即无变化\\\\ 对于负数，原码符号不变，数值部分按位取反 \\end{cases} [X]原​−&gt;[X]反​{对于正数,[X]原​=[X]反​，即无变化对于负数，原码符号不变，数值部分按位取反​ 和原码表示的数值数量一样。 原码、反码、补码之间的转换 我们要能看懂上面这张转换表，实际上很好看懂，对于原码永远都是符号位+数值位的拼接所以有正0和负0两种情况，对于补码，正数部分和原码没有区别，只是补码对于0000000既可以解释为正0也可以表示为负0，而负数部分就是原码的数值位取反+1或者正数补码整体取反加1。而反码正数部分和原码也没有区别，负数部分就是原码的数值位取反，或者正数反码整体取反，或者补码-1。 我们以126和-126为例如何求出他们对应的原码，反码，补码： 对于126 原码就是0111 1110 反码和原码相同就是0111 1110 补码也和原码相同就是0111 1110 对于-126 原码就是1111 1110 反码就是原码数值位取反1000 0001 或者126的反码（0111 1110）整体取反1000 0001 或者-126的补码（1000 0010）减一1000 0001 补码就是原码数值位取反加一1000 0010 或者126的补码（0111 1110）整体取反加一（1000 0010） 或者反码加一1000 0010 反过来，对于0111 1110和1000 0010看成不同的码又如何求出真值： 对于0111 1110 原码就是直接拼接是0,1111110=+126 因为符号位0是正数，所以反码同原码真值为+126 因为符号位0是整数，所以补码同原码真值为+126 对于1000 0010 原码就是拼接1,0000010=-2 因为符号位1是负数，所以转换成原码时是数值位取反1,1111101就是-125 或者转换成其对应的正数的反码（也就是正数的原码）就是整体取反0,1111101在改变符号位为负变成1,1111101就是原码了真值就是-125 因为符号位1是负数，所以转换成原码时有效位先-1变成1000 0001再取反1,11111110就是-126 或者转换成其对应的正数的补码（也就是正数的原码）就是整体先减1再取反0111 1110再改变符号位为负就是1,1111110就是-126 所以我们可以总结出一个规律，对于真值转码按照规则转写即可，但是码转真值都是统一转换成原码再求解真值（因为原码符合人类思维的真值计算） 这里我们给出一个关系图： 移码 移码常用来表示浮点数的阶码，它只能用来表示整数。移码就是在真值X上加了一个常数（偏置量），通常这个常数取2^n（这里的n表示的是有效信息位，一般在有符号数的二进制串中我们把位数说成n+1,n单独表示有效信息位的个数）。即 [X]移=2n+X[X]_移=2^n+X [X]移​=2n+X 比如： 移码有如下几个特点： 移码中零的表示是唯一的，[+0]移=2^n+0=[-0]移=2^n-1=100…00(n个0)。 一个真值的移码和补码只是符号位相反，即在移码中1表示正，0表示负，而原码，反码，补码都是0表示正，1表示负 移码全0时，是真值的最小值为-2^n，移码全1时，对应真值最大值2^n-1。 移码保持了数据原有的大小顺序，移码大真值就大，移码小，真值就小 思考：怎么根据移码求得真值？ 我们知道 [X]移=2n+X[X]_移=2^n+X [X]移​=2n+X 所以有 X=[X]移−2nX=[X]_移-2^n X=[X]移​−2n 所以对于移码为0111 1110我们先转换成无符号数的真值126，而2^7=128,所以真值就是126-128=-2或者0111 1110-1000000=1111 1110对应补码真值-2。 所以对于真值转移码按照公式计算，而移码转真值同样是按照公式计算，但是要注意最后的细节问题（例如都转成真值计算时是转换成无符号数，用码计算后转真值时是按照补码规则计算） 总结 这部分内容很难理解，计算较难，重点是要掌握真值和码相互转换的方法。不会了可以看看上面的例题和转换公式。 定点数的运算 移位运算 我们知道在数学计算中经常会形容小数点左移或者右移几位，比如 但是在计算机的定点表示中我们不可能移动小数点，所以我们采取的就是数据移位，移位分为两种：①算术移位，算术移位的对象是有符号数②逻辑移位，逻辑移位的对象是逻辑代码，又可视为无符号数 算术移位 要注意算术移位中因为采用的是有符号数，所以移位后必须保证正负不改变，所以只是数值位移位，符号位不参与移位。 我们知道对于原码，反码，补码的正数部分，即符号位是0的部分，他们的真值是一样的，所以都是移位后空位以0添之。其效果相当于左移乘以2右移除以2（类似于10进制左移乘以10，右移除以10），但是由于原码，反码，补码的负数部分表示有差异，所以移位到底是补0还是补1是不同的，规律见下表： 思考：上面的规律是怎么来的？ 我们知道负数的原码部分和正数的原码相同，都是数值位就是真值的绝对值，所以只要移位过程中，符号位不变，补0即可。而观察负数的反码，他除符号位其他的数值位刚刚好和负数的原码相反，所以反码移位填1相当于原码的移位填0。而分析由原码到补码的过程我们发现，当对其由低位向高位找到第一个1时在此1的左边即高位的各位与对应的反码相同，而此1的右边的各位（包括这个1）即低位都与原码相同。所以左移时产生低位填的代码要与原码移位规则相同，所以左移填0，而右移时产生高位，所以右移时代码要与反码移位规则相同，所以右移填1。 对于原码，我们一定要关注的是左移和右移是否会丢1，如果左移那么必定丢位，如果丢的是0不是1，那么计算正确，就是扩大两倍，但是如果左移丢1了，那么计算就会出错误，不是扩大两倍了，右移时如果丢0那么就是缩小两倍，但是一旦丢1，那么精度就不准确了，大约缩小两倍，但是不准确比如上图中的53/2=26，主要是因为后面的小数部分无法表示导致的。 逻辑移位 机器采用的是无符号数，这个就简单多了，就是如下规律： 逻辑左移时，高位移丢，低位添0 逻辑右移时，低位移丢，高位添0 所以01010011逻辑左移1位就是10100110，逻辑右移一位就是00100110，最终结果就是左移扩大两倍，右移缩小两倍。 思考：为什么欲要实现左移扩大两倍，右移缩小两倍，算术移位比逻辑移位复杂很多？ 究其原因就是因为有符号数在移位时符号位不动导致的各种特殊情况产生，而逻辑移位由于是无符号数一定是正数就简单了许多。 循环移位 循环移位主要的作用不是用来计算的，而是将数据的低字节数据和高字节数据互换用的，一般有四种情况，主要的特点就是移出的数位会再移入到数据中，而是否带进位就要看是否将进位标志位也加入到循环移位中去。所以有如下四种情况： 对应着的结果是 a:11011010 b:11011010(注意虽然结果相同，但是移位的方法是不同的) c:11101010 d:01101011 加减运算 首先我们要明确加减运算一般只发生在原码和补码中，原码计算复杂，一般不用，补码能够计算出正确结果，并且所有的加减运算最终实际上都是转换成了补码的加法运算。反码一般不用来进行计算，移码更不用说。 原码定点数的加减运算 加法规则：先判断符号位，如果符号位相同，则绝对值相加，符号位不变。㘝符号位不同，那就是减法，绝对值大的减绝对值小的，并且符号位跟绝对值大的。 减法规则：两个原码表示的数相减，首先将减数符号取反，然后将被减数与符号取反后的减数按原码加法进行运算。 一定要注意，当左边位出现溢出时，那就直接丢位 补码定点数的加减运算 因为补码加减运算计算规则简单且结果准确，所以计算机常使用补码加减运算。其加减运算需要满足以下特点: 参与运算的两个操作数都需要是补码表示 按2进制运算规则得2进1 符号位和数值位按照同样的规则一起计算，符号位运算产生的进位要丢掉，结果的符号位由运算得出 补码的加减运算依据下面的公式，当参加运算的数是定点小数时，模M=2；当参加运算的数是定点整数时，模M=2^n+1。（注意,n是数值位长度，所以n+1就是代码的长度）。mod M是为了将溢出位丢掉。 [A+B]补=[A]补+[B]补(modM)[A+B]_补=[A]_补+[B]_补(mod M) [A+B]补​=[A]补​+[B]补​(modM) [A−B]补=[A]补+[−B]补(modM)[A-B]_补=[A]_补+[-B]_补(mod M) [A−B]补​=[A]补​+[−B]补​(modM) 计算实际上很简单，我们以一道例题讲解： 设计器字长是8位（含1位符号位），A=15,B=24，求解A+B和A-B。 A=+15=00001111=[A]补，B=+24=0011000=[B]补，所以 A+B=[A]补+[B]补=[A+B]补=0001111+00011000=00100111=+39A+B=[A]_补+[B]_补=[A+B]_补=0001111+00011000=00100111=+39 A+B=[A]补​+[B]补​=[A+B]补​=0001111+00011000=00100111=+39 A−B=[A]补+[−B]补=00001111+11101000=11110111=−9A-B=[A]_补+[-B]_补=00001111+11101000=11110111=-9 A−B=[A]补​+[−B]补​=00001111+11101000=11110111=−9 这里要自己计算出-B的补码，实际上就是B的补码整体取反加1，并且最终得到的结果代码都是补码，我们还需要自己将结果补码转换成真值。 符号扩展 首先我们要明确符号和移位运算是不同的，移位运算是一种为了扩大基数倍移动位数的计算方法。而符号扩展虽然也会增加位数填0或者1，但是其根本目的是将一个真值X的短码扩展至为长码，表示的真值最终应该不发生任何变化。比如一个8位机器字长的数和一个32位数进行相加，那么我们首先需要将8位的数进行符号扩展扩展为32位才能进行加减运算，这就是符号扩展。那么符号扩展的填值同样有自己的规律： 对于正数部分，仍然是统一的因为原码，反码，补码都一样附加位全部填0即可 对于负数部分，因为表示方法和解码放手不同，附加为的填值也不同： 原码：附加位全部填1 反码：附加位全部填1 补码：如果是整数附加位填1，如果是小数，附加位填0 思考：符号扩展的正数附加位填0真值不变，移位运算正数也是填0为什么就是扩大真值？ 我们要注意符号扩展附加位填0只是将先出现的附加我进行填值，归根结底这些附加位是机器字长的扩大导致的，不是自身数值位移位导致的。而移位运算的添加0的位是由数值位自己左移或者右移“腾”出来的位置再填0才导致的扩大真值，所以我们要加以区分这两者的区别。 我们以一道例题讲解：假设机器字长为8位（含一位符号位），A=15,B=-24，求[A+B]补，[A-B]补。 A补=0,1111=0,0001111A_补=0,1111=0,0001111 A补​=0,1111=0,0001111 B补=1,01000=1,1101000B_补=1,01000=1,1101000 B补​=1,01000=1,1101000 我们符号扩展以后再根据补码的加减运算规则进行计算： [A+B]补=[A]补+[B]补=0,0001111+1,1101000=1,1110111[A+B]_补=[A]_补+[B]_补=0,0001111+1,1101000=1,1110111 [A+B]补​=[A]补​+[B]补​=0,0001111+1,1101000=1,1110111 所以A+B的原码是1,0001001，真值就是-9 [−B]补=[B]补整体取反加一=0,0011000[-B]_补=[B]_补整体取反加一=0,0011000 [−B]补​=[B]补​整体取反加一=0,0011000 [A−B]补=[A]补+[−B]补=0,0001111+0,0011000=0,0100111[A-B]_补=[A]_补+[-B]_补=0,0001111+0,0011000=0,0100111 [A−B]补​=[A]补​+[−B]补​=0,0001111+0,0011000=0,0100111 因为补码是整数，所以这个同时也是原码，所以真值就是+39 溢出判断 我们再计算两个式子，假设A=15,B=-24，C=124。那么此时计算[A+C]补和[B-C]补。 我们会发现结果计算错误了，为什么？我们看一下计算过程，发现A+C时数值位无法表示这个更大的正数绝对值了，从而进1使得1占了符号位导致结果变成负数，这种因为两个正数相加而导致结果过超出了最大正数值表示范围我们成为上溢。而B-C可以看成两个负数-24和-124相加，我们发现两个符号位相加后产生了一个新的符号位0而后面的数值位相加又没有产生进位1导致了结果变成了正数，这种两个负数相加而导致结果超出了最小负数值表示范围的我们成为下溢。 思考：那么难道只要是两个负数相加就一定下溢吗？因为符号位两个1相加一定产生0。 不对的，一定要亲手距离进行计算才能感受到补码负数相加仍是负数的过程。我们来计算一下-1和-2相加。-1的补码是1,1111111，-2的补码是1,1111110，那么-1-2的补码是 [−1−2]补=1,1111111+1,1111110=1,11111101[-1-2]_补=1,1111111+1,1111110=1,11111101 [−1−2]补​=1,1111111+1,1111110=1,11111101 那么原码就是1,0000011刚好是-3，也就是说如果两个负数相加没有下溢，那么虽然符号位1+1会产生0，但是恰巧此时的补码数值位相加会进位产生一个1占用符号位导致结果仍然是一个负数从而不会下溢。而下溢的原因就是因为数值位相加没有产生进1从而导致的。 思考：什么时候会产生溢出？ 实际上只有两种情况，会产生，就是正数+正数（也就包括了正数-负数，因为补码都是按照加法进行计算的，这里的正+正是补码正+补码正）上溢以及负数+负数（也就包括了负数-正数）。一句话就是同号相加或者异号相减才会导致溢出。 判断溢出的方法一：采用一位符号位 我们发现无论是上溢还是下溢，最终都是操作数补码符号相同结果补码不同的情况，即设 As:操作数一的补码符号位数值A_s:操作数一的补码符号位数值 As​:操作数一的补码符号位数值 Bs:操作数二的补码符号位数值B_s:操作数二的补码符号位数值 Bs​:操作数二的补码符号位数值 Ss:结果数的补码符号位数值S_s:结果数的补码符号位数值 Ss​:结果数的补码符号位数值 规定{AsBsSs=As∩Bs∩Ss即三个符号位相与As+Bs+SS=As∪Bs∪Ss即三个符号位相或As‾,Bs‾,Ss‾表示取非即符号位取反规定\\begin{cases} A_sB_sS_s=A_s∩B_s∩S_s即三个符号位相与\\\\ A_s+B_s+S_S=A_s∪B_s∪S_s即三个符号位相或\\\\ \\overline{A_s},\\overline{B_s},\\overline{S_s}表示取非即符号位取反 \\end{cases} 规定⎩⎪⎪⎨⎪⎪⎧​As​Bs​Ss​=As​∩Bs​∩Ss​即三个符号位相与As​+Bs​+SS​=As​∪Bs​∪Ss​即三个符号位相或As​​,Bs​​,Ss​​表示取非即符号位取反​ 那么我们可以定义 V=AsBsSs‾+AsBs‾SsV=A_sB_s\\overline{S_s}+\\overline{A_sB_s}S_s V=As​Bs​Ss​​+As​Bs​​Ss​ 当V=0的时候表示无溢出，V=1的时候表示有溢出。我们思考一下上面的式子，发现只有110或者001的时候会出现V=1也就是所说的操作数符号相同但是结果符号不同时溢出此时刚好V=1。 判断溢出的方法二：采用双符号位 我们发现上面的一号位检验只能检测出是否发生了溢出，具体是上溢还是下溢不能检测出来，所以就有了方法二。方法二的双符号位也称模4补码，实际上检测方法很简单，此时的符号位有两位，就是对于结果的溢出符号位进行观察。我们还是以A=15,B=-24,C=124为例，我们观察他们最终结果的补码： [A+C]补=00,0001111+00,1111100=01,0001011[A+C]_补=00,0001111+00,1111100=01,0001011 [A+C]补​=00,0001111+00,1111100=01,0001011 我们发现对于上溢，实际上是双符号位的00变成了01，此时就是上溢。 [B−C]补=01,1101000+01,0000100=10,1101100[B-C]_补=01,1101000+01,0000100=10,1101100 [B−C]补​=01,1101000+01,0000100=10,1101100 对于下溢，实际上是双符号位的01变成了10，此时就是下溢。 而对于不溢出的情况： [A+B]补=00,0001111+00,0011000=00,0100111[A+B]_补=00,0001111+00,0011000=00,0100111 [A+B]补​=00,0001111+00,0011000=00,0100111 [−1−2]补=01,1111111+01,1111110=11,11111101[-1-2]补=01,1111111+01,1111110=11,11111101 [−1−2]补=01,1111111+01,1111110=11,11111101 无论是正+正，还是负+负刚好两个符号位相同。 所以我们得到如下规律： Ss1:结果补码的第一个符号位数值，Ss2:结果补码的第二个符号位数值S_{s1}:结果补码的第一个符号位数值，S_{s2}:结果补码的第二个符号位数值\\\\ Ss1​:结果补码的第一个符号位数值，Ss2​:结果补码的第二个符号位数值 {Ss1Ss2=00:结果为正数，无溢出Ss1Ss2=01:结果正溢出(上溢)Ss1Ss2=10:结果负溢出(下溢)Ss1Ss2=11:结果为负数，无溢出\\begin{cases} S_{s1}S_{s2}=00:结果为正数，无溢出\\\\ S_{s1}S_{s2}=01:结果正溢出(上溢)\\\\ S_{s1}S_{s2}=10:结果负溢出(下溢)\\\\ S_{s1}S_{s2}=11:结果为负数，无溢出 \\end{cases} ⎩⎪⎪⎪⎪⎨⎪⎪⎪⎪⎧​Ss1​Ss2​=00:结果为正数，无溢出Ss1​Ss2​=01:结果正溢出(上溢)Ss1​Ss2​=10:结果负溢出(下溢)Ss1​Ss2​=11:结果为负数，无溢出​ 为了更加简单的判断出是否溢出，我们规定逻辑表达式 V=Ss1⊕Ss2V=S_{s1}⊕S_{s2} V=Ss1​⊕Ss2​ V=0表述无溢出，V=1（01或者10）表示有溢出。 判断方法三：采用一位符号位根据数据位的进位情况判断溢出 我们再观察一下这两种溢出情况的特点，发现上溢时是之前的符号位为0，然后最高位数的进位是1，而下溢时是之前的符号位为1，然后最高位数的进位是0。即符号位和最高数位的进位总是相反的，而对于无溢出的情况，要么最高数位不产生进位(比如正+正不溢出）或者最高数位产生的进位和符号位相同(比如负+负不溢出)。 所以逻辑表达式如上图。我们对比一下这三个方法，我认为还是方法二比较简洁易于理解。但是无论是哪个方法，归根结底都是V=0无溢出，V=1有溢出。 乘法运算 乘法运算有两种计算方法，这里我们分别讲解： 方法一：原码一位乘法 顾名思义，是使用原码进行乘法计算，这很符合我们人类的思维，但是又有一些变化。原码一位乘法的特点是符号位和数值位要分开求，首先我们单独判断一下结果的正负，这个可以使用乘数和被乘数取异或操作即可得到结果的正负。那么接下来重点是我们要看一下数值位（那么就必定是绝对值了，正数）的乘法操作了。首先我们参考一下规则： 被乘数和乘数均取绝对值参加运算，符号位为异或即可 部分积的长度同被乘数，取n+1位，以便存放乘法过程中绝对值大于等于1的值，初值为0. 从乘数的最低位开始判断，若最低位为1，那么部分积加上被乘数，然后逻辑右移一位（即补0），若最低位为0，那么部分积加上0然后右移一位。 重复步骤3n次即可得到正确结果。 注意：考虑到运算时可能出现绝对值大于1的情况（但是此刻并没有溢出），所以部分积和被乘数都采用双符号位。 相比你也和我一样看蒙了，没关系，我们实际操作一下便可轻易理解。 设x=-0.1101，y=0.1011，采用原码一位乘法求解x*y。我们首先用我们之前学过的乘法计算一下： 那么计算过程如上图所示，可以看出乘数的某一位位权决定被乘数是否本次加上乘数，然后4个每次的中途计算结果都要左移一位，最后累加4个中间结果得到一个2倍被乘数长的结果。但是我们知道计算机是不可能自己理解这种计算方法的，单单中途结果左移就很难实现，所以我们使用了上面的计算规律： 可以看出，对于每一次高位部分积是否加上乘数主要取决于乘数的最后一位。而每次的中间结果和乘数都要右移，但是中间结果是逻辑右移，而乘数每次右移后新增加的高位要添加中间结果逻辑右移时丢失的地位，因为最后还要用到这些中间结果右移丢失的地位来组成低位部分积，这样当乘数全部右移出去以后，存储乘数的寄存器里存储的就是低位部分积了，最终高位部分积和低位部分积拼接即得到了最终结果的原码。 为了更加容易理解上面这段话我们来用图示的方法演示一遍： 首先第一步1101最后一位是1所以高位部分积加一次被乘数： 然后中间结果逻辑右移同时乘法寄存器中乘数右移，然后中间结果的丢弃低位保存到乘数寄存器的空高位 然后继续乘，此时乘数寄存器中的乘数还剩三位101且最后一位是1所以还要进行高位部分积加被乘数（一定要注意此时的乘数寄存器中的最高位不是乘数的一部分了，而是之前中间结果的丢弃的低位1，实际上后来这个位1会用来组成低位部分积）： 然后再次将中间结果逻辑右移，乘数也右移，并且同时中间结果的最低位1移到乘数的空高位： 然后继续乘，此时乘数寄存器中的乘数还剩两位10且最后一位是0所以高位部分积进行加被0（一定要注意此时的乘数寄存器中的高2位不是乘数的一部分了，而是之前中间结果的丢弃的低位，实际上后来这2个位会用来组成低位部分积）： 然后中间结果再次逻辑右移，同时乘数右移，再将中间结果右移丢弃的低位移到乘数寄存器的空高位： 然后继续乘，此时乘数寄存器中的乘数还剩一位1且最后一位是1所以还要进行高位部分积加被乘数（一定要注意此时的乘数寄存器中的高3位不是乘数的一部分了，而是之前中间结果的丢弃的低位，实际上后来这3个位会用来组成低位部分积）： 然后中间结果逻辑右移，乘数右移，然后中间结果的丢弃低位移到乘数寄存器的空高位： 这样我们就通过原码一位乘法完成了计算，再加上符号是负号所以最终结果就是-0.100001111。我们最后来总结一下这个过程，发现实际上高位部分积寄存器中的每一次逻辑右移就相当于将中间结果左移了，乘数寄存器的每一次右移就相当被乘数下一次乘以乘数的前一位。而为什么高位部分积寄存器中中间结果右移的丢弃位要用掉乘数寄存器中呢？实际上是因为这个被丢弃位就是低位部分积的组成部分需要保留下来以便后面拼接出最终结果，而刚好可以存储到乘数寄存器中，这样就充分利用了空间，使得计算过程只需要两个寄存器即可完成。现在我们再对比之前的纸质乘法图就可以轻易理解原码乘法规则了。 方法二：补码一位乘法（Booth算法） 我们想一想上面的原码一位乘法是一种符号单独拿出来确定，然后后面的数值就是无符号数的绝对值之间进行乘法运算，而接下来我们的补码一位乘法运算时将补码中的符号位连带着数值位一起进行计算最终的结果同时表示正负和数值。所以这是一种有符号数的乘法，采用相加和相减操作计算补码的乘积。设 [X]补=xsx1x2...xn;[Y]补=ysy1y2...yn[X]_补=x_sx_1x_2...x_n;[Y]_补=y_sy_1y_2...y_n [X]补​=xs​x1​x2​...xn​;[Y]补​=ys​y1​y2​...yn​ 运算规则如下： 符号位参与运算，运算的数均以补码表示 被乘数一般选取双符号位参与运算，部分积取双符号位，初值为0，乘数可以去单符号位。 乘数末尾新增设一个附加位yn+1，且初值为0 根据（yn,yn+1)的取值来确定操作，见下表： 移位按补码右移规则进行 按照上述算法进行n+1步操作，但第n+1步不再移位（共进行n+1次累加和n次右移），仅根据yn和yn+1的比较结果做相应的运算 最终取高位部分积的低n位和低位部分积（就是乘数寄存器中的高n位）组成最终结果 我们还是求解上面的例题：设x=-0.1101，y=0.1011，采用补码一位乘法求解x*y。 最终我们拼接得到结果是1.01110001，但是要注意这是补码，如果是正数那么就直接可以看成原码求真值了，但是现在还是补码，我们还要将它转换成原码最终结果是-0.10001111。 思考：两种方法的异同点？ 乘法类型 符号位参与运算 部分积位数 乘数位数 累加次数 移位方向 移位次数 每次移多少位 原码一位乘法 否 2位 0位 n 右 n 1 补码一位乘法 是 2位 1位 n+1 右 n(最后一次累加后不一位) 1 一定要注意原位一位乘法每此累加必移位，而补码一位乘法最后一次累加补移位，无论是哪种方法最后乘数寄存器抛弃掉了乘数的所有位，并且都是高位部分积的逻辑右移低位放到乘数寄存器的空高位。最终的结果都是高位部分积和低位部分积拼接而成，并且一定是2倍的被乘数长度。 除法运算 我们再来讲一下定点数的除法运算，除法运算同样有两种方法： 原码除法运算（不恢复余数法） 又称为原码加减交替除法，特点和原码一位乘法一样，符号和数值分开计算，商的符号由操作数的异或取得，求商的数值规则如下： 设被除数[X]原=xsx1x2...xn，除数[Y]原=ysy1y2...yn设被除数[X]_原=x_sx_1x_2...x_n，除数[Y]_原=y_sy_1y_2...y_n 设被除数[X]原​=xs​x1​x2​...xn​，除数[Y]原​=ys​y1​y2​...yn​ 商的符号：被除数和除数的符号异或得到 商的数值：|Q|=|X|/|Y|。实际上就是绝对值的运算，我们定义除法规则如下： 先用被除数减去除数（|X|-|Y|=|X|+(-|Y|)=|X|+[(-|Y|]补)，当余数为正时，商上1，余数和商左移一位，再减去除数。当余数为负时，商上0，余数和商左移一位，再加上除数。 当第第n+1步余数为负时，需要再加上|Y|得到第n+1步正确的余数（保证余数和被除数同号，因为是绝对值之间的除法，被除数必定是正的） 我们以一道例题讲解：机器字长为5位（含一位符号位，n=4），x=0.1011,y=0.1101，采用原码加减交替除法求x/y。 一定要注意在最开始先进性一次减去除数，然后再开始商。所以虽然进行了5次操作，但是商只是左移了4位刚好将数值位填满了，商的符号位仍应为正。而上面这到题最终余数刚好为正，所以没有进行最后一步即可。这样我们就求解出来商是+0.1101，余数是0.0111*2^(-4)。这里一定要注意余数后面的级数，为什么会产生2^(-4)呢？因为实际上我们最终得到的只是余数的数值位，他的每一次左移都会缩小2倍，所以就没一次左移（我们发现实际上就是逻辑左移）对余数产生一个*2^(-1)。并且一定要注意虽然说是原码除法，但是实际上操作时加减的除数使用的是补码但是最终结果得到的是原码所以叫原码除法运算即余数和商都是原码。 补码除法运算（加减交替法） 补码法原则的特点就是符号位与数值位一同参加运算，最终拼接的结果自动带正负号。他和原码除法原则最大的不同就是在第一次不是必定减去除数，而是根据被除数和除数的符号决定是加除数还是减除数。并且要注意这种方法需要双符号位。规则如下： 符号位参加运算，除数与被除数均使用补码形式表示，商和余数也用补码形式表示。 若被除数与除数同号，则被除数减去除数，若被除数和除数异号，则被除数加上除数。 若余数与除数同号，那么商1，余数左移一位减去除数，若余数和除数异号，则商上0，余数左移一位加上除数。 重复步骤3n次（注意字长为n+1次，所以n表示的是数值串长度） 若对商的精度没有要求，那么最后一次第n+1次，商恒置为1（末位恒置1法） 我们还是以一道例题讲解：机器字长为5位（含一位符号位，n=4），x=0.1000,y=-0.1011，采用补码加减交替法求x/y。采用双符号位表示： [X]原=00.1000,[X]补=00.1000[X]_原=00.1000,[X]_补=00.1000 [X]原​=00.1000,[X]补​=00.1000 [Y]原=11.1011,[Y]补=11.0101,[−Y]补=00.1011[Y]_原=11.1011,[Y]_补=11.0101,[-Y]_补=00.1011 [Y]原​=11.1011,[Y]补​=11.0101,[−Y]补​=00.1011 注意到此时使用的是双符号位，并且对于字长为5，执行了5次加减操作，4次移位，并且此时商和余数也都是逻辑左移。最终的商的补码是1.0101所以原码是1.0101也就是-0.0101，余数的补码是00.0111，为正数，所以原码也是00.0111，所以余数就是0.0111*2^(-4)。一定不要忘记逻辑左移会让余数每次都乘一个2^(-1)即缩小两倍。 思考：两种方法的异同点？ 乘法类型 符号位参与运算 加减次数 移位方向 移位次数 说明 原码除法（不恢复余数法） 否 N+1或者N+2 左 N 若最终余数为负，需要恢复余数，所以加减次数为N+1或N+2 补码除法（加减交替法） 是 N+1 左 N 商末位恒置1 我们发现对于原码的乘法或除法通常都是一符号位即可，因为计算时肯定是正数，小数点前面的符号位主要是用来暂存移位时产生的进位的。而对于补码的乘法或除法运算，通常需要两个符号位，这是因为一个符号位需要用来表示正负，还有一个是用来暂存进位结果的。并且无论是哪种乘法或者除法运算，一定是移位n次，但是加减次数却是不同的。且一定要注意对于原码的乘法和除法运算结果就是原码可以直接计算真值，但是对于补码乘法和除法运算结果都是补码，如果是正数那么可以直接计算真值，但是如果是负数一定要记得先转化成原码再计算真值，并且对于除法运算，余数会有一个级数不要忘记。 强制转换 在考纲中还要求我们要对高级语言高级程序设计语言（如C）的语言变量的类型强制转换有深入的掌握，所以接下来我们学习一下两种常见的强制转换。 有符号数和无符号数的转换 我们观察下面的C代码 12345678910#include&lt;bits/stdc++.h&gt;using namespace std;int main()&#123; short x=-4321; unsigned short y=(unsigned short)x; printf(&quot;x=%d, y=%u &quot;,x,y); system(&quot;pause&quot;); return 0;&#125; 他最终的输出结果为 1x=-4321, y=61215 和我们预期的效果不同，我们肯定是希望类型转换以后表示的值是不变的，但是我们知道无符号数是无法表示一个负数的，所以最终结果变成了一个我们“意料之外”的值。但是我们仔细观察一下此时两个数x,y的二进制数： 变量 值 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 x -4321 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 y 61215 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 实际上x和y的二进制代码是一样的，我们前面也见过对变量不同的声明并不会改变代码，而只是改变了对于一个二进制码的解读方式，例如上面的x会被解释为一个-4321的补码，而y则会直接按照原码进行解释。这也就造成了当强制转换以后对于同一个二进制代码的解读方式发生了改变从而导致了值的异常改变。但是我们知道了这个无符号数和有符号数的强制转换方法以后就可以预测到强制转换后的数值会变成多少。比如： 12345678910#include&lt;bits/stdc++.h&gt;using namespace std;int main()&#123; unsigned short x=65535; short y=(short)x; printf(&quot;x=%u, y=%d &quot;,x,y); system(&quot;pause&quot;); return 0;&#125; 那么我们猜测以下x,y的真值会是多少。首先我们写出x的二进制代码，我们知道short和unsigned short都是2B，占16位，所以我们可以写出x的原码是： 变量 值 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 x 65535 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 那么当转换成有符号数以后由于最高位是-1所以是负数，那么就会将上面这个二进制代码解读为y的补码，所以我们可以推出y的原码，就是在补码的数值位减1后逐位取反得 变量 值 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 y -1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 所以y的原码如上我们可以计算出真值就是-1，我们用机器验证一下得到结果却时是我们预测的值： 这就是无符号数和有符号数之间的强制转换方法。 不同字长整数之间的转换 我们知道有时候还会有字长的强制转换，比如长数值类型转换成短数值类型如下： 1234567891011#include&lt;bits/stdc++.h&gt;using namespace std;int main()&#123; int x=165537,u=-34991; short y=(short)x,v=(short)u; printf(&quot;x=%d, y=%d &quot;,x,y); printf(&quot;u=%d, v=%d &quot;,u,v); system(&quot;pause&quot;); return 0;&#125; 最终的结果如下: 我们发现数值发生了很大的变化，并且连正负号都发生了变化，这是为什么？我们用16进制输出一下上面各值。 12345678910111213141516#include &lt;bits/stdc++.h&gt;using namespace std;int main()&#123; int x = 165537, u = -34991; short y = (short)x, v = (short)u; // printf(&quot;x=%d, y=%d &quot;,x,y); // printf(&quot;u=%d, v=%d &quot;,u,v); cout &lt;&lt; hex &lt;&lt; setw(8) &lt;&lt; setfill(&#x27;0&#x27;) &lt;&lt; x &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; y &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; u &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; v &lt;&lt; endl; system(&quot;pause&quot;); return 0;&#125; 输出结果： 我们发现他只是将高位部分截取了，这样我们就不难理解为什么会发生数值的正负变化了，肯定是之前的最高位为0所以解释为正数，但是当截断以后最高位变成了1，那那么就自然就解释成了负数。但是这是长-&gt;短使用了截断的方法，那么如果是短-&gt;长呢？ 1234567891011121314#include &lt;bits/stdc++.h&gt;using namespace std;int main()&#123; short x = -4321; int y = x; unsigned short u = (unsigned short)x; unsigned int v = u; printf(&quot;x=%d, y=%d &quot;, x, y); printf(&quot;u=%d, v=%d &quot;, u, v); system(&quot;pause&quot;); return 0;&#125; 输出结果： 我们发现对于short类型的短负数x再强制转换为int类型的长负数y以后真值并没有改变，而将x转换为无符号数u以后再转换为长int型v以后数值也没有发生变化，我们再观察一下此时这四个值的16进制代码： 123456789101112131415161718#include &lt;bits/stdc++.h&gt;using namespace std;int main()&#123; short x = -4321; int y = x; unsigned short u = (unsigned short)x; unsigned int v = u; // printf(&quot;x=%d, y=%d &quot;, x, y); // printf(&quot;u=%d, v=%d &quot;, u, v); cout &lt;&lt; hex &lt;&lt; x &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; setw(8) &lt;&lt; setfill(&#x27;0&#x27;) &lt;&lt; y &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; u &lt;&lt; endl; cout &lt;&lt; hex &lt;&lt; setw(8) &lt;&lt; setfill(&#x27;0&#x27;) &lt;&lt; v &lt;&lt; endl; system(&quot;pause&quot;); return 0;&#125; 我们发现对于x-&gt;y的负数形式增长时高位全部补得是十六进制的f，也就是说对于二进制代码高位全部补1，而对于u-&gt;v的正数形式增长时高位补得是十六进制的0，也就是说二进制的高位补得全部是0。所以我们可以总结出一个规律，对于短-&gt;长的代码扩展，新添加的高位补得数和原先代码的最高位一致，这样我们就可以保证增长位数的强制转换以后数的真值没有发生变化了。并且我们还可以总结出只有长整数-&gt;短整数的强制转换真值不发生变化，其他情况都是会发生改变的，当然了了，长-&gt;短的字长强制转换也有小概率不会发生改变。前三个例子的转换规则都是保证相应的位值相等，而短字长到长字长的转换，在位值相等的条件下还要补充高位的符号位，可以理解为数值的相等。但是注意，char类型为8位ASCII码整数，其转换为int时，在高位部分补0即可。 总结"},{"title":"卡诺图与编译码器","path":"/wiki/数字逻辑与数字系统笔记/卡诺图与编译码器/index.html","content":"使用卡诺图化简表达式 我们接下来回忆总结一下卡诺图化简逻辑函数的过程，首先有以下几个概念： 卡诺图上的每一个圈都代表一个蕴含项 主蕴含项：扩展到最大的蕴含项 奇异“1单元”：卡诺图中仅能被单一主蕴含项覆盖的方格 质主蕴含项：包含着一个或者多个奇异”1“单元的主蕴含项 最终我们是要将逻辑表达式化简为最简与或式，最简与或式就要求化简时： 项数最少，意味着卡诺图中圈数最少 每一项中的变量数最少，意味着卡诺图中的圈尽可能大 有时候可能会存在某个奇异“1”单元，他只能自己单独成一个圈： 或者也有可能一个卡诺图用两个不同的思路化简会得到两个最简式： 但是无论怎样化简我们都要遵循以下规则： 每一个1的方格必须至少被圈一次 每一个圈中包含的相邻小方格数必须为2的整数次幂 为了得到尽可能大的圈，圈和圈之间可以重叠 若某个圈中的所有1方格，已经完全被其他圈所覆盖，则改圈就是多余的，即每一个圈中至少应该有一个标1方格是他特有的。 练习 上面的式子进行化简后可以表示成下方的最简与或式。我们来分析一下：首先四个角被红色框圈起来得到¬B¬D，然后两侧的蓝圈圈出四个方块得到¬A¬D，然后中间竖着的绿色圈圈出四个方格得到¬CD，最后橘色圈圈中两个方法得到ABD。将四个项相加记得到最简式子，我们可以看出每一个标1方格都至少被圈中了一次，并且每一个圈都是尽可能大的，并且每一个圈都有自己圈中的独有的标1方格。 无关项的化简 我们前面所讲的卡诺图化简时要求，一个方格要么是1，要么是0。但是我们之前学到过无关项，他对结果不产生决定作用，因此无论取何值都可以，即你可以把他看成是0也可以把他看成是1。在卡诺图中当输出的值不重要或者相应的输入组合从不处显示，就可以由设计者决定这些输出时0还是1。充分利用无关项，我们可以进一步化简逻辑表达式。比如下图中： 我们发现对于某些组合，其结果是无关项，那么我们就在相应的方格表标记X，由于无关项既可以是0也可以是1，所以我们在化简时就可以用圈尽可能的圈最多的1，同时圈也可以圈X，也可以不圈。如上图，这样在化简时明显就更加简单了。 那么讲了这么多，我们都是在学习卡诺图的构件简化过程，他具体是如何应用的呢？实际上他通常是用来设计某一个复杂功能的元件的电路逻辑的，如下面几个我们分别来介绍卡诺图的应用： 7段数码管驱动电路 7段数码管常用来表示一个十进制数，由于一共是十个数0-9，所以我们使用四个位就可以表示了。 一般7段数码管有两种连接方法，共阴极和共阳极： 无论是哪一种实际上设计思路都是一样的。首先我们列出不同数字对应的应该亮的数码管编号： 然后用D0D1D2D3表示十进制数的0-9，对应的就要使得输出端Sa-Sg输出不同的值： 那么我们列出真值表以后使用卡诺图画出不同数对应的电路，这里以Sa为例： 那么用卡诺图得到Sa的最简表达式以后我们就可以画出电路图了： 编码器 我们前面学习了优先级线路，他的输出信号总是和最高级输入信号的值相同，那么我们之前用了一个很复杂的图来实现这个功能的，那么有没有更好的方法呢？当然有，此时我们就可以使用编码器，那么编码器是如何实现的呢，看下图： 上面是一个4线-2线编码器（因为输入信号是4个线编号0~3，所以只需要2个位就可以表示4个输入线，所以只需要两个输出线，因此叫做4线-2线编码器）。其中X0,X1,X2,X3是输入信号线，输出A0，A1是用来输出有效信号的编号的，EO是用来判断是否存在有效输入的。 我们用编码器模拟了优先级线路，他的工作原理如上图，当没有有效输入时，那么EO=1，此时无论A0,A1是何值都是没有用的。但是当EO=0，那么就说明此时有有效输入了，具体是哪个输入为有效输入，就需要A0,A1来输出表示有效输入的编号了，例如当X3位有效输入时，那么A0=A1=1，即此时二进制编号11即10进制的3号输入信号是有效输入。当然上面的表格我们也可以使用无关项来描述： 表示的意思是一样的。 注意编码器不仅可以用来表示优先级线路，他也可以用来表示更加复杂的有效线路情况，我们需要透彻理解编码器的工作原理。 那么同样的我们也可以使用卡诺图来写出最简逻辑表达式来表示A0,A1和EO，首先EO只有当所有的输入信号都是无效输入0时他才输出1，所以很明显 EO=X0+X1+X2+X3‾EO=\\overline{X_0+X_1+X_2+X_3} EO=X0​+X1​+X2​+X3​​ A0和A1我们根据真值表先对卡诺图进行标1填写： 然后化简我们就得到了A0和A1的最简表达式，这样我们就可以画出编码器的实现电路图了： 当然上面仅是一个4线-2线编码器的电路图，更加复杂的电路图我们需要按照上面的步骤重新推导。 译码器 译码器我们并不陌生，在《机组原理》中我们学习了译码器是用来解析生成片选信号用的，那么译码器到底是如何通过电路实现的呢？实际上译码就是编码的逆过程，所以对于4线-2线的编码器生成的指令，我们需要使用2线-4线译码器来进行译码。并且由于是逆过程，编码器是接收的有效输入信号然后输出有效输入信号的编号，那么译码器就是接受有效输入信号的编号，然后相应的将对应编号的输出端输出信号1。如下： 当接收到10编号，那么就是Y2应该输出有效信号1。那么我们同样可以使用卡诺图进行化简写出表达式然后画出译码器的电路： 思考：编码器和译码器的合作使用有什么优点？ 我们思考一下如果不使用编码器和译码器实际上也可以表示这个有效输出和有效输入之间的关系，只是中间需要许多的复杂线路来实现，逻辑复杂同时功耗大，但是使用编码器和移码以后逻辑简单了许多，同时两者之间的传输信号线也很少，功耗少。实际上编码器和译码器的实现都是卡诺图的应用体现。 当然我们也可以使用译码器实现更加复杂的逻辑，例如实现同或门： 只需要将输出端的输出信号进行更改即可。 多路选择器 多路选择器的功能是可以从选择信号的值从N个可能的输入中选择一个作为输出，他一般需要使用log2N位选择信号作为输入来表示编号X输入信号，控制输入信号的选择，比如： 最简单的就是二选一电路，那么当S=0时说明输出信号Y和输入信号D0相同，当S=1时说明输出信号Y和输入信号D1相同。这种选择器的实现我们也可以使用卡诺图化简得到他的电路表达式： 或者使用三态缓冲器实现： 当然对于更加复杂的多路选择器，我们也需要按照先列真值表，画卡诺图再化简的步骤得到电路表达式甚至可以借用其他组件： 我们回忆一下这四个复杂器件，他们的电路设计都离不开卡诺图的应用，其中设计思路都是以下几个步骤：对实际问题进行抽象，然后定义输入和输出 2. 由实际逻辑问题列出真值表 3. 由真值表写出表达式并构建卡诺图 4. 使用卡诺图化简表达式得到最简式 5. 画出原理图 组合逻辑电路的时序问题 我们发现在设计电路时并不仅仅需要考虑式子的简单与否，还要考虑延迟等外界因素，这就涉及到了组合逻辑电路的时序问题。在实际电路中，输出相应输入的改变是需要一定的时间，而不是理想情况下的立刻改变： 所以我们在设计电路时还要考虑时序问题，即怎样设计电路使得整体的延迟最小。这里我们先学习几个概念： 传播延迟：t_pd即为输入改变直到一个或多个输出改变为最终值所经历的最长时间延迟 最小延迟：t_cd即为输入发生变化直到任何一个输出开始改变的最短时间 如刚才的A-&gt;Y电路，传播延迟就是A开始改变到Y改变稳定所需要的时间，而最小延迟就是A开始改变到Y开始改变的时间，很明显传播延迟总是要大于等于最小延迟。 思考：延迟产生的原因？ 电路中的电阻和电容的充放电 光速的上限 首先我们知道许多门是由mos管实现的，而mos管的原理是PN结偏置实现的，这肯定是有延迟的，同时伴随着科技的发展，速度最大不能快于光速，由于这种速度上限，会产生延迟。 思考：传播延迟总是大于等于最小延迟的原因？ 实际上最理想的情况就是输出端同时改变同时迅速稳定为改变后的值，那么此时最小延迟和传播延迟就会相等，但是实际电路中以下几个原因会造成传播延迟总是更大： 上升沿与下降沿的延迟可能不同（即上升和下降的幅度不同，毕竟我们前面学习了低电平信号和高电平信号都是一个区间范围) 电路存在多个输入和输出时，不同输出的延迟可能不同 电路对温度敏感，电路较热时速度会变慢、 根据不同路径的延迟不同，我们定义： 很明显，一般门越多的电路延迟越大，并且由于我们的目的是为了提升整体的运行性能，即降低整体的延迟，我们一般关注的是关键路径的延迟，降低关键路径的延迟才能大幅提升整体的性能。 毛刺 在电路中还会涉及到“毛刺”的问题，这种问题在电路图中不易察觉，但是在实际电路中却很明显很有可能造成整体电路的错误。那么什么是毛刺呢？实际上就是指一个输入的一个变化可能会引起后面多个输出的多次变化。比如： 当A=0,C=1时，B突然由1变成0，从电路图和卡诺图中我们通常会认为Y不会发生变化还是维持信号1，但是实际上我们分析一下电路信号的传输速度，由于B信号需要经过非门再和非A相或才能得到¬A¬B,而得到BC则不需要经过非门，所以BC会先发生变化变成0，而此时¬A¬B还没有从0变成1，所以有一段时间Y会变成0，待¬A¬B变化完成后变成1了，此时Y才会变回1。所以实际上Y的变化时1-&gt;0-&gt;1，而不是保持1不变。此时如果Y后面还有其他逻辑操作，那么这种微小的变化可能会被无限放大从而造成整体电路的异常。因此毛刺是一种风险，究其原因产生毛刺是因为输入端的变化不能同时到达逻辑门从而可能造成输出端的多次变化： 为了防止毛刺的产生，我们不能一味追求电路的表达式最简，而要同时保证没有毛刺产生。当信号的变化在卡诺图中穿越两个主蕴含项的边缘时就会产生“毛刺”： 如上图两个圈的边缘没有过渡。为了避免，我们只需要增加多余的蕴含项来盖住这些边缘以避免毛刺： 我们发现此时得到的表达式就不是最简式了，但是这样做的意义很重要，他可以有效避免毛刺对整体电路的影响。 注意，毛刺是大多数电路中都存在的现象，但是不用每一个毛刺都避免，毕竟毛刺只是有可能引起输出端的多次变化，实际上大多数情况下这种多次变化都是瞬间的，我们只需要在产生异常时再修改电路避免毛刺即可。同时还要注意多输入（几乎）同时改变也会产生毛刺，这种情况不能通过上面这种增加硬件的方法来避免。 使用卡诺图化简表达式我们接下来回忆总结一下卡诺图化简逻辑函数的过程，首先有以下几个概念： 卡诺图上的每一个圈都代表一个蕴含项 主蕴含项：扩展到最大的蕴含项 奇异“1单元”：卡诺图中仅能被单一主蕴含项覆盖的方格 质主蕴含项：包含着一个或者多个奇异”1“单元的主蕴含项 最终我们是要将逻辑表达式化简为最简与或式，最简与或式就要求化简时： 项数最少，意味着卡诺图中圈数最少 每一项中的变量数最少，意味着卡诺图中的圈尽可能大 有时候可能会存在某个奇异“1”单元，他只能自己单独成一个圈： 或者也有可能一个卡诺图用两个不同的思路化简会得到两个最简式： 但是无论怎样化简我们都要遵循以下规则： 每一个1的方格必须至少被圈一次 每一个圈中包含的相邻小方格数必须为2的整数次幂 为了得到尽可能大的圈，圈和圈之间可以重叠 若某个圈中的所有1方格，已经完全被其他圈所覆盖，则改圈就是多余的，即每一个圈中至少应该有一个标1方格是他特有的。 练习 上面的式子进行化简后可以表示成下方的最简与或式。我们来分析一下：首先四个角被红色框圈起来得到¬B¬D，然后两侧的蓝圈圈出四个方块得到¬A¬D，然后中间竖着的绿色圈圈出四个方格得到¬CD，最后橘色圈圈中两个方法得到ABD。将四个项相加记得到最简式子，我们可以看出每一个标1方格都至少被圈中了一次，并且每一个圈都是尽可能大的，并且每一个圈都有自己圈中的独有的标1方格。"},{"title":"存储器建模","path":"/wiki/数字逻辑与数字系统笔记/存储器建模/index.html","content":"位单元 上一讲我们学习了存储器阵列，而存储器阵列是由位单元阵列组成的，每一个位单元只存储1位数据，每一个位单元与一个字线（wordline）和一个位线（bitline)相连，如下图： 读写数据主要是通过位线来完成的： 那么现在我们再来从整体上观察一下存储器阵列的结构： 可以得到以下几点规律： 字线与使能端类似 用于控制阵列中一行数据的读/写 对应着唯一的地址 同一时刻至多有一个字线位高电平 一个字线控制着一个数据字 当某个字线为高电平时，那么这行数据就要进行位修改或者位读取，接下来通过位线传入要修改的新的数据，或者读出位单元存储的位数据 我们要注意到由于每次只有一个字线处于高电平，因此虽然位线控制着一列位单元，但是实际上每次每一个位线上也只有一个位单元处于读/写状态，但是同一时刻，可能会有多个处于同一个字线的位单元处于读/写状态。 存储器的类型 这里实际上我们在《计算机组成原理》中介绍过，但是当时并没有从存储器阵列的角度去分析。这里我们会以存储器阵列的角度去介绍，首先我们回忆一下存储器的类型。 随机访问存储器（RAM）：易失的 动态随机访问存储器（DRAM）：计算机的主存 静态随机访问存储器（SRAM)：CPU中的高速缓存 只读存储器（ROM）：非易失的 ROM也是可以随机访问的，大多数现代ROM也已经支持的可读写功能。 DRAMvsSRAM DRAM DRAM是将数据存储在一个电容上，读操作后，存储的数据会被破坏，电容上的存储的电荷量会慢慢泄漏，因此为了维持数据的存在，需要频繁的进行刷新充电（读，然后写），所以被称为动态存储器。如下图： SRAM 而SRAM是将数据存储在一个交叉耦合的反相器中，交叉耦合反相器具有很强的抗干扰能力，因此并不需要频繁的进行刷新，因此被称为静态存储器。 几种存储器的比较 存储器类型 每个位单元的晶体管数 成本 延迟 触发器 ≈20 高 低 SRAM 6 中等 中等 DRAM 1 低 高 ROM虽然也是存储器，他的读速度非常快，但是写速度很慢。 存储器端口 单端口是存储器中常见的端口，即一次性只能读/写。使用同一个端口来接受/输出数据，因此我们需要保证任何时刻，存储的端口只能处于读/写状态。 实现原理实际上就是使用了两个三态缓冲器，保证两个三态缓冲器的使能端任一时刻相反即可，这样即保证了每一次只有一个线路处于通路状态，也就保证了每次只能读入/输出数据。 寄存器文件 寄存器文件通常是一个小型的多端口SRAM存储器阵列，如下图就是一个32寄存器×32的3端口寄存器文件。 注意寄存器文件不是寄存器，他是一个寄存器堆，是CPU中多个寄存器组成的阵列，因此可以多路并发访问不同的寄存器 他有两个读端口A1/RD1和A2/RD2，还有一个写端口A3/WD3，地址线均是5位，可寻址2^5=32个寄存器。他可以同时读两个寄存器和写一个寄存器。 RAM建模 RAM是一个随机访问存储器，他需要接收地址，数据，clk时钟信号等，然后还要有输出端等，结构如下图： 那么我们接下来对他进行建模： 1234567891011121314151617module ram #(parameter N=6,M=32) (input logic clk,we, input logic [N-1:0] adr, input logic [M-1:0] din, output logic [M-1:0] dout ); //注意**是幂运算 //这里的声明mem可以看成是定义了一个mem数组 //他的每一个存储单元的数据是32位 //同时寻址范围是0~32 //因此是一个32×32的存储器阵列 //有32行字线和32列位线，每一个字线对应有32个位单元 logic [M-1:0] mem[2**N-1:0]; always_ff @(posedge clk) if(we) mem[adr]&lt;=din; assign dout = mem[adr];endmodule 上面的赋值语句当且仅当clk处于有效上升沿并且we为高电平时执行，并且注意虽然这里的赋值语句可以使用阻塞赋值，但是为了建模代码的规范，always_ff时序逻辑电路的建模中使用非阻塞赋值语句更好。 ROM建模 虽然ROM在现代的计算机中也实现了写操作，但是在我们的408学习中，一般还是认为ROM是不能进行写操作的，只能进行读操作。接下来我们同样对ROM进行建模，由于这里我们只进行读操作的建模，而读操作可以随时进行读取，并不需要等待有效沿，因此就是一个最简单的组合逻辑模块： 123456789101112module rom(input logic [1:0] adr, input logic [2:0] dout ); //只有读出数据的操作，没有写入修改数据操作\talways_comb case(adr) 2&#x27;b00:dout&lt;=3&#x27;b011; 2&#x27;b01:dout&lt;=3&#x27;b110; 2&#x27;b10:dout&lt;=3&#x27;b100; 2&#x27;b11:dout&lt;=3&#x27;b010; endcaseendmodule 时序 接下来我们讨论一下时序问题，我们前学习到了D触发器只有在时钟的有效沿（上升沿/下降沿）才对输入D进行采样，并赋值给Q，因此在采样的时刻，D必须处于一个稳定的状态，保持为0或者1。这个过程就如同照相，只有在被拍摄的物体静止不动时才能获得清晰的图像，Q想要得到一个明确的电平信号，那么就要求在采样D信号时，D需要保持稳定在一个确定的状态。如果在采样的过程中,D未处于稳定的状态，那么就会产生亚稳态。 输入时序约束 建立时间（Setup time)：t_setup=在时钟有效边沿到来前信号所需要稳定的时间 保持时间（Hold time)：t_hold=在时钟有效边沿到来后在采样时输入信号需要保持稳定的时间 孔径时间（Aperture time)：t_a=在时钟边沿附近输入信号需要维持的总时间 很明显有以下规律： ta=tsetup+tholdt_a=t_{setup}+t_{hold} ta​=tsetup​+thold​ 输出时序约束 前面我们讲到的仅仅是在clk有效时对采样信号D的时序约束要求，但是采样完成以后赋值给Q还有一定的时间。这里的输出时序同样需要加上约束： 传播延迟（Propagation delay)：t_pcq=时钟有效边沿到达后到Q最终稳定所需要的最长时间 最小延迟（Contamination delay)：t_ccq=时钟有效边沿到达后到Q开始改变所需要的最短时间 动态约束 我们在学习了几个有关约束的概念以后，需要添加动态约束，首先同步时序电路中，输入必须在时钟有效边沿附近的孔径时间内保持稳定。即输入信号必须 在时钟有效边沿到达前，至少要稳定t_setup 同时在时钟有效边沿到达后，至少要稳定t_hold 系统时序 时钟周期Tc是指两个时钟上升沿（下降沿）之间的间隔 fc=1/Tc,表示时钟频率f_c=1/T_c,表示时钟频率 fc​=1/Tc​,表示时钟频率 那么提高时钟频率（也就是缩短时钟周期）就可以增加数字系统在单位时间完成的工作量，但是频率不能无限制的增加。 如上图所示，两个寄存器间的延迟具有最小和最大延迟，这些延迟由其中的电路元件的延迟所决定。很明显D2想要变化，首先需要Q1改变完成并稳定，因此T_c有一个最小值，同样的也会有一个最大值。 建立时间约束 建立时间约束由路径R1至R2间的最大延迟所决定： 寄存器的传播延迟t_pcq 组合逻辑电路的传播延迟t_pd 我们通过上图可以容易得到结论，寄存器R2的输入信号D2必须在下一个时钟上升沿的t_setup时间前稳定。 同时D2稳定至少需要t_pd+t_pcq。因此有以下约束公式： {Tc&gt;=tpcq+tpd+tsetuptpd&lt;=Tc−(tpcq+tsetup)\\begin{cases} T_c&gt;=t_{pcq}+t_pd+t_{setup}\\\\ t_{pd}&lt;=T_c-(t_{pcq}+t_{setup}) \\end{cases} {Tc​&gt;=tpcq​+tp​d+tsetup​tpd​&lt;=Tc​−(tpcq​+tsetup​)​ tpd&lt;=Tc−(tpcq+tsetup)t_{pd}&lt;=T_c-(t_{pcq}+t_{setup}) tpd​&lt;=Tc​−(tpcq​+tsetup​) 上式就被成为建立时间约束或者最大延迟约束，即上式限制了我们在设计组合逻辑电路的最大延迟。 在商业设计中： Tc是由研发总监和市场部提出的，以确保产品的竞争性 制造商确定触发器的传播延迟t_pcq和建立时间t_setup t_pcq+t_setup被称为时序开销，由芯片的生产工艺决定 而通常，只有t_pd即组合逻辑电路的最大时间延迟是我们设计人员可以控制的变量，因此我们在设计组合逻辑电路时要保证设计出来的t_pd小于建立时间约束 保持时间约束 保持时间约束由路径R1至R2间的最短延迟所决定： 寄存器的最小延迟t_ccq 组合逻辑电路的最小延迟t_cd 寄存器R2的输入信号必须在时钟上升沿后至少稳定t_hold,也就是D2稳定的时间必须小于变化值传来的时间，毕竟他要改变值了，不能继续hold维持原先的值了，因此规律是： {thold&lt;=tccq+tcdtcd&gt;=thold−tccq\\begin{cases} t_{hold}&lt;=t_{ccq}+t_{cd}\\\\ t_{cd}&gt;=t_{hold}-t_{ccq} \\end{cases} {thold​&lt;=tccq​+tcd​tcd​&gt;=thold​−tccq​​ tcd&gt;=thold−tccqt_{cd}&gt;=t_{hold}-t_{ccq} tcd​&gt;=thold​−tccq​ 上式被称为保持时间约束或者最小延迟约束，其限制了我们设计的组合逻辑电路的最小延迟，因此组合逻辑电路延迟不能太大也不能太小。下面我们介绍一种特殊的情况，触发器背靠背相连： 此时触发器之间没有组合逻辑电路，因此t_cd=0，那么如果要不违反保持时间约束，需要保证 thold&lt;=tccqt_{hold}&lt;=t_{ccq} thold​&lt;=tccq​ 因此一个可靠的触发器，保持时间要比最小延迟短。这样才能保证变化的值不会在D2还在稳定的状态时就抵达。 在实际应用中，经常将触发器设计成t_hold=0，来保证保持时间约束在各种情况下都可以满足 教材中如非特别注明，后面的讨论会忽略保持时间约束 保持时间约束又非常重要，如果一旦违反保持时间约束，必须重新设计电路，这一点与建立时间约束不同，如果违反了建立时间约束，可以通过调整时钟周取Tc来修正，但是保持时间约束无法这样修正 因此一旦违反了保持时间约束后果很严重 思考：建立时间约束和保持时间约束的关系以及由来？ 可能我们会有点懵，不知道建立时间约束和保持时间约束的由来，下面我们来总结一下两个D触发器的工作原理。 如上图，两个D触发器有一个CLK控制，并且R2的输入信号是R1输出信号经过组合逻辑电路进行计算加工得到的。因此在第一个CLK上升沿抵达后Q1会更新，然后会用组合逻辑电路进行计算得到D2，我们需要保证在第二个CLK上升沿抵达前D2已经稳定得到了Q1根据组合逻辑电路计算出来的新信号值，因此有一个建立时间延迟。同时在第一个CLK抵达后第二个CLK抵达前，Q1很快就会变化完成并且经过组合逻辑电路计算得到了新的修改值可以传递给D2了，但是D2并不是得到修改值后马上就能变化，他需要保证维持一个t_hold来保证R2的输出Q2可以正确得到D2的值，当Q2稳定得到D2的值以后D2才能变化更改为新的值，因此新的值不能计算抵达的太快，他需要晚于t_hold，因此也就是保持时间约束。两者共同限制了组合逻辑电路延迟不能过长也不能过短。 时序分析 我们前面学习了时序问题的约束条件，那么接下来我们来以一道例题学习一下时序分析。如下图： 根据题干我们可以知道 {tpd=35ps∗3=105pstcd=25ps\\begin{cases} t_{pd}=35ps*3=105ps\\\\ t_{cd}=25ps \\end{cases} {tpd​=35ps∗3=105pstcd​=25ps​ 因此 {Tc&gt;=tpcq+tpd+tsetup=50+105+60=215pstcd=25ps,thold−tccq=70−30=40ps\\begin{cases} T_c&gt;=t_{pcq}+t_{pd}+t_{setup}=50+105+60=215ps\\\\ t_{cd}=25ps,t_{hold}-t_{ccq}=70-30=40ps \\end{cases} {Tc​&gt;=tpcq​+tpd​+tsetup​=50+105+60=215pstcd​=25ps,thold​−tccq​=70−30=40ps​ 我们得到最大时钟周期至少为215ps,而t_cd=25ps小于要求的40ps，也就是说延迟太小了，违反了保持时间约束。 思考：如何修改电路使其不违反保持时间约束？ 我们只需要将t_cd提升即可，我们发现之前的最短路径是只经过一个门，因此出现t_cd=25ps。我们可以修改电路为使其至少要经过两个门，因此在只经过一个门的电路上增加一个缓冲器门，如下图： 缓冲器就是仅仅减缓了信号传递的速度，这样t_cd就至少为50ps&gt;40ps了，因此也就不违反保持时间约束了。"},{"title":"定点数的表示与运算","path":"/wiki/计算机组成原理笔记/数据存储方式与浮点数的表示与运算/index.html","content":"数据的存储方式和排列 数据的大端/小端存储 我们知道对于一个int型的数是4B，而存储方式又是按字节存储，对于一般的数据都是采用连续存储，所以我们可以知道一个4B的内容数据存储时是需要占据连续4个地址空间单元，我们假设现在有一个int型变量i，他的机器数为01 23 45 67H，那么一般我们不用最左或者最右来形容这个数的两边，这与大端/小端的存储方式有关，我们一般形容为最低有效字节LSB和最高有效字节MSB，所以01是MSB,67是LSB，注意H是16进制的意思。那么我们现在讲解一下大端存储和小端存储。 假设我们现在要将上面的数存储到一段连续的4个存储空间，分别为0800H,0801H,0802H,0803H，那么01 23 45 67H分别放到哪个空间中呢？按照大端存储（Big endian)方式存那么就是我们通常理解的从高有效字节到低有效字节的顺序存储： 0800H 0801H 0802H 0803H 01H 23H 45H 67H 这样我们到真是够指针访问时就是直接得到了01234567H，如果是小端存储（Little endian)方式，那么是按照最低有效字节到最高有效字节存储： 0800H 0801H 0802H 0803H 67H 45H 23H 01H 这样我们顺序访问存储单元后得到的是67452301H，所以需要转换一下每次都将后面数放到前面即可。这样才能读出正确的数值01234567H。 那么在实际的底层汇编语言，我们要根据不同的数据存储类型得到正确的读取方式才能够读出正确的数据，比如对于由反汇编器（汇编逆过程，将机器代码转换为汇编代码）得到的文本表示： 14004d3 01 05 64 94 04 08 add %eax, 0x8049464 上面一个常见的汇编文本，前面4004d3是执行到的指令地址，01 05 64 94 04 08分别是指令的机器代码，add是一种相加的汇编指令，%eax是一个寄存器用来存储数据，一般变量的数据会从内存中拿出到寄存器中，而0x8049464就是一个立即数。假设现在是小端存储，那么执行这条指令时，从指令代码的后4个字节取出这个立即数，立即数存放的字节序列就应该是64 94 04 08H（最后一个8要补0）。 所以在阅读小端存储方式的机器代码时，要时刻注意字节是按相反形式显示的。 “边界对齐”方式存储 我们首先来介绍一下按字节和字，半字寻址方式的关系： 寻址方式 定义 所寻位数 按字节寻址 一次搜索跳过一个字节宽度 8bit 按字寻址 一般是一次搜索跳过整数个字节，具体多少字节根据机器类型不同，但是一定是整数个字节 8bit*n 按半字寻址 顾名思义，一次跳过半个字 4bit*n 假设有一个机器存储字长为32位，可以按照字节，半字和字寻址，那么如果数据是以边界对齐的方式存储，半字地址一定是2字节的整数倍，字地址一定是4字节的整数倍，这样无论所取的数据时字节，半字还是字，都可以一次访存取出。当所存储的数据不满足上面的要求时，就将填空字节使其满足边界对齐，这样虽然浪费了存储空间，但是加快了搜索：下图的任意一个数据都必定一次访存得到。 如果不是边界对齐的方式存储，那么虽然可以充分利用存储空间，但是半字或者字长的指令可能会存储在两个存储字中，此时我们就需要两次访存了，从而影响了指令的执行效率： 此时我们尝试取出字1或者半字3的数据内容都需要两次访存，这主要是因为数据内容分开存储到了两个字中。 边界对齐方式相对边界不对齐方式是一种空间换时间的思想，RISC如ARM采用边界对齐方式，而CISC如x86对齐和不对齐都支持。因为对齐方式取指令时间是确定相同的（就是一次访存的时间），因此更能适应指令流水。 浮点数的表示 浮点数的表示格式 浮点数，和定点数不同，他是以适当的形式将比例因子表示在数据中，让小数点的位置根据需要浮动，这样既扩大了表示范围，同时也保证了数的有效精度。通常浮点数的表示形式为： N=rE∗MN=r^E*M N=rE∗M 为什么浮点数的表示形式是这样的呢？我们可以拿科学计数法表示小数做对比，比如电子的质量： 9∗10−28=91∗10−28{r=10(r就是10进制基底10）E=−28M=99*10^{-28}=9^1*10^{-28}\\begin{cases} r=10(r就是10进制基底10）\\\\ E=-28\\\\ M=9 \\end{cases} 9∗10−28=91∗10−28⎩⎪⎪⎨⎪⎪⎧​r=10(r就是10进制基底10）E=−28M=9​ 所以我们发现上面的基数10是隐藏的，且M(9)都不能超过基数10，因为是10进制，那么我们类比写出浮点数的形式： 其中Jr和Sr分别代表的是阶码和尾数的正负，所以Jm和Sr之间是小数点的位置，他会随着m和n阶码和尾数的长度变化而浮动位置。其中阶码就是类比于刚刚的级数-28，但是这里由于是机器语言，r一般是2即二进制，所以J1J2…JM是一个二进制串，而后面的尾数类比于9，但是同样是以二进制形式表示，但是E和M肯定都是定点数。这样我们只要给出任意一个阶码E和尾数M我们都可以求出这个浮点数的真值。并且由于有正负问题，一般我们都用补码来表示阶码和尾数： 对于一个浮点数a他的阶码和尾数分别如下： E=0.01M=1.1001E=0.01 \\quad M=1.1001 E=0.01M=1.1001 那么阶码是一个正数很容易就可以转成10进制真值为+1，而尾数是一个补码，我们需要先转换原码-0.0111再求出10进制真值： {方法一：直接按照定点小数求解−0.0111=−(2−2+2−3+2−4)=−7/16方法二：可以看成定点整数−111.=−7右移4位变成−.111所以除以16=−7/16\\begin{cases} 方法一：直接按照定点小数求解-0.0111=-(2^{-2}+2^{-3}+2^{-4})=-7/16\\\\ 方法二：可以看成定点整数-111.=-7右移4位变成-.111所以除以16=-7/16 \\end{cases} {方法一：直接按照定点小数求解−0.0111=−(2−2+2−3+2−4)=−7/16方法二：可以看成定点整数−111.=−7右移4位变成−.111所以除以16=−7/16​ 这样我们就算出了E=+1，M=-7/16，所以再带入浮点数计算公式就可以求解： a=21∗(−7/16)=−7/8a=2^{1}*(-7/16)=-7/8 a=21∗(−7/16)=−7/8 现在我们要用1B来存储，那么也就是8位： 7(Jf) 6(J1) 5(J2) 4(Sf) 3(S1) 2(S2) 1(S3) 0(S4) 0 0 1 1 1 0 0 1 刚好可以将阶码和尾数拼接放在一起，且此时小数点是在5和4之间。 对于一个浮点数b他的阶码和尾数分别如下： E=0.01M=0.01001E=0.01 \\quad M=0.01001 E=0.01M=0.01001 阶码还是一个正数转换成真值就是+1，而尾数也很好计算： {方法一：直接按照定点小数求解+0.01001=+(2−2+2−5)=9/32方法二：可以看成定点整数+1001.=9右移5位变成+.01001所以除以32=+9/32\\begin{cases} 方法一：直接按照定点小数求解+0.01001=+(2^{-2}+2^{-5})=9/32\\\\ 方法二：可以看成定点整数+1001.=9右移5位变成+.01001所以除以32=+9/32 \\end{cases} {方法一：直接按照定点小数求解+0.01001=+(2−2+2−5)=9/32方法二：可以看成定点整数+1001.=9右移5位变成+.01001所以除以32=+9/32​ 这样我们就算出E=+1，M=+9/32，所以再带入浮点数计算公式就可以求解： b=21∗(9/32)=9/16b=2^1*(9/32)=9/16 b=21∗(9/32)=9/16 现在我们也用1B来存储，但是发现貌似有点问题： 001001001貌似是9位，1B放不下（因为尾数最后一位是1不能丢弃，如果丢弃了就是近8/16近似9/16了，不是准确的9/16了）。所以此时我们尝试对这个浮点数码进行转换： b=21∗(+0.01001)=20∗(+0.01001+0.01001)=20∗(+0.10010)b=2^1*(+0.01001)=2^0*(+0.01001+0.01001)=2^0*(+0.10010) b=21∗(+0.01001)=20∗(+0.01001+0.01001)=20∗(+0.10010) 所以阶码转换成了+0，位数M转换成了+0.10010，这样再拼接，由于最低位是0可以丢弃不影响真值，所以可以用1B存储： 7(Jf) 6(J1) 5(J2) 4(Sf) 3(S1) 2(S2) 1(S3) 0(S4) 0 0 0 0 1 0 0 1 小数点仍然是在5和4之间，我们发现尾数能占用的位数就是总位数减去阶码占用的位数，而小数点就在阶码和尾数的交界处。我们思考一下b在存储时还需要手动进行对阶码和尾数的转换以便能够存储，那么我们能不能有一种规则保证了尾数和阶码可以恰好占满存储位数而不会出现丢位缺失精度的方法？答案是有的，请看下面： 规格化浮点数 为了能够提高运算的精度，我们需要充分利用尾数的有效位数，所以我们要规格化浮点数，实际上规格化就是保证最高位数位必须有一个有效值，非规格化浮点数需要进行规格化操作才可以变成规格化浮点数。 我们在规格化的时候，一般是要进行以下两个操作的： 左规：当浮点数运算的结果为非规格化时要进行规格化处理，将尾数算术左移一位（注意是算术左移），阶码减1（基数为2时）的方法称为左规，左规可能会进行多次。 右规：当浮点数运算的结果尾数出现溢出（双符号位01或者10）时，将尾数算术右移一位，阶码加1（基数为2时）的方法称为右规。需要右规时，只需进行一次即可。 那么规格化浮点数后应该满足尾数M的绝对值： 1/r&lt;=∣M∣&lt;=11/r&lt;=|M|&lt;=1 1/r&lt;=∣M∣&lt;=1 若是r=2，即基数为2，用的是2进制，那么1/2&lt;=|M|&lt;=1 原码规格化以后 正数为0.1×××…×的形式，其最大值就表示为0.11…1，最小值就是0.100…0。 尾数范围是1/2&lt;=M&lt;=(1−2−n)尾数范围是1/2&lt;=M&lt;=(1-2^{-n}) 尾数范围是1/2&lt;=M&lt;=(1−2−n) 负数为1.1×××…×的形式，其最大值表示为1.10…0，最小值为1.11…1。 尾数范围是−(1−2−n)&lt;=M&lt;=−1/2尾数范围是-(1-2^{-n})&lt;=M&lt;=-1/2 尾数范围是−(1−2−n)&lt;=M&lt;=−1/2 补码规格化以后 正数为0.1××…×的形式，其最大值表示为0.11…1，最小值就是0.100…0。 尾数范围是1/2&lt;=M&lt;=(1−2−n)尾数范围是1/2&lt;=M&lt;=(1-2^{-n}) 尾数范围是1/2&lt;=M&lt;=(1−2−n) 负数为1.0××…×的形式，其最大值表示为1.01…1，最小值表示为1.00…0。 尾数范围是−1&lt;=M&lt;=−(1/2+2−n)尾数范围是-1&lt;=M&lt;=-(1/2+2^{-n}) 尾数范围是−1&lt;=M&lt;=−(1/2+2−n) 思考：为什么补码的负数最值边界表示发生了变化？ 首先我们需要遵循一个规则才是规格化浮点数，就是上面所讲的原码形式的尾数最高位必须是1，补码的尾数最高位必须和符号位相反。那么在这个前提下我们观察原码的最值，正数0.1开头，就已经保证了M一定是&gt;=1/2了，同时要求最大值，那么后面就全部填1尽可能的多加2^n最终话会无限逼近1，所以最大值时0.11…1，而最小值同理后面全补0。而负数最大值就是尽可能的不要在加2^(-n)了，所以全部补0，得到最大值1.10…0，最小值就是尽可能的全加上2^(-n)，所以为1.11…1。那么在得到原码的基础上我们来观察补码，补码正数的部分和原码相同，但是负数部分，我们认为就是将原码的负数最大值转换成补码应该就得到的是补码最大负数值。可是我们看原码的最大负数值1.10…0的补码应该是1.1…0虽然确实满足了|M|&gt;=1/2,但是却不是负数规格化的形式（要求必须是尾数最高位和符号位相反）。所以这不符合，我们取比1.10…0小一点的次大值1.10…01，他的补码是1.01…1满足|M|&gt;=1/2并且还满足了负规格化浮点数的补码要求，所以他才是最大负值。至于最小值我们认为应该也是将原码的负数最小值转换成补码应该就得到的是补码最小负数，所以应该是1.00…01，但是实际上不是这个值，而是1.00…00，这是为什么呢？我们可以这样理解原码的最小负数值1.11…1假设尾数部分有n个1，那么总会有一个更小的值即1.11…11尾数部分有n+1个1，其补码就会是1.00…001(多了个n+1位是1），取前n位就得到了1.00…00。所以我们可以理解为补码1.00…0是负无穷。 思考：为什么规格化浮点数后原码形式尾数最高位必须是1？为什么补码形式的尾数最高位和符号位要相反？ 实际上我们思考一下刚刚的b，他的未转换前的尾数是9/32&lt;16/32=1/2。那么此时他的尾数最高位就不是1而是0，也就是说如果不满足尾数&gt;1/2，那么尾数的第一个1之前就会可能有许多个不确定的0，比如9/32的尾数是.01001前面有1个0,再比如3/64的尾数是.000011前面有4个0，这样我们就不能给出一个准确的位数来存储尾数，但是如果我们保证了尾数一定&gt;=1/2。那么他的第一个位必须是1，这样才能保证至少为1/2，也就是说此时我们保证了尾数的第一个1的前面不会有许多个不能确定的0了，即有效位。这样我们就可以将尾数保证在一定的位数范围内存储了，当然这是对于原码来说就是最高位必须为1了，对于补码正数来说也是最高位为1且此时补码的符号位为0，所以就必定是0.1开头，而对于补码负数来说，其产生是原码取反加1所以就必定是最高位为0了，又因为此时符号位一定是1，所以就是1.0开头了。所以我们可以总结出一个规律，对于二进制的规格化浮点数，尾数的原码最高位必须是1，尾数的补码最高位必须和符号位相反。 思考：如果不是二进制，而是4进制，8进制规格化浮点数又是什么规律？ 我们思考前面提到了对于r进制需要保证|M|&gt;=1/r，所以对于2进制才有了|M|&gt;=1/2,这样也就推理出来尾数的最高位必须是1了，那么如果对于4进制，那么|M|&gt;=1/4,也就是说尾数的前两位只能是01,10,11这三种情况才能保证尾数&gt;=1/4,所以只用要求尾数原码的前两位不是全0即可，相对应的对于8进制，原码规格形式的尾数最高3位不能全为0即可，而此时补码形式的规律就不太好推了，我们也无需掌握。 浮点数的溢出 对于定点数我们定义过上溢和下溢，这里浮点数同样也有溢出的概念，我们可以将浮点数的溢出按照下面这张图进行定义： 一个浮点数是否溢出一定要看规格化以后的浮点数 运算结果大于最大正数时称为正上溢，小于绝对值最大负数（就是最小负数）时称为负上溢，正上溢和负上溢统称为上溢。 运算结果在0~最小正数时称为正下溢，在0~绝对值最小负数（就是最大负数）时称为负下溢，正下溢和负下溢统称为下溢。 只有在数据上溢时，计算机才必须中断运算操作，进行溢出处理（原因是此时存储位置不够导致丢失了有效位造成了数值精度下降，可能会影响后面的操作），但是对于数据下溢，浮点数会趋于0，计算机只是将其当做机器0处理。 思考：定点数和浮点数的溢出概念区别？ 溢出类型\\数值类型 定点数 浮点数 上溢 大于最大正值 正上溢：大于最大正值负上溢：小于最小负值 下溢 小于最小负值 正下溢：0~最小正值负下溢：0~最大负值 定点数只要溢出就中断，但是浮点数只有上溢会中断。 浮点数的IEEE754标准 我们已经了解了浮点数的表示和规格化的方法了，但是这样还是不易于存储表示，我们看此时对于一个规格化的浮点数的解码和尾数都有原码，补码，等不同的表述形式，并且都有正负的问题，所以接下来我们学习一个重要的浮点数表示标准，即IEEE754标准。说来也简单，我们看下图： 我们规定，这个浮点数的正负单独存储在最前面的数符位来表示正负，而阶码必须是由移码表示，且尾数必须使用原码表示。我们根据不同的浮点数二进制码的长度分成了三种情况，代表了不同的精度，存储时只能是这三种的任意一种。 段浮点数就是我们熟知的float类型，他是短浮点数，一共需要32位来存储浮点数，而长浮点数double精度更高，是64位，还有一个是不太常见的临时浮点数又称为扩展双精度浮点数long double为80位。我们观察一下上表，思考几个问题： 思考：偏置量是什么？ 我们在学习移码的时候讲过偏置量，就是对于一个n+1位的移码，其有以下规律： [X]移=(偏置量)2n+X[X]_移=(偏置量)2^n+X [X]移​=(偏置量)2n+X 所以偏置量是用来将阶码的真值转换成移码的，又因为阶码有固定的的位数，所以三种浮点数都对应这固定的偏置量。 思考：为什么偏置量变成了2^n-1？为什么IEEE754中没有阶符？ 我们原先学习移码的偏置量时规定偏置量为2^n，但是这里却减小了1，我们首先需要透彻理解一下为什么要引出偏置量，我们知道一个级数的指数是有正负之分的，比如2^9和2^(-9)，但是这样我们还需要拿出一个位单独来表示正负（即阶符），这样我们对于解读这个阶码就很复杂，所以我们引出了移码，那么移码的作用就很明显了，为了能够全部按照无符号数（即非负数）解读也可以表示负指数。那么我们怎么做到呢？就需要引入一个偏置量，我们可以将原先8位阶码按正负解读的-127~127更改为全部按照无符号数解读的0~255，但为了得到-127~127我们需要减去一个数，这个数可以是127或者128，这样我们就可以将E总是按照无符号数解读最后减去一个偏置量即可表示出-127~127了。所以采用移码以后，阶码E必定是解读为一个无符号数，只要在减去一个偏置量即可表示出负指数了。但是我们又规定在IEEE754中11111111阶码不能解读为+255，而是需要特殊表示为无穷大，而00000000也不能解读为0，而是非规格化浮点数，所以E实际上只能解读的无符号数范围是1~254，那么对应着指数的范围就变成了-126~-0以及1~127，即-126~127,那么对应着IEEE754的偏置量为127时即可恰好保证阶码E解读为[1,254]减去一个偏置量127表示为指数的[-126,127]。所以在IEEE754中偏置量时2^n-1,而在非IEEE754的情况下偏置量就是2^n。 思考：为什么11111111和00000000在IEEE754中要单独拿出来特殊表示？ 我们知道11111111应该原先表示为无符号数的127，但是我们原先在溢出哪里讲过无穷可以使用全1来表示，所以11111111在IEEE754中失去了127的数值意义，反而用来表示了无穷。同样的，00000000也具有特殊意义表示非规格化浮点数，至于为什么，规定而已。 然后我们在来继续讲解IEEE754浮点数的表示，经过上面的思考，我们知道数符是来标识浮点数的正负的，而阶码绝对是一个无符号数，经过减去偏置量即可完美表示出级数的指数正负，那么也就不存在阶符了，这也是阶码必须使用移码的原因。但是对于尾数我们还必须采用原码，原因是这样我们可以用23位来表示纯小数数值的24个有效信息位。实际上就是因为尾数采用了隐藏位策略的原码表示导致的。 思考：隐藏位原码为什么可以使得尾数用23位表示24个数值？ 我们思考一下原码的特点：尾数的最高位必定是1。那么我们可不可以隐含这个最高位1，这样不就可以多表示1位了吗？例如对于十进制的12，我们将它改写成二进制串是1100，用浮点数表示应该写成0.1100*2^4，但是最高位必定是1，那么我们就可以隐藏不填写他，即改成1.100*2^3，这样前面的1我们就可以不占用尾数的一位1，相应的，尾数就可以多表示1位了。所以23位可以表示24位尾数值。 思考：二进制1100怎么就快速转换成了0.1100*2^4？ 我们知道在十进制的科学计数法中9*10^6可以快速转换成0.9*10^7，实际上就是尾数真值除以基数10，将这个10给了阶码，所以阶码+1。那么1100是同样这样转换的，1100=1100*2^0，那么1100.右移4位即除以基数2四次，变成了0.1100，同样给了阶码4个2就变成了0.1100*2^4。 对于短浮点数和长浮点数都采用了这种尾数隐藏1位的原码表示，所以尾数都可以多表示一位有效数值，但是临时浮点数就没有，他就是正常存储（毕竟位数多不缺这一位）。那么我们就可以写出IEEE754浮点数的真值计算公式了： {短浮点数：(−1)ms∗1.M∗2E−127长浮点数：(−1)ms∗1.M∗2E−1023\\begin{cases}短浮点数：(-1)^{m_s}*1.M*2^{E-127}\\\\ 长浮点数：(-1)^{m_s}*1.M*2^{E-1023} \\end{cases} {短浮点数：(−1)ms​∗1.M∗2E−127长浮点数：(−1)ms​∗1.M∗2E−1023​ M是23位加上前面的1就是24位尾数表示值了，这就是隐含原码多一个表示位的原因。那么同样我们也可以根据浮点数真值转换IEEE754标准的浮点数表示了。上式中，ms是数符0表示正，1表示负，短浮点数E的取值是1~254（8位），M为23位可以表示24位。而长浮点数E的取值是1~2046(11位表示)，M为52位可以表示53位。 并且我们可以得到以下结论（以短浮点数为例）： 只有E=0且M=0时，表示真值为0 E=0,M≠0，则为非规格化数，真值为 (−1)ms∗0.M∗2−126(-1)^{m_s}*0.M*2^{-126} (−1)ms​∗0.M∗2−126 一定要注意此时M小数点前面就不是1了，就是正常的0了，因为非规格化数的尾数最高位不能保证是1了，所以此时23位尾数就是表示23个有效数值位了 1&lt;=E&lt;=254,真值就是短浮点数真值计算公式的计算结果，一定要注意偏置量为127 E=255且M≠0时，真值为‘NaN’(非数值) E=255且M=0时，真值为正无穷或负无穷（看符号位） 我们可以计算出单精度短浮点数和双精度长浮点数的表示范围了 当然啦此时E=0,M≠0的非规格化浮点数可以表示的更小，但是他不符合IEEE754标准要求，也就不属于单精度和双精度浮点数的表示范围，所以我们还可以推断出IEEE754表示范围内的数理论上一定是一个规格化浮点数。但是实际上IEEE754标准也可以用来表示非规格化数。 定点数、浮点数的区别 角度一：数值的表示范围 如果定点数个浮点数的字长相同，那么浮点表示法所能表示的数值范围将远远大于顶点表示法。 角度二：精度 精度，就是一个数所包含的有效数值位的位数。对于字长相同的定点数和浮点数，浮点数虽然扩大了数的表示范围，但是精度降低了。 这里有点小疑惑，为什么浮点数精度会下降呢？我们可以想一想因为定点小数小数点就在最高位，那么后面的位都是有效位，而对于浮点数，同样的位数，却要分出一部分用来表示阶码，这样虽然扩大了表示范围，但是尾数就短了，相应的精度就低了。比如定点数可以表示0.007783526，但是在浮点数中，可能只能表示成7.78*10^(-3)了。 角度三：数的运算 浮点数包括阶码和尾数两部分，运算时不仅要做尾数的运算，还要对阶码进行运算，而且运算结果还要求规格化，所以浮点数比定点数运算要复杂。 角度四：溢出问题 在定点运算中，当运算结果超出数的表示范围，发生溢出，而在浮点运算中，运算结果超出尾数表示范围却不一定溢出，只有规格化后阶码超出所能表示的范围时，才发生溢出。 为什么浮点数运算结果可能不会溢出呢？因为小数点可以根据阶码和尾数的具体长度浮动，如果尾数很长需要更多的位，而恰巧阶码不需要很多位，那么阶码可以让出一些为给尾数，即小数点浮动了，但是一旦规格化以后根据IEEE754要求，尾数和阶码必须占据固定尾数就可能产生溢出了。 总结 浮点数的运算 加减运算 浮点数运算的特点是阶码运算和尾数运算要分开进行，浮点数的加减运算一律采用补码进行。浮点数的加减运算包括以下几个步骤。 对阶 我们知道在科学计数法中，加减运算时要求级数相同，这里也是。对阶是使两个操作数的阶码相同，也就等价于两个操作的小数点位置相同。这里我们要求小阶向大阶对齐，即阶码小的操作数，尾数右移1位相当于除以2，那么阶码就可以加一。直到两个数的阶码相等为止。尾数右移时，那么会舍掉有效位产生误差，影响精度。 一定要注意，由于最终短阶码要变成长阶码，所以必定会造成占用了尾数的位，所以尾数右移会少位，这就会造成精度降低的原因。 尾数求和 对阶后的尾数按照定点数加减运算规则进行。一定要注意如果操作数是按照IEEE754格式写的，需要先将移码转换成真值或者补码在进行加减运算。 规格化 我们以双符号位为例，当尾数大于0时，即是一个大于时，其补码规则是 [S]补=00.1××...×[S]_补=00.1××...× [S]补​=00.1××...× 当尾数小于0时，即是一个负数时，其补码规则是 [S]补=11.0××...×[S]_补=11.0××...× [S]补​=11.0××...× 这里的双符号位前面讲过，如果有遗忘，速速回去复习-&gt;传送门。可见，当补码形式的尾数，数值最高位与符号位必须相反，只有当尾数的最高数值位和符号位不同时，即为规格化形式，规格化分为左规和右规两种。 左规：当尾数出现00.0××…×或者11.1××…×时，需要左规，即尾数左移一位，和的阶码减1，直到尾数为00.1××…×或11.0××…×。 右规，当尾数求和结果溢出（如尾数为10.××…×或者01.××…×)时，需要右规，即尾数右移一位，和的阶码加1。这里我们要注意其实此时并不是真的结果溢出了，他最终经过右规以后是可以表示的，毕竟浮点数的表示范围非常大，一般是不会溢出的。 舍入 我们知道在对阶和右规的过程中（都是尾数右移的操作），会将尾数的低位丢弃，引起误差，影响精度。其中舍入规则有两种： “0”舍“1”入法：类似于十进制的运算中的四舍五入法，即在尾数右移时，被移去的最高数值位为0，那么就直接舍去。如果被移去的最高数值位为1，那么就在尾数的末位加1，这样做可能会使尾数又溢出，此时需要再做一次右规。 恒置“1”法：尾数右移时，不论丢掉的最高数值位是1还是0，都使右移后的尾数末位恒置1，这种方法同样有使尾数变大和变小的可能。 我们距离说明一下，比如对于0.xxxx|010100，|后面的是丢弃数串，那么如果按照“0舍1入法”，因为被丢弃的是010100最高位是0，所以就直接丢弃即可，剩余的尾数为没有变化， 如果被舍弃的是110100，那么剩余的尾数应该为0.xxx+0.xx1即最后一位加1。如果是恒置1法，那么无论被舍弃的串什么样子，最后剩余的尾数最低位必须置为1，即变成0.xx1。上面这两种方法都不能避免尾数精度的降低，毕竟尾数的位数减少了，这是精度降低的根本原因，但是上面两种方法一定程度上缩小了误差。 溢出判断 和定点数加减法一样，浮点数加减运算的最后一步也是需要进行溢出判断的，一定要注意规格化的右规时不时结果溢出，只有规格化以后才进行真正的溢出判断。 我们在规格化讲了尾数的01或者10并不是真正的溢出，只是需要右规即可。其实浮点数的溢出判断，是根据阶码来判断的，假设浮点数的阶码此时是双符号位补码形式，那么如果出现01，即阶码大于最大阶码，那么就是上溢，进入中断处理。当阶码为10，即阶码小于最小阶码，那么就是下溢，此时只是看成机器0（无论尾数是多少都是0），不会发生中断。实际上原理还是阶码符号位不同表示溢出，且真符号位和最高位一致才不溢出（00,11）。 例题 那么接下来我们以一道例题讲解浮点数加减运算的整体过程： 已知十进制数X=-5/256,Y=+59/1024，按照机器补码浮点运算规则计算X-Y，结果用二进制表示，浮点数格式如下：阶符取2位，阶码取3位，数符取2位，尾数取9位。用补码和尾数来表示尾数和阶码。 我们首先看完题干，很容易就可以判断出肯定是双符号位了，并且一定要知道因为阶码是补码形式，所以才给出了阶符，如果阶码是移码，那么就不要阶符了。现在我们进行求解： 首先我们将X转换成规格化的浮点数形式： 5D=101B，1/256=2−8−&gt;X=101∗2−8=−0.101∗2−5=−0.101∗2−1015D=101B，1/256=2^{-8}-&gt;X=101*2^{-8}=-0.101*2^{-5}=-0.101*2^{-101} 5D=101B，1/256=2−8−&gt;X=101∗2−8=−0.101∗2−5=−0.101∗2−101 所以X的二进制浮点数形式为（将尾数和阶码均转换成补码，并且符号位为负数11正数00） 11011,11.011000000{阶码：−101原码就是11101−&gt;补码：11011尾数：−0.101原码就是11.101−&gt;补码：11.011−&gt;扩展：11.01100000011011,11.011000000\\begin{cases} 阶码：-101原码就是11101-&gt;补码：11011\\\\ 尾数：-0.101原码就是11.101-&gt;补码：11.011-&gt;扩展：11.011000000 \\end{cases} 11011,11.011000000{阶码：−101原码就是11101−&gt;补码：11011尾数：−0.101原码就是11.101−&gt;补码：11.011−&gt;扩展：11.011000000​ 我们再将Y转换成规格化浮点数形式： 59D=111011B，1/1024=2−10−&gt;Y=+111011∗2−10=+0.111011∗2−4=+0.111011∗2−10059D=111011B，1/1024=2^{-10}-&gt;Y=+111011*2^{-10}=+0.111011*2^{-4}=+0.111011*2^{-100} 59D=111011B，1/1024=2−10−&gt;Y=+111011∗2−10=+0.111011∗2−4=+0.111011∗2−100 所以Y的二进制浮点数形式为（将尾数和阶码均转换成补码，并且符号位为负数11正数00） 11100,00.111011000{阶码：−100原码就是11100−&gt;补码：11100尾数：+0.111011原码就是00.111011−&gt;补码：00.111011−&gt;扩展：00.11101100011100,00.111011000\\begin{cases} 阶码：-100原码就是11100-&gt;补码：11100\\\\ 尾数：+0.111011原码就是00.111011-&gt;补码：00.111011-&gt;扩展：00.111011000 \\end{cases} 11100,00.111011000{阶码：−100原码就是11100−&gt;补码：11100尾数：+0.111011原码就是00.111011−&gt;补码：00.111011−&gt;扩展：00.111011000​ X,Y都写成了规格化浮点数形式以后我们进行对阶： X阶码减去Y阶码： ΔE=[X]阶补−[Y]阶补=[X]阶补+[−Y]阶补=11011+00100=11111−&gt;真值：−1ΔE=[X]_{阶补}-[Y]_{阶补}=[X]_{阶补}+[-Y]_{阶补}=11011+00100=11111-&gt;真值：-1 ΔE=[X]阶补​−[Y]阶补​=[X]阶补​+[−Y]阶补​=11011+00100=11111−&gt;真值：−1 所以X阶码比Y小1，所以X进行一次尾数右移，阶码加一，右移时算术右移，因为尾数是补码，右移是算术右移，所以高位补1变成： X：11011,11.011000000−&gt;11100,11.101100000X：11011,11.011000000-&gt;11100,11.101100000 X：11011,11.011000000−&gt;11100,11.101100000 对阶完成以后，我们进行尾数的加减： [X]尾数−[Y]尾数=[X]尾数+[−Y]尾数=11.10100000+11.000101000=10.110001000[X]_{尾数}-[Y]_{尾数}=[X]_{尾数}+[-Y]_{尾数}=11.10100000+11.000101000=10.110001000 [X]尾数​−[Y]尾数​=[X]尾数​+[−Y]尾数​=11.10100000+11.000101000=10.110001000 完成尾数加减运算以后，我们进行规格化 对于现在的结果，尾数是10.110001000，阶码是11100，发现此时X-Y的结果尾数符号位是10，需要右规，算术右移，同时阶码加1： 11101,11.011000100{阶码加一：11100+00001=11101尾数算术右移高位补1:10.110001000−&gt;11.01100010011101,11.011000100\\begin{cases} 阶码加一：11100+00001=11101\\\\ 尾数算术右移高位补1:10.110001000-&gt;11.011000100 \\end{cases} 11101,11.011000100{阶码加一：11100+00001=11101尾数算术右移高位补1:10.110001000−&gt;11.011000100​ 这样我们一次右规就完成了规格化 接下来我们进行舍入，我们知道舍入一般是因为尾数或者阶码长度过程需要舍弃才会涉及舍入，但是题干给出的位数很多，我们不但不需要舍弃低位，还要扩展位数，所以依旧没有舍入的问题。 最终我们再判断结果是否溢出，查看阶码符号位是11，没有溢出，所以最终结果就是 11101,11.011000100−&gt;真值：−2−3∗−(0.1001111)211101,11.011000100-&gt;真值：-2^{-3}*-(0.1001111)_2 11101,11.011000100−&gt;真值：−2−3∗−(0.1001111)2​ 经过验证答案正确，那么我们现在思考几个问题： 思考：为什么右归和对阶时都没有涉及舍入？ 我们看一下题干发现给的阶码位数和尾数位数是固定的，所以对阶时只是阶码表示的真值不同，但是两个操作数X和Y所占用的阶码位数确实必定一样的，所以就不涉及到某一个操作数阶码短需要增长占用尾数位数的问题，所以自然尾数也就不会有丢位，也就不涉及 到舍入。而右规时本来有可能涉及到丢位的，即尾数太长了比规定的位数还要长则可能需要丢位，但是现在尾数给了9位，足够放下所有尾数有效位，所以也不涉及到了舍入。所以舍入一般情况下不会出现（毕竟很难，题干会有意避开），但是实际上浮点数的运算时经常涉及到舍入问题的。 思考：全过程难点有哪些？ 首先就是小数的转换，例如-0.101，我们可以先看成正数0.101，前面加了一个负号变成了负数，所以符号位是1，又因为是双符号位所以转换成了11.0101，还有就是补码加减运算的规则，忘记了一定要去复习，还有补码算术右移规则，以及最后结尾转换成真值时补码要转换成真值或者原码以及结果可能溢出需要判断的细节问题。 强制转换 这里的情况很复杂，我们不进行定量分析，只要能定性分析即可。我们以C语言举例，float和double分别对应着IEEE754的单精度浮点数和双精度浮点数（这也就是说明float和double阶码都是移码,尾数都是原码），而long double对应着扩展双精度浮点数，一般长度和格式随着编译器和处理器类型的不同而有所不同。在C中，我们知道： 所以char-&gt;int-&gt;long-&gt;double和float-&gt;double从前到后都是精度和表示范围从小到大，所以转换过程没有损失，但是注意这几种情况： int-&gt;float:不发生溢出，但是int可以保留32位，而float只能保留24位，可能有数据舍入，如果从int转换成double就不会出现舍入问题。 int或者float-&gt;double，因为double的有效位更多，因此能保留精确值 double-&gt;float：float范围更小，可能产生溢出，此外，由于有效位变少，可能出现舍入问题 float或者double-&gt;int:因为Int没有小数部分，所以数据会向0方向被截断（只保留整数部分），影响精度。最典型的就是(int)0.5=0，另外，由于int表示范围小，因此可能发生溢出。 总结"},{"title":"单周期MIPS32","path":"/wiki/数字逻辑与数字系统笔记/单周期MIPS32/index.html","content":"单周期MIPS32处理器的设计 接下来我们来设计一个单周期MIPS32位处理器，我们需要考虑一下几个方面： MIPS指令集 首先我们需要知道MIPS3类指令的主要组成是什么，这里我们只学习最基本的指令集： R-type指令：and,or,add,sub,slt等 存储器指令：lw,sw等 分支指令：beq等 扩展指令：addi等 上面是我们将要实现的MIPS指令（后面我们将学到上面的这种指令分类是根据主译码模块的功能进行分类的）。接下来我们看一下每一个类型指令的功能： 对于R-type类型指令op都是0，并且都对应有三个寄存器类型存储的操作数，并且格式都是 1助记符 目的操作数 源操作数1 源操作数2 这里实际上只有slt指令我们不太熟悉，他是一个比较两个源操作数大小的指令。 L-type类型指令是立即数类型指令，他的特定是有一个源操作数为立即数常数，我们要注意此时op不再是全0并且形式为： 1助记符 源操作数1 目的操作数 源操作数2 J-type类型指令就是地址跳转指令，实现起来比较简单。 思考一个问题，op位数是有限的，这也就意味着可以表示的指令类别是有限的，因此我们为了尽可能多的取表示更多的不同类型的指令，我们只对最基础（即其他指令不能组合表示)的指令进行编写并且为其分配Opcode。 设计目标 我们在编写MIPS处理器结构前，我们需要明确一下型号，这里我们设计的MIPS32处理器的配置： 单周期MIPS32处理器 每一条指令必须在一个时钟周期内完成 32个32位寄存器，哈佛结构，小端存储模式，支持23条指令 数据通路+控制通路 数据通路：完成对指令中操作数的操作、存储等处理工作 控制通路：从数据通路接受指令，并对其进行翻译以告知数据通路如何处理，因此控制电路决定数据的某一部分到哪里去接受什么操作后将目的信息传输到哪里 处理器设计相当于在各个记忆部件之间添加组合逻辑电路，在控制单元的控制下根据当前电路的状态计算出电路的新状态 MIPS32位处理器的概念模型 我们简单的来认识一下上面的概念模型的运行方式，首先我们根据指令，对输入信号进行操作，他可能会需要到其他操作数的帮助，因此我们需要从现态的记忆部件中取出需要的信息，然后进行组合逻辑的运算（实际上就是指令控制着数据的处理），指令在一个时钟周期内完成信息的处理后会产生输出数据，此时我们需要将这个新的输出数据存储起来也就是改变了记忆部件的状态，因此也就是现态，同时我们还需要进行输出信号。因此上图实际上可以看成就是一个取数据-&gt;处理数据-&gt;存放数据的过程，这其中涉及到了组合逻辑电路和时序逻辑电路的合作使用。 记忆部件 分别是存储地址的程序计数器，存储指令的内存块，寄存器以及存储数据内存块他们都是cpu内部的核心部件，需要受到clk时钟周期控制。 在寄存器模块中有六个端口，其中A1对应RD1，A2对应RD2，这两组端口是从寄存器读出数据时需要的，其中A端口用来接收要读出数据到的地址，RD端口使用来输出32位的数据的。而A3是用来接收要从那个地址写入数据的地址，WD3是用来接收要写入的32位数据。WE3是写使能端，控制着此时寄存器是写/读和数据（一次性只能读或写）。 数据存储和寄存器也类似，A和RD是用来读出数据的，WD是用来写入数据的。WE还是控制着内存的读/写。 具体指令的实现 数据通路——LW 此时我们从程序计数器中读出下一个指令的地址，然后到存储指令的存储块中取出指令。我们知道一个指令在MIPS32中也是32位的，但是也可以使用8位16进制码来表示。 这里我们假设的不是J型指令而是I型指令，因此25:21这六位是对应的rs，我们将指令的这六位地址传进去即可获得源操作数rs的值，接下来我们还需要取立即数操作数： 取得立即数后我们得到只是一个16位的，我们需要对齐进行符号扩展为32位立即数 然后我们进行数据的处理，因此将两个源操作数传入到ALU中，同时我们需要告诉ALU进行那种类型的计算，因此传入ALUcontrol信号（实际上这个是由数值计算的指令来操控）。然后这里假设传入的是010，代表是加法，因此ALU此时进行加法，然后要注意我们得到的结果是要到存储数据的内存块中的地址，然后我们将计算结果传送到内存块地址接受端口即可得到我们最终要找到的数。 然后我们将从内存中读出的数据放到寄存器中以便使用，因此使用A3（接受要存放的地址位置）跟WD3（要存入的具体32位数值）端口接受要写入寄存器的数据。我们要注意从存储数据内存块处得到的数据是放到指令的rt目的操作数处，因此我们在写入寄存器时，传进去的是I型指令的20:16区域。 然后我们要进行程序计数器的更新，说来也简单，就是将PC加4就可以得到下一个指令的地址了😃。 思考：为什么要加四？ 我们知道MIPS中是按字节编址的，因此一个地址对应一个字节，而一个指令是32位的对应4个字节，因此加4才是下一条指令的地址。 数据通路——SW 因此我们此时是将寄存器读出的数据写入到数据内存中，我们先用20:16目的操作数地址传进去读出这个目的操作数，然后写入到数据内存中（使用WD接受这个数，同时写使能端要为1代表此时内存可写入数据）。前面的过程都不变，还是可能需要LW的操作来将所需要的数据首先保证存储到了寄存器中。 数据通路——R型指令 之前我们所学习的指令是LOAD指令加载一个内存中的数到寄存器或者SAVE指令集将寄存器中的一个数写回到内存中，现在我们要学习一个更加复杂的R型指令，他是将立即数与源操作数或者两个源操作数进行数值计算处理的结果存储到目的操作数寄存器中，因此我们此时需要先获得源操作数，由于我们可能只需要一个或者2个寄存器存储的操作数，然后在进行计算，我们可能会使用一个从寄存器中取出的源操作数与立即数进行ALU计算或者两个从寄存器中取出的源操作数进行数值计算，因此由ALUSrc来决定（首先有一个寄存器操作数由RD1连接的SrcA给出，另一个是使用RD2的寄存器操作数充当SrcB还是使用立即数来作为SrcB由AluSrc决定）。然后我们最终得到的结果并不是内存地址了，而是一个确切的结果数值了，我们决定是否需要将它写回到寄存器中，因此由MemtoReg来决定，如果需要我们再将数值写回到寄存器中，这需要RegDst来决定使用哪个寄存器地址段（RS还是RT？）来存储这个结果数。最后如果我们需要内存存储这个结果数，还需要通过RD2连接的WriteData线进行写内存的操作来存储结果数到内存中。我们思考一下整个的过程，一个R型指令需要两个源操作数首先存在于寄存器中，如果不存在很明显我们需要在前面的步骤中先使用LW将源操作数数据取出放入到寄存器中，因此在R指令中的数据通路也会涉及到LW的过程，而SW也是有可能的，因为很可能最终寄存器存储的结果数值需要写入数据存储块中存储，这就是一个完整的R型指令可能涉及到的所有数据通路。 数据通路——BEQ指令 上面的BCQ指令是根据是否满足条件进行跳转，因此首先我们需要判断是否满足条件，通过branch控制的与aluzero标志位（结果为0是zero为1）取与操作得到的结果作为是否满足条件的判断结果（当rs与rt值相等时满足条件），只有在满足条件即PCSrc为1时才会进行跳转，那么具体跳转到哪里，是由下面的通路给出的，他是用一个立即数偏移量来决定的，最终的跳转的指令地址为： BTA=(sign_extended)(immediate&lt;&lt;2)+(pc+4)BTA=(sign\\_extended)(immediate&lt;&lt;2)+(pc+4) BTA=(sign_extended)(immediate&lt;&lt;2)+(pc+4) 也就是sign_extended的意思是有符号数位数扩展，我们要注意最终位数扩展后的立即数偏移量是与下一条指令PC+4的值求和得到的跳转地址，而不是当前地址，所以说明跳转前程序计数器已经进行了一次更新指令地址的操作。 思考：上面是如何进行rs与rt是否相等的判断的？ 这里的ALU的zero并不是返还0的意思，他是alu的一个零标志位，只有计算结果为0时zero标志位为1，因此很明显此时alu进行的是相减操作让rs和rt相减，当两者相等时结果为0，zero标志位才能置为1，那么此时PCSrc才能变成1代表满足条件需要跳转。 CPU加入到通路中对记忆器件进行控制 根据上面的MIPS概念图，我们还没有加入控制通路，即需要连接控制单元使得他可以控制我们之前连接起来的记忆组件。如下图我们加入控制单元形成控制通路： 控制单元 上面的控制单元又可以拆分成主解码模块，另一个是ALU解码模块，主解码模块输入的是指令的opcode，主解码模块来识别具体是哪一种类型以便控制分配任务。对于R型指令有许多不同的数值计算功能，因此此时需要ALU解码模块来根据FUNC5:0来解码具体的数值ALU计算功能并分配ALUcontrol信号，当然alu解码模块还受到主解码模块的信号控制。 ALU译码 ALU译码是ALU解码模块根据funct和aluop来解码指令的具体功能同时生成ALU控制信号来告诉ALU进行何种数值操作 ALUOP1:0 Meaning 00 Add加法 01 Subtract减法 10 Look at Funct需要根据funct具体分析功能 11 Not Used不使用 ALUOP1:0 Funct ALUControl2:0 00 X 010(Add) X1 X 110（Subtract) 1X 100000(add) 010(Add) 1X 100010(sub) 110(Subtract) 1X 100100(and) 000(And) 1X 100101(or) 001(Or) 1X 101010(slt) 111(SLT) 主译码 主译码是主解码模块根据op判断不同类型的主要指令来控制数据通路的控制各种选择器的信号以决定数据通路的走向： Instruction Op5:0 RegWrite RegDst AluSrc Branch MemWrite MemtoReg ALUOP1:0 R-type 000000 1 1 0 0 0 0 10 lw 100011 1 0 1 0 0 0 00 sw 101011 0 X 1 0 1 X 00 beq 000100 0 X 0 1 0 X 01 思考：addi拓展指令怎样加入上面的表内？ 首先我们要知道addi是拓展指令，他独立于其他类型的指令，因此我们需要单独为他分配一个opcode，因此他也需要加入到主译码模块： Instruction Op5:0 RegWrite RegDst AluSrc Branch MemWrite MemtoReg ALUOP1:0 addi 001000 1 0 1 0 0 0 00 addi指令和lw相比只是没有内存取出的数加入到寄存器的功能，其他和lw相同，但是addi还需要进行一个加法操作，因此最终还需要到alu移码生成加法控制信号。 J型指令数据通路 我们前面已经学些了跳转指令的工作过程了，他的跳转计算公式就是： BTA=(PC+4)31:28∣∣instr_index∣∣0BTA=(PC+4)_{31:28}||instr\\_index||0 BTA=(PC+4)31:28​∣∣instr_index∣∣0 因此实际上后面补两个0的操作就是乘四左移2位，又因为instr_index26位的限制，我们可以知道跳转指令一次跳转的地址量是有限的，他的能跳转的最远地址是 max=(226−1)∗4max=(2^{26}-1)*4 max=(226−1)∗4 又因为一个地址是4字节，因此能最终跳转的指令个数是 max=226−1max=2^{26}-1 max=226−1 一定要注意BEQ指令与J型指令的跳转地址计算公式是不一样的。BEQ跳转地址的计算是先取出instr的26:0位，然后进行有符号数扩展为32位有符号立即数再左移两位与PC+4进行求和得到跳转地址PCBranch,而对于J型指令，则是直接获取instr的26:0位然后左移两位与PC+4的高四位进行拼接得到32位跳转地址。因此两者的计算方式不同，使用的地址计算线路也是不同的。 J指令主译码控制信号 由于J型指令也是单独的一类指令，因此也需要单独分配一个opcode 单周期处理器的性能分析 表示的是一个程序的时间，它是由以下公式原理给出的： 一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度 一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度 我们知道一个程序运行的有效时间是由其关键路径决定的也就是运行时间开销最长的通路，如下图是我们设计出的MIPS处理器的关键路径： 我们可以给出单周期处理器的关键路径时间： Tc=tpaq_PC+tmem+max{tRFread,tsext,tmux}+tALU+tmem+tmux+tRFsetupT_c=t_{paq\\_PC}+t_{mem}+max\\{t_{RFread},t_{sext},t_{mux}\\}+t_{ALU}+t_{mem}+t_{mux}+t_{RFsetup} Tc​=tpaq_PC​+tmem​+max{tRFread​,tsext​,tmux​}+tALU​+tmem​+tmux​+tRFsetup​ 很明显上面的公式难以进行具体的计算，因此我们简化一下上面的公式给出关键路径的计算公式： Tc=tpcq_PC+2tmem+tRFread+tmux+tALU+tRFsetupT_c=t_{pcq\\_PC}+2t_{mem}+t_{RFread}+t_{mux}+t_{ALU}+t_{RFsetup} Tc​=tpcq_PC​+2tmem​+tRFread​+tmux​+tALU​+tRFsetup​ 从上面的公式我们可以看出关键路径的时间开销主要是由内存的访存时间，ALU计算时延，指令加载和回写寄存器数据以及寄存器的读数据时间组成的。 例题 如下图是部分给出的参数，请给出具体的关键路径的计算公式并计算处结果："},{"title":"常用逻辑器件","path":"/wiki/数字逻辑与数字系统笔记/常用逻辑器件/index.html","content":"复用器 复用器（多路选择器）是一种多输入单输出的组合逻辑电路，常用MUX来表示，具有k个数据输入端口的复用器，即为k:1复用器，数据输入端口数目k和选择控制器的数目n应该满足k&lt;=2nk&lt;=2^nk&lt;=2n。如下图： 复用器的功能就是当使能端有效时，根据选择控制端口的值从多个数据输入中选择一个送到输出端（每个数据输入端的宽度可以是1位或者多位）。我们可以使用SystemVerlog HDL进行建模。这里我们以4:1复用器为例，首先我们列出真值表： EN S1S_1S1​ S2S_2S2​ Y 0 X X 0 1 0 0 D0D_0D0​ 1 0 1 D1D_1D1​ 1 1 0 D2D_2D2​ 1 1 1 D3D_3D3​ 因此我们根据真值表可以使用卡诺图求解逻辑表达式，然后建模： 上面一个基于过程块的建模，实际上对照着真值表逻辑很容易想清楚。 译码器和编码器 实际上前面我们已经讲过了，这里复习一下。译码器是一种将输入翻译成特定输出信号（独热码）的组合逻辑电路，它具有n个输入端和m个输出端，满足m&lt;=2nm&lt;=2^nm&lt;=2n。因此即为n:m译码器。 译码器就是接受要输出信号的端口的编号，然后在对应的编号端口进行输出。他和多路选择不同，多路选择器是决定唯一的输出端和哪一个输入端电平信号相同，而译码器是翻译出哪一个哪一个输出端电平有效。 译码器功能：使能端有效时，对应每一组输入，仅有一个输入端为有效电平，其他均是无效电平，否则，所有输出端都是无效电平，如果有效电平是1，那么无效电平就是0。 同样的我们也可以使用SystemVerilog HDL对其建模，我们这里以2:4的译码器为例，首先我们也是列出真值表： 然后我们根据真值表进行建模： 虽然查看真值表建模的方法对于大型电路不适用，但是学习阶段我们完全可以参考真值表进行建模，而不用使用非常复杂的方法。 编码器是一种将特定输入（独热码）转化为一个编码输出的组合逻辑电路，是译码器的逆过程，具有m个输入和n个输出，因此需要满足的端口数量条件是m&lt;=2nm&lt;=2^nm&lt;=2n。 编码器功能是使能端有效时，用n位二进制码对m个输入中的当前有效信号进行编码输出，标志信号VALID有效（VALID信号用于标识所产生的编码是否合法），如果m个输入信号均无效或使能端无效，那么VALID信号无效，编码输出可以为任何值（一般为0）。 编码器是将多个输入信号中选出一个有效输入，然后输出端输出这个有效输入端的编码的二进制码。所以我们不难总结出译码器总是输入端少于输出端，而编码器输入端多于输出端。 我们也可以使用SystemVerilog HDL对编码器进行建模，同样先列真值表： 我们以4:2编码器为例，最终建模的代码是 思考：复用器，编码器和译码器的异同？ 首先他们都有一个使能端用来表示当前的输入端是否有效，复用器是多输入一输出，永远选择一个输入端，使得输出端的电平信号和输入端相同。编码器是多输入多输出，并且输入端多于输出端，输出端输出的是有效输入端的编号的二进制码。而译码器也是多输入多输出，但是输入端少于输出端，输出端对应的输入编号的信号的电平有效位1。 1位加法器 1位加法器是算术电路元件的一种，其中又分为半加器和全加器，但是这两者都是针对的二进制码的某一位的算术运算。 1位半加器 半加器有两个输入A和B，两个输出S和C_&#123;out&#125;​。S是A和B之和，C_&#123;out&#125;​本位产生的进位信号。如下图： 其实上面的加法并不全面，他没有考虑从自己的低一位传进来的进位信号，因此为半加器。我们可以看到上图右侧的公式就是S和C_&#123;out&#125;​的计算方法。A异或B决定的就是本位的填写数值，A与B就是进位信息，很明显只有A=B=1时才能产生有效进位Cout=1C_{out}=1Cout​=1 1位全加器 1位全加器在半加器的基础上增加了一个进位输入CinC_{in}Cin​,此时得到的才是一个通常意义上的一位加法，实际上这部分内容在《计算机系统基础》学习过了，这里就不再细讲计算原理。 多位加法器（CPAs) 一个N位加法器将两个N位输入（A和B）与一个进位C_&#123;in&#125;​相加，产生一个N为结果和一个输出进位C_&#123;out&#125;​。因为在N为加法器内部，一位进位将传播到下一位，所以这种加法器通常又称为进位传播加法器。 很明显多位加法器实际上就是由许许多多的一位加法器组合形成的，因此不同的组合形式会形成性能不同的多位加法器。这里分为了三种： 行波进位加法器（慢速） 先行进位加法器（快速） 前缀加法器（更快速） 对于高位宽的加法器，先行进位和前缀更具优势，但需要消耗更过的硬件资源（实际上就是空间换时间的思想），这部分内容实际上也在《计算机系统基础》中讲过，只不过那里讲的是组合形式的原理，这里我们会对比学习。 行波进位加法器 行波进位加法器实际上应用的就是我们之前学习的一位全加器的串行进位连接方式，如下图： 对比计算机组成原理的图： 两者是一样的原理表示。我们不难看出这种进位一级一级的从低位传输到高位的形式，当N较大时即很多位时，计算延迟也会非常大，即延迟量tripplet_{ripple}tripple​随着位数的增加而增加。 假设一个一位全加器的延迟为tFA,假设一个一位全加器的延迟为t_{FA}, 假设一个一位全加器的延迟为tFA​, 那么tripple=N∗tFA那么t_{ripple}=N*t_{FA} 那么tripple​=N∗tFA​ 因为第i位必须等待第i-1位的进位信号传进来以后才会进行计算。我们以一道例题分析： 上图是一个四个模块组成的算术逻辑电路，很明显总延迟取决于局部模块中延迟量最大的关键路径的延迟量之和，因此上图的延迟量为9T。 先行进位加法器 先行进位加法器是一种快速的进位传播加法器，他把加法器分解成若干块，当每块一有进位时就会快速确定此块内的所有加法器的进位信号，从而实现块内的位加法器并行计算，因此他不需要等待通过一块内的所有加法器，而是直接先行通过该块。因此原理是单级先行进位方式： 对比计算机组成原理的图： 具体的原理请看《计算机系统基础》，这里就不细讲了。 这里我们计算一下两者的延迟，假设对于32位行波进位加法器和4位块组成的先行进位加法器的延迟。假设每个输入门电路的延迟为100ps，全加器的延迟是300ps。 那么32位的行波进位加法器的传播延迟就是(此时没有门电路延迟，全是全加器延迟) tripple=N∗tFA=32∗300ps=9.6nst_{ripple}=N*t_{FA}=32*300ps=9.6ns tripple​=N∗tFA​=32∗300ps=9.6ns 而32位的先行进位加法器的传播延迟就是（此时只有4个全加器延迟加上7个进位信号的传播延迟） tCLA=tpg+tpg_bloack+(N/K−1)tANDOR+ktFAt_{CLA}=t_{pg}+t_{pg\\_bloack}+(N/K-1)t_{AND_OR}+kt_{FA} tCLA​=tpg​+tpg_bloack​+(N/K−1)tANDO​R​+ktFA​ =(100+600+7∗200+4∗300)ps=3.3ns=(100+600+7*200+4*300)ps=3.3ns =(100+600+7∗200+4∗300)ps=3.3ns 我们可以对比发现此时的先行进位逻辑电路要快了许多。 实际上他还可以更快速，因为此时低二CLA的C_4​还是必须等待最低CLA计算出来以后才可以计算，因此此时的C_&#123;12&#125;、C8C_8C8​、C4C_4C4​的不是并行产生的，因此我们可以再次提速，也就是计算机组成原理所讲的多级先行进位： 具体的讲解间计算机组成原理。 我们也尝试使用SystemVerilog HDL对多位加法器CPA进行建模，HDL提供了+运算符来描述多位加法器的CPA。EDA工具在满足速度要求的前提下会自动的从众多可能实现的方法中选择成本最低(逻辑门最少)的设计，因此我们只需要直接写出逻辑表达式即可，具体的哪一种计算组成形式由HDL来决定。下面是一个有进位输入/输出的CPA： 减法器 实际上减法只是特殊一点的加法而已，参考这篇《定点数的减法运算》以后我们知道减法运算实际上最终还是转换成了加法运算。即减法运算可以表示为 [A−B]补=[A]补+[−B]补=[A]补+[B]补‾+1[A-B]_补=[A]_补+[-B]_补=[A]_补+\\overline{[B]_补}+1 [A−B]补​=[A]补​+[−B]补​=[A]补​+[B]补​​+1 所以减法器就是对补码进行一定的转换以后调用加法器： 在计算机中所有的数据都用补码表示，因此计算机中是没有减法器的，加法和减法都是通过加法器实现，如下图： 当sub为0时，那么就是A+B，因此执行a+b,当sub为1时我们观察上图可以看出B走左侧的线路，他先经过了一个取反加一的过程，然后再和A相加，也就是a+~b+1实际上实现的就是减法运算，之所以b要取反加一是因为此时要从正数补码转化为负数补码。 比较器 比较器是判断两个N位二进制数A和B是否相等，或者一个比另一个大还是小，常见的有两种类型： 相等比较器，产生一个输出，表示A是否等于B（A==B) 数值比较器，产生一个或多个输出，表示A和B的关系（&gt;,&lt;)。 如下图： 我们同样可以使用SystemVerilog进行建模： 算术逻辑单元 算术逻辑单元是将各种算术和逻辑运算组合到一个单元模块中，典型的ALU算术逻辑单元可以执行加法、减法、量值比较、逻辑运算等，ALU是大多数计算机的核心。 F是三位，可以表示8中可能的运算方式，但是实际上011是没有用到的。这里我们给出ALU的模型图： 移位器和循环移位器 这部分内容实际上计算机系统基础也讲过，这里作为复习。我们主要是了解各种移位运算的方式： 逻辑移位器 将数据向左（LSL）或向右（LSR）移动指定位数，空出的位置补0。 11001&gt;&gt;2=00110 11001&lt;&lt;2=00100 算术移位器 算术左移（ASL）和LSL相同，算术右移（ASR）时使用数据的最高位(符号位)填充空位 11001&gt;&gt;2=11110 11001&lt;&lt;2=00100 循环移位器 循环移动数据，从一端移走位重新填充到另一端的空位上。 11001 ROR 2=01110 11001 ROL 2=00111 这里实际上也可以使用SystemVerilog HDL进行建模，N位移位器可以用N个N:1复用器构成： 左移时乘法一个特例，即A&lt;&lt;N=A*2N2^N2N 00001&lt;&lt;2=00100(1*222^222=4) 11101&lt;&lt;2=10100(-3*222^222=-12) 当然如果左移位数太多会造成溢出。 算术右移是除法的一个特例，即A&gt;&gt;N=A÷2N2^N2N 01000&gt;&gt;2=00010(8/222^222=2) 10000&gt;&gt;2=11100(-16/222^222=-4) 注意对于左移包含了算术左移和逻辑右移都是表示乘2，但是对于右移只有算术右移表示除以2的运算。 乘法和除法的具体运算实现请参考《定点数的乘法和除法》。估计太难，也不会考，这里给出乘法器的模型图： 他的SystemVerilog HDL建模的代码为："},{"title":"建模方法拓展与测试","path":"/wiki/数字逻辑与数字系统笔记/建模方法拓展与测试/index.html","content":"结构化建模 结构化建模也称为层次化建模，特点是将一个比较复杂的数字逻辑电路划分为多个子模块，再分别为每一个子模块建模，然后将这些子模块组合在一起，完成所需要的电路。因此，结构化建模描述了一个模块是怎样由简单的模块组成的。 其中根据建模的过程分为自顶向下的设计和自底向上的设计，两者只是在模块构建逻辑上有所差异，但是最终达到的效果是一样的。 我们以一道例题体会一下结构建模，比如我们要将3个2-1多路选择器组合成一个4-1多路选择器。我们可以轻易写出2-1多路选择器的建模形式： 因此接下来我们只是需要用适当的方式自底向上组成4-1多路选择器。因此在4-1多路选择器的建模过程中需要引入二路选择器的实例组件。假设我们现在已经得到了4-1多路选择器的结构图如下： 思路很简单，sel[0]用来决定lowmux和highmux的两个二路选择器的选择信号，sel[1]充当finalmux的选择信号。因此lowmux和highmux分别都有2种可能输出的信号，而finalmux又决定了选择lowmux或者highmux的其中一个输出信号，因此又有2中选择，因此一共有2*2=4可能选择的情况，刚好和4路选择器的功能一致。接下来我们只需要根据上图进行建模了： 123456789module mux4(input logic D0,D1,D2,D3,input logic [1:0]s,output logic y);\tlogic low,high; //使用2路选择器模块进行实例化\tmux2 lowmux(D0,D1,s[0],low);\tmux2 highmux(D2,D3,s[0],high);\tmux2 finalmux(low,high,s[1],y);\tendmodule 我们发现实际上结构化建模和java的类的使用很相似，就是使用已经建模完成的模块来组装更加高层次复杂的结构化模块。 模块实例化 在结构化建模中，父模块对子模块的调用通过模块实例化实现，其格式如下： 1模块名 实例化名 （信号列表） 模块名：定义子模块时，紧跟在module关键字后面的名字，例如上例中的mux2 实例化名：父模块为所调用的子模块命名的名称，是该子模块的唯一标识，例如上例中的lowmux,highmux和finalmux 信号列表：父模块与子模块之间端口信号的关联方是，用于实现子模块与父模块的通信。通常有位置关联法和名称关联法。 位置关联法就是我们通常上理解的使用函数是传参的格式，即实例化模块时，按照子模块定义时端口出现的顺序建立端口的连接关系。例如： 123//mux2定义的形式module mux2(input logic D0,D1,intput logic [1:0]s,output logic y);mux2 lowmux(D0,D1,sel[0],low) 那么D0就是mux2模块的第一个形参关联的端口参数，D1就是第二个。 但是由于在建模时可能一个模块有多达数十个端口信号，那么此时在使用位置关联法就很容易出现错误，因此还有一种名称关联法，就是实例化子模块时，直接通过名称显式建立子模块端口的连接关系，不考虑排列顺序（注意，此时所有的参数又要显式的声明和一个形参绑定）。如： 12345//mux2定义的形式module mux2(input logic D0,D1,intput logic [1:0]s,output logic y);//实例化一个mux2//注意实参写在形参后面的小括号后面 mux2 lowmux(.D0(D0),.D1(D1),sel(.sel[0]),y(.low)); 此时就与位置无关了，因为每一个实参端口信号都显式的和一个形参端口信号建立了连接。这种方法适用于端口信号很多的模块实例化中。 一定要注意对于名称关联法，形参在外，括号内是传进来的实参信号，同时形参前面有一个.。 接下来我们以mux4的两种实例化方法直接对比： 门级建模 门级建模是一种低层次的结构化建模方法，他通过调用SystemVerilog HDL提供的基本逻辑元件描述他们之间的连接，建立数字逻辑电路的模型。 门级建模可以理解为将逻辑电路图转化为SystemVerilog HDL描述的建模过程。门级建模只能用于描述组合逻辑电路，不能用来描述复杂的时序逻辑电路，这是因为门级建模使用的都是逻辑门元件。因此门级建模实例化的语句：‘ 1门级元件名&lt;实例名&gt;(端口列表) 其中实例名可以忽略不写，即为一个匿名门元件实例。一般常用到的门级元件有： 假设我们现在要使用门级建模构造一个mux2二路选择器，那么根据下面的图 我们可以建模: 1234567module mux2(input logic D0,D1,sel,output logic y)\tlogic a,b,sel_inv;\tnot N1(sel_inv,sel);\tand N2(a,D0,sel_inv);\tand N3(b,D1,sel);\tor(y,a,b);//注意实例名可以忽略endmodule 结构化建模总结 模块只能以实例化的方式嵌套在其他模块中（和java的外部类的实例化引用思路一样），嵌套层次是没有限制的，但是不能在一个模块内部使用关键词module和endmodule取定义另一个模块，也不能再always语句内部引用子模块。 实例化的子模块可以是一个在SystemVerilog文件中定义好的模块，或者是用别的HDL语言（例如Verilog,VHDL)设计的模块，还可以是IP（Intellectual Property,知识产权)核模块。 在一条实例化子模块的语句中，不能一部分端口用位置关联，另一部分用名称关联，即不能混用这两种方式建立端口之间的链接。 原则上在一个模块中可以使用行为建模和结构化建模，但是为了便于设计层次化、模块化，建议在一个模块中不要混用两种建模方式。 参数化建模 在SystemVerilog HDL中，参数化建模是指使用关键字“parameter&quot;声明一个标识符来代表一个常量，程序中凡是出现这个常量的位置，都可以用这个标识符来代替，从而大大增加了设计的灵活度和程序的可读性。参数化建模最常见的用法就是参数化建模，如下图： 左边的模块中定义了字符&quot;#&quot;同时声明为WITH代表位宽8，那么所有的[WIDTH-1:0]代表的都是一个位宽为8的线信号量，当我们需要修改时只需要修改定义语句即可完成对全部模块的相对应的位宽信号的修改。我们再看中间的模块和右侧模块定义的都是一个4路选择器，只是中间定义的是位宽为8的信号，那么当我们需要修改为32位宽时，只能手动逐一的对每一个[7:0]进行修改为[31:0]，这很麻烦耗时，而右侧的使用了参数化建模，所有的#只要定义为32位宽即可完成所有的信号的位宽更新，这就是参数化建模的优点。 我们可以将parameter语句置于模块内部，与参数化建模的区别是对模块化实例化时无法修改该参数的值。并且通过预编译指令`define(即宏定义指令)可以声明一个标识符来代表一个常量，通常位于模块外部，该常量是一个全局常量，其作用范围是从定义起点到整个程序的结束，既可以对多个文件起作用。这样parameter只能决定一个模块自身内部的信号的更新，而`define指令定义的是对多个模块起修改作用的全部常量语句，两者搭配，可以高效的完成所有文件的信号的更新操作。如下： parameter语句只对mux2内部的信号量起作用，而通过`define指令声明的WIDTH可以修改所有文件的信号位宽。同时要注意宏定义指令结尾处不需要分号。 generate语句 generate语句（即生成语句）可以动态的生成SystemVerilog HDL代码，可以大大简化程序的编写过程。generate语句结合参数化建模方法可以生成可变数量的硬件，此外，generate语句还可用于对向量信号中的多个位进行重复操作，或者对一个模块进行多次实例化，或者根据参数的定义来确定程序中是否应该包含某段SystemVerilog代码。 generate语句通过“generate…endgenerate&quot;来确定生成的代码范围，可以动态生成模块（实例化）、持续赋值语句（assign)、always过程块等内容。通常generate语句还可以和for,if和case语句组合使用。 如下图是generate生成一个由多个2路选择器组成的N路选择器的模块： 这里的几个注意事项见上图。 思考：为什么要用generate语句来包裹而不是直接调用for语句？ 在建模过程中，我们通常定义一个变量时都是定义为信号量，并且这个信号量是一个具体的确定值，但是我们分析上面的代码实际上x并不是一个信号量，他是一个由i决定的若干个信号量的一个抽象表示。具体生成多少个x信号量以及对于第i个信号量x的定义都需要由i来决定。同时a信号量也会再generate语句中多次使用表示不同的值。因此generate语句的引入是有必要的，当我们不使用generate语句包裹时，那么如果想创建10000个类似于x的相同作用的信号量，那么首先需要构建10000个不同名的信号变量值，这显然不现实。 SystemVerilog的测试程序 前面我们简单学习过仿真验证的概念，他是在线平台上通过模拟来对一个为构建的组合逻辑电路模块进行建模检测，查看是否完美符合预期功能。 电路验证是确认所设计的电路功能正确性的过程，而仿真是进行电路验证的主要手段，它可以及早发现所存在的设计问题，从而降低了设计风险，节约了设计成本。通常，仿真是通过编写测试程序完成的，测试程序也称为测试台，他是用于测试待测模块功能是否正确的一端SystemVerilog HDL代码，是不可综合的，由激励信号、DUT和输出响应三部分组成。 思考：什么是综合？ 综合是真正在组件一个模块元件时所必要的完成功能构建的语句。不可综合的语句一般是不用于完成元件功能的语句，在最终制造阶段舍弃，例如验证语句虽然在构建模块时进行编写，但是在测试完成后构建元件时，这部分代码不会被综合，不参与最终元件的功能实现中。 我们看一个测试程序的例子： 上面的代码就是用于验证的测试代码，它是用来测试一个数学计算模块是否正确的语句： 我们从上面的例子中不难看出我们分别测试的激励信号组合分别是： 也就是说每一次在验证时输入的信号是持续的，当改变信号时，只需要输入需要被修改的信号值即可，未被修改的信号是维持不变的。如上面的第一组激励信号测试组合为a=0,b=0,c=0并且持续时间为10个单位时间，然后我们修改了c的信号值为1，因此第二个激励信号组合为a=0,b=0,c=1并且测试时间也是10个单位长度。因为每一个激励信号的测试时间都是10个单位长度，因此最终屏幕上的输出脉冲为等宽。 测试程序的语句 首先我们可以总结出测试程序的模板如下： 123456module testbench_name //testbench为顶层模块，不会被其他模块实例化，因此不需要任何端口 //信号定义 //模块实例化，很重要，我们需要实例化一个待测模块 //添加激励信号 //显示输出结果（可以不添加任何显示打印语句，那么只生成波形图）endmodule 施加激励信号 在SystemVerilog中，施加激励就是想DUT添加输入信号（即测试向量），主要由三种方法： 通过initial过程过施加（线性）激励 通过always过程块施加（循环）激励，主要用于产生时钟信号（后面有一章专门介绍，这里不细讲）。 通过文件施加激励（比较人性化） 首先，通过initial块施加激励就和上图的那个例子一样，每一个仿真时刻只用列出需要改变的信号值，initial只执行一次改变语句。在一个测试程序中可以包含多个initial块，并且他们都是同时并行执行。 需要注意同一个initial块中的激励信号语句是串行执行的，initial块中的激励信号语句是并行执行的，并且在同一个仿真时刻避免为同一个信号赋予不同的信号值，否则将会冲突。 当通过文件施加激励时，只需要将激励（测试向量）存放在一个文本文件中，测试程序从文件中读取激励，对DUT进行测试。 这种方式更加高效，可以预先存储上万个不同的测试样例，测试验证时只需导入测试文件即可。 输出响应 在SystemVerilog中，输出响应是指在向DUT施加激励以后，通过观察DUT输出结果，并与预期结果进行比较，以验证电路是否正确。这个过程可以通过直接观测波形图或者借助SystemVerilog HDL提供的一系列系统任务显示输出结构来实现。毕竟有时候看图不好发现错误，那么可以打印输出信息。 在SystemVerilog中常用的系统任务包括： 系统任务 方法 获取仿真时间 $time，$stime,$realtime 显示信号值 $display,$monitor(常用) 结束/中断仿真 $finish,$stop 文件输入 $readmemb,$readmemh,$fopen,$fclose,$fdisplay,$fmonitor 文件输出 $fopen,$fclose,$fdisplay,$fmonitor 获取仿真时间的系统任务的返回值使用由`timescale宏定义指令声明的时间为单位时间，只是$time返回的是一个64位整数时间值，$stime返回的是32位整数时间值，$realtime返回的是一个实数时间值。例如： 1$monitor($time,&quot;a=%b b=%b c=%b y=%b&quot;,a,b,c,y); 一定要注意$time和$stime是会取整的，因此不是精确值，而$realtime返回的才是实数准确时间值。 对于显示信号值的系统任务$display和$monitor，相当有C中的printf函数，输出变量的值显示在控制台上，语法格式为 12$display($time,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$monitor($time,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;); 显示格式控制符有： %h %o %d %b %c %s %t %m 16进制 8进制 10进制 2进制 ASCII 字符串 时间 模块名 例如： $display和$monitor的区别在于前者只有执行到该语句时才进行显示操作，而后者就像一个监视器，只要输出变量列表中的某个变量发生变化，就执行一次显示操作，后者更加方便实用。 结束/中断仿真的系统任务包括：$finish和$stop两种，其格式如下： 1234$finish();$finish(n);$stop();$stop(n); 其中参数n可以取0,1等值，0表示不输出任何信息，1表示给出仿真时间。 在SystemVerilog HDL中文件输入不需要打开文件操作，直接读取文件即可，也有$readmemb和$readmemh两种，其中前者读取2进制数据，后者读取16进制数据，语法格式如下： 12$readmemb(&quot;数据文件名&quot;,数组(存储器)名,&lt;起始地址&gt;,&lt;结束地址&gt;);$readmemh(&quot;数据文件名&quot;,数据(存储器)名，&lt;起始地址&gt;,&lt;结束地址&gt;); 其中起始地址和结束地址也可以缺省。并且输入文件格式有以下细节： 可以使用&quot;_&quot;提高数据的可读性 可以包含单行或者多行注释 可以使用空格或者换行来区分单个数据 可以设定一个特定地质，规定其后的数据从该地址开始存储。地址必须是16进制，且不区分大小写，并且@和地址之间不允许有空格，即 1地址写法：@hex_addr 假设现在有一个输入文件如下： 现在我们打开这个文件： 那么最终我们读取文件到stim数组的地址数据如下图： 也就是前三个地址是连续的，然后从3-255是空缺的没有地址，然后从256（十六进制的@100）有一个单独的地址数据为1111_1100，然后257-1022又是空缺的，到达1023时再继续存储定义的地址。 文件输出操作需要首先用系统任务$fopen打开文件，然后通过系统任务$fdisplay和$fmonitor将需要的保存的信息输入到指定文件中。 例如现在要打开一个MCD文件： 12345int MCD;MCD=$fopen(&quot;文件名&quot;,&quot;操作模式&quot;);$fdisplay(MCD,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$fmonitor(MCD,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$fclose(MCD);//一定要记住关闭文件呀 $fopen是打开指定文件并且返回一个32位整数，如果打开失败了则返回0，操作模式为w,w+,a,a+。$fclose是关闭打开的文件，而$display和$fmonitor的用法与$display和$monitor的用法类似，区别在于不是将输出响应输出到控制台，而是将信息输出到文件中。 自动化测试 我们思考一下无论上面的那种测试方法，最终我们还是需要自己去对比输出结果是否正确，这对于上万个输出响应的测试程序来说，人工复查太难了，因此我们需要机器来自动帮助我们比对判断输出响应是否正确，因此就产生了自动化测试。 实际上自动化测试的过程和仿真验证类似，只是多了一步自动将输出响应和预期结果比对的过程。具体的写法见上图。 测试程序总结 测试程序由激励信号、待测模块DUT和输出响应三部分组成，其本身也是一个SystemVerilog代码(这很重要，需牢记)。并且是最顶层的模块，当没有端口，不可综合。 由于测试程序不会变为电路，因此在测试程序中可以使用所有的SystemVerilog语句。 为了便于复用和管理，测试程序可以通过文件施加激励。 进行验证时，尽量采用自动化对比方式，毕竟人工复查还是容易出错。 虽然观察波形图寻找错误开始时比较困难，但是习惯以后发现波形图能够帮助我们发现那些控制台输出不易察觉的问题。 以上的测试程序本质上都是对使用SystemVerilog HDL所编写的程序进行仿真测试，并没有考虑门延迟，线延迟等问题，因此也称为行为仿真或者前仿真，虽然行为仿真可以发现很多设计问题，但是并不意味着通过了行为仿真电路就一定没有问题了，后面还是需要进行大量的测试的。"},{"title":"时序逻辑电路","path":"/wiki/数字逻辑与数字系统笔记/时序逻辑电路/index.html","content":"时序逻辑电路 时序逻辑电路的输出由当前时刻的输入和之前时刻的输入共同决定的逻辑电路。也就是说时序逻辑电路内部具有记忆性。其中时序逻辑电路有以下概念： 状态：用于解释电路未来所需要的信息 锁存器和触发器：用于存储1比特状态的模块 同步时序逻辑电路：一类由组合逻辑电路和一组电路状态的触发器所构成的电路 思考:时序逻辑电路的特征？ 时序逻辑电路是按照一定输入和输出时序实现的功能电路模块，它具有记忆性，并且输出与输入之间具有反馈电路，如下图： 时序逻辑电路和组合逻辑电路最大的一个区别就是组合逻辑电路输入和输出之间没有反馈回路，即输出永远只能受输入影响。而在时序逻辑电路中输入和输出之间是可以有反馈电路的，这也就是说明在时序逻辑电路中，输出信号反过来是可以影响输入信号的。 存储电路状态的模块 电路中的状态会影响电路未来的行为，而下面是一些常见的可以存储电路状态的模块： 双稳态电路 SR锁存器 D锁存器 D触发器 我们可以理解为触发器是锁存器的一个改良模块。那么接下来我们分别来详细了解一下各个存储电路状态的模块的具体功能实现。 双稳态电路（bistable) 首先双稳态电路是其他存储模块的基础，其他的存储电路状态的模块都是根据双稳态电路衍生而来的。如下图是常见的双稳态电路图： 我们可以看出双稳态电路有以下几个特点： 对称性：即电路总是对称的，有一个对称轴，对称轴两侧的电路元件相同 有两个输出：Q和非Q 没有输入 我们分析一下双稳态电路是如何稳定存储电路的1比特状态的。首先我们知道电路理论上只有两种状态即1和0，因此我们想要Q和非Q可以稳定存储这两个状态。那么假设此时Q存储的是0，那么很明显非Q可以很稳定的存储1，并且反过来他又会影响Q的输入从而维持Q稳定存储0状态，因此两者相互影响从而实现稳定存储电路的0和1两个状态。同样的，假设Q存储的是1，那么不难看出此时非Q也会稳定存储0状态。 因此双稳态电路可以稳定存储电路的0和1两种状态。但是我们发现双稳态电路存在一个缺陷，即改电路没有输入端，因此我们无法认为的控制电路中状态的存储，也就是说当一个双稳态电路模块在制作完成后就已经确定了两个输出端存储的电路状态了不能再改变，这很不好。 SR锁存器（Latch) 为了解决双稳态电路的这一缺陷，因此改良产生了SR锁存器，如下图： 此时就是在双稳态电路中加入了R和S两个输入端，同时门元件换成了或非门，因此在SR锁存器中： 总是存在两个输入端用来输入激励信号 两个输出端用来输出存储的电路状态 此时我们同样分析一下SR锁存器的功能实现，我们发现有以下四个不同的状态。 状态一：置位（SET） 当S=1,R=0时，那么此时SR锁存器的状态稳定为： 即Q永远存储的是1，而非Q永远存储的是0，此时这种状态我们称之为置位。 状态二：复位（RESET） 当S=0,R=1时，那么，此时SR锁存器的状态稳定为： 即Q永远存储的是0，而非Q永远存储的是1，此时这种状态我们称之为复位。 我们形象的记忆：首先SR锁存器的这两种状态输入端和对应的输出端信号状态总是相反的，同时S=1（SET=1)是置位，R=1（RESET=1)是复位。 状态三：保持态 当S=R=0时，那么次此时我们既没有置位，也没有复位，此时Q和非Q的值会保持之前的状态。我们先看一下保持态的图： 我们不难看出当S=0,R=0时，上面的Q和非Q的两种状态是都有可能出现的，那么何时出现的是左侧的图，何时出现的是右侧的电路状态呢？这取决于在保持态出现之前的状态，加入，保持态出现之前是置位态，那么切换到保持态时就会稳定成右侧的状态图，若保持态出现之前是复位态，那么切换到保持态后就会维持成左侧的状态图。因此保持态实际上就是时序逻辑电路中最能体现具有记忆性特点的状态。 状态四：非稳态 这种情况一般出现在S=R=1时出现，他是一种非稳态会导致输出端出现随机的状态，因此一般是避免的： 我们发现虽然S=R=1时确实电路状态维持成了Q=非Q=1的状态，当时当切换成其他状态时就会出现Q和非Q不可预测的情况。因此这种状态称为非稳态，他并不是指自身不能稳定，而是值切换到其他状态时会导致不稳定的输出状态，因此称为非稳态，一般我们要避免这种情况出现。 四个状态总结 SR锁存器是一个基于双稳态电路衍生改良出现的可以存储1比特电路状态的功能模块，其中两个输入端S表示置位（Set)，R表示复位（Reset) 通过控制S和R的信号输入，我们可以控制切换SR锁存器的输出稳定状态（这是比双稳态电路优秀的地方）： Set置位:S=1,R=0-&gt;Q=1 Reset复位：R=1,S=0-&gt;Q=0 保持：S=R=0-&gt;使Q和非Q维持保持态之前的状态 非稳态：S=R=1，禁止出现 上图是一个SR锁存器的状态波形图，他展示了输入不同的激励信号S和R后产生的状态切换过程。我们可以假设一开始初始状态为0，那么初始时S=R=0，也就是保持态，因此Q维持为初始态0，当S=1时，此时R=0，切换成为了置位态，因此Q变成了1，然后S又变成了0，那么此时又处于S=R=0的保持态，但是此时保持态会维持之前的置位态的输出，因此此时Q=1，然后R=1，此时S=0因此切换成了复位态，因此Q复位成0，然后R又变成了0，此时S=R=0，因此电路又变成了保持态，因此Q又维持复位态的输出，即Q=0。我们从上面的过程可以直观的感受到SR锁存器的强大的存储状态的功能，同时我们还可以看到上面的过程中总是保证了S和R只有一个为高电平，从而避免了非稳态的出现。 D锁存器 D锁存器同样是一种可以存储电路状态的功能模块，他的电路符号如下图: D锁存器的特点是包含了两个输入端CLK和D，CLK控制存储器状态发生改变的时间，D是数据输入端，控制下一个状态的值。 实际上CLK可以更加形象的理解为使能端，当CLK=1时，那么Q跟随输入端D随时变化，即D锁存器此时可以看成是透明不存在的，此时就是一个组合逻辑电路的特点，输出随时跟随输入端变化， 但是当CLK=0时，那么Q就维持之前的状态，即类似于SR锁存器的保持态，此时输出端并不会跟随D改变，因此体现了“锁存”的特点，是时序逻辑电路具有记忆性特点的体现。其具体的功能实现： 我们不难看出实际上D锁存器是在SR锁存器的基础上进行改良的版本，他的主要优点是即实现了与SR锁存器相同的置位、复位、保持功能，同时还避免了非稳态的出现，更加安全。也就是此时D锁存器只有三个状态，没有了非稳态： 注意此时D同时实现了复位和置位两种状态，当D=1时实现的是与SR锁存器相同的置位功能，D=0时实现的就是与SR锁存器相同的复位功能，而CLK主要是用来切换保持态的。 我们同样可以分析一下他的波形图： 如上图，初始时CLK为0，因此此时是保持态，Q保持为初始态0，因此当D升为1以后由于此时CLK=0，因此是保持态，Q不会跟随D发生变化，当CLK变成1以后，D同时为1时，Q才会跟着变成1信号。 D触发器（Flip-flop) D触发器实际上并没有相较于D锁存器有什么改进，因为D锁存器已经很完美了，D触发器只是另一种不同的状态切换方式的模块。D触发器的电路符号如下图: 注意D触发器和D锁存器的电路符号的区别，D触发器多了个下三角符号。为了更加明显的区分两者，使用右侧的符号更好。 D触发器的特点是包含两个输入端CLK和D，实际上和D锁存器一样。 但是D触发器的功能即状态切换与D锁存器不太一样，首先D触发器同样是有三个状态。但是只有在CLK的上升沿才会对D进行采样，即只有当CLK的信号从0到1的瞬间过程，Q被修改为当前时刻D的值，其他时刻Q都处于保持状态。也就是说Q只会在CLK上沿的时刻可能发生信号值的改变。 主从式D触发器的实现电路如下图： 可以看到D触发器是通过两个D锁存器实现的。两个D锁存器L1和L2顺序串联，同时有一组相反的时钟信号所控制。 当CLK=0时 主锁存器L1是透明的 从锁存器L2是不透明的 因此N1跟随D发生变化，但是Q和非Q不会跟随N1变化 当CLK=1时 主锁存器L1是不透明的 从锁存器L2是透明的 从锁存器的状态跟随N1变化，即此时N1不跟随D变化，但是Q和非Q会跟随N1变化 因此一个完整的Q跟随D变化实际上是上面两个过程的结合体，也就是在时钟的上升沿（CLK从0-&gt;1）时刻，完成一次Q被D赋值的功能 同样的我们分析一下他的状态波形图： 起初CLK是0，因此是保持态，即Q（触发器）此时是初始态1，而当CLK处于第一次上升沿时由于此时D=0，而Q（触发器）处于1与D不同，因此Q（触发器）变成0，而Q（锁存器）同样也变成0是因为最终CLK会处于1状态，那么Q（锁存器）就可以更改Q跟随D取值。但是当CLK还保持为1的同时，D变成1的时候我们可以看到此时D触发器和D锁存器的输出端发生了不同的情况，对于Q（触发器）由于此时CLK=1，因此Q还可以跟随D变化，因此Q（锁存器）变成了与D相同的1状态，但是此时触发器由于CLK一直稳定为状态1而不是上升沿，因此此时Q（触发器）不发生变化还维持0。因此我们可以总结出D锁存器和D触发器还是有区别的，即D触发器中CLK=0或是CLK=1时都是保持态，这是和D触发器最大的不同。 寄存器 寄存器可以存储CPU暂时不需要的信息，那么寄存器是如何实现的呢？实际上一个N为寄存器就是由一个共享的CLK输入和N个D触发器组成的，如下图： 由于此时N个D触发器共享一个CLK，因此寄存器的N个D触发器肯定是同时更新数据的，并且只有在CLK处于上升沿的时候才能更新数据，寄存器的所有位同时被更新，这是大多数时序逻辑电路中的关键组件。 思考：为什么寄存器要设置成N个D触发器共享一个CLK？ 我们知道寄存器一般存储的是一个N为二进制数据，那么很明显这个数据是一次性存储到寄存器中的，因此数据的每一位同时存储到寄存器的一个D触发器当中。 带使能端的D触发器 实际上就是在D触发器的基础上有添加了一个使能端EN如下图： 使能端EN是用来控制D是否能被触发器存储的，此时功能是： EN=1时且在时钟上升沿时，Q才能被更新为当前D的值 EN=0时即使时钟处于上升沿，Q也不能更新为D的值 因此只是相较于D触发器又增加了一个条件使得Q更新为D值的条件更加苛刻了。 带复位功能的D触发器 我们思考一个问题，前面我们学习D触发器的时候，学习到D=0且CLK处于上升沿时可以将Q置位0，即类似于SR锁存器的复位功能，但是我们发现D触发器想实现这个功能条件过于严苛了，需要同时满足D=0且CLK处于上升沿，我们想改进为D=1时也可以对Q进行恢复为0的复位功能，此时就产生了带复位功能的D触发器。如下图： 此时Reset=1时，那么无论D是何值，都可以将Q强制设置为0，Reset=0是就是正常的D触发器，此时我们又可以将带复位功能的D触发器分类为同步复位和异步复位： 同步复位：只在CLK处于上升沿时可以进行复位 异步复位：只要Reset信号为1有效，那么无论CLK是否处于上升沿都可以进行复位 带置位功能的D触发器 同样的，我们也可以类比得到带置位功能的D触发器： 当Set=1时无论D取何值，Q都被强制设置为1，当Set=0时D触发器正常工作。同样的也有同步置位和异步置位的区分。 非稳态电路 非稳态电路是一种特殊的时序逻辑电路，他的特点是输出端不稳定，会发生周期性的翻转变化，如下图是一个非稳态电路： 此时这个电路是一个具有回路的，且输出端会反馈到输入端的时序逻辑电路，我们分析一下可以轻松的发现输出结果会发生周期性的翻转变化，即X,Y,Z不断的在0和1信号之间切换，此时他们的波形图是： 上面的这种非稳态电路可以应用为环形振荡器。 同步时序电路 对于上面的这种非稳态的时序逻辑电路，我们在信号传播的途径中插入寄存器来断开电路中的环路，此时就会使得电路变成一个组合逻辑电路和寄存器的集合体，也就是同步时序逻辑电路。他的特点是： 寄存器包含着系统的下一个要切换的状态 状态仅在时钟边沿（注意上升沿或者下降沿都可以）到达发生变化，也就是状态同步于时钟信号 如果时钟足够慢，使得在下一个时钟沿到达之前，输入到寄存器的信号都可以稳定下来，那么所有的冒险都将会被消除 一个同步时序电路包含一组有限的离散状态{S0,S1,…,Sk-1} 同步时序电路有一个时钟输入 上升沿表示电路状态转变发生的时间，其中涉及到两个状态 现态：当前系统的状态 次态：下一个时钟沿后系统将进入的状态 同步时序逻辑电路的功能主要是描述当前状态和输入的各种组合对应的下一个状态与输出的电路，他需要明确建立时间和保持时间。这样每隔一个CLK就会自动切换到下一个给定输入所对应的输出状态。组成一个同步时序逻辑电路需要满足以下规则： 电路中的模块或者是寄存器或者是组合逻辑电路 模块中应该至少包含一个寄存器 所有的寄存器都共用一个时钟信号 电路的每个环路中至少包含一个寄存器 其中常见的两个同步时序逻辑电路是有限状态机（FSM）和流水线 下面我们看一下一个最简单的同步时序逻辑电路模块： 一个D触发器本身实际上就是一个最简单的同步时序逻辑电路，它包含一个输入D，一个时钟信号CLK和一个输出Q，同时也具有两个离散的不同状态{0,1}，并且D触发器下一个状态就是D，Q就是当前状态,，而D触发器本身就是一个寄存器。 思考：下列哪些电路是同步时序电路？ 对于上面的CL符号表示逻辑电路，因此上面的这些电路模块中，只有4,5是同步时序电路，其他的模块之所以不是同步时序逻辑电路的原因是： 1：就是一个组合逻辑电路，肯定不是时序逻辑电路更不是同步时序逻辑电路 3：注意那个不是D触发器，而是D锁存器，所以不是 6：没有D触发器 7：如果三个clk是共享一个时钟沿那么就是同步时序逻辑，否则就不是 所以同步时序逻辑电路就是一个在组合逻辑电路基础上增加了记忆组件触发器的电路系统，并且还要求所有的触发器的时钟沿共享一个时钟输入。正式由于拥有了记忆组件D触发器，才能实现时序逻辑的当前输出由当前输入和以前输入共同决定的特点。 思考：时序逻辑电路到底有没有回路？ 都可以，有没有回路都是可以的，只是有回路时更加复杂，此时的时序逻辑电路不仅输出由当前输入与以前输入决定，而且当前输入也由当前的输入与之前的输出共同决定。只要有组合逻辑电路+D触发器那么就是一个时序逻辑电路。当所有clk共享一个时钟输入时就是同步时序逻辑电路，否则就是异步时序逻辑电路。 异步时序电路 非同步时序电路就是异步时序电路，很明显异步时序电路并不需要在特定的CLK变化沿时才可以切换电路状态，而是只要满足条件就可以切换。这种系统的时序不受时钟控制的寄存器所约束的异步时序电路实际上在实际应用中更加广泛。但是实际生活中，所有的系统本质上都是同步的，因为同步时序电路比异步时序电路更容易设计实现，最典型的就是CPU中切换线程时的RR（时间片轮转方法）。虽然不是最优情况，但是在最低的实现成本情况下可以实现较优的策略。"},{"title":"有限状态机","path":"/wiki/数字逻辑与数字系统笔记/有限状态机/index.html","content":"有限状态机的结构 有限状态机就是同步时序逻辑电路的最典型应用，因此有限状态机的结构实际上和同步时序逻辑电路的特点很类似： 即有限状态机有状态寄存器和组合逻辑电路两大组成部分，其中状态寄存器存储当前时刻的状态，并且状态在下一个有效时钟沿会发生改变，更新为次态的状态。而组合逻辑电路通常就是根据输入来计算次态，和根据现态计算出输出值。 有限状态机的分类 有限状态机有两大类，分别是Moore机和Mealy型有限状态机。两者的区别在于： Moore型有限状态机中，输出仅由当前状态所决定，而对于Mealy型状态机，输出由当前状态和输入共同决定。但是无论是哪种状态机，都属于同步时序逻辑电路。 状态机是一种很特殊的同步时序逻辑电路，他的特殊性就在于一定拥有一个回路连接着输入端与触发器的输出端，从而保证状态机的次态一定是由当前的输入以及之前的输出即之前的电路状态共同决定的。 Moore型有限状态机的应用 接下来我们用一到例题来详细学习Moore型有限状态机的应用和具体的工作原理。假设现在有一个十字路口，那么X轴方向的两个对立的红绿灯我们设置为La,Y轴方向的两个对立的红绿灯我们设置为Lb如下图： 那么很明显会存在两个输入即两个交通传感器Ta和Tb,当X轴上有小轿车等待时，那么Ta传感器返还true，即输入端Ta的值是1，否则为0。同理对于Y轴当有轿车等待时Tb为1否则为0。 同时有两个输出，即La和Lb红绿灯的颜色。 我们设置CLK周期为5s，因此每一个时钟沿到达时，灯会根据交通传感器来改变。同时还存在一个复位按键，可以使交通灯控制器回到初始状态。那么很明显有限状态器的寄存器黑盒视图如下： 这就是有限状态机的输入，输出的设置。接下来我们来分析一下有限状态机黑盒内部的具体状态转换结构是什么样子的。我们画出状态转换图如下图： 上面就是有限状态机根据不同的输入转换成不同的状态的循环图了。我们其实可以类比成计算机网络Rdt中的发送接收端的状态转换图，原理是类似的。此时： 图中的每一个圆圈代表一个状态 图中的每一个圆弧代表两个状态之间的转换 圆弧上的项表示实现状态所需要的输入 状态转换发生在时钟有效沿产生的时刻 Moore型状态机的状态转换图中，输出信息都是标在圆圈内部的，因此上图中的圆圈内部的La和Lb的颜色就是输出。 那么下面我们分析一下状态转换图是如何正确表示Moore型有限状态机的转换的： S0表示的是La绿灯，Lb红灯的情况，即X轴车可以通过十字路口，Y轴的车需要等待的情况。但是当输入端Ta不是1即非Ta是1的情况时，表示此时X轴没有车了，那么此时就从S0切换到S1即X轴的红绿灯La闪烁一段黄灯后继续转换到S2状态，即Y轴的车可以通过狮子路口，同时X轴的车需要排队。同理的，当Tb=0即Y轴没有车时，那么Lb闪烁一段黄灯以后，切换回到S0状态，即X轴绿灯。同时我们考虑到如下情况，可能Ta一直为1，表示X轴一直有车，那么此时X轴就要一直亮绿灯即S0圆圈右上角闭环的情况出现，同理，也会存在Y轴正在通车且Y轴一直有车的情况，那么此时就需要一直Lb亮绿灯也就是S2左下角闭环的情况。同时我们还要有一个复位Reset端来使得我们可以在任何时段强制恢复成S0的状态。自此我们发现上图的状态转换过程是正确的，可以表示出不同情况下十字路口的红绿灯状态。 因此我们根据上图的状态转换图可以总结出下图的状态真值表： 即根据不同的输入Ta和Tb以及现态来决定次态的情况。（这里的现态决定次态就是带有回路的同步时序逻辑特有的特点）我们可以总结出上图的表格，然后对状态进行编码，即使用若干个逻辑表达式来整理表示出次态和现态与输入的关系： 要注意，此时的中间的真值表的现态是有两位二进制码S1S0来表示的，这是因为状态转换一共有4个不同的状态，需要至少使用2位二进制码才能表示出来，因此此时00表示状态S0，01表示状态S1,10表示状态S2，11表示状态S3。同时次态很明显也会有4中状态，因此也是使用2位二进制编码表示。然后我们即可得到逻辑表达式： {S1′=S1⊕S0S0′=S1S0TA+S1S0TB\\begin{cases} S_1&#x27;=S_1⊕S_0\\\\ S_0&#x27;=S_1S_0T_A+S_1S_0T_B \\end{cases} {S1′​=S1​⊕S0​S0′​=S1​S0​TA​+S1​S0​TB​​ 这就是有限状态机根据输入端的输入值和现态来计算次态的公式。因此此时我们只得到了有限状态机前半部分用来计算次态的组合逻辑电路的表示式，接下来我们还要得到根据现态计算出输出的组合逻辑表达式。 我们知道此时由状态寄存器输出的现态有S1‘S0’表示,但是最终我们要得到的输出时La个Lb。因此可以根据S1‘S0’和状态转换图列出以下真值表： 即现态和输出的关系。由于La和Lb都有三种状态，因此需要使用2位二进制码才能表示出来，因此最终的输出并不是La和Lb两个输出端，而是4个输出端。如下图： 这就是一个完整的表示十字路口红绿灯的有限状态机的同步时序逻辑电路。我们发现有限状态机黑盒（也是状态寄存器）只是其中的核心部位，他还需要左右两侧的组合逻辑电路来根据输入计算次态，以及根据现态计算输出。因此有限状态机总是可以抽象为： 下面我们根据得到的状态机，可以实时的画出有限状态机的端时序图： Moore型有限状态机设计方法 我们根据上面的案例可以总结出Moore型有限状态机的设计方法一定是遵循以下步骤得到的： 根据问题进行抽象，确定输入和输出对应的逻辑含义 画出状态转换图 列出状态转换表 对状态进行编码，并列出次态计算方程 列出输出表 对输出进行编码，并列出输出的计算方程 绘制原理图 思考：上面的红绿灯设计是否存在缺陷？ 有一个明显的设计漏洞。我们思考易得，当此时处于S0状态，并且Ta一直为1即X轴正在通车且X轴一直有车的情况，那么根据我们列出的状态转换图，此时会一直处于S0状态，这明显不符合实际。因为Y轴方向的车不可能一直排队等待，而是现需要在经过一段时间后强制转换成Y轴通车即S2状态，即使此时X轴还有车。因此我们设计的红绿灯状态转换图是有缺陷的。 思考：此时如何修改来弥补缺陷？ 没办法在已经列出的状态装换图上进行修改，只能重构状态转换图来重新制作有限状态机的电路图。 状态编码 我们在上面的案例设计与实现中发现经常需要用到编码来抽象表示状态转换图，因此学习状态编码是很有必要的。首先我们要知道不同的状态编码和输出编码会产生不同的电路，因此需要在设计中一直使用一套标准的状态编码，例如个案例中00就表示S0状态，自此不能改变这个编码的意义。同时进行合理的编码，可以产生一个逻辑门更少且传播延迟更短的电路，因此我们在对状态进行编码时要选取合适的编码规则。最常用的两种编码规则就是二进制编码与独热码。 二进制码：4中状态：00,01,10,11 独热编码：实际上我们对此并不陌生，对于编码器实际上就是独热编码的应用。即状态的每一位（1bit)表示一种状态，任何时候都只有一位是’热’的(true或者1)，例如：0001,0010,0100,1000等。使用独热编码相较于二进制编码，更容易表示次态逻辑和输出逻辑表达式。 Mealy型状态机 我们前面讲到了Mealy型状态机，他和Moore型状态机最大的不同就是输出不仅仅由现态计算得出，还会受到输入端的影响（注意不是现态的影响）。 一定要区分输入输出和次态现态。输入和输出是时序电路最外层的接口，而次态和现态只是状态寄存器的输入和输出。次态需要用输入经过组合逻辑计算后才能得到，而输出需要用次态（或者次态+输入端）经过组合逻辑计算后才能得到。 现在我们还是以一道案例来学习： 举一个形象的例子，假设现在有一串二进制码100101100,假设蜗牛每次走过位需要1s,那么这个蜗牛会在4s和6s时对我们微笑。现在我们需要设计有限状态机来表示。 我们先使用Moore型状态转换图来分析： 很明显状态转换图如上图形式，S0是未记住任何一位时的状态即不笑的状态，而S1是已经经过了一个0位时的状态即马上要笑的状态，而S2就是刚好经过的最后两位是01的状态即笑的状态。那么未出发时或者刚刚走过01时处于S0状态，当向后走了一位后得到一个0时，那么就到达S1状态，只要再在下一步经过1就能够微笑即转换为S2状态。但是假设S1时又经过一个0，那么就还处于S1状态，即S1状态左下角闭环的情况。同样的当S0状态经过了一个1，那么仍然处于S0状态，即右上角闭环情况。当处于S2状态并且下一位是1时那么就换成S0状态，否则是0就转换成S1状态。我们分析一下蜗牛走100101100时每一位的状态应该是S0-&gt;S0(1)-&gt;S1(0)-&gt;S1(0)-&gt;S2(1)-&gt;S1(0)-&gt;S2(1)-&gt;S0(1)-&gt;S1(0)-&gt;S1(0)。因此上面的状态转换时逻辑正确的，接下来按照之前所讲的步骤即可得到Moore型有限状态机的电路图，这里就不给出具体过程了。 我们接下来尝试使用Mealy型状态转换图表示，由于Mealy型状态转换机的现态同时受次态和输入决定，因此只会存在马上要笑和不笑的两个状态，而不会存在马上要笑的状态，即状态会更少，如下图： 此时S0表示未记住任何一位时的状态即不笑的状态，因此当处于S0并且接收到输入时0时就已经可以判断出输出是不笑即0了，然后转换到S1马上要笑的状态，当S1状态时得到输入为0，那么仍保持在S1状态，否则就笑输出1然后转换到S0状态。我们发现此时和Moore型状态转换图的逻辑是一样的，只是此时的表示更加简洁，少了一个状态图相应的也就降低了电路的复杂度。 思考：Mealy型状态转换相较于Moore型转换在哪里更加简单了？ 究其原因，两者的状态切换和输出存在差异，对于Moore型状态转换，是先进性状态切换再输出，这是因为Moore型状态机中，输出总是需要等待现态切换成次态以后才能计算得到。而对于Mealy型状态机状态切换和输出是同时执行的，因为输出可以提前得到输入来进行计算。因此Mealy型状态转换图中输出是在圆弧上，而Moore型输出是在状态圈中。 接下来我们同样得到状态转换真值表： 我们发先Mealy型的状态转化表更加简单，因为只有两个状态，所以编码只需要使用一位。最终我们可以得到Mealy型状态转换机的电路图： 我们发现Mealy型状态转换机电路图更加简洁，但是实际上实现的逻辑功能和Moore型没有差别。最终我们同样给出Mealy型状态机时序图： 我们发现对于同样的输出Y的变化，由于Mealy型状态更少，因此中间的状态转换过程也更少，因此Mealy型Y的变化整体比Moore型要快。 Mealy型有限状态机设计方法 我们同样给出Mealy型有限状态机的设计步骤： 根据问题抽进行象，确定输入输出以及对应的逻辑含义 画出状态转换图 列出状态转换表和输出表（可以同时列出，原因是输出可提前得到输入因此状态转换的计算和输出的计算可以同时进行） 对状态和输出进行编码，并列出次态方程和输出方程 绘制原理图 Moore型状态机和Mealy型状态机的总结"},{"title":"行为建模","path":"/wiki/数字逻辑与数字系统笔记/行为建模/index.html","content":"在SystemVerilog HDL中，行为建模是指将数字逻辑电路的功能以较高的抽象形式描述出来，他通过输入和输出之间的因果关系直接建立电路模型，行为建模包括两种描述风格： 基于持续赋值语句（assign）的建模 基于过程块（always和initial）的建模 基于过程块语句的建模相比基于持续赋值语句的建模具有更高的抽象层次，编程也更加便捷。 基于持续赋值语句的建模 基于持续赋值语句的建模是指根据信号量之间的逻辑关系，采用持续赋值语句（assign）描述数字逻辑电路的方式，也称为数据流建模，其使用方法如下： 1assign &lt;#延迟量&gt; 信号名=逻辑表达式//&lt;#延迟量&gt;可以缺省 比如： 1234logic [3:0]out1,out2,A,B;assign out1=A+B;//经过5个单位时间延迟后赋值给out2assign #5 out2=~(A&amp;B); 我们注意到行为建模语句主要是基于已经定义的变量，来定义输入变量和输出变量之间的某种关系，即为行为建模。基于持续赋值语句的建模的特点是只要“=”右侧表达式中的任意变量发生变化，那么这个表达式就会立即重新计算并赋值给左边的变量。如果定义了延迟量，那么赋值将在相应的单位时间内（默认为纳秒，ns）后再完成。 一定要注意延迟量主要用于仿真，是不可以综合的。 并且持续赋值语句左侧可以是变量类型（如logic)的信号，也可以是线网类型（如tri）信号，也可以是信号的拼接形式。对于持续赋值语句，任何输入的变化都会立即影响输出结果，体现了组合逻辑电路的特征，即变化瞬时性，因此，基于持续赋值语句的建模只能用来描绘组合逻辑电路。而且基于持续赋值语句的建模方式提供了使用逻辑表达式描述电路的一种方式，不必考虑电路的组成结构以及元组之间的连接。 刚刚上面我们已经给出了基于持续赋值语句的建模例子了，建模语句主要是用来描述信号之间的行为关系，下面我们给出基于持续赋值语句的建模模板： 12345678910module 模块名 (端口列表);\t//中间变量声明\tlogic 信号1，信号2... //逻辑功能定义\tassign 赋值语句1;\tassign 赋值语句2;\t...\tassign 赋值语句n;endmodule 下面我们以一道例题来讲解如何进行基于赋值语句的建模，我们这里以译码器为例，我们前面学习过译码器是根据接收的信号所组成的编号，从而让特定的输出信号输出高电平真值。比如2线-4线译码器： 我们可以根据真值表列出不同信号取真值的表达式（简单的当然也可以使用卡诺图进行简化），然后定义译码器模块来进行建模： 123456789module dec2to4(input EN,A,output Y);\tlogic EN;\tlogic [1:0] A;\tlogic [3:0] Y;\tassign Y[0]=EN&amp;~A[1]~A[0];\tassign Y[1]=EN&amp;~A[1]&amp;A[0];\tassign Y[2]=EN&amp;A[1]&amp;~A[0];\tassign Y[3]=EN&amp;A[1]&amp;A[0];endmodule 当然我们还可以通过这个方法来实现机组原理中讲到的一位全加器： 他的建模语言代码如下： 1234567module fulladder(A,B,cin,sum,cout);\tinput logic A,B,cin;\toutput logic sum,cout; assign sum=A^B^cin;\tassign cout=(A^B)&amp;cin;endmodule 如果我们在基于持续赋值建模中的代码中使用了延迟量，那么虽然最后得到的电路完全相同，但是在仿真综合时是会出现不同的结果的，我们前面学习了最终仿真综合平台的结果会以脉冲的形式显示在图上，那么当增加了延迟后，脉冲出现的时间就会发生改变，如下： 未加延迟量的结果： 增加了延迟量的结果： 基于过程块的建模 前面我们介绍了基于持续赋值语句的建模方式，接下来我们来学习一下另一种建模方式–基于过程块的建模。基于过程块的建模关注数字逻辑电路输入输出的因果关系（行为特性），即在何种输入条件下，产生何种输出（即完成什么操作），并不关注电路的内部结构细节。这种建模适用于规模庞大、复杂的电路设计，配合EDA工具，构成了现代超大规模集成电路（VISI）的设计基础。 基于过程块的建模使用关键字initial和always定义，通过块标识符begin…end（相当于大括号）包围起来的过程块对电路进行描述。initial主要用于仿真验证，always则主要用于电路建模，也可以用于仿真。always过程块是一个无限循环，每一个always块描述了一个独立的电路功能。 always过程块分为三中类型：always_comb（描述组合逻辑），always_ff和always_latch（描述时序逻辑）。这里我们主要关注always_comb。他的代码模板如下： 12345678910module 模块名 (端口列表);\t//中间变量声明(如果需要)\tlogic 信号1，信号2，...,信号n; //逻辑功能定义（过程块）\talways_comb begin 过程赋值语句 高级语言结构\tendendmodule 基于过程块的建模最重要的就是一定记住块标识符类型的声明以及begin…end包裹。这里我们给出二路选择器的建模板子： 我们发现上面的代码中是使用条件语句结构推动描述某几个信号之间的因果关系来进行行为建模的，但是仅仅使用条件语句明显是无法完成建模行为描述的，他也可以像基于持续赋值语句建模一样使用过程赋值语句即对某些变量信号进行赋值，但是他不需要使用assign声明，并且“=”左边的信号必须是变量类型（如logic类型），并且不能是线网类型，“=”右边的信号的类型无限制。如下： 123456789101112131415module adder(input a,b,cin,output[1:0] out);\tlogic half_sum,half_carry;\talways_comb begin //正确 half_sum=a^b^cin; //正确 half_carry=a&amp;b|a&amp;~b&amp;cin|~a&amp;b&amp;cin; //错误，端口信号如果不显示声明为变量类型 //那么默认为wire类型，即线网类型 out=&#123;half_carry,half_sum&#125;; //下面的是正确的语句 logic out; out=&#123;half_carry,half_sum&#125;;\tendendmodule 阻塞赋值 在之前一讲的最后我们学习到了基于过程块的建模中的过程赋值语句，在SystemVerilog中，过程赋值语句可以分为两类：阻塞赋值（=）和非阻塞赋值(&lt;=)，其格式如下面所示。其中延迟量意义不变，也是不可以综合的。阻塞语句用来描述组合逻辑电路，非阻塞赋值用于描述时序逻辑电路。 12#5 out =a&amp;b;//阻塞赋值out[3:0]&lt;=&#123;b[2:0],1&#x27;b1&#125;;//非阻塞赋值 阻塞语句在该语句结束后就会立即完成赋值操作，如果在一个过程块有多条阻塞赋值语句，在前面的赋值语句没有完成之前，后面的赋值语句就不能执行，仿佛被阻塞了一般、由此可以，阻塞赋值中输入的变化会立即影响输出，故用于描述组合逻辑电路。 思考：阻塞语句貌似是串行的，这和SystemVerilog的并行性不冲突吗？ 不冲突，两者强调的方面不一样。并行性是指语句的执行之前没有串行机制，因此假设 12logic a=5;logic b=7; 那么两个指令是并行执行的，没有变量的先后创建之分，这是并行性，他值得是语句的执行没有串行机制。但是对于一个变化来说，一定是前面的先变化，然后后面的赋值语句再接收到前面的变化后，在执行这个变化，因为对于后面的语句来说变化在未传达之前是不可预知的，因此必须先等待前面的赋值语句做出改变。 思考：阻塞语句和非阻塞语句的区别？ 其实就是组合逻辑电路与时序逻辑电路的区别。我们前面学习了时序逻辑电路并不是接收到变化后立刻发生改变，而是需要等待所有的条件全部具备以后在发生变化，因此非阻塞语句就是等待全部变化赋值以后才可以执行。而阻塞语句就是接收到改变立刻修改赋值的语句，只能用于逻辑组合电路。 很明显上面额y想要变化，首先需要a和b更新赋值才可以。这就是逻辑上的串行，但是同时这几条指令是同时执行的，即a和b时同时发生变化的，因此是并行的，当y接收到a和b的变化后会立刻发生改变。 分支结构 在SystemVerilog中，分支结构有if…else语句和case语句。If…else语句是可综合的，主要用于生成多路选择器，其格式如下。if…else语句支持多层嵌套，可以使用begin…end增加可读性（类似于大括号）。 一定要注意在SystemVerilog中使用if…case语句尽量要考虑所有的条件（完整分支），即所有的情况都进行处理，这样才能产生组合逻辑电路，否则将综合出带有锁存器的时序电路。 也就是说即使某些情况我们不需要进行任何操作，最好也要加以讨论，如： 我们发现水位最高位14m,而我们使用的是4位表示，那么最高可以表示15，即使15的时候什么等也不亮，我们最好也加上一个灭灯的操作使得讨论完整。即总是要加上一个else总是好的。不要像写oj题一样只写if不写else。 同样的case语句也是一种分支结构语句，也是可以综合的，他主要用于生成多路选择器、译码器等。格式如下，同样的，对于case尽量也要考虑全面，这样才能产生组合逻辑电路，否则，将综合出带有锁存器的时序电路。也就是说，最后要加上default使得讨论完整。 并且某个分支项item_expr中的某位无关值，用？表示，那么该位的比较就不予考虑，即意味着比较结过永远为“真”。如下图： 下面我们来看一下如果未讨论完整所有的情况，那么综合时就会出现锁存器。 对于上面将2位的4中情况全部都讨论了，那么没事正常运行。如果出现下面这种少讨论的情况，那么就会出现锁存器，实际上锁存器很好理解。EN是使能端，只有EN为1时，输出端才会随着输入端立刻变化，即如果是a,b,c的某一种情况，那么Dout也会瞬间会根据不同的情况输出相对应的值，但是如果是未讨论的d情况出现了，那么此时EN会变为0，但是此时他和三态缓冲器不同，他的输出端并不是变为浮空，而是被锁住一直维持最后一次的输出状态，即如果在d情况之前Dout一直输出的是a的输出信号，那么锁住以后就一直维持输出a情况的输出信号直至d情况结束。如果d情况之前Dout一直输出的是c的输出信号，那么此时就会一直维持c情况的输出。 循环结构 在SystemVerilog中，循环结构主要包括for、repeat、while和forever。 for:满足条件表达式时执行（和C一样） repeat：直接循环预先给定的次数 while()：满足条件时执行 forever:一直循环下去 在这4种循环语句中，for语句是可综合的，可以用于数字电路的建模，其他三种语句多用于仿真当中，不一定能被综合工具支持。 注意这里的循环变量i等一定要设置为int或者其他的二态变量型，而不要使用logic向量型，否则会造成死循环。 行为建模总结 在行为建模中我们分别学习了基于持续赋值语句的建模和行为建模两个不同风格的建模。这里做一个总结： 基于持续赋值语句的建模只能用于描述组合逻辑电路 在过程块中，过程赋值“=”左边的信号必须是变量类型，不能是线网类型，而对右边的表达式则没有任何限制。 基于过程块的组合逻辑电路建模可以通过always_comb和阻塞赋值语句完成 基于过程块的组合逻辑电路，使用if…else和case…语句时要特别注意需要列出所有可能的条件，否则，综合得到的将不是组合逻辑电路。（对于case,必要时不忘记default语句） 基于持续赋值语句的建模方式和基于过程块的建模方式在一个模块设计中可以混用，并且没有顺序关系。"},{"title":"指令集体系","path":"/wiki/数字逻辑与数字系统笔记/指令集体系/index.html","content":"指令集体系结构 不同的处理器会有不同的指令集，但是无论是哪一种，最终要解决的问题就是兼容性问题，即可以使得一个软件在不同的系统上运行，我们在学习了OS后知道操作系统实际上就是一个服务软件，用来协调硬件系统和上层软件之间的合作运行。而指令集来充当一个服务的翻译官，使得不同的软件可以在可兼容的硬件系统中将运行的指令翻译为硬件系统可以识别的命令供处理器运行。因此一个软件可以运行在装配有不同intel处理器的个人电脑上，也可以同时运行在装配有不同ARM处理器的安卓手机上，实际上就是指令即完成的可兼容功能。因此通过指令集的可兼容功能，不同类型，不同品牌的硬件产品只要使用相同的指令集，就可以进行组合使用。 思考：操作系统和指令集体系结构谁更靠近底层？ 我们前面讲到了操作系统是本质上一个服务软件，因此他如果想在不同的硬件系统中进行运行，也需要可兼容性，因此需要指令集体系结构来实现翻译功能，因此指令集体系结构更靠近底层。 如上图是一个计算机不同层次的模块，可以看到指令集体系结构更靠近底层，因此他会向os提供服务。并且指令集体系结构属于硬件模块层次。 定义：什么是指令集体系结构？ 指令集体系结构（ISA，也称为指令系统），是对处理器硬件细节的抽象描述，即设计规范，他定义了处理器能够做什么，也是对系统级程序员所能看到的处理器的属性。 指令集体系结构之所以能够定义处理器能够做什么，是因为他为处理器提供最基础的命令，处理器只能组合使用指令集体系结构提供的指令来实现软件需要的功能。比如指令集体系结构提供了add功能，那么处理器才能识别并完成add功能。并且要注意指令体系结构不仅仅局限于指令功能的编码，他还包括一些其他的硬件机制。 下面这些功能也都属于指令集体系结构中： 软件就是使用指令集体系结构给出的规则恰当的使用硬件来完成功能。 拓展：ISA中的“五朵金花” 五大主流生产指令集体系结构的厂商，x86常用于桌面，arm，power常用于移动端设备,mips常出现于通信系统中。 其中MIPS指令集（无内部互锁流水级处理器）是最经典的RISC处理器，由斯坦福大学校长Hennessy领导的小组在1981年开始设计，MIPS的理念就是使用相对简单的指令，结合优秀的编译器以及应用流水线技术执行指令，从而使用更少的晶体管生产处更快的处理器。我们后面的实验就是要设计实现一个简单的MIPS指令集体系结构。 思考：指令集系统结构为什么很重要？ 通过层次图我们可以看到指令集体系结构起到了协调硬件与软件之间协调兼容的作用，只有硬件与软件使用同一套指令集体系结构，两者才能合作工作形成一个计算机。因此指令集体系结构是计算机产业的枢纽，连接着软件与硬件行业。 一个指令集体系结构并无好坏之分，但是明显被更多地区，行业广泛接受支持的指令集体系结构是更具有影响力的，当前最主流的计算机体系结构就是x86指令集体系结构，但是这并不能说明x86在功能上就一定是最好的isa，只是被更多的行业产商所接受。所以在设计软、硬件时生产商需要参考x86指令集体系结构来实现其在其他使用x86指令集体系结构应用的兼容性，所以指令集体系结构还是计算机软硬件的重要标准，当isa被更多人普遍接受，那么会被更多人所参考，也就逐渐形成了重要的行业标准。 并且指令系统决定了系统的性能和实现复杂性，例如RISC,CISC提供的指令复杂度不同，那么系统工作时的性能也会受到影响，再比如32/63位，媒体向量，向量指令等不同的ISA会采用不同的应用方式，也就决定了系统工作性能的高低。 微体系结构 微体系结构是指令集体系结构的一种具体硬件实现，如指令的数据通路结构，计算单元的电路结构（加法器等），存储器体系（寄存器文件、主存的结构）等等。 我们可以看到x86进一步拆分出了许多微体系结构，不同的微体系结构模块有不同的功能。 汇编语言 汇编语言就是从机器易于识别的机器语言到人能易于理解的高级语言的一个过渡语言，他能够使用标注符号（助记符）将高级语言简化成贴近机器语言的形式，更便于我们人来阅读理解机器语言的功能。 其中汇编语言包括汇编指令，伪指令（标签）、宏指令等。而机器语言仅仅是01编码。汇编语言可以将高级语言的复杂功能拆分简化，使得汇编指令和机器指令一一对应，然后汇编指令的不同搭配即可实现高级语言的功能。这里我们主要学习MIPS汇编指令，也就是学习MIPS指令集体系结构中的指令。 我们以加减法指令为例，学习一下汇编语言得基本格式： 1助记符 目的操作数 源操作数 助记符是用来区分不同的汇编指令的符号，目的操作数是计算输出数据最终的去向，源操作数是输入数据的来源。在MIPS指令集系统结构中设计的准则是 指令格式前后一致 操作数格式一致 易于在硬件编码和处理 因此MIPS仅仅包含了非常简单常用的指令，使得硬件编码和指令指令变得简单，短小和快速。但是同样对于复杂的指令操作就只能使用许多简单的指令搭配组合去实现，而intel的x86则引入了更加复杂功能强大的指令，这也导致了x86指令集体系结构的硬件阶码和指令执行速度慢于MIPS。因此MIPS为RISC(精简指令)，而intel的x86为CISC（复杂指令）。 在汇编操作中，以下三个形式可能是操作数： 寄存器（存储操作数） 存储器（存储操作数) 常数（立即数,自身就是操作数） MIPS32位寄存器 MIPS定义了32个32位的寄存器组成的寄存器文件，我们学习过OS和机组原理后知道寄存器的访问速度是要快于内存的，但是存储容量确是有限的，因此我们要尽可能的使得寄存器能够存储更多的数据。MIPS中的寄存器操作的数据宽度为32位数据，因此MIPS又被称为32位体系，这体现了“越小的设计越快&quot;的设计准则。 通用寄存器（General Purpose Register) 32个寄存器，并且每一个寄存器的操作数据长度为32位，寄存器文件/寄存器堆是一个32×32位的通用寄存器组成的，这32个通用寄存器都是被程序员可见的寄存器。 特殊寄存器 特殊寄存器一般被定义来实现一些特殊的存储功能，如用于存储乘/除法结果的寄存器HI和LO，这些特殊寄存器程序员是可见的，但是用于存储指令地址的PC（程序计数器，功能是存储下一条要被cpu进行处理的指令的地址的寄存器），这种寄存器程序员是不可见的。 系统控制状态寄存器 例如CP0协处理中的寄存器，一般也是程序员不可见的，他是用来存储记录当前系统状态操作数的寄存器，他能决定系统是否处于目态，很明显为了安全，是不允许程序员看见并修改的。 思考：在汇编语言中我们如何区分识别当前使用的是哪一个寄存器？ 为了对我们使用的寄存器加以区分，我们对每一个不同的寄存器都设置了唯一的寄存器编号，如下图： 一定要注意寄存器的助记符是要在数字编号前加上一个$符号的！例如$0代表的就是0号寄存器 我们观察上表可以看出并不是所有的寄存器都可以随意存储操作数的，有一些寄存器有专有用途，如： $0总是表示立即数0 $0-$7为保存寄存器，用于保存变量 $0-$9为临时寄存器，用于存储大型计算中的中间值 当然了大部分还是通用寄存器，在我们学习过程中，可以默认为处了$0寄存器，其他寄存器都是可以任意使用来充当通用寄存器的 下面我们最后看几个包含寄存器的汇编指令： MIPS存储器 存储器可以存储更多的数据，并且访问时间更长，但是访问的时间开销也更大，因此常用的数据常放在寄存器中，而不常用的大量数据会存储到存储器中，当某个存储器的数据被使用后会放到寄存器中以便接下来一段时间可能会经常使用（局部性原理的体现）。MIPS中存储器和寄存器的综合搭配使用的机制实际上和页面调度算法中tlb和内存的工作机制是类似的。 对于MIPS而言，存储器的地址为32位，一个存储字的长度也是32位。注意在MIPS中只采用按字节编址存储器，每一个字节有一个单独的地址，但是我们可以按字节、半字和字的方式进行寻址。 按字编址和寻址 按字编址时，一个字对应一个地址，如上图此时是一个词（字）对应着一个地址，而不是，他相较于按字节编址，一个地址对应着更多的数据（四个字节）。 读存储器的指令称为加载指令（load)指令，他一次性加载一个字的指令助记符为lw（load a word)。例如： 1lw $s0,5($t1) 上面是一个读存储器的指令，作用是把某个地址对应的字数据加载到s0寄存器，后面的5($t1)实际上返还的是访存的地址。计算方式为： 访存地址=基地址($t1寄存器中的值)+偏移(5) 1.注意$t1是一个通用寄存器,只是这里刚好基地址存储在t1寄存器，实际上基地址可以存储在任意一个寄存器中 2. 一个字对应四个字节 , 写存储器的指令称为存储指令（store指令），他一次性存储一个字的指令助记符为sw（store a word)。例如： 1sw $s0,5($t1) 同样的访存地址还是($t1+5)，但是此时的作用是将t0寄存器中的字写入到这个主存地址中。因此lw和sw时一个对立的指令，两者搭配使用，完成读/写存储器的功能。 按字节编址 此时一个字节对应着一个地址，因此一个字会分成4个字节存储到4个存储器的地址单元中。此时根据一次性读/写1,2,4个字节可以分类成一下几种指令，他们都是读/写存储器的指令，但是一次性读/写对应的数据字节大小不同： 读/写1个字节：lb(load a byte),sb(store a byte) 读/写半字（2个字节）：lh(load half byte),sh(store half byte) 读/写字（4个字节）：lw(load a word),sw(store a word) info, 一个字(32bit=4byte)为4字节，字地址按4递增，字节地址按1递增 因此，如果我们想在按字编址的存储器中读一个字节只能先取出一个字，在拆分处相应的需要的字节数据，而在一个按字节编址的存储器中如果我们想要读一个字的数据，那么应该一次性读4个字节的信息，因此访存地址应为4的倍数，即地址最后两位均为0，否则会出错。 假设我们现在想从存储器地址4处，加载一个字到寄存器$3中，那么MIPS汇编代码如下： 1234#基地址为0，因此$0永远存储的是常数0，请区分$s0和$0寄存器#因此偏移4个单位对应的访存地址就是000000004#又因为使用的是lw按字读，因此一次性读4个字节lw $s3,4($0) 因此最终$3寄存器存储的数据时0xF2F1AC07。 写按字节编址存储器也是类似的，假设我们现在想要将$t7寄存器中的值写入到存储器地址44处，那么MIPS汇编代码是： 1sw $t7,44($0) 总之，我们要会区分按字和按字节编/寻址的操作，同时我们要注意具体的指令如何操作，取决于存储器的编址方式，我们学习的是使用按字节编址的MIPS存储器，因此大部分操作使用都是按字节读/写操作。 大端和小端 在按字节编址的存储器中，根据一个字中的字节的存储顺序将存储器的组织方式为两种：大端和小端。 大端：一个字中，最高有效字节存储在低地址 小端：一个字中，最高有效字节存储在高地址 两种组织方式，字地址都是相同的，只是字中的字节存储的地址是不同的。大端/小端由ISA确定，对于MIPS而言，两者都可以。 一定要注意，大端存储并不是指大的数存储到低地址，而是高有效字节的数据存储在低地址。小端存储并不是指小的数存储到低地址，而是低有效字节的数据存储在低地址。 我们以下面的例子来具体区分一下大端和小端存储的区别： 因此我们发现对于一个数00112233H，大端存储就是正常的高位数从左到右存储，因此高位有效数存储到了低字节地址处。而小端存储反而相反，高位有效数存储到了高字节地址处，也就造成了实际上一个字的数拆分成4个字节后是从右到左存储的，因此读出来的数要逆序一下才是真正的数值。 例题 假设$s0中的初始值为0x23456789,对于大端和小端组织形式，下面程序执行后，$s0的值是多少？ 12sw $s0,0($0)lb $s0,1($0) 对于大端存储：首先将0x23456789存储到了地址0处，并且存储的顺序从低字节地址到高字节地址为23 45 67 89，因此再lb取1处的一个字节的数据时得到的是45 而对于小端存储：首先将0x23456789存储到了地址0处，并且存储的顺序从低字节地址到高字节地址为89 67 45 23，因此再lb取1处的一个字节的数据时得到是67 思考：如果上面的代码改写为lw $s0,1($0)可以吗？ 不可以，因此lw一次取一个字也就是四个字节，又因为从0开始存储第一个字，因此地址一定是4的倍数才行，但是1这里对应的并不是一个字的地址起点，因此是不可行的。 思考：如何用一段C程序，来判断运行机器采用的是大端存储还是小端存储？ 实际上我们只需要先将一个四字节的信息存储到四字节的参量中，然后取出一个字的信息即可判断，如下： 123456bool big_little_endian()&#123;\tint i=0x23456789; char *c=(char*)&amp;i; //返还true就是大端存储，返还false就是小端存储 return (*c==0x23);&#125; 操作数–立即数 立即数既不来自寄存器，也不来自存储器，而是直接来自指令，他通常使用16位二进制补码来表示，直接嵌入在汇编指令中使用。 如上图所示，4和-12就是立即数，他们可以直接在指令中嵌入使用，而不是通过寄存器，存储器等方式进行取操作后再使用。 机器语言 在MIPS指令集中我们可以将指令根据32位指令代码区域划分规则的不同而分类： 寄存器类型指令（R型指令） 立即数类型指令（I型指令） 跳转类型指令（J型指令） 寄存器类型指令（R型指令） MIPS指令集是32位的，因此每一个指令都使用32位代码，其中按照上面的规则进行划分，每一个区域都有特定的功能： op字段：操作码，通常为全0（在nemu实验中opcode_table中的各种指令名的名称大多相似） func字段与op字段一起决定指令的功能（在nemu实验中opcode_table中相同地址地址的指令虽然前缀相似，但是后面有些许不同的后缀，实际上就是func，两者共同决定一个指令类型） rs字段和rt字段是寄存器编号，表示两个源操作来自于哪两个寄存器 rd字段用来表示目的寄存器的编号 sa(shamt)字段只在移位指令中使用，表示移位位数，对于其他R-型指令sa字段全为0 上面的指令由两个源操作加上一个目的操作数，并且所有的操作数都来源与寄存器，因此称为寄存器类型指令（Register command),也就是R-型指令。下面是一个寄存器类型指令的例子： 他们的指令划分（下表中的数据都使用十进制真值来表示)如下： 我们一定要注意rs,rt,rd各对应的是谁，在mips指令add和sub等寄存器指令，书写时的规则是 123#助记符 目的操作数 源操作数1 源操作数2 add $s0 $s1 $s2sub $t0 $t3 $t5 和划分的区域略有顺序的不同。因此在机器中的代码存储如下; 然后在使用16进制代码表示整个的32位指令，因此一个指令是由8为十六进制数表示。 立即数类型指令（I型指令） 划分规则： op字段表示操作码 rs字段为寄存器编号，表示一个源操作数来自于寄存器 imm字段是一个16位立即数，表示另一个操作数，需要扩展为32位再使用 rt字段表示目的寄存器的编号，用于存放指令运行结果 我们发现此时的指令所有的操作数中有一个是立即数，因此称为立即数类指令，要注意此时的目的操作数夹在两个源操作数之间，但是在书写指令时，仍然为操作数在最前面： 123456#助记符\t目的操作数\t源操作数1\t源操作数2（立即数）addi rt, rs immlw rt, immsw rt, immlw rt, rs sw rt, rs 最终再机器码中还要将十进制真值数改用二进制数表示，然后最终的汇编代码再将32位的二进制码转换为8位16进制码来表示： 跳转型指令（J型指令) op字段表示操作码，用于确定指定的类型 instr_index用于产生跳转的目的地址，但是我们知道一个应该是32位，因此我们需要对instr_index进行一定的处理; (PC+4)31:28∣∣instr_index∣∣0(PC+4)_{31:28}||instr\\_index||0 (PC+4)31:28​∣∣instr_index∣∣0 实际上就是使用instr_index处理PC+4这个数想办法使其表示不同的32位地址数。 注意上面的||不是取或的意思，而是地址拼接的意思，我们是将下一条地址的31:28这4位和instr_index26位拼接再在低两位拼接两个0形成跳转地址。并且后面拼接两个0实际上就是&lt;&lt;2的操作，因此后面我们学习到跳转指令的数据通路时会用移位操作实现。 总结 一定要注意无论是哪种指令都是对一个32为二进制码进行划分，然后指令使用8位16进制码来简单表示，同时要注意上面的这种划分规则只是MIPS指令集的规则，对于intel的x86等并不适用。指令可以根据opcode和后面的低16位的划分规则来进行判别类型。"},{"title":"状态机建模","path":"/wiki/数字逻辑与数字系统笔记/状态机建模/index.html","content":"根据电路图导出状态机 有时候我们并不是事先了解到需求功能后设计电路图，而是在给定电路原理图的情况下推断电路的逻辑功能，也就是电路设计的逆过程。此时我们需要按照如下步骤进行： 检查电路，标明输入输出和状态位 写出次态方程和输出方程 列出状态表和输出表 删除不可达状态以简化状态表 给每个有效状态编码指定状态名称 用状态名称重写状态表和输出表 画出状态转换图 使用文字描述有限状态机的功能 下面我们用一个案例来学习根据电路原理图导出状态机：如下图是一个键盘锁电路，包含两个输入和一个输出，当输出为1时表示开锁成功，试分析，如何进行输入才能使电路产生开锁信号 首先我们要检查电路图，标明输入，输出和状态位： 输入A0,A1 输出unlock 状态位S0,S1 电路的输出只取决于状态位Unlock=S1 很明显这个电路使用个Moore型状态机 接下来我们写出次态和输出的计方程： 观察上面的电路图，我们可以直接对照着写出次态的计算方程 {S1′=S0A1‾A0S0′=S1S0‾A1A0\\begin{cases} S_1&#x27;=S0\\overline{A_1}A_0\\\\ S_0&#x27;=\\overline{S_1S_0}A_1A_0 \\end{cases} {S1′​=S0A1​​A0​S0′​=S1​S0​​A1​A0​​ 同样输出的计算方程我们也可以轻松推得： Unlock=S1Unlock=S_1 Unlock=S1​ 接下来我们要根据上面的方程枚举所有的情况列出状态表和输出表： 然后我们将状态表填写完整，进行不可达状态的删除： 我们发现状态S1:0=11从未在表中作为次态出现过，即无论输入A1,A0取何值都不可能计算得到次态的11，因此将状态表和输出表对应不可达状态S1:0=11的一栏删除。同时对于现态S1:0=10，总是得到次态S1:0=00，因此此时与输入无关，可以使用无关项X来进一步化简。最终我们得到化简后的状态表和输出表如下图： 接下来我们为状态表和输出表中的每一个有效状态编码指定状态名称，从而使得更容易知道输入情况同时也方便后面进行状态转换图的绘制： 我们规定有效状态编码对应的名称如下图： 因此将上面的化简后的两个表使用新的名称来表示： 此时我们根据已经用状态名称标注的状态表和输出表进行状态转换图的绘制，要注意因为是Moore型状态转换机，因此输出应该是写在状态圆圈的内部的。 最后我们再观察状态转换图，进行以下逻辑整理，便可以描述出这个电路图要实现的功能了，如上图，在复位状态下，只有先后输入了3和1才能到达解锁状态S2，这也就说明这个键盘输入锁的密码就是31。 基于SystemVerilog HDL的时序逻辑设计 前面我们学习了使用建模语言设计组合逻辑电路，那么接下来我们来学习使用SystemVerilog HDL来设计时序逻辑电路。首先我们需要注意SystemVerilog使用一些特殊的编码风格（IDIOMS)描述锁存器、触发器和状态机。其他的编码风格虽然可以正确的进行仿真，但是综合后会产生错误的电路。 这里我们学习一下如何使用always过程块进行时序逻辑电路的建模: always过程块分为三类： always_comb(描述组合逻辑) always_latch always_ff 其中后面两个都是描述时序逻辑电路的声明语句。always过程块结构： 12always @(sensitivity list) statements; sensitivity list是敏感事件列表，当列表中的事件产生时，过程块的语句就开始工作。下面我们就来用几个实例来具体学习一下使用always过程块进行时序逻辑器件的建模。 寄存器建模 寄存器是一个典型的时序逻辑器件，他在同一时刻更新存储多位信息。其结构如下： 那么我们的建模代码如下 123456module flop(input logic clk, input logic[3:0] d, output logic[3:0] q); always_ff @(posedge clk) q&lt;=d;endmodule 我们使用正边沿D触发器来实现这个寄存器的功能，always_ff用来表示触发器，@后面括号中的posedge clk就是敏感事件，其实就是时刻监视clk，即clk就是时序逻辑电路的条件，当满足时就执行内部的代码，posedge clk表示信号上升沿有效，因此当clk处于有效上升沿时，q的更新赋予d的值。其中这里的赋值符号不是=，而是&lt;=，这在前面其实将结果是非阻塞赋值的意思，这里我们还不用深究，暂时可以把它视为普通的赋值语句。 那么接下来我们来尝试为这个寄存器增添一个复位端，使其能够恢复到最初始的状态。我们前面学到了复位有两种方式： 同步复位：只有在clk处于上升沿时可以进行复位 异步复位：只要reset=1，那么无论是clk是否处于上升沿都可以强制进行复位，也就是说只要reset处于有效沿，那么就可以执行复位代码。 这里我们给出两种不同复位方式的寄存器建模代码： 我们可以看到对于同步复位功能的寄存器，他的敏感事件只有clk，因此只有clk处于有效沿时才能执行always内部的代码，因此只有在clk有效时才可能进行reset的判断以及复位。但是对于异步复位的寄存器，敏感事件有两个即新增了一个reset，也就是说此时只要reset或者clk处于有效沿，都可以执行过程块内部的语句，因此此时是异步复位。 一定要注意senitivitylist只要有一个事件满足就可以进行过程块下的代码，因此条件之间是或的关系 进一步我们还可以为具有复位功能的寄存器添加一个使能端，只有使能端en=1时才能将Q更新为采样的输入值D： 锁存器建模 接下来我们再来实现以下锁存器的建模，实际上并不是所有的综合工具都能够很好地支持锁存器，除非你能明确的知道那些工具支持锁存器，否则最好不要优先使用锁存器，而是使用边沿触发器来替代。同时我们还要防止HDL意外生成锁存器。 我们思考一下锁存器的功能，实际上就是只有在clk=1有效状态时，才能让Q时刻跟随采样的输入值D变化，否则就维持之前的值。因此建模代码很简单： 123456module latch(input logic clk, input logic[3:0] d, output logic[3:0] q); always_latch if(clk) q&lt;=d;endmodule 阻塞赋值语句= VS 非阻塞赋值语句&lt;= 我们前面学习过非阻塞赋值语句和阻塞赋值语句区别： &lt;=是非阻塞赋值语句，他的特点是可以和其他的语句同时执行 =是阻塞赋值语句，他的特点是按照语句的在代码中的顺序依次工作 但是当时我们很难理解两者的应用上有何异同，接下来我们使用一个案例来分析一下： 我们发现上面的两个建模代码很相似，只是在赋值的时候使用了不同的赋值语句，最终对应的电路图有很大的区别，这就是非阻塞赋值语句和阻塞赋值语句造成的。首先我们分析一下左侧使用非阻塞赋值语句的建模代码，由于非阻塞赋值语句是并行执行的，而不是阻塞式的串行，因此上面两个赋值代码是同时执行的，也就是说q被赋予的是n1还没被更新成d的值。举个例，假设初始时n1=0,d=1，那么执行上面的非阻塞赋值语句后n1=1,q=0，我们发现q的值是n1之前的值0，而不是被更改为d后的1值，这是因为n1和q同时更新值，从q的视角来看，此时n1还是0值，只有当q更新为0以后n1才变成了新的值1。 而阻塞赋值语句就很好理解了，就是我们通常意义上的与C和java等高级软件编程语言都类似的串行赋值，因此n1先更新成了1，然后q才被赋予了n1的值也就是1，因此对于右侧阻塞赋值语句最终的结果q=n1=1。 我们发现正是这两种不同的赋值语句导致了最终实现的电路图是不同的，左侧最终实现的是两个串联的D触发器，而右侧的是一个D触发器。我们还可以进一步尝试将左侧的非阻塞赋值语句用阻塞赋值语句来表示： 123456//下面两个代码是等同效果的n1&lt;=d;q&lt;=n1;//等同于q=n1;n1=d; 赋值语句使用规则 因此我们可以对各种建模方式的赋值语句进行一个总结： 当使用同步时序逻辑电路要使用always_ff @(posedge clk)和非阻塞赋值语句是代码如下： 12always_ff @(posedge clk)\tq&lt;=d; 而当对于简单的组合逻辑电路中可以使用赋值语句assign 1assign y=a&amp;b; 而对于使用always_comb和阻塞赋值语句=的描述复杂组合逻辑电路的语句如下： 123456always_comb begin\tp=a^b;\tg=a&amp;b;\ts=p^cin;\tcout=g|(p&amp;cin)end 注意不要在多于1个always语句块或者连续赋值语句中对同一个信号赋值 计数器建模 N位二进制计算器如下图： 他的输入有时钟信号clk,复位信号reset，同时输出就是一个N位二进制计数结果。功能是每次在时钟上升沿到达时将结果加1并输出。能够实现循环计数：000,001,010，…。因此这是一个时序逻辑器件，他常用数字时钟和程序计数器（PC）中。 下面我们来对他进行建模： 123456789module counter #(paramer N=8) (input logic clk, input logic reset, output logic [N-1:0] q); //很明显是异步复位 always_ff @(posedge clk,posedge reset) if(reset)q&lt;=0; else q&lt;=q+1;endmodule 注意上面的赋值语句虽然使用阻塞赋值语句也不会有问题（这是因为每种情况只会有一个赋值代码），但是为了规范可以在任何综合工具上都能综合，因此还是要求使用&lt;=来进行赋值。 移位寄存器 移位寄存器输入有时钟信号clk,串行输入信号Sin,输出由串行输出Sout以及N位并行输入的Qn-1:0。移位寄存器的功能就是在时钟信号的每一个上升沿，从Sin移入一个新的位，并将寄存器的整体向前（高位）移动一位，因此最前面（最高位）会出来位移如Sout。我们可以将其看成是一个串行到并行的转换器，每一个周期从Sin输入一位，N个周期后可以通过Qn-1:0直接访问N位输入。因此在将内容整体移位时很明显是需要并行同时执行赋值更新操作的，因此是用非阻塞赋值语句的同步时序逻辑来实现，使用的实现器件就是将N个D触发器串联即可。 下面我们对这个移位寄存器进行优化，使其可以并行加载，什么意思？ 此时输入增加了Load信号和并行输入信号Dn-1:0。我们思考一下，之前如果我们想要先将这个N位寄存器加载一个N位数，那么需要先执行N次移位操作，才能将这个N为二进制码加载进去，这很麻烦，因此使用并行输入信号同一时刻并行的为每一个位进行赋值从而实现单位时间不用移位就完成移位寄存器对于一个N为二进制数的加载。此时功能是： Load=1时，并行加载一个N位二进制数 Load=0时，移位寄存器进行移位操作，每一次clk上升沿整体向高位移动一次，最低位由Sin填入 那么此时可以实现串行转并行：Sin到Qn-1:0，同时还有并行转串行Dn-1:0到Sout。那么此时我们来实现一个建模： 123456789101112131415161718module shiftreg #(parameter N=8) (input logic clk, input logic reset,load, input logic sin, input logic [N-1:0] q, output logic [N-1:0] q, output logic sout); //很明显又是一个异步复位 always_ff @(psoedge clk,posedge reset) //复位 if(reset)q&lt;=0; //同时并行赋值同一时刻完成N位二进制数的加载 else if(load)q&lt;=d; //移位，注意要将sin拼接到最低位 else q&lt;=&#123;q[N-2],sin&#125;; //同时记录sout值 assign sout=q[N-1]endmodule 有限状态机建模 我们之前学习的建模都是只是将最核心的同步时序电路部分进行了建模，使用的是always_ff实现的，但是实际上对于一个状态机来说，他在状态寄存器的两侧还存在输入到现态的计算的组合逻辑电路，还有右侧连接的根据现态计算出输出的组合逻辑电路，因此实际上在对一个有限状态机进行建模时即需要alwalys_ff的同步时序过程块，也需要alwyas_comb组合逻辑过程块。如下： 这是一个最简单的3分频计数器，他就是一个moore型的有限状态机，输入是一个时钟输入信号，一个输出，功能是每3个周期后输出产生一个周期的高电平。因此状态转换图如上图，输出是时钟的3分频。因此建模代码如下： 12345678910111213141516171819202122module divideby3FSM(input logic clk, input logic reset, output logic q);\t//枚举类型集合的声明,类似于结构体的声明\ttypedef enum logic [1:0] &#123;S0,S1,S2&#125; statetype;\t//statetype枚举集合的实例化\tstatetype [1:0] state,nextstate;\t//核心状态寄存器使用同步时序逻辑\talways_ff @ (posedge clk,posedge reset) if(reset) state&lt;=S0; else stats&lt;=nextstate;\t//次态的计算使用次态组合逻辑计算\talways_comb case(state) S0:nextstate=S1; S1:nextstate=S2; S2:nextstate=S0; default:nextstate=s0; endcase\t//输出逻辑\tassign q=(state==S0);endmodule 我们会发现上面又添加了两个组合逻辑过程块分别同来计算输入到次态和现态到输出，同时由于SystemVerilog HDL硬件语言具有并行性的特点，因此nextstate虽然先在always_ff的同步时序逻辑过程块中使用了，但是其具体值其实是通过下面的次态组合逻辑过程块计算得到的。 一定要注意SystemVerilogHDL的代码具有并行性的特点，因此信号的调用和声明赋值无先后顺序。 存储器阵列 接下来我们学习一个重要的器件–存储器阵列，他是一种有效的可以存入大量数据的模块，每一个N位地址都可以读出或者写入M为数据。 数据：存储的内容 地址：数据的索引 存储器由一个二维存储单元阵列构成，每一各位单元存储一位数据，每一行存储的是一个M位二进制码数据，由于地址编码是N为，因此一共有2^N行，也就是说可以存储2^N个M位二进制码数据。 对一个N位地址M位数据的阵列： 有2^N行和M列 深度（Depth)：阵列的行数 宽度（Width)：阵列的列数 阵列的总大小（Array Size)：深度×宽度=2^N×M 字（Word)：每行数据成为一个字 例如一个2位地址和3位数据的存储器阵列： 他的阵列深度会是4行，同时数据字个数也就是4个，每一个字的字长是3位。如上图所示，10地址存放的数据就是100。"},{"title":"表达式化简与三态缓冲器","path":"/wiki/数字逻辑与数字系统笔记/表达式化简与三态缓冲器/index.html","content":"定理化简表达式 我们学习了标准与或式和标准或与式以后，那么以后对于任何一个逻辑表达式都可以使用这种方法进行化简了，最终表示成标准与或式或者标准或与式。如下面这道题： 根据布尔表达式绘制原理图 我们知道任何一个逻辑表达式最终都可以转化成最简的标准与或式或者标准或与式，那么接下来我们在进行原理图绘制主要需要解决的问题就是如何绘制标准与或式或者标准或与式。这里我们只需要使用两级门电路即可以轻松表示与或式和或与式。 例如标准与或式，那么我们先试用一级与门写出所有最小项，然后在使用二级或门将所有的最小项相加即可，如当我们要用电路图表示下面的标准与或式时： Y=AˉBˉCˉ+ABˉCˉ+ABˉCY=\\bar{A}\\bar{B}\\bar{C}+A\\bar{B}\\bar{C}+A\\bar{B}C Y=AˉBˉCˉ+ABˉCˉ+ABˉC 我们先分别用一级与门分别表示出了三个最小项，然后在使用了一个三输入或门相加就得到了上面的逻辑表达式。 电路原理图绘制原则 原理图绘制需要遵循一致的风格，以便于阅读和检查错误，绘制的原则如下： 输入在原理的左边（或顶部） 输出在原理的右边（或底部） 门电路流应从左到右或者从上到下 尽量使用直线连接 T型接头表示两条线有连接 两条线交叉的地方有一个点，表示有连接 两条线交叉的地方没有点，表示没有连接 并且还要尽可能的使用更少的门以降低成本，例如下图中右侧的德摩根表示电路就要好于左边，因为右边的门更少： 多输出电路 多输出电路顾名思义就是有多个输出出口的电路，一般他也会对应着多个输入入口，但是每次只有一个输出出口的信号有效，比如我们这里介绍一下优先级电路。优先级电路，是一种特殊的电路，他在所有输入为真的信号中，选择其中最重要的信号所对应的输出为1，其余输出为0。如下图： 这里的Ai中i越大表示优先级越高，所以当A3为0时，那么Y3就输出0了，，A2A1A0无论是多少都为0。这就是一个多输出的优先级电路。那么我们是如何实现的呢？实际上我们只需要三个门就可以实现如下图： 我们发现为了减少门的使用，实际上使用了更加复杂的三输入甚至四输入门，并且还有不同的取非功能。 多级组合逻辑 所以我们可以知道在多级组合逻辑电路中我们要遵循的规则： 规则1：减少硬件 所有的逻辑表达式都可以转化为与或式，理论上与或式可以使用两级门电路来实现即先与后或，但是二级逻辑可能会带来更高的成本，所以使用多输入门又称为扇入门。但是门电路的扇入数不可能无限制的增加（受工艺、成本等方面的制约）。 这里我们以三输入异或门的实现为例： 我们发现三输入异或门可以用来顶替右侧的复杂的组合逻辑电路，这无疑是更加高效的，但是三输入异或门同样造价高昂，且实现起来很复杂，更不要说五输入异或门等了。所以有时候我们需要在门数和们元件的选择上作一个这种考虑如下： 实际上我们也可以使用两个造价更便宜的异或门来顶替三输入异或门。所以减少硬件的目的并不是盲目追求组合逻辑电路的门数量减少，而是尽可能的使用更加直观简单的电路形式来表示逻辑表达式。 规则2：推气泡 实际上我们发现对于一个标准与或式或者标准或与式的逻辑表达式总是会使用与非门和或非门，即器件上有许多小圆圈符号表示取非，但是我们在绘制组合逻辑电路时如果照搬表达式会有许多取非的过程（同时一般商家也不会卖最后输出端取非的门元件），这很不直观同时也不符合实际情况，但是又难以直接化简逻辑表达式。所以我们可以在照搬逻辑表达式绘制出组合逻辑电路后使用推气泡的方法来简化电路。首先我们介绍一下推气泡的规则： 一定要注意推气泡后门也变了，别光顾着画气泡了。 那么现在我们就可以优化电路了，如下图： 此时我们推完气泡以后发现有4个气泡，实际上是取非输出后又取非了，那么就相当于双重取反等于没去反，所以可以将这四个气泡都消掉。所以我们给出一个规则： 推气泡要从输出端向输入端推 将气泡从电路最后的输出端开始推 如果当前门有一个输入气泡且上一级输出门无气泡，则消除这个门的输入气泡，然后在上一级门的输出加上气泡 如果当前门有一个输入气泡且上一级输出门也有气泡，那么就同时消除两端的气泡 最终我们就会得到一个所有取非都在输入端的门电路，这个才是一个逻辑清晰同时符合实际的电路，如下图： 我们推完气泡以后得到了如下电路（逻辑功能完全相同）: （画的丑，见谅，但是注意门也改变了）。具体的推气泡过程如下： 非法值（illegal):X 我们其实前面已经讲过了讲个输出电路不能直接相交汇，即节点不能同时连接两个输出，否则会出新冲突，实际上就是节点同时被0和1驱动，0是对应着电压0,1是对应着VDD，那么如果冲突了电压值就会介于0~VDD，那么这个信号可能是0也可能是1，也可能处于禁止区域内（前面将多有一个禁区表示既不是0也不是1，不懂了请看第1讲）。这时我们就成为交汇后的信号值为非法值X，一般出现这种竞争情况都是电路设计缺陷引起的，我们要避免此种情况，因为他会导致电路功耗变大，电路发热，并导致电路损坏。 无关项（Don’t Care):X 无关项一般会出现在优先级电路中，例如之前讲过的优先级电路： 那么很显然如果输入信号A3位输入，那么就不需要考虑其他输入量，此时对于不需要考虑的输入信号量就是用X来表示。 浮空值（floating):Z 浮空值称为悬空、高阻态、高Z态、开路、断路等，即次数电路断开的意思。首先我们要注意，浮空值Z就是指电路断开了，此时信号会介于0~VDD之间，具体是多少不知道，所以使用电压表并不能判断哪个电路节点处于浮空状态（可能这个信号就是0，也可能这个信号是浮空Z并且恰好Z是0），且测量断路节点的电压和接地点的电压，在电压表上的读数都为0。所以浮空值输出不确定，产生浮空节点常见的原因是忘记将电压连接到输入端。 注意浮空就是电路断开，所以输出信号就会自然变化，并不一定是0这和物理上的理想电路是不同的，其次浮空节点并不意味电路一定出错，浮空有时是人为设定的可以来制造某些特殊逻辑器件。 三态缓冲器（tristate buffer) 三态缓冲器就是使用了浮空，他可以用来防止节点处于竞争状态，具体实现如下： 当一个节点同时连接了n个输出时，若其中n-1个输出处于浮空状态（即断开状态），那么当前的节点值就等于驱动正常电平输出端的值。所以使用三态缓冲器就可以允许节点连接多个输出端了，这无疑优化了电路。例如上面的三态缓冲器，有三种输出状态：高电平VDD表示1信号，低电平0表示0信号以及浮空状态表示线路断开。 例如此时A是输入端，Y是输出端，使能端E是控制何时断开的，那么此时当使能端为0时，输出端浮空，表示A-&gt;Y的线路断开，那么这个输出信号Y暂时不等于A了，而是浮空值Z了，所以Y就暂时不参与下一级门的逻辑运算了，当E=1时，那么线路连接，Y=A的信号值，所以就可以看成一个导线了，那么Y就会以A信号值参与下一个门的逻辑运算。 三态缓冲器的应用 那么很明显在连接多个芯片的总线时，会用到三态缓冲器，许多不同的设备同时连接到同一总线上，但是某一时刻只允许一个芯片的信号有效，并向总线输出数据，其他芯片的输出必须浮空，以防止总线竞争，任何芯片在任何时刻都可以通过总线读取信息： to bus表示的就是从设备向总线输出数据的信号，每一次只有一个设备的三态缓冲器使能端为1表示每一次总线只会接受一个设备的信号。但是from bus表示的是设备从总线获取的信号，那么如果这个设备需要，就可以让from bus线上的三态缓冲器使能端为1接受来自总线的信号，并且同一时刻可以有多个设备都接受总线的信号，但是他们接受的信号是相同的。 使用卡诺图化简布尔表达式 我们回忆一下之前我们学习的补1法将布尔表达式转化成标准与或式，他可以使得式子更加符合电路逻辑，便于我们绘制组合逻辑电路，但是对于人类思维却不友好，因此如果我们现在知道标准与或式，我们希望可以将它化简成比较简洁清晰的形式，即变量尽可能的少，此时我们就可以使用卡诺图进行化简。 卡诺图的思想很简单，他就是通过合并项来化简布尔表达式。那么我们该合并哪些项呢？就是相邻最小项，比如PA和P非A，他们相加合并就可以变成P。卡诺图化简法是将逻辑表达式用一种称为“卡诺图”的图形来表示，然后在卡诺图上进行函数化简。下图就是几个卡诺图化简时的中间过程： 我们首先来介绍一下卡诺图的构成： 卡卡诺图是一种包含一些小方块的几何图形，图中的每一个小方块称为一个单元，每个单元对应一个最小项（注意一定要是最小项）。两个相邻的最小项在卡诺图中也必须是相邻的，卡诺图中相邻的含义： 几何相邻性，即几何位置上相邻，也就是左右上下紧挨 对称相邻，即图形中对称位置的单元是相邻的 注意，卡诺图里的相邻只要满足上面的两个条件之一即可，所以在卡诺图中两个相邻的最小项可能是左右上下紧挨的，也可能是对称的，但是在卡诺图中都称为相邻。 思考：为什么卡诺图使用的是最小项，而不是最大项？ 实际上很好解释，我们知道卡诺图的核心就是合并，那么合并肯定是相加，而与或式就是相加的，他的每一个元素就是最小项，所以使用最小项，而最大项之间的运算是相交，很明显不符合卡诺图的需求。 思考：能否更加详细的解释卡诺图中的相邻？ 如下图： {AˉBˉCˉ和AˉBˉC是左右相邻AˉBˉCˉ和ABˉCˉ是上下相邻AˉBˉCˉ和AˉBCˉ是对称相邻\\begin{cases} \\bar{A}\\bar{B}\\bar{C}和\\bar{A}\\bar{B}C是左右相邻\\\\ \\bar{A}\\bar{B}\\bar{C}和A\\bar{B}\\bar{C}是上下相邻\\\\ \\bar{A}\\bar{B}\\bar{C}和\\bar{A}B\\bar{C}是对称相邻 \\end{cases} ⎩⎪⎪⎨⎪⎪⎧​AˉBˉCˉ和AˉBˉC是左右相邻AˉBˉCˉ和ABˉCˉ是上下相邻AˉBˉCˉ和AˉBCˉ是对称相邻​ 并且要注意这里的相邻方块内的最小项也是相邻的。即任何两组相邻，只有一位变量取值不同，即符符号循环码排列规则。 思考：卡诺图还有哪些特点 除了方块相邻，我们还要注意对于n为元素，那么就会有2^n个卡诺方块，即2^n个最小项，并且卡诺图的横纵栏排列也是有讲究的，比如上图中的BC一行的值每一次都是只有一个位发生变化：00-&gt;01-&gt;11-&gt;10，所以BC的排列不能是00-&gt;01-&gt;10-&gt;11因为第2个位置和第3个位置两位都不同。并且卡诺图的编号就是按字典序的元素取值拼接出的二进制数，比如上图中的A(0)BC(00)就是二进制的000，所以m编号为0，在比如A(1)BC(01)就是二进制的101，所以m编号是5。 那么接下来我们来举例几个卡诺图熟悉一下卡诺图的特点，首先我们来观察一下二变量和四变量卡诺图： 注意A(AB),B(CD)谁在横向菜单栏，谁在纵向菜单栏无要求，看习惯，但是要注意编号时必须是按照字典序的顺序拼接组成二进制数。并且能对称，尽量使得卡诺图对称。 那么接下来我们看一个较为复杂的五变量卡诺图，他一共会有32个方格，一种编号如下： 一定要注意CDE和AB的排列编号要保证相邻的只有一位取值不同。 使用卡诺图表示逻辑函数 上面我们主要是讲解了卡诺图的构成和对卡诺方块的编号，那么接下来我们来学习以下每一个方格填的值来表示给出的需要化简的布尔表达式，实际上就是布尔表达式中出现的最小项对应的方格填1，其他地方默认填写0。如： F(A,B,C)=AˉBC+ABˉC+ABCF(A,B,C)=\\bar{A}BC+A\\bar{B}C+ABC F(A,B,C)=AˉBC+ABˉC+ABC 那么我们的卡诺图应该如下图： 3,5,7处对应的最小项就是布尔表达式中出现的，所以这几个地方填0。那么接下来我们来介绍一下卡诺图上合并最小项的规则，即化简的规则： 当卡诺图中有最小项相邻时（即：有标1的方格相邻），可以利用最小项相邻的性质，对最小项进行合并。 卡诺图上任何两个相邻的两个标1的方格，可以合并为1项，并可消去1个（取值取反的）变量。 卡诺图上四个标1方格合并，可合并为一项，并可以消去2个变量 四个标1方格的特点是四个方格同在一行或一列，或者同在一个田字格 根据上面的规则，我们可以将卡诺图中的5,7合并，3,7合并： 5,7左右相邻，且标号均为1同时观察菜单栏发现B的标号不同，所以可以消去变量B，同时3,7号合并，变量A取值不同，所以可以消去A，这样我们就得到了F的化简表达式了。 但是规则还没有结束，这只是对应着一种相邻的情况，我们知道还有对称的情况，所以下面的卡诺图也可以进行合并： 0000和0010由于对称相邻，所以可以合并，C取值不同所以合并后消去C，1101和1111左右相邻，可以合并，C不同，所以消去C，所以我们根据上面的卡诺图可以得知这个布尔表达式的原先表达和化简后的表达应为： F=AˉBˉCˉDˉ+AˉBˉCDˉ+ABCˉD+ABCDF=\\bar{A}\\bar{B}\\bar{C}\\bar{D}+\\bar{A}\\bar{B}C\\bar{D}+AB\\bar{C}D+ABCD F=AˉBˉCˉDˉ+AˉBˉCDˉ+ABCˉD+ABCD F=AˉBˉDˉ+ABDˉF=\\bar{A}\\bar{B}\\bar{D}+AB\\bar{D} F=AˉBˉDˉ+ABDˉ 所以我们发现补1法是将布尔表达式转换成标准与或式，而卡诺图化简就是逆过程，是将复杂的标准与或式化简成简单的形式。那么接下来我们再来尝试相除4个格的，如下： 同样的，四个格同在一行，或者同在一列或者同在一个田字格也可以进行合并消除化简。并且此时是2^2个相邻格，所以可以一次消除两个变量，我们横看可以消除一个变量，纵看又可以消除一个方格。 思考：如果我就要按照两个两个的消除可不可以？ 可能你会产生疑惑，为什么要按照4个格相邻进行消除，而不是继续看成许许多多个2个格相邻进行消除，我们知道最终要得到的式子尽可能的最简，对比上面两个图我们发现右边的式子最终并不是最简式，因此为了得到最简式，我们必须用尽可能最大的圈去包裹1矩阵。 那么接下来我们练习一下四个格相邻的消除，同时你也可以自己尝试按照2个格消除，最终对比一下化简得到的布尔表达式是否一样。 那么既然可以合并4个，当然也就可以合并8个啦，那么合并8个格的规则是8个格子相邻组成一个8元素矩阵或者有对称的行和列也可以： 最终我们会消除3个变量。如上图图1最终只剩下了一个非A，图2只剩下了非B。 思考：那么可不可以16个格进行合并消除，甚至更多？ 当然可以，我们枚举了这几种情况可以总结出如下规律： 在n变量的卡诺图中，会有2^n个方格，只有2的i次方个相邻的标1方格（必须排列成方形格或者矩阵形格的形状）才能圈在一起，合并为一项（当然，有对称的也可以）。该项保留了n-i个相同的变量，也就是说明会消除i个不同的变量。 注意一般我么也就会用到4个格的合并，8个的都很少，首先是因为随着n和i的增大，合并的规则会比较复杂，同时也很难出现许多多相邻的标1的格。"},{"title":"逻辑电路基本元件","path":"/wiki/数字逻辑与数字系统笔记/逻辑电路基本元件/index.html","content":"逻辑门 大部分逻辑门我们在《机组原理笔记》中已经学习了大部分逻辑门，这里不再细讲，但是这里补充一个门。 这个门并未改变数值，也就是说逻辑功能上来讲和导线并未区别，但是一个电流在经过多个逻辑门以后电压难免会降低，但是电压又是用来表述0和1值的。为了位置数值不变即电压稳定，这个门可以为电流提供稳定的能量驱动，从而保障电流电压的稳定即数值的正确性。 逻辑电平 你可能会疑惑在逻辑门中如何区分传进来的值是0还是1。其实是通过电平的高低来区分。理想情况下使用离散电压来表示0和1，即各用一个电平值来表示。比如0V是0,5V是1，但是电平能量是连续的，肯定会存在4.99V，3.2V等，因此用离散电平来表示仅是理想情况，不易实现。所以一般使用一个区间来表示两个值，比如[0,2.5]的电平区间表示0，[2.6,5]的电平区间表示1，这样就可以用连续的电平来表示两个离散的二进制位数值0和1了。 噪声 任何使得信号衰减的事物都是噪声，例如给电源供电时耦合到传输线中的阻抗等就是噪声，如下图： 那么如果不巧刚好高电平的信号受噪声干扰降为了低电平，那么就相当于应该表示1的信号衰减为了0信号，这就是错误了。因此为了尽量避免这种情况，我们应该经过一段时间加入一个驱动Buf门来保证电平的稳定性。 类似的，传输信号的距离越长，也会导致信号衰减越强，因此每隔一段距离需要一个Buf。 静态约束 即为了保障有效的逻辑输入，所有的电路单元产生有效的逻辑输出，我们使用有线的电压范围来表示离散的数值1和0。如下图： 作为输出端高电平表示1的范围是VOH，低电平是VOL，然而其中间范围的空白区域既不用来表示1也不表示0，而是作为错误信号区域，这样，当输出的信号总是在空白区域及说明输出信号段器件已损坏，需要及时修复。而作为接收端，原理也类似，但是要注意接受端的高电平范围会更大即临界值更小，低电平范围也会更大即临界值更大。 VIH&gt;VOH,VIL&lt;VOLV_{IH}&gt;V_{OH},V_{IL}&lt;V_{OL} VIH​&gt;VOH​,VIL​&lt;VOL​ 原因很简单，因为噪声的干扰，可能高电平的信号会略微降低，低电平的信号略微增强，那么接收端可以适当的增大误差接受范围来保证信号的接受率。这里的误差范围： NMH=VOH−VIH,NML=VIL−VOLNM_H=V_{OH}-V_{IH},NM_L=V_{IL}-V_{OL} NMH​=VOH​−VIH​,NML​=VIL​−VOL​ 如果接收端的信号也常处于Fobidden Zone，那么需要增加Buf来稳定电平信号或者确定输出端器件完好。 这里我们可以轻松记住这几个信号值，VOH表示的是out出去的High电平，VIL表示的是in进来的Low电平。因此带O的都是输出端的，带I的都是接收端的。并且H表示高电平信号1，L表示低电平信号0。 思考：为什么中间要留白一部分范围？ 我们假设[0,2.5]为低电平信号，[2.6,5]是高电平信号，那么干扰信号的事物很多，可能有一些事物会降低电平信号，但是也有一些会增强电平信号。那么现在有一个2.54V的电平信号，我们就不好判断到底是本身就是高电平的2.54V信号，还是由2.49低电平信号受到噪声干扰增强到2.54V的信号了。因此中间有一个分割区是必须的。 直流传输特性 通过下图我们可以看出，左图是理想的电平信号，即0和1信号之间的电平是骤增的，这样就没有中间过渡变量信号值了，但是实际生活中，直流传输特性都是如右图的，所以我们需要用区间来划分高低电平信号。 并且误差区间NMH和NML一般不会大于VDD/2(VDD就是逻辑器件可表示的最大信号电平值，即表示范围的最大值）,即陡峭的部分一般不会过大。当然判断一个器件性能是否足够好，可以通过观察其从低电平到高电平的增长曲线斜率是否大（是否陡峭）。越陡峭表示误差范围越小，从低电平到高电平的增长越快，性能也就越好。 逻辑电平系列 逻辑器件系列 VDD VIL VIH VOL VOH TTL 5（4.75~5.25） 0.8 2.0 0.4 2.4 CMOS 5（4.5~6） 1.35 3.15 0.33 3.84 LVTTL 3.3（3~3.6） 0.8 2.0 0.4 2.4 LVCMOS 3.3（3~3.6） 0.9 1.8 0.36 2.7 CMOS晶体管 他是其中一种逻辑电平系器件，它是通过半导体来实现的。如下图： 类似的C,SI等都是半导体，他们是通过共用电子对连接的，稳定性强。共价键的强结合力，是原子排列规则，形成晶体。这样自由电子就很少，共价键中的两个电子都被紧紧束缚在共价键之中，称为束缚电子，常温下束缚电子很难脱离称为自由电子，因此本征半导体中（就是不含杂质的半导体）的自由电子很少，所以导电能力弱。 现在我们将一些C换成高价磷如下： 那么就会多出一个自由电子，这样磷原子就成了不能移动的带正电离子了，我们将次时的结构称为N型半导体。 思考：为什么是正电离子？ 虽然会有自由电子，但是我们想一想之前的P是2,8,5结构缺少三个电子，得到一个电子才会变为负离子，但是现在确实和其他的C原子共享了其中的4个电子，因此他呈现了正价+4。因此是正电，在英文中为Positive因此是P型半导体。 同样的我们也将一些C换成三价元素如硼或者铟等，那么就会少一个电子即为空穴如下： 那么此时的结构我们称为P型半导体。 思考：为什么是N型负电半导体？ 上图中的空穴位置画错了，应该是在硼原子旁产生一个空穴，由于他缺少一个电子和别人共享，所以会产生一个空穴，因此需要一个自由电子，所以刚好可以和P型半导体结合。空穴越多，他的导电性也就越强。和P型结构相反，因此是Negative即N型半导体。实际上此时空穴会向左移动和自由电子结合形成PN结。 PN结 那么我们在同一个半导体基片上，分别制造P型半导体和N型半导体，经过载流子的扩散，在他们的交界处就会形成PN结如下图： PN结正向偏置 那么我们知道随着越来越多的自由电子和空穴结合，在P,N中间区域就会形成许多PN结也就导致了导电性变差了，同时由于自由电子和空穴的减少，PN型半导体的导电性会减弱。因此PN型半导体导电性如果不在外界的影响下，导电性会逐渐自动变差。我们为了避免这种情况，维持其导电性，接入如下的电源： 那么PN半导体内自由电子会自动向右移动去和空穴结合形成PN结堆积在中间部分使得虚线包括部分逐渐变厚（因为有许多的自由电子和空穴形成的呈电中性的PN结）。但是现在我们加入了如上图的电源，其电流方向和半导体内的电流方向刚好相反，也就阻碍了PN半导体内的自由电子向右移动去和空穴集合，因此PN结会变少，中间部分也就会变薄，同时由于会PN结形成的少，说明空穴和自由电子也就更多，维持了PN半导体的导电性强。上图是PN结正向偏置。 PN结反向偏置 那么如果电源反接，那么就会促进PN结的形成，也就造成了中间部分变厚，同时PN半导体的导电性会加速削弱，如下图： 这是PN结反向偏置。我们发现上面两种情况都是PN解单向导电特性的体现。正反向偏置利用PN结单向导电性的特点可以实现半导体的功能，时而断点，时而通电。 半导体二极管 半导体二极管如硅二极管就是半导体正向偏置和反向偏置的应用。首先我们给出硅二极管伏安特性曲线： 也就是说明只有电压大于0.5V才能产生电流。那么导通时 就类似于电源闭合，允许电流通过，实际上就是半导体正向偏置维持其导电性所以可以通过电流。而截至时 就类似于电源断开，不允许电流通过。实际上就是半导体反向偏置加速了半导体导电性削弱直至到0，所以不允许通过电流。 类似的还有如下形式：MOS晶体管是多个PN结形成 nMOS 通电和断点就是使用Gate是否接入来决定导电性的，也就模拟出了半导体的特性。 pMOS 当然上面的是npn形式的我们称为nMOS，同样也有pnp形式的我们称为pMOS，只是Gate信号相反了如下： 一定要注意两个符号不一样，pMOS多了一个圈表示取反的意思，因此Gate信号功能刚好相反。那么两个晶体管的功能如下： 也就是nMOS可以更好的导电0信号,pMMOS导电1信号。他们两个组合就可以形成一个非门如下： 此时当输入信号为A时，那么nMOS关闭Gate，导致不导电0信号GND，而此时正相反pMOS打开Gate，可以导电高电平VDD，因此Y输出信号1，也就实现了非门的功能了。当然如果反一下，nMOS接VDD，pMOS接GND那么就是一个驱动BUF门了。 注意区分pMOS和nMOS的区别是有无圆圈，同时带三角的是GND低电平。 同样更复杂的连接还可以形成与非门： 此时两个pMOS并联为P1,P2分别受A,B控制，同时两个nMOS串联为N1,N2分别受A,B控制。那么只要N1,N2有一个Gate，那么就不能输出低电平，因此只有A=1&amp;B=1的时候才能输出低电平信号0，其他情况只要A=1||B=1，那么并联的P1,P2就可以输出高电平信号1。刚好满足与非门的功能，因此再复杂的门我们都可以通过不同的pMOS和nMOS来进行拼接组合表示出来。并且都是体现了半导体PN结单向导电的性质和正向偏置与反向偏置的应用。"},{"title":"硬件描述语言","path":"/wiki/数字逻辑与数字系统笔记/硬件描述语言/index.html","content":"硬件描述语言的起源 有名为HDL，是一种和C++,JAVA不同的硬件描述语言。他产生的原因是因为我们发现对于复杂逻辑的元件设计，使用卡诺图和组合逻辑电路很难实现，即使实现也会有许多细节上的纰漏，比如毛刺，延迟过大等问题，所以此时我们就需要学习硬件描述语言了。硬件描述语言和电子设计自动化工具搭配使用，可以轻松优化电路得到我们最满意的电路设计图。 我们首先要知道，HDL是具有特殊结构能够对硬件逻辑电路的功能和时序进行描述的一种高级编程语言，称之为硬件描述语言，他和我们之前学习的C++,JAVA等软件描述语言有以下的本质区别： 信号连接：硬件描述语言一般是使用涉及循环，变量等语句描述门元件之间的连接形式的，而软件描述语言不会涉及到底层门元件的连接的 功能时序：硬件描述语言反映了门元件的时序，延迟等信息，而软件描述语言不会考虑到这些问题 抽象层次：可以在多种层次上进行建模设计等，而软件描述语言仅仅限制于软件算法层 并行特性：和软件描述语言有很大不同，在HDL中，指令都是并行的，而不是串行的，因此指令的顺序并不会影响功能的实现 上图给出了两种不同的语言实现功能的方法，软件描述语言中是通过编译器将程序编译成01二进制代码来执行。而SystemVerilog(我们要掌握的一种硬件描述语言)编写的程序是通过综合器生成电路网表文件（即描述组合逻辑电路的文件）最终交给厂商去制造某一个元件。 我们前面提到过HDL可以在抽象层次上进行建模设计，如下图： 一个硬件描述语言可以在开关机，门级和寄存器传输级的任意一个层次上进行建模设计数字逻辑电路。而软件描述语言只能在算法级层次上进行设计。本次我们主要是学习在RTL寄存器传输级进行硬件描述语言应用的知识学习。 逻辑综合 在HDL中并不是所有语句都被综合形成描述逻辑电路的文件，只有一部分语句是被综合为逻辑电路的，称之为可综合HDL，而不能被综合的语句一般用于仿真验证（后面会讲到，实际上就是用来对设计的电路进行模拟测试的）。 一个门级网表的实现需要经过许多步骤，其中翻译，逻辑优化和实现与布局布线是非常重要的步骤，我们分别介绍： 翻译：翻译过程就是将RTL描述（即我们设计的语言程序）被EDA工具转换为一个未经优化的内部表示，不考虑目标工艺和设计约束。也就是仅仅将一个问题的解决办法生成为一个布尔表达式。 逻辑优化：取出冗余逻辑，使用大量与工艺无关的布尔逻辑优化技术，产生优化后的内部表示。即我们之前学到的卡诺图等优化方法将逻辑函数进行简化。 实现与布局布线：EDA工具接受内部表示，使用工艺库提供基本逻辑门进行实现，并根据设计约束进行优化。即使用代工厂（你可以理解为零件厂商）提供的门元件进行实现，这其中需要考虑成本，性能等问题来对设计进行约束优化（毕竟在实际电路实现中，并不是表达式越简越好）。 在实现与布局布线中我们发现有两个方面的内容，首先是工艺库，一般是由代工厂提供的门元件组成的标准单元库，我们在对设计进行实现和布局时要使用这些不同功能的门单元和宏单元（类似于一位加法器，乘法器等器件）。这些工艺元件由Foundry工厂提供，如：中兴国际（工艺在20nm左右），台积电（10nm左右），三星（10nm）和intel(7nm)。 注意英特尔虽然既设计电路，又提供实现电路的工艺元件，但是他只会为自己提供，即不为其他国家公司提供工艺库服务，所以虽然掌握最尖端的技术但是只是自己使用。 设计约束就是为了考虑整体电路性能（速度，工作频率），面积（成本）、功耗等外界因素对电路进行优化。 仿真验证 仿真验证实际上就是对我们设计的电路进行测试，以防出现漏洞或错误，但是我们不可能造出来这个门网表再进行测试，这样的话即使检测出来是有错误的也不能修改只能报废掉了，所以我们一般是使用虚拟仿真技术对我们设计的电路先进行测试。如下图： 在特定的时间将激励信号送入待测模块（DUT）的输入端口 EDA工具根据DUT的逻辑功能模拟信号在电路中的运算和传输过程 检查（人工或自动）输出相应以判断所涉及模块的功能是否正确 最终输出的信号是右图中脉冲形式的信号图 SystemVerilog HDL程序的基本结构 一个硬件描述语言创建的模块结构如下图： 这是一个二选一电路的模块功能的设计，我们发现其实和软件描述语言的函数很类似。他有以下几个特点： SystemVerilog HDL程序的文件名通常以扩展名.sv结尾 代码中第一行和第八行通过&quot;module…endmodule&quot;定义了一个名字为mux2的逻辑电路模块，该模块一共具有3个输入端口（由input定义）和1个输出端口（由output定义） 代码第三行定义了两个logic类型的中间变量（内部信号）a和b，实际上中间变量就类似于函数的局部变量，只能模块内部使用，不能作为对外输出使用。 代码中4-6行定义了模块mux2的逻辑功能，他是实现某个元件功能的核心语句部分 模块 模块是SystemVerilog的基本建模单位，他用于描述逻辑电路的功能，一个模块可以包括整个系统或者一部分，他的定义关键词就是一module开始，以endmodule结束。模块声明的格式是 1234module 模块名 (端口1，端口2,...);endmodule 注意没有大括号包裹，模块名是一个模块唯一的标识。 端口 端口是模块与外界进行通信的接口，他的定义需要指明四个要素（方向、类型、位宽、名字），其中类型和位宽可以缺省： input [类型] [位宽] 端口名1，端口名2，端口名3,… output [类型] [位宽] 端口名1，端口名2，端口名3,… inout [类型] [位宽] 端口名1，端口名2，端口名3,… input标识输入端口，output表示输出端口，inout表示双向端口。所有相同类型的端口都统一一起声明即可（都排列在一个关键字后面即可）。类型有logic等，位宽就是信号的位数，一般默认是1位，当然也可以声明为多位。端口的声明可以有多种方式，如下： 这三种都是正确的，也就是说在模块声明处可以将端口所有的属性全部声明完，也可以只声明一部分属性（但是无论如何端口名称必须在module声明语句中），然后再在内部对端口的方向，类型，位宽进行声明。 内部变量 上图中a和b都是内部变量，他们只在模块内部使用，主要是负责存储中间信号量，最终的输出信号需要若干个中间变量信号的逻辑组合来形成。 逻辑功能 逻辑功能的定义是一个模块中最核心的部分，明确了模块的行为和数据流动例如上面的4-6行，在SystemVerilog HDL中，定义模块的逻辑功能主要有两种建模（描述）风格： 行为建模：描述输入和输出之间的因果关系（其中又分为基于持续赋值语句的建模和基于过程语句的建模) 结构建模：调用其他已经定义过的模块对整个电路的功能进行描述。 在一个System HDL程序中，其代码模板如下： 要注意module语句后面是有分号的，而endmodule后面是不用分好的，其他中间的语句也是严格要求分号结尾的。 我们要注意声明部分必须写在逻辑功能定义部分的前面，而对于逻辑功能定一部分，由于HDL的并行性的特点，语句是并行的而不是串行的，因此语句之间的顺序并不会影响功能的实现，即下面的y定义语句也可以写在最前面： 但是为了便于我们理解，我们最好还是根据一定的逻辑顺序来构建代码。接下来我们再来学习以下HDL的语法要素。 HDL语法要素 间隔符和注释 即可以换行，他不会影响语句的实现，只是要注意语句的最后要加分号来表示一个语句的结束。一定的空格和换行使得代码风格优雅，同时注释规则和C一样，分为单行注释//和多行注释/*…*/。 标识符和关键字 接下来就是标识符和关键字，标识符用来给逻辑电路中的对象（如模块、输入和输出端口、中间变量）取名，规则和C一样，对字母大小写敏感。如： 关键字就是预留的表示特殊意义的字符串，用来定义语言的结构，通常是小写的，比如module,input,assign等。关键字不能作为标识符来使用。 逻辑值 在HDL中为了表示数字逻辑电路的逻辑状态，SystemVeilog规定了4种逻辑值，如下表： 逻辑值 电路的逻辑状态 0 逻辑零，逻辑假 1 逻辑1，逻辑真 x或X 不确定的值（未知状态） z或Z 高阻态（浮空） 一般情况下，逻辑门的输出端口产生0或者1，对于三态门，在非连通状态下输出为高阻态Z，对于正常的运行的电路，逻辑X是不能存在的，必须在设计时就杜绝（例如一个节点连接多个输出端口导致的信号线同时驱动两个不同值的情况）。 常量 SystemVerilog HDL有三种常量：整数型常量、实数型常量和字符串型常量，其中整数型常量是可以综合的。 整数型常量的格式如下： &lt;+/−&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt;&lt;+/-&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt; &lt;+/−&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt; 其中除了数值，其他项都可以缺省。&lt;+/-&gt;表示正负，&lt;位宽&gt;用10进制数来描述常量对应的二进制数的宽度，&lt;进制&gt;定义了整数型常量的进制格式，可以是二进制（用b或者B表示）、八进制表示（用o或O表示）、十进制数（用d或D表示)，十六进制（用h或者H表示），数值表示具体的取值，EDA工具按照无符号数进行处理，因此如果是二进制格式，可以是0,1,x和z,如果是十六进制格式，那么A-F不区分大小写。 如果常量带有负号，那么EDA工具按照有符号数的补码进行处理。 上图给出了部分常量的表示方法，一定要注意位宽一定是二进制表示的位数，而负数常量是要按照有符号数补码的格式在EDA中表示。求补码的方法见《机组原理》 为了增加数字的可读性，可以在数字之间增加下划线（类似于银行显示余额时使用的逗号），比如8’b1001_0011就是表示的位宽为8位的二进制常量数10010011。 并且如果没有给出位宽，那么该常量被指定为当前表达式的位数当位宽比数值的实际二进制位数少时，高位部分被舍去即截取时永远从低位向高位截取，当位宽比数值的实际二进制位数多时，那么高位补0。比如assign w=b1101(没有声明位宽)，那么如果w是2位，w=2’b01即只要低2位，当w时6位，那么w=6’b001101即高位补0，只有当w=4时，w=4’b1101。 注意低位截断时数值会发生变化可能不等于右侧表达式的值了，但是当位宽大于等于右侧表达式的长度时，那么数值并不会发生变化。 如果没有给出进制，那么默认是10进制，并且此时常量EDA工具将其作为有符号数，使用补码来处理。比如10=(01010)_补，-15=(10001)_补。 我们需要注意，某一个常量在电路中就是一个由0/1组成的二进制串，所以在电路层面并不会区分该常量是有符号数还是无符号数，或者是原码还是补码，这些信息都是由设计者或软件（EDA工具）负责解释的。比如： 数据类型 除logic外的其他变量类型，都属于二态类型（即只有0/1），如下所示： bit：定义1位信号 byte：定义8位信号（1个字节），类似于C/C++的字符型 shortint：用于定义16位信号，类似于C/C++的short类型 int：定义32位信号（即4个字节），类似于C/C++的int类型 bit和logic很像，标量信号和向量信号均可以定义，并且支持域选，但是bit类型只有0/1两种取值： 12345678//定义了两个16位的向量信号，每位只能是0或1//注意是16-0位，其实可以类比于数组bit [15:0] addrbus,databus;//定义了两个1位的标量信号，每位只能是0或1bit a,b;//域选就是截取，这里可以域选bit的15-7位//所以gugu向量信号的数值用addrbus的15-7位填充bit [8:0] gugu=addrbus[15:7]; byte、shortint、int都具有预定义向量宽度（即固定的位宽），所以定义变量时不能使用位宽，也不支持域选。 12345//正确，定义了两个32位的向量信号，每位只能是0或者1int addrbus,databus;//错误，不能使用位宽//int向量信号只能是32位int [16:0] addrbus; SystemVerilog HDL中的线网类型主要包括：wire,tri等。wire类型只能定义单源驱动信号，因为常使用logic来代替wire,在SystemVerilog中wire类型已经被弃用（但是端口信号默认为wire类型）。tri类型可以用于定义多源驱动信号，例如： 123module tristate(input logic a,input logic en,output tri y);\tassign y=en?A:1&#x27;bz;endmodule 思考：单源驱动信号和多源驱动信号的区别？ 单源驱动信号就是这个信号由一个输入信号来驱动，最常见的就是X-&gt;Y,因此wire信号完全可以用logic信号来代替，而多源驱动信号就是一个输出信号由多个输入信号决定，类似于{X1,X2}-&gt;Y。这种信号不同于前面讲到的常量信号，他可能会根据不同的情况变换，所以是多源线网型信号，需要使用tri来定义，很显然三态缓冲器和译码器等输出信号就是使用多源驱动信号。 tri类型信号的定义格式和logic几乎是一样的，支持域选和自定义位宽： 1234//定义了两个16位的tri类型向量信号tri[15:0] addrbus,databus;//支持域选out[3:0]=addrbus[7:4] 运算符 先给出所有的运算符的含义和优先级。然后我们讲解几种细节问题： 当两个位数不同的操作数进行单符号位运算时表示的是按位进行处理，位数少的操作数需要进行零扩展到相同位数，比如： a=4’b1011 b=8’b01010011 那么c=a|b时，a需要先零扩展为8’b00001011 我们之前学过这种按位的操作总是需要两个操作数，比如a&amp;b,a^b等，但是在SystemVerilog HDL中也可以是单操作数自己进行这种运算，即为缩减运算，他的特点就是将操作数的各个位之间进行或，与等操作，最终一个很长位数的操作数就会变成一位数，比如： 12345module and8(intput logic [7:0]a,output logic y);\tassign y=&amp;a;\t//那么就等同于下面的操作\t//assign y=a[7]&amp;a[6]&amp;a[5]&amp;a[4]&amp;a[3]&amp;a[2]&amp;a[1]&amp;a[0];endmodule 假设a是10000000，那么最终的y输出信号就是0，如果a是11111111，那么y就是1。类似的还有|a等。 而当使用的是多符号是那么是将两个数的真值进行处理，并且所有非零的真值数都是按照1处理，零真值是0。比如： 在SystemVerilog HDL中还会经常使用到算术运算，算术运算包括加减乘除，其中除和取模是不可综合的。并且当两个位数不同的操作数进行算术运算时，如果操作数是无符号数，那么位数少的进行零扩展即可，如果操作数是有符号数，咋位数少的操作数需要进行位数扩展到相同位数。比如： 移位运算实际上和计算机系统基础中的移位操作相同，规则： 逻辑左移：将操作数无符号数左移若干位，右侧产生的空余位使用0填充 逻辑右移：将操作数无符号数右移若干位，左侧产生的空余位使用0填充 算术左移：将操作数有符号数左移若干位，右侧产生的空余位使用0填充 算术右移：将操作数有符号数右移若干位，左侧产生的空余位使用符号位填充 关系运算就是比较大小然后返还0/1（假/真）。注意如果表达式中有一个操作数为无符号数，那么表达式的其余操作数均会被当做无符号数进行处理： 123456//-3和5都是有符号数(前面讲过10进制数默认是按有符号数处理)(-3*5)&lt;10//4&#x27;d5是无符号数，所以-3的二进制串也被当为无符号数处理//(-3)_补=(1101)_补，那么作为无符号数被处理为13//13*5=65&gt;10(-3*4&#x27;d5)&lt;10 再次强调，在SystemVerilogHDL中所有的数最终都是在硬件上进行二进制运算，所以这里的-3,5等都只是一个符号，他不能说明值是多少，最终数值都是取决于他们的二进制01串被处理后得到的真值。还有就是在HDL中没有true和false布尔值，都是用1来代表真，0代表假。 当然HDL中也存在条件运算–三目运算。和C的一样： 123module mux2(intput logic [3:0]d0,d1,intput logic s,output logic [3:0] y);\tassign y=s?d1:d0;endmodule 这里再介绍一下特有的位混合（拼接）和复制运算，说来也简单，位混合运算就把多个信号的某些位拼接起来形成新的信号。格式为： {信号1[n1:m1],信号2[n2:m2],...,信号n[nn:mn]}\\{信号1[n_1:m_1],信号2[n_2:m_2],...,信号n[n_n:m_n]\\} {信号1[n1​:m1​],信号2[n2​:m2​],...,信号n[nn​:mn​]} 位混合运算中的每一个操作数必须是确定位宽的数，不允许出现未指定位宽的常数。如果要多次拼接同一个操作数可以使用复制运算，格式为 {n{A}}\\{n\\{A\\}\\} {n{A}} 我们来看几个例子： 小练习"},{"title":"逻辑电路的表达式","path":"/wiki/数字逻辑与数字系统笔记/逻辑电路的表达式/index.html","content":"晶体管功耗 功耗就是单位时间内消耗的能量，这里分为两种：静态功耗和动态功耗。 动态功耗 对栅极电容进行充电所消耗的能量，对电容充电到电压VDD所消耗的能量为CVDD^2即： Pdynamic=1/2∗C∗VDD2fP_{dynamic}=1/2*C*V_{DD}^2f Pdynamic​=1/2∗C∗VDD2​f 其中C就是电容，单位法拉第，当晶体管以频率f来工作，充电的消耗为f/2，放点的频率也是f/2，因为放电过程不需要消耗能量，因此动态功耗中还乘了一个1/2f。 静态功耗 当系统处于空闲状态时，晶体管处于截止状态，单仍然会泄露少量的电流，因此会产生静态功耗，静态功耗由电源和地直接的漏电流IDD产生，正比于漏电流。公式如下： Pstatic=IDD∗VDDP_{static}=I_{DD}*V_{DD} Pstatic​=IDD​∗VDD​ 思考：对比前面学到的PN结知识，我们可以怎样理解动态功耗和静态功耗？ 动态功耗充电就是可以看成借助外界力量解除堆积的PN结，从而增强导电能力，而静态功耗就是可以看成自然状态下自动向PN结形成的过程，他会产生微小电流也就是漏电流同时由于产生PN结从而降低了导电能力。 例题 估算如下无限手持设备的功耗，假如此时VDD=1.2V,C=20nF,f=1GHz,IDD=20mA。那么晶体总功耗是多少？ Pdynamic=1/2∗C∗VDD2f=1/2∗(20nF)∗(1.2V)2∗(1GHz)P_{dynamic}=1/2*C*V_{DD}^2f=1/2*(20nF)*(1.2V)^2*(1GHz) Pdynamic​=1/2∗C∗VDD2​f=1/2∗(20nF)∗(1.2V)2∗(1GHz) Pstatic=(20mA)∗(1.2)VP_{static}=(20mA)*(1.2)V Pstatic​=(20mA)∗(1.2)V P=Pdynamic+Pstatic=14.4WP=P_{dynamic}+P_{static}=14.4W P=Pdynamic​+Pstatic​=14.4W 数字逻辑电路 数字逻辑电路是一个可以处理离散值变量的网络。它主要是使用一种逻辑门电路图来显示各种逻辑计算的实现原理，例如我们上面画的非门和异或门的图就是数字逻辑电路。数字逻辑电路具有如下几个特点： 一个或多个离散值输入端 一个或多个离散值输出端 描述输入和输出关系的功能规范 描述当输入改变时输出相应延迟的时序规范 结点和模块 电路由结点和模块组成，结点是一段导线，通过电压传递离散值变量，结点可以分为如下几种： 输入结点：接收外部的值，比如上图中的A,B,C是三个输入结点，个输如一个0/1信号值 输出结点：输出值到外部，是输入信号经过门电路处理后输出的离散值信号 内部节点：不属于以上两者的结点，比如n1 模块本身是一个带有输入、输出、功能规范和时序规范的电路（注意buf逻辑也是一个模块，它具有驱动的功能）。每一个电路都是一个电路，一般会有逻辑门组合，例如上图中的E1,E2,E3。 数字逻辑电路的分类 组合逻辑电路 任一时刻的输出仅由该时刻的信号决定 无记忆的，与电路状态无关 时序逻辑电路 任一时刻的输出由该时刻的输入和电路该时刻的状态共同决定 具有记忆性，与电路状态有关 思考：组合逻辑电路与时序逻辑电路的延迟？ 首先我们需要明确无论是哪种逻辑电路，都是一定会有延迟的即输出会晚于输入一段时间才输出，因为都需要通过逻辑门对输入进行处理才可以输出。但是组合逻辑电路无外界或电路状态的影响，会随着输入信号即刻改变，例如非门，当输入信号为0，那么输出信号就是1，但是一旦输入信号改变成了1，那么输出信号也会立刻改变成1，所以不会受到电路状态的影响。而对于时序逻辑电路，例如一个时序逻辑模块的功能是对于输入信号A和B，只有当B信号为1时才可以对A信号取非，那么此时即使A传进来1了，也需要等待电路状态改变成接收到了B信号1才可以对A进行信号取非，即此时会受到电路状态影响，同时如果此时B不为1，那么模块也会记录输入信号A为1，所以有记忆性。 一定要注意基本上每一个模块都是一个组合逻辑模块（毕竟一般是多个逻辑门的组合，功能会复杂）。如下图： 对于组合逻辑电路，每一个电路节点或者叫线交汇点只可能是两种情况：①电路的输入结点②只连接电路模块的一个输出端。毕竟如果一个电路结点连接着两个输出端的话，当两个输出不同即一个信号为1一个信号为0时，那么交汇结点就会出现信号冲突。 并且要注意电路中应该不能存在回路，因为也可能会造成信号冲突。 组合逻辑电路的错误状况 图二错误，就是因为存在回路可能会造成冲突。比如假设此时传入的两个信号都是1，那么经过异或门后应该输出的是0，但是还有一部分1信号却通过短接的回路到达了输出导线上，那么此时输出导线上同时有接收到的0和1会产生信号冲突，所以不正确。 图四错误，由于一个结点接受了两个输出端的信号，可能会产生信号冲突。 图六也是错误的，由于有回路同样也有可能会产生信号冲突（分析一下就很容易知道）。所以数字逻辑电路中是坚决要避免回路或者连接多个输出端的结点的。 布尔代数的定义 我们在前面也知道了数字逻辑电路通过不同门组成了有不同功能的模块，每一个模块实际上就是使用的0/1信号的逻辑运算来模拟各种复杂的数学计算的。（如果学习了机组原理，我们知道实际上ALU中的一位加法器也是使用的各种逻辑门实现的）。那么明显布尔代数对于数字逻辑电路的规划设计很重要，所以我们详细介绍一下布尔代数。在布尔代数中变量只能取&quot;真&quot;或者&quot;假&quot;。1代表的就是真，0代表的就是假。并且有三种最基本的逻辑运算： 与运算：A·B或者AB 或运算：A+B 非运算：—A（假装横线在A上面） 布尔表达式 实际上就是一些布尔代数的复杂运算表达公式，一般是来描述组合逻辑电路中输入与输出之间的功能规范的。比如： 实际上我们不难发现上面的这个布尔表达式就是模拟的加法。这种加法运算实际上已经是需要复杂的布尔表达式来表示的了。 布尔代数的公理 下面我们给出以下布尔代数常用的公理，理解最重要： 对偶规则 F为任意逻辑表达式，若将F中所有运算和常量作如下变换： 所得到的的新的表达式就是F的对偶式F’，比如： 我们发现就是分别将数值和符号进行了上面的对偶规则的改变，那么我们可以得出以下结论: 对偶式相互的，F和F’互为对偶式 对偶规则：两个逻辑表达式F和G相等，那么对偶式F’和G’也是相等的 一定要注意对偶规则不是逻辑表达式的整体取反，他是在原有的顺序不变的基础上，对于每一个元素进行了逻辑取反。其主要是为了使用第二个特点来描述两个表达式的内在关系。 单变量定理 那么对于上面这几种定理，我们都可以使用组合逻辑电路表示： 如果你对门的符号还不太熟悉，请快速跳转《机组原理门符号》 多变量定理 这部分就有点难理解了，可能需要思考一段时间或者画韦恩图分析。一定要注意这里的值只能取0或1，所以上面的吸收律等才可以成立。 思考：上面的一致律如何推得的？ 我们以左边的式子为例： 实际上就是补1法，缺哪个就用X+非X补。右边的式子也类似，我就不讲解了。同样的买也可以使用组合逻辑电路表示： 最小项 最小项就是一种特殊的乘积项（或者叫做&quot;与&quot;项）。即元素之间只能是乘积，并且还要求对于n个变量逻辑函数的每一个最小项，必须同时包含有n个因子的乘积，即各个最小项中，每一个变量必须以原变量或者反变量形式作为因子出现一次，而且仅出现一次，（毕竟n个变量只够每一个变量因子出现一次）。 如上面，都是最小项，我们就可以理解每一个元素因子为什么只能出现一次了，如果有一个元素出现了两次，那就必定有一个元素没出现过，那么就不是最小项了，因为最小项要求n位最小项必须由n个元素。并且我们可以知道： 最小项个数=2n(n是元素种类数)最小项个数=2^n(n是元素种类数) 最小项个数=2n(n是元素种类数) 最小项的编号 最小项用mi来编号（i从0开始递增），最小项的编号值是由使最小项取值为1决定的，比如： 那么很明显编号为零的就会非A非B非C，只有三个元素取值都为0整体才为1。这里我们给出三变量的最小项： 我们不难看出每一个最小项只有一组变量能使其值为1，而其他各组取值该最小项都为0.由于这种函数真值表中1的个数最少，因此称为最小项。 最小项的性质 性质1 变量任取一组值，仅有一个最小项为1，其他最小项为0 性质2 n变量的全体最小项（共有2^n个)之和为1，毕竟有一个最小项会为1，那么整体之和就是1了。 ∑n=02n−1mi=1\\sum_{n=0}^{2^n-1}{m_i}=1 n=0∑2n−1​mi​=1 性质3 n个变量任意两个不同的最小项相与，结果恒为0，毕竟每次只有一个最小项为1，其他最小项都是0，所以取交就是0。 性质4 如果两个最小项仅有一个变量因子不同，那么我们就成这两个最小项相邻。两个最小项相邻，相邻最小项相或，可以合并成一项，并且可以消去一个变量因子，比如： 性质5 任一n变量的最小项，必定有n个不同最小项相邻（即n位变量因子有一个取反就成为了他的相邻最小项），比如： 最大项 最大项是一种特殊的和项（又称为&quot;或&quot;项）。即元素之间只能是或，并且还要求对于n个变量逻辑函数的每一个最大项，必须同时包含有n个因子的或，即各个最大项中，每一个变量必须以原变量或者反变量形式作为因子出现一次，而且仅出现一次，（毕竟n个变量只够每一个变量因子出现一次）。比如： 最大项的编号 最大项用Mi来编号（i从0开始递增），最大项的编号值是由使最大项取值为0决定的，比如： 如上面，都是最大项，我们就可以理解每一个元素因子为什么只能出现一次了，如果有一个元素出现了两次，那就必定有一个元素没出现过，那么就不是最大项了，因为最大项要求n位最小项必须由n个元素。并且我们可以知道： 最大项个数=2n(n是元素种类数)最大项个数=2^n(n是元素种类数) 最大项个数=2n(n是元素种类数) 其实和最小项的结论很相似。可以对比着记忆。 那么很明显编号为零的就会ABC，只有三个元素取值都为0整体才为0。这里我们给出三变量的最大项： 每一个最大项只有对应的一组变量取值为0，而其他各组取值该最大项都为1.由于这种函数真值表中1的个数最多，因此称为最大项。 最大项的性质 性质1 变量任取一组取值，仅有一个最大项为0，其他最大项为1 性质2 n变量的全体最大项之和为0（毕竟有一个最大项取值为0，那么整体就是0了）。 ∏n=12n−1Mn=0\\prod_{n=1}^{2^n-1}{M_n}=0 n=1∏2n−1​Mn​=0 性质3 不同的最大项相或结果为1，毕竟每一次只有一个最大项取值为0，其他的最大项取值都是1，所以取或就是1。 性质4 两个最大项如果仅有一个变量因子不同，其他变量均相同，则称这两个最大项相邻。两个相邻的最大项相&quot;与&quot;，可以合并成一项（等于相同因子之和），并且可以消去一个因子。 性质5 任一n变量的最大项，必定有n个不同的相邻最大项（n位中任意一个变量因子取反就是一个相邻最大项）。 最小项和最大项的关系 编号下标相同的最小项和最大项互为相反数，即 Mi=mi‾或者mi=Mi‾M_i=\\overline{m_i}或者m_i=\\overline{M_i} Mi​=mi​​或者mi​=Mi​​ 标准与或式 由最小项之和构成且最小项之间取或的运算逻辑表达式，如下： 我们可以使用编号和运算求和符号来简写表达式。那么他的真值表如下： 我们发现有如下几个特点： 每一个最小项都对应真值表中值为1的一行 标准与或式是最小项之间的或运算，不存在其他运算 标准与或式与真值表间一一对应 从标准与或式中可以直接判断哪些变量取值可以使表达式为1（就是有一个最小项取1的时候可以使表达式值为1） 我们发现一个规律：任一逻辑函数都可以表达为最小项之和的形式，而且是唯一的，比如： 标准或与式 由最大项之积构成且最大项之间取乘积的运算逻辑表达式，如下： 我们可以使用编号和运算求乘积符号来简写表达式。那么他的真值表也和标准与或式一样有以下几个特点： 每一个最大项都对应真值表中值为0的一行 标准或与式是最大项之间的与运算，不存在其他运算 标准或与式与真值表间一一对应 从标准或与式中可以直接判断哪些变量取值可以使表达式为0（就是有一个最大项取0的时候可以使表达式值为0） 我们同样发现一个规律：任一逻辑函数都可以表达为最大项之积的形式，而且是唯一的，再联系任一一个逻辑函数也可以唯一表示成一个标准与或式，所以我们可以推出一个结论，相同的逻辑函数对应的标准与或式和标准或与式可以互相转化。 标准与或式和标准或与式的关系 那么我们接下来就给出他们之间转换的关系公式： F=∑imi=∏j≠iMjF=\\sum_{i}{m_i}=\\prod_{j≠i}{M_j} F=i∑​mi​=j=i∏​Mj​ 证明如下： 那么也就是说对于3位逻辑表达式F如果标准与或式使用了编号1,3,7的最小项，那么标准或与式就是用了编号0,2,4,5,6的最大项。 一定要求是标准与或式或者标准或与式，如果不是，那么需要用补1法进行变换使之转化成标准式。 布尔表达式到真值表的转化 我们对于一个布尔表达式，可以将它表示为标准式，然后使用编号就可以轻易求得一个式子取得不同值所需要的变量组了。比如： 我们将这个非标准化布尔表达式首先用补1法转换成标准式，然后转换成标准与或式，那么编号有3,6,7的最小项，所以只有ABC取011,110和111时可以使表达式为1，其他情况都是0，并且是3位表达式，所以一共真值表有8行对应8个情况： 我们可以用标准或与式再求解以下上面的布尔表达式，那么F就会转化成标准或与式： ∏M(0,1,2,4,5)\\prod{M(0,1,2,4,5)} ∏M(0,1,2,4,5) 那么也就是说当ABC,000，001,010,100,101的时候表达式会为0，其他情况为1，发现和上面的真值表一样。这样我们也就证明了标准与或式和标准或与式的转换定理是正确的。"},{"title":"创建型模式","path":"/wiki/设计模式笔记/创建型模式/index.html","content":"概念介绍 首先我们要知道设计模式传授的是前辈对23种复杂应用场景下最优策略的经验总结，他们是一种编程的套路，而不是语法规定，我们在学习应用23种设计模式之后可以提高代码的可复用性和可维护性。 总体上我们可以将23种设计模式划分成三类： 创建型模式(5)：单例模式、工厂模式、抽象工厂模式、建造者模式、原型模式 结构性模式(7)：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式 行为型模式(11)：模板方法模式、命令模式、迭代器模式、观察者模式、中介模式、备忘录模式、解释器模式、状态模式、策略模式、职责链模式、访问者模式。 他们无一例外都在尝试使得我们的代码符合以下7大原则： 原则名称 原则内容 开闭原则 对扩展开发，对修改关闭 里氏替换原则 继承必须确保父类所拥有的的性质在子类中仍然成立 依赖倒置原则 要面向接口变成而非面向实现编程 单一职责原则 控制类的粒度大小，将对象解耦，提高内聚性 接口隔离原则 要为各个类建立他们需要的专用接口 迪米特原则 只与你的直接朋友交谈，不跟陌生人说话 合成复用原则 尽量使用组合或者聚合关联关系来实现，其次才考虑使用继承关系来实现 创建型模式 由于篇幅有限，我将分成三章来记录设计模式的学习笔记，本章先介绍5大创建型模式，他的主要关注点都是“如何创建对象”，主要目标就是让对象的创建和对象的使用分离。在创建型模式中，使用者不需关注创建的细节，对象的创建由相关的工程来完成。 我们首先给出5大创建型模式的特点，方便我们在学习时随时尝试感悟他们的特点： 单例模式：某个类使能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式 工厂方法模式：定义一个用于创建产品的接口，由子类决定生产什么产品，即局限于一种产品的创建 抽象工厂模式：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品，即可以生产多种不同的产品 建造者模式：将一个复杂的对象拆解成相对简单的部分，然后根据不同需要分别创建他们，最后构建该复杂对象。 原型模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例 以上的5中创建型模式，除了工厂方法模式属于类创建型模式，其他的全部属于对象创建型模式。 单例模式 单例模式是比较简单的一种创建型模式，我们仅仅针对内存的占用以及线程安全性两方面来学习单例模式。 首先我们观察以下代码，他被称为饿汉式单例，原因是一旦他被创建立刻会占用相对应大小的内存，类似于饿汉疯狂吃内存： 1234567891011121314151617181920//饿汉式单例public class Hungry &#123; //假设他有以下成员数组变量 private byte[] arr1 = new byte[1024 * 1024]; private byte[] arr2 = new byte[1024 * 1024]; private byte[] arr3 = new byte[1024 * 1024]; private byte[] arr4 = new byte[1024 * 1024]; //构造器为私有，只能自己创建保证了全局只有一个实例即单例 private Hungry() &#123; &#125; private final static Hungry h = new Hungry(); //一个对外公开的接口提供单例的调用 public static Hungry getInstance() &#123; return h; &#125;&#125; 上面的代码是一个饿汉式单例的创建类，此时他有4个byte数组，并且每一个byte数组都是1MB大小，那么此时当饿汉式创建后就已经占用了4MB的内存了，即使此时可能还没有其他模块会调用这个单例，因此此时的代码并不完美，最好是再有其他模块调用这个单例时我们再初始化这个单例的内存空间。因此出现了下面的更加完美的懒汉式单例创建: 12345678910111213141516171819202122232425262728293031323334/懒汉式单例模式，有名为DLC单例public class Lazy &#123; //假设他有以下成员数组变量 private byte[] arr1 = new byte[1024 * 1024]; private byte[] arr2 = new byte[1024 * 1024]; private byte[] arr3 = new byte[1024 * 1024]; private byte[] arr4 = new byte[1024 * 1024]; private Lazy() &#123; System.out.println(Thread.currentThread().getName() + &quot;ok&quot;); &#125; //先创建的，但是并没有初始化，因此此时l是null不占用很大的空间 private static Lazy lazy; public static Lazy getInstance() &#123; //当外部模块调用这个单例对象时再进行初始化 if (lazy == null) &#123; l = new Lazy(); &#125; return lazy; &#125; //但是多线程并发情况下有问题 public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i ++) &#123; new Thread(() -&gt; &#123; lazy.getInstance(); &#125;).start(); &#125; &#125;&#125; 上面的代码就是饿汉式单例模式的，但是他只在单线程情况下完美运行，我们发现此时多线程运行时会出现错误，原因是多个线程并发情况下会造成访问冲突同时调用getInstance()并且此时在每一个线程的视角下l都是未初始化的，因此许多线程进行初始化造成了错误，因此我们需要在源代码的基础上上锁，保证当l未初始化时只会有一个线程对这个l进行初始化，而其他的线程则等待初始化后直接获取即可： 123456789101112public static Lazy getInstance() &#123; //当外部模块调用这个单例对象时再进行初始化 if (lazy == null) &#123; synchronized (Lazy.class) &#123; //双重null判断加快效率 if (lazy == null) &#123; lazy = new Lazy(); &#125; &#125; &#125; return lazy; &#125; 此时理论上没有问题了，但是我们运行以后发现结果是只有一个线程运行成功了如下图： 这是因为涉及到了指令重排的问题，一个实例的创建（即new的过程)并不是一个原子事务，它是由一下三个步骤完成的： 分配内存空间 执行构造函数，初始化对象 将对象引用指向预分配的空间 正常情况下cpu并不会真正的按顺序执行，他会有指令重排的情况，即可能这个实例的创建初始化过程的顺序是132或者123，或者213。那么假设此时线程A先调用了getInstance()方法发现lazy是null，于是尝试new这个实例，但是new的过程中cpu进行了指令的重排造成按照132的顺序执行了。但是A刚刚执行到3的步骤，此时已经分配了空间并且先占用了这个空间，还差构建实例到这个内存空间的步骤。恰巧此时线程B也调用了getInstance()方法，由于synchronized是根据空间是否已经创建占用来判断的，因此此时虽然内存空间内还没有创建初始化真正的实例，但是从synchronized视角来看空间已经被占用，那么线程B就会认为此时lazy已经创建完成了于是走return路线，可是此时A还并没有初始化这个lazy对象，造成了线程B返回的是一个虚无实例造成异常。因此我们需要保证线程在new这个实例时必须是禁止指令重排的，只需要在创建语句中加入volatile关键字即可，因此最终完美的懒汉式单例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839//懒汉式单例模式，有名为DLC单例public class Lazy &#123; //假设他有以下成员数组变量 private byte[] arr1 = new byte[1024 * 1024]; private byte[] arr2 = new byte[1024 * 1024]; private byte[] arr3 = new byte[1024 * 1024]; private byte[] arr4 = new byte[1024 * 1024]; private Lazy() &#123; System.out.println(Thread.currentThread().getName() + &quot;ok&quot;); &#125; //先创建的，但是并没有初始化，因此此时l是null不占用很大的空间 private static volatile Lazy lazy; public static Lazy getInstance() &#123; //当外部模块调用这个单例对象时再进行初始化 if (lazy == null) &#123; synchronized (Lazy.class) &#123; //双重null判断加快效率 if (lazy == null) &#123; lazy = new Lazy(); &#125; &#125; &#125; return lazy; &#125; //此时多线程情况下就没有问题了 public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; lazy.getInstance(); &#125;).start(); &#125; &#125;&#125; 我们一定要时刻注意单例模式中实例只能创建一次，所有的模块通过一个对外开放的接口来调用这个单例进行接下来的操作。 工厂模式 工厂模式主要特点就是实现了创建者和调用者的分离。在介绍工厂模式之前，我们先介绍一下简单工厂模式，简单工厂模式就是类似工厂的一种开发模式，但是特并没有满足开闭原则。而工厂模式就是对简单工厂模式的改进，首先我们先来通过下面的代码了解一下简单工厂模式： Consumer.javaCar.javaWuLing.javaTesla.javaCarFactory.java12345678910111213141516171819202122public class Consumer &#123; public static void main(String[] args) &#123; //原先如果要购买两辆车，需要如下声明 //需要了解所有的先关的车接口和实现类 //相当与自己创建车 //每次创建参数都要重新再填写一次// Car car1 = new WuLing(200, 30000, 2);// Car car2 = Tesla(280, 40000, 6);;//// car1.name();// car2.name(); //现在我们只需要调用CarFactory的接口即可获取 //可以和显示生活中的购买车类比 //车工厂负责造车，消费者只买车 //简化了多次填写重复参数的过程 Car car3 = CarFactory.getCar(&quot;五菱&quot;); Car car4 = CarFactory.getCar(&quot;特斯拉&quot;); car3.name(); car4.name(); &#125;&#125; 1234//抽象接口，不写具体的实现public interface Car &#123; void name();&#125; 12345678910111213141516public class WuLing implements Car &#123; @Override public void name() &#123; System.out.println(&quot;五菱宏光!&quot;); &#125; private int weight; private int price; private int capacity; public WuLing(int weight, int price, int capacity) &#123; this.weight = weight; this.price = price; this.capacity = capacity; &#125;&#125; 12345678910111213141516public class Tesla implements Car &#123; @Override public void name() &#123; System.out.println(&quot;特斯拉!&quot;); &#125; private int weight; private int price; private int capacity; public Tesla(int weight, int price, int capacity) &#123; this.weight = weight; this.price = price; this.capacity = capacity; &#125;&#125; 1234567891011public class CarFactory &#123; public static Car getCar(String car) &#123; if (car.equals(&quot;五菱&quot;)) &#123; return new WuLing(200, 30000, 2); &#125; else if (car.equals(&quot;特斯拉&quot;)) &#123; return new Tesla(280, 40000, 6); &#125; else &#123; return null; &#125; &#125;&#125; 我们发现这种类似于工厂的代码开发模式有一个非常显著的特点，那就是new创建的过程和调用是分离，当我们需要一台新车的时候，并不需要自己去new来创建一个车，而是直接从CarFactory工厂提供的getCar()接口取提车即可。但是这又和普通的new有什么区别呢？我们观察上面的代码发现此时WuLing和Tesla的构造器需要传递三个参数，这是因为车的幸好总是在发生变化，很显然我们在创建车时需要给出车的参数，但是实际生活中我们往往需要传递上万个参数，那么此时这种简单工厂模式的优点就很明显了，在CarFactory我们只需要填写一次参数即可，而相比于多次new都需要再填写以便上万个参数，很显然这种模式更加人性化，并且后期代码进行参数修改时也很简单，只需要修改CarFactory的构造器的参数即可。 思考：简单工厂模式有没有什么缺陷？ 我们发现我们是在CarFactory中对传进的车型进行判断，然后调用对应的车构造器来创建车再返还的，那么当需要添加1000+种不同的车型时，那么我们需要在这个类中写上万个同级的if-else判断！！很显然这是典型的判断膨胀现象，既不优雅也不高效。同时简单工厂模式也并不符合开闭原则，即假设此时我们需要再加入一个新的车型大众时，那么我们需要修改原先写好的CarFactory类，扩展性并不好，因此产生了下面更加优秀的工厂方法模式。 我们简单的绘画一下简单工厂模式图： 此时我们是通过车工场进行判断然后车工场来生产不同的车返回给我们消费者，全过程中我们消费者并不需要关心车的具体构建，但是此时我们要新添加一个车型，势必要修改车工厂的，为了解决这个违背开闭原则的缺陷，我们并不能直接对车工厂进行修改，解决策略就是对车工厂在进行一层封装如下图： 这个更加符合现实生活中生产商的情形，即不同的车型都有自己的工厂，消费者提取不同的车只需要去不同的车工厂提车即可，此时当我们再新添加大众品牌车时，很显然我们并未对其他的工厂类进行修改，满足了开闭原则。那么接下来我们就给出代码： Consumer.javaCar.javaCarFactory.javaWuling.javaTesla.javaWulingFactory.javaTeslaFactory.java1234567891011public class Consumer &#123; public static void main(String[] args) &#123; //获取不同类型的车 Car car1 = new WulingFactory().getCar(); Car car2 = new TeslaFactory().getCar(); car1.name(); car2.name(); &#125;&#125; 1234//抽象接口，不写具体的实现public interface Car &#123; void name();&#125; 123public interface CarFactory &#123; Car getCar();&#125; 12345678910111213141516public class WuLing implements Car &#123; @Override public void name() &#123; System.out.println(&quot;五菱宏光!&quot;); &#125; private int weight; private int price; private int capacity; public WuLing(int weight, int price, int capacity) &#123; this.weight = weight; this.price = price; this.capacity = capacity; &#125;&#125; 12345678910111213141516public class Tesla implements Car &#123; @Override public void name() &#123; System.out.println(&quot;特斯拉!&quot;); &#125; private int weight; private int price; private int capacity; public Tesla(int weight, int price, int capacity) &#123; this.weight = weight; this.price = price; this.capacity = capacity; &#125;&#125; 12345public class WulingFactory implements CarFactory &#123; public Car getCar() &#123; return new Wuling(200, 30000, 2); &#125;&#125; 123456public class TeslaFactory implements CarFactory &#123; public Car getCar() &#123; return new Tesla(280, 40000, 6); &#125;&#125; 上面的代码就是工厂方法模式的代码，他对简单工厂模式进行了优化，现在就符合了开闭原则了，但是这又会导致另一个问题即类膨胀，此时每一个相似结构不同类型的产品都需要一个自己的工厂类，会导致出现许多功能类似的工厂，但是当代码量很大时，这种工厂方法模式整体来看性能还是较优的。 抽象工厂模式 前面我们所学习的简单工厂模式和工厂方法模式都是针对同一个产品的开发模式，只是工厂方法模式的可扩展性更强。那么假设我们现在需要一种可以生产许多种产品的工厂又该如何实现呢？此时就产生了抽象工厂模式的概念，实际上可以把他理解成一种生产工厂的工厂，如下图是一个基于抽象工厂模式的生产手机产品和路由器产品的工厂示例： 此时我们发现每一个工厂不再只能生产一种产品了，而是许多产品了。即在抽象工厂模式中可以提供了一个创建一系列相关或者相互依赖对象的接口，无需指定他们具体的类。在用代码实现应用场景之前，我们来理解一下产品族和产品等级的概念： 即所有属于同一品牌的产品是同一个产品族的，但是不同类型的产品是属于不同的产品等级。那么我们可以将抽象工厂模式理解为此时的具体工厂可以生产同一个产品族了而不再是单一产品了。而抽象工厂是定义具体工厂可以生产的产品等级的工厂。如下代码： Consumer.javaIphoneProduct.javaIRouterProduct.javaIProductFactory.javaXiaomiphoneXiaomirouter.javaHuaweiphone.javaHuaweirouter.javaXiaomiFactory.javaHuaweiFactory.java1234567891011121314151617181920212223242526272829public class Consumer &#123; public static void main(String[] args) &#123; System.out.println(&quot;小米系列产品&quot;); //小米工厂 XiaomiFactory xiaomiFactory = new XiaomiFactory(); //获取一台小米手机 IphoneProduct iphoneProduct1 = xiaomiFactory.iphoneProduct(); iphoneProduct1.callUp(); iphoneProduct1.sendSMS(); //获取一台小米路由器 IRouterProduct iRouterProduct1 = xiaomiFactory.routerProduct(); iRouterProduct1.openWifi(); iRouterProduct1.setting(); System.out.println(&quot;华为系列产品&quot;); //华为工厂 HuaweiFactory huaweiFactory = new HuaweiFactory(); //获取一台华为手机 IphoneProduct iphoneProduct2 = huaweiFactory.iphoneProduct(); iphoneProduct2.callUp(); iphoneProduct2.sendSMS(); //获取一台华为路由器 IRouterProduct iRouterProduct2 = huaweiFactory.routerProduct(); iRouterProduct2.openWifi(); iRouterProduct2.setting(); &#125;&#125; 12345678910//第一个产品等级产品--手机的抽象功能接口public interface IphoneProduct &#123; void start(); void shutDown(); void callUp(); void sendSMS();&#125; 12345678910//第二个产品等级产品--路由器的抽象功能接口public interface IRouterProduct &#123; void start(); void shutDown(); void openWifi(); void setting();&#125; 12345678//抽象产品工厂定义具体工厂可以生产的产品等级public interface IProductFactory &#123; //生产手机 IphoneProduct iphoneProduct(); //生产路由器 IRouterProduct routerProduct();&#125; 123456789101112131415161718192021222324//小米手机具体实现类public class Xiaomiphone implements IphoneProduct &#123; @Override public void start() &#123; System.out.println(&quot;开启小米手机&quot;); &#125; @Override public void shutDown() &#123; System.out.println(&quot;关闭小米手机&quot;); &#125; @Override public void callUp() &#123; System.out.println(&quot;小米手机打电话&quot;); &#125; @Override public void sendSMS() &#123; System.out.println(&quot;小米手机发短信&quot;); &#125;&#125; 12345678910111213141516171819202122public class Xiaomirouter implements IRouterProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开小米路由器&quot;); &#125; @Override public void shutDown() &#123; System.out.println(&quot;关闭小米路由器&quot;); &#125; @Override public void openWifi() &#123; System.out.println(&quot;打开小米wifi&quot;); &#125; @Override public void setting() &#123; System.out.println(&quot;关闭小米wifi&quot;); &#125;&#125; 123456789101112131415161718192021public class Huaweiphone implements IphoneProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开华为手机&quot;); &#125; @Override public void shutDown() &#123; System.out.println(&quot;关闭华为手机&quot;); &#125; @Override public void callUp() &#123; System.out.println(&quot;华为手机打电话&quot;); &#125; @Override public void sendSMS() &#123; System.out.println(&quot;华为手机发短信&quot;); &#125;&#125; 123456789101112131415161718192021public class Huaweirouter implements IRouterProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开华为路由器&quot;); &#125; @Override public void shutDown() &#123; System.out.println(&quot;关闭华为路由器&quot;); &#125; @Override public void openWifi() &#123; System.out.println(&quot;打开华为wifi&quot;); &#125; @Override public void setting() &#123; System.out.println(&quot;关闭华为wifi&quot;); &#125;&#125; 12345678910111213public class XiaomiFactory implements IProductFactory &#123; //生产小米产品族，并且满足抽象工厂的开发模式，可扩展性强 @Override public IphoneProduct iphoneProduct() &#123; return new Xiaomiphone(); &#125; @Override public IRouterProduct routerProduct() &#123; return new Xiaomirouter(); &#125;&#125; 12345678910111213public class HuaweiFactory implements IProductFactory &#123; //生产华为产品族，并且满足抽象工厂的开发模式，可扩展性强 @Override public IphoneProduct iphoneProduct() &#123; return new Huaweiphone(); &#125; @Override public IRouterProduct routerProduct() &#123; return new Huaweirouter(); &#125;&#125; 此时结构图如下图所示，我们会发现实际上抽象工厂模式不过就是对工厂进行了又一次的抽象封装，所以此时支持了工厂可以生产产品族了。 思考：简单工厂模式，工厂方法模式和抽象工厂模式的异同点？ 学习完上面三种关于工厂模式的介绍，我们会发现实际上这三种开发模式都和现实生活中的开发模式非常类似，简单工厂模式首先提出了创建和应用分离，工厂方法模式在基础上优化了扩展性能，而抽象工厂模式支持了产品族的生产。但是这三者都会导致一定程度的类膨胀现象，所谓有利就有弊，但是在面对复杂场景下工厂模式总是最优解。 建造者模式 建造者模式也是一种创造模式，但是他和工厂模式不同，他是将一个复杂对象的构建与表示分离，使得用户可以在不知道对象的建造过程和细节的情况下就可以完成复杂对象的创建。它主要的特点就是用户只需要给出指定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象， 把具体的内部的建造过程和细节隐藏起来，同时还支持携带默认值的复杂对象的创建。 举一个应用场景，现在我们已经有了轴承，发动机，轮胎等产品的工厂了，但是最终我们需要的是一辆车，那么此时我们就需要由建造者身份来保证我们完成最终的组件的拼装以及进一步加工，最终由他来向我们交付完成的汽车。 也就是说面对简单对象的创建时，我们是用不到建造者模式的。同时要注意所有的设计模式并不是单一使用的，而是互相依赖的，比如上面的过程中我们也用到了工厂模式。 现在我们用代码来演示一下建造者模式的应用场景，假设现在我们需要建筑一栋大厦，那么首先我们需要找到一个建筑公司或者工程承包商（指挥者），由他来指挥工人（具体的建造者）来造房子（产品）。最终我们向建筑公司索要大厦产品。 上图就是一个建造者模式的演示图，建筑公司就是Director，工人建造者就是具体的Builder,而抽象的Builder就是设计图纸，即指挥者给出抽象的建造顺序，建造者根据建造顺序具体实现建造或者产品的组装，最终指挥官将完成的产品交付给我们客户。代码如下： Consumer.javaProduct.javaDirector.javaBuilder.javaWorker.java12345678910111213//我们客户身份public class Consumer &#123; public static void main(String[] args) &#123; //创建一个指挥者 Director director = new Director(); //我们只需要命令指挥者开始搭建房子即可 //具体后面的指挥者如何指挥工人搭建房子 //甚至房子的组成结构我们一概不知也无需关心 Product p = director.build(new Worker()); System.out.println(p.toString()); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/具体的房子产品public class Product &#123; //房子有四个值需要建造填充 private String buildA; private String buildB; private String buildC; private String buildD; public String getBuildA() &#123; return buildA; &#125; public void setBuildA(String buildA) &#123; this.buildA = buildA; &#125; public String getBuildB() &#123; return buildB; &#125; public void setBuildB(String buildB) &#123; this.buildB = buildB; &#125; public String getBuildC() &#123; return buildC; &#125; public void setBuildC(String buildC) &#123; this.buildC = buildC; &#125; public String getBuildD() &#123; return buildD; &#125; public void setBuildD(String buildD) &#123; this.buildD = buildD; &#125; @Override public String toString() &#123; return &quot;Product&#123;&quot; + &quot;buildA=&#x27;&quot; + buildA + &#x27;\\&#x27;&#x27; + &quot;, buildB=&#x27;&quot; + buildB + &#x27;\\&#x27;&#x27; + &quot;, buildC=&#x27;&quot; + buildC + &#x27;\\&#x27;&#x27; + &quot;, buildD=&#x27;&quot; + buildD + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 12345678910111213141516171819//具体的指挥者，他来只会工人按顺序创建产品//核心public class Director &#123; //指挥者有一个开始指挥构建产品的函数 //他需要接收传进来一个工人即具体的实现Builder类实例 public Product build(Builder builder)&#123; //他在指挥 着这个工人按照一定的顺序来盖房子 //这里指挥工人按照A-B-C-D顺序构建房子 //他负责具体的房子结构组装 builder.buildA(); builder.buildB(); builder.buildC(); builder.buildD(); //最终从工人那里拿到盖好的房子 //然后指挥者来向客户交付产品 return builder.getProduct(); &#125;&#125; 12345678910111213//抽象的Builder，不提供具体的建造实现//仅仅定义建造的步骤//注意这里使用接口或者抽象类都是相同的作用//表示抽象的功能,这里用抽象类表示public abstract class Builder &#123; abstract void buildA();//地基 abstract void buildB();//钢筋水泥 abstract void buildC();//铺电线 abstract void buildD();//粉刷 //完工交付产品 abstract Product getProduct();&#125; 123456789101112131415161718192021222324252627282930313233343536373839/具体的Builder实现public class Worker extends Builder &#123; //工人仅仅是会做这些工作的，但是如果没有人指挥他并不会做 //即他不知道盖房子的具体步骤，只是会搭建房子的一系列操作 private Product product; public Worker() &#123; //一定要注意是工人这个具体Builder来创建产品 //抽象的Builder仅仅定义方法和实现顺序 product = new Product(); &#125; @Override void buildA() &#123; //先达地基 product.setBuildA(&quot;地基&quot;); &#125; @Override void buildB() &#123; product.setBuildB(&quot;钢筋工程&quot;); &#125; @Override void buildC() &#123; product.setBuildC(&quot;铺电线&quot;); &#125; @Override void buildD() &#123; product.setBuildD(&quot;粉刷&quot;); &#125; @Override Product getProduct() &#123; return product; &#125;&#125; 上面实例时Builder建造者模式的常规用法， 其中指挥类Director在Builder模式中有很重要的作用，它用于指导建造者Worker如何按照顺序正确的创造产品，并且在完成产品生成后将产品返还给客户。 但是我们在现实生活中可能客户并不是真的不关心具体的实现操作，而是客户本身就是指挥者，因此此时我们并不需要来实现一个复杂的指挥者，只需要一个工人可以根据我们客户的只会进行产品的创建即可。因此通过静态内部类方式实现零件无需装配构造，这种方式更加灵活符合定义。当内部有复杂对象的默认实现，使用时可以根据用户需求自定义更改内容，并且无需改变具体的构造方式，就可以生产出不同复杂产品。下面我们通过麦当劳点餐的应用场景模拟一下这种方式，即服务员（具体的建造者）可以随意搭配任意几种产品（零件）组成一款套餐（产品），然后出售给客户，但是客户可以指挥服务员更改默认的套餐，这种方式把指挥者身份交给了用户自己来扮演，使得产品的创建更加简单灵活： Consumer.javaProduct.javaBuilder.javaWorker.java123456789101112131415public class Consumer &#123; public static void main(String[] args) &#123; //我们自己扮演指挥者来更改套餐 //首先需要创建一名服务员即建造者 Worker worker = new Worker(); //修改默认的套餐，将汉堡更改为上校鸡块 //修改默认的套餐，可累更改为咖啡 //最终我们从这个当前worker实例所携带的套餐实例product获取修改的套餐 //即静态内部类的体现 //同时这里也体现了链式变成的特点 Product product = worker.buildA(&quot;上校鸡块&quot;).buildB(&quot;咖啡&quot;).getProduct(); //输出套餐信息 System.out.println(product.toString()); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//产品套餐public class Product &#123; //默认的套餐产品所拥有的的食物 private String BuildA = &quot;汉堡&quot;; private String BuildB = &quot;可乐&quot;; private String BuildC = &quot;薯条&quot;; private String BuildD = &quot;甜点&quot;; public String getBuildA() &#123; return BuildA; &#125; public void setBuildA(String buildA) &#123; BuildA = buildA; &#125; public String getBuildB() &#123; return BuildB; &#125; public void setBuildB(String buildB) &#123; BuildB = buildB; &#125; public String getBuildC() &#123; return BuildC; &#125; public void setBuildC(String buildC) &#123; BuildC = buildC; &#125; public String getBuildD() &#123; return BuildD; &#125; public void setBuildD(String buildD) &#123; BuildD = buildD; &#125; @Override public String toString() &#123; return &quot;Product&#123;&quot; + &quot;BuildA=&#x27;&quot; + BuildA + &#x27;\\&#x27;&#x27; + &quot;, BuildB=&#x27;&quot; + BuildB + &#x27;\\&#x27;&#x27; + &quot;, BuildC=&#x27;&quot; + BuildC + &#x27;\\&#x27;&#x27; + &quot;, BuildD=&#x27;&quot; + BuildD + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 123456789101112//抽象类，也可以使用接口，最终功能一致public abstract class Builder &#123; abstract Builder buildA(String msg);//汉堡 abstract Builder buildB(String msg);//可乐 abstract Builder buildC(String msg);//薯条 abstract Builder buildD(String msg);//蛋挞 abstract Product getProduct();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445//具体的建造者，服务员public class Worker extends Builder&#123; //这里体现了懒汉式单例创建 private Product product; public Worker()&#123; //注意产品的创建还是由创建者来完成 product=new Product(); &#125; @Override Builder buildA(String msg) &#123; //修改套餐的第一个食品 product.setBuildA(msg); //注意这里优点不好理解 //返回的是当前的worker实例，由于这个worker内部包含了一个产品 //因此间接的这个worker所更改创建的套餐也返还了 //这就是静态内部类的体现 return this; &#125; @Override Builder buildB(String msg) &#123; product.setBuildB(msg); return this; &#125; @Override Builder buildC(String msg) &#123; product.setBuildC(msg); return this; &#125; @Override Builder buildD(String msg) &#123; product.setBuildD(msg); return this; &#125; @Override Product getProduct() &#123; //返还当前worker所携带的产品 return product; &#125;&#125; 通过上面的两个示例，我们可以看出建造者模式将复杂对象产品的创建步骤分解在了不同的方法中，使得创建过程更加清晰，同时使得客户无需在关心复杂对象的创建，具体的创建交付给了Builder和Director来完成。并且我们根据第二个例子可以看到建造者模式还可以提供默认产品值和他的链式修改方法，使得产品的自定义程度更高。但是我们发现这种模式也存在一定的弊端，即创建的产品要求一般具有较多的共同点，如果产品之间的差异较大时，则不适用于建造者模式。同时由于产品内部变化复杂，可能会导致需要定义很多具体的建造类来实现这种变化，导致系统变的很庞大（只是这里的例子中产品较为简单，因此只用了一个建造类即完成了复杂对象的创建）。 思考：抽象工厂模式和建造者模式的区别？ 其实我们很容易就可以感受到区别。抽象工厂模式是返还一系列产品，这些产品可以直接通过new即可创建完成，但是在建造者模式中的产品一般都很复杂，并不能一步new即可完成创建，他需要多个零件组装完成。因此如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装返还一个完整的车辆。 一般建造者模式是使用抽象工厂模式创建的各种产品零件进行组装完成一个复杂对象的创建，因此两个模式是相互合作的！ 原型模式 所谓原型模式，说白了就是实例的赋值，类似于克隆动物。但是他要求克隆以后两个实例再也没有关系，即一个实例的变化不会再影响另一个实例即两个实例指向不同的内存空间，这其中涉及到了浅拷贝和深拷贝的区别。 浅拷贝的克隆 Video.javaBilibili.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Video implements Cloneable &#123; //1.实现Cloneable接口 private String name; private Date createTime; //2.重写这个方法 @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; public Video() &#123; &#125; public Video(String name, Date date) &#123; this.name = name; this.createTime = date; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; @Override public String toString() &#123; return &quot;Video&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, createTime=&quot; + createTime + &#x27;&#125;&#x27;; &#125;&#125; 12345678910111213141516171819202122232425//客户端：实现克隆public class Bilibili &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; //原型对象 Date date = new Date(); Video v1 = new Video(&quot;狂神说java&quot;, date); System.out.println(&quot;v1=&gt;&quot; + v1); System.out.println(&quot;v1=&gt;hash&quot; + v1.hashCode()); //克隆v1 Video v2 = (Video) v1.clone(); //此时v2和v1内容会完全一致，并且存储到了不同的内存空间 //发现此时HashCode确实不同，说明存储的内存空间不同 //此时更改v2的名字确实不会改变v1的名字 v2.setName(&quot;Clone:狂神说java&quot;); //但是此时有浅拷贝的情况，即v2和v1的date指向同一个位置 //造成v2修改时间后v1的时间也会发生变化，这就是浅拷贝 date.setTime(22131231); v2.setCreateTime(date); //此时v1和v2大的时间会保持一致，即v1的时间自动发生了变化和v2保持一致 System.out.println(v2.getCreateTime().equals(v1.getCreateTime())); &#125;&#125; 上面之所以出现浅拷贝，是因为此时虽然两个对象各占用了不同的内存空间，并且name变量也确实占用了不同的空间，但是由于date默认是更改引用的，因此此时两个实例的date还是共享的，即指向了一个内存空间，导致了浅拷贝的情况。我们用图表示一下此时的情况： 为了解决这个问题，我们需要修改clone方法改成所有的变量也全部都是使用不同的内存空间即深拷贝。 深拷贝的克隆 Video.javaBilibili.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//1.实现克隆接口//2.重写一个方法即可完成克隆public class Video implements Cloneable &#123; //1.实现Cloneable接口 private String name; private Date createTime; //2.重写这个方法 @Override protected Object clone() throws CloneNotSupportedException &#123;// return super.clone(); //重写克隆方法 Object obj = super.clone(); Video v = (Video) obj; //将对象的属性也全部重新克隆一遍 v.createTime = (Date) this.createTime.clone(); //这里最终返回v或者obj都是可以的 return obj; //return v &#125; public Video() &#123; &#125; public Video(String name, Date date) &#123; this.name = name; this.createTime = date; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; @Override public String toString() &#123; return &quot;Video&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, createTime=&quot; + createTime + &#x27;&#125;&#x27;; &#125;&#125; 123456789101112131415161718192021222324//客户端：实现克隆public class Bilibili &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; //原型对象 Date date = new Date(); Video v1 = new Video(&quot;狂神说java&quot;, date); System.out.println(&quot;v1=&gt;&quot; + v1); System.out.println(&quot;v1=&gt;hash&quot; + v1.hashCode()); //克隆v1 Video v2 = (Video) v1.clone(); //此时v2和v1内容会完全一致，并且存储到了不同的内存空间 //发现此时HashCode确实不同，说明存储的内存空间不同 //此时更改v2的名字确实不会改变v1的名字 v2.setName(&quot;Clone:狂神说java&quot;); //更改为了深拷贝，因此此时更改v2的日期，v1的日期不会发生改变 date.setTime(22131231); v2.setCreateTime(date); //因此此时下面为false System.out.println(v2.getCreateTime().equals(v1.getCreateTime())); &#125;&#125; 此时的深拷贝的情况如下图所示，因此此时两个实例所有成员变量全部都指向了自己的内存空间，解决了浅拷贝的问题。当然我们也可以使用序列化/反序列化方法实现深拷贝，但是远没有这种修改clone方法简单。 思考：为什么重写的clone方法部分返还v和obj都可以？ 我们要理解v和obj的区别，此时他们两个指向的是同一个内存空间，只不过是v有一个Video类型强转的过程，因此最终obj和v的date是同一个变量，它实现了重新克隆即完成了深拷贝，具体返还obj还是v都可以，因为最终他们返还都是这个新拷贝的对象实例的内存空间。 原型模式的应用场景很容易联想到，即工厂模式下工厂生产产品我们可以不再使用new来创建，而是选择clone的方法创建来提升效率。 您可以点击左上方链接获取上面教程所使用的代码,同时可以参考本篇博客完成homework01实验巩固学习😊"},{"title":"行为型模式","path":"/wiki/设计模式笔记/行为型模式/index.html","content":"行为型模式 上一章我们学习了7大结构型模式，本章我们来学习11种重要的行为型模式，行为型模式描述了多个类或对象之间怎么相互协作共同完成单个对象都无法完成的任务，涉及算法与对象间职责的分配。同样他也分为类行为模式和对象行为模式，为了满足合成复用原则，我们尽量选择使用聚合方式的对象行为模式。 我们也是首先给出11种行为型模式的特点和重要功能，方便我们在学习时能随时带着思考学习： 模板方法模式：定义一个操作中的算法结构，将算法的一些步骤延迟到子类中，使得子类可以在不改变算法结构的情况下重新定义该算法的某些特定步骤。 命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分隔开。 迭代器模式：提供一个方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 观察者模式：多个对象之间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。 中介者模式：定义一个中介者来简化原有对象之间的复杂交互关系，降低系统中对象间的耦合度，使得原有对象之间不必相互了解。 备忘录模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复他。 解释器模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。 状态模式：允许一个对象在其内部状态发生改变时改变其行为能力。 策略模式：定义一系列算法，并将每一个算法封装起来，使得它们可以相互替换，且算法的改变不会影响使用算法的客户。 职责链模式：把请求从链中的一个对象传到下一个对象，直到请求被相应为止。通过这种方式去除对象之间的耦合。 访问者模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每一个元素有多个访问者对象访问。 上面的11种行为型模式中，除了模板方法模式和解释器模式是类行为模式，其他的全部为对象行为型模式。 模板方法模式 模板方法模式我们非常熟悉，在日常开发中实际上我们就已经经常使用这个模式了他针对的是一些操作流程大致相同，只是具体的某些特定步骤的操作细节不同的应用场景，此时我们可以将大体的流程在抽象类中定义，然后相同操作的流程也可以在抽象类中实现，但是对于那些具体操作细节不太相同的步骤延迟到子类实现，这就是模板方法模式。比如炒菜的步骤是固定的，分为倒油、热油、倒蔬菜、倒调理品、爆炒等步骤，现在我们将制作炒包菜和炒菜心两个菜品，很明显他们的大体步骤是相同的，但是在倒蔬菜、倒调料品和爆炒三个环节略有不同，此时我们就可以使用模板方法来实现。UML图如下 代码也很简单，就是一个抽象类然后被两个具体实现继承即可，因此模板方法是类行为型模式，但是这种类行为型模式是有必要的，他不能通过接口来实现，这是因为往往多个具体实现类还会有一些相同的成员属性，那么此时我们就可以在抽象类中定义好这些成员变量，但是接口却无法实现。 Client.javaAbstractClass.javaConcreteClass_BaoCai.javaConcreteClass_CaiXin.java1234567891011public class Client &#123; public static void main(String[] args) &#123; //炒包菜 ConcreteClass_BaoCai baoCai = new ConcreteClass_BaoCai(); //炒菜 baoCai.cookProcess(); System.out.println(&quot;===============&quot;); ConcreteClass_CaiXin caiXin = new ConcreteClass_CaiXin(); caiXin.cookProcess(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132public abstract class AbstractClass &#123; //模板方法定义 public final void cookProcess() &#123; pourOil(); heatOil(); pourVagetable(); fry(); &#125; //基本方法 //第一步 public void pourOil() &#123; System.out.println(&quot;倒油&quot;); &#125; //第二步热油是一样的，直接实现 public void heatOil() &#123; System.out.println(&quot;热油&quot;); &#125; //第三步要倒的菜是不同的，因此这里方法维持抽象 public abstract void pourVagetable(); //第四步倒的调料不一样，也抽象 public abstract void pourSauce(); //第五步翻炒是一样的，直接在这里实现 public void fry() &#123; System.out.println(&quot;炒啊炒啊炒啊吵到熟啊&quot;); &#125;&#125; 1234567891011121314//炒包菜类public class ConcreteClass_BaoCai extends AbstractClass &#123; @Override public void pourVagetable() &#123; System.out.println(&quot;下锅的是包菜&quot;); &#125; @Override public void pourSauce() &#123; System.out.println(&quot;下锅的是辣椒&quot;); &#125;&#125; 1234567891011public class ConcreteClass_CaiXin extends AbstractClass &#123; @Override public void pourVagetable() &#123; System.out.println(&quot;下锅的是菜心&quot;); &#125; @Override public void pourSauce() &#123; System.out.println(&quot;下锅的是蒜蓉&quot;); &#125;&#125; 命令模式 命令模式初看感觉没有什么明显的作用，很难理解他的做法。但是我们在联想C/S的HTTP请求模型以后就很好理解了，命令模式实际上就是类似于请求与执行分离的开发模式，他的主要目的就是为了使得命令发起者和命令的执行者想分开，两者独立工作，通过命令这个请求来建立联系。这样我们就可以很好的去实现复杂应用场景下高并发复杂请求的接收-&gt;执行-&gt;响应的调度过程了。我们以餐厅为案例学习，在日常生活中，我们出去吃饭都会遇到如下面的场景： 此时一个客户就类似于以应用进程，许许多多个客户（应用进程）发起了多个异步请求（多个订单），此时需要由服务员这个调度这接收所有请求然后合理的分配给命令执行者（厨师）完成订单（请求）。这就是一个典型的命令模式，这里的订单就是命令，我们发现从客户的角度来看，他并不知道具体的订单（命令）是由哪位厨师（命令执行者）完成的并且他也并不关心，只要菜品（响应）及时正确的返回就可以了。而从厨师的角度来看，他也并不知道订单（命令）的请求者（上层应用）是谁并且他也并不关心，他只需要及时完成订单（执行命令）即可。而订单（命令）的调度分配有调度者（服务员）完成。UML图如下 我们注意上面的UML类图，服务员调度者可以间接的调用分配命令和命令执行者，这与显示生活中的开发场景非常类似。代码如下 Client.javaCommand.javaOrder.javaOrderCommand.javaSeniorChefWaitor.java12345678910111213141516171819202122232425public class Client &#123; public static void main(String[] args) &#123; Order order1 = new Order(); order1.setDiningTable(1); order1.setFood(&quot;西红柿鸡蛋面&quot;, 1); order1.setFood(&quot;小杯可乐&quot;, 2); Order order2 = new Order(); order2.setDiningTable(2); order2.setFood(&quot;尖叫肉丝盖饭&quot;, 1); order2.setFood(&quot;小杯雪碧&quot;, 1); //创建厨师 SeniorChef receiver = new SeniorChef(); //创建命令对象 OrderCommand cmd1 = new OrderCommand(receiver, order1); OrderCommand cmd2 = new OrderCommand(receiver, order2); //创建服务员 Waitor waitor = new Waitor(); waitor.setCommand(cmd1); waitor.setCommand(cmd2); waitor.orderUp(); &#125;&#125; 123public interface Command &#123; void execute();&#125; 1234567891011121314151617181920212223public class Order &#123; //下订单的餐桌号码 private int diningTable; //所下的菜品及份数 private Map&lt;String, Integer&gt; foodDir = new HashMap&lt;String, Integer&gt;(); public int getDiningTable() &#123; return diningTable; &#125; public void setDiningTable(int diningTable) &#123; this.diningTable = diningTable; &#125; public Map&lt;String, Integer&gt; getFoodDir() &#123; return foodDir; &#125; public void setFood(String name, int num) &#123; foodDir.put(name, num); &#125;&#125; 12345678910111213141516171819202122public class OrderCommand implements Command &#123; //持有接受者对象 private SeniorChef receiver; private Order order; public OrderCommand(SeniorChef receiver, Order order) &#123; this.receiver = receiver; this.order = order; &#125; @Override public void execute() &#123; System.out.println(order.getDiningTable() + &quot;的订单：&quot;); Map&lt;String, Integer&gt; foodDir = order.getFoodDir(); Set&lt;String&gt; keys = foodDir.keySet(); for (String foodName : keys) &#123; receiver.makeFood(foodName, foodDir.get(foodName)); &#125; System.out.println(order.getDiningTable() + &quot;桌的饭菜准备完毕&quot;); &#125;&#125; 123456public class SeniorChef &#123; public void makeFood(String name, int num) &#123; System.out.println(num + &quot;份&quot; + name); &#125;&#125; 1234567891011121314151617181920public class Waitor &#123; //持有命令对象,但是一个服务员可以发布多个命令，因此持有多个命令对象 private List&lt;Command&gt; commands = new ArrayList&lt;Command&gt;(); public void setCommand(Command cmd) &#123; //将cmd对象存储到List中 commands.add(cmd); &#125; //发起命令的功能，喊订单来了 public void orderUp() &#123; System.out.println(&quot;美女服务员说：大厨，新订单来了！&quot;); //遍历List集合 for (Command command : commands) &#123; if (command != null) &#123; command.execute(); &#125; &#125; &#125;&#125; 迭代器模式 迭代器模式有什么作用？通常情况下我们使用的都是array或者list来存储，那么它们会面临一种风险，即全局暴露和被更改，这种风险隐患很大，在许多对安全要求极高的应用场景下是需要避免的，那么此时我们就会使用到迭代器模式，他是一种由开发者完成确保安全的情况下主动向外暴露的一个迭代器的模式，这种情况下我们主动规避了可更改的权限，保护了数据。假设现在我们要采用迭代器模式来顺序打印一个存储学生信息对象的容器，那么UML图如下 我们会发现我们是将学生对象存储到了一个列表中，同时这个列表又是Aggregate实例的一个隐私成员变量，是不允许外界访问获得甚至修改的，那么很显然此时这些数据时被安全保护的，那么现在如果我们需要顺序打印他们，并不能直接通过for循环访问列表，而是需要使用开发者定义的一个迭代器来完成，同时这个迭代器返还的并不是对象引用，而是一个复制对象，那么也就是说我们在使用这个开发者提供给我们的迭代器后也是无权访问源数据的，可见安全性极高。代码如下 Client.javaStudentjavaStudentAggeragate.javaStudentAggregateImpl.javaStudentIterator.javaStudentIteratorImpl.java1234567891011121314151617public class Client &#123; public static void main(String[] args) &#123; //创建聚合对象 StudentAggregateImpl studentAggregate = new StudentAggregateImpl(); //添加元素 studentAggregate.addStudent(new Student(&quot;张三&quot;, &quot;001&quot;)); studentAggregate.addStudent(new Student(&quot;李四&quot;, &quot;002&quot;)); studentAggregate.addStudent(new Student(&quot;王五&quot;, &quot;003&quot;)); studentAggregate.addStudent(new Student(&quot;赵六&quot;, &quot;004&quot;)); //1.获取迭代器对象 StudentIterator studentIterator = studentAggregate.getStudentIterator(); //2.遍历 while (studentIterator.hasNext()) &#123; System.out.println(studentIterator.next().toString()); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536public class Student &#123; private String name; private String number; public Student() &#123; &#125; public Student(String name, String number) &#123; this.name = name; this.number = number; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getNumber() &#123; return number; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, number=&#x27;&quot; + number + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125; public void setNumber(String number) &#123; this.number = number; &#125;&#125; 12345678910public interface StudentAggregate &#123; //添加学生功能 void addStudent(Student student); //删除学生功能 void removeStudent(Student student); //获取迭代器对象功能 StudentIterator getStudentIterator();&#125; 12345678910111213141516171819public class StudentAggregateImpl implements StudentAggregate &#123; private List&lt;Student&gt; studentList = new ArrayList&lt;Student&gt;(); @Override public void addStudent(Student student) &#123; studentList.add(student); &#125; @Override public void removeStudent(Student student) &#123; studentList.remove(student); &#125; @Override public StudentIterator getStudentIterator() &#123; return new StudentIteratorImpl(studentList); &#125;&#125; 12345678//抽象迭代器角色接口public interface StudentIterator &#123; //判断是够还有元素 boolean hasNext(); //获取下一个元素 Student next();&#125; 123456789101112131415161718192021222324//具体的迭代器角色类public class StudentIteratorImpl implements StudentIterator &#123; private List&lt;Student&gt; studentList; //用来记录遍历时的位置 private int position; public StudentIteratorImpl(List&lt;Student&gt; studentList) &#123; this.studentList = studentList; &#125; @Override public boolean hasNext() &#123; return position &lt; studentList.size(); &#125; @Override public Student next() &#123; Student student = studentList.get(position); position++; return student; &#125;&#125; 观察者模式 观察者模式解决的就是一个一对多通知变化的应用场景，优点类似于广播的形式。由于通知发起者需要向全部观察者发起变更通知，所以跟容易想到他肯定是有一个列表聚合存储了其他观察者实例，UML图如下 Client.javaObserver.javaSubject.javaSubscriptionSubject.javaWeixinUser.java123456789101112public class Client &#123; public static void main(String[] args) &#123; //1.创建公众号对象 SubscriptionSubject subscriptionSubject = new SubscriptionSubject(); //2.订阅公众号 subscriptionSubject.attach(new WeixinUser(&quot;孙悟空&quot;)); subscriptionSubject.attach(new WeixinUser(&quot;猪悟能&quot;)); subscriptionSubject.attach(new WeixinUser(&quot;沙悟净&quot;)); //3.公众号更新发送推送消息 subscriptionSubject.notify(&quot;传至黑马的专栏更新了&quot;); &#125;&#125; 1234//抽象观察者类public interface Observer &#123; void update(String msg);&#125; 1234567891011//抽象主题角色类public interface Subject &#123; //添加订阅者或者观察者对象 void attach(Observer observer); //删除订阅者 void detach(Observer observer); //通知观察者更新消息 void notify(String msg);&#125; 1234567891011121314151617181920212223public class SubscriptionSubject implements Subject &#123; //定义一个集合用来存储多个观察者对象 private List&lt;Observer&gt; weixinUserList = new ArrayList&lt;Observer&gt;(); @Override public void attach(Observer observer) &#123; weixinUserList.add(observer); &#125; @Override public void detach(Observer observer) &#123; weixinUserList.remove(observer); &#125; @Override public void notify(String msg) &#123; for (Observer observer : weixinUserList) &#123; observer.update(msg); &#125; &#125;&#125; 12345678910111213public class WeixinUser implements Observer &#123; private String name; public WeixinUser(String name) &#123; this.name = name; &#125; @Override public void update(String msg) &#123; System.out.println(name + &quot;-&quot; + msg); &#125;&#125; 实际上上面和这个案例还有点简单，因为他是单方向的通知，即多个订阅观察者订阅专栏，当专栏变化时其他订阅观察者获取到通知，这是一个单方向的案例。但是我们常用的一般是双向甚至多向的案例，比如现在有一个战地小分队，所有的队员都在同一个频道，任何一个队员受到攻击都可以告知其他的同组队友地方战斗信息，这种多向的应用场景下使用观察者模式优点更加明显，如果有兴趣你可以尝试实现。 中介模式 中介模式很容易理解，因为我们在日常生活中经常会观察到这个模式的应用，他就是为了解决多个对象之间关系过于复杂的场景，由中介者引入管理所有的通信简化关系网是最优设计模式，我们用两个图可以清晰感知到他的强大之处。 引入中介模式前引入中介模式后 实际上我们在学习计网时，就曾经学习过，对于中介模式就是所谓的星形结构，他极大的简化了通信的复杂程度，但是这也对中介者这个中枢组件提出了高负荷情况下准确完美运行的极高要求。因为一旦中介者损坏，整个联络网将瘫痪。这里我们还是以中介，房东，租房者这个再常见不过的案例来模拟实现以下中介者模式，UML图如下 很明显中介者是用来协调双方的，因此他MediatorStructure具体中介实现类聚合了Tenant租房者类和HouseOwner房东类。代码如下 Client.javaPerson.javaTenant.javaHouseOwner.javaMediator.javaMediatorStructure.java1234567891011121314public class Client &#123; public static void main(String[] args) &#123; //创建中介者对象 MediatorStructure mediatorStructure = new MediatorStructure(); Tenant tenant = new Tenant(&quot;李四&quot;, mediatorStructure); HouseOwner houseOwner = new HouseOwner(&quot;张三&quot;, mediatorStructure); mediatorStructure.setTenant(tenant); mediatorStructure.setHouseOwner(houseOwner); tenant.contact(&quot;我想租房子&quot;); houseOwner.contact(&quot;我可以租给你，5000一月&quot;); &#125;&#125; 12345678910//抽象同事类public abstract class Person &#123; protected String name; protected Mediator mediator; public Person(String name, Mediator mediator) &#123; this.name = name; this.mediator = mediator; &#125;&#125; 1234567891011121314151617//具体同事角色类public class Tenant extends Person &#123; public Tenant(String name, Mediator mediator) &#123; super(name, mediator); &#125; //和中介者联系方法 public void contact(String msg) &#123; mediator.contact(msg, this); &#125; //获取信息的方法 public void getMessage(String msg) &#123; System.out.println(&quot;租房者&quot; + name + &quot;获取到的信息是：&quot; + msg); &#125;&#125; 1234567891011121314151617//具体的同时角色类public class HouseOwner extends Person &#123; public HouseOwner(String name, Mediator mediator) &#123; super(name, mediator); &#125; //和中介者联系方法 public void contact(String msg) &#123; mediator.contact(msg, this); &#125; //获取信息的方法 public void getMessage(String msg) &#123; System.out.println(&quot;房主&quot; + name + &quot;获取到的信息是：&quot; + msg); &#125;&#125; 12345//抽象中介者类public abstract class Mediator &#123; public abstract void contact(String msg,Person person);&#125; 12345678910111213141516171819202122232425262728293031//具体的中介者角色类public class MediatorStructure extends Mediator &#123; //聚合房主和具体的租房者 Tenant tenant; HouseOwner houseOwner; public Tenant getTenant() &#123; return tenant; &#125; public void setTenant(Tenant tenant) &#123; this.tenant = tenant; &#125; public HouseOwner getHouseOwner() &#123; return houseOwner; &#125; public void setHouseOwner(HouseOwner houseOwner) &#123; this.houseOwner = houseOwner; &#125; @Override public void contact(String msg, Person person) &#123; if (person == houseOwner) &#123; tenant.getMessage(msg); &#125; else &#123; houseOwner.getMessage(msg); &#125; &#125;&#125; 备忘录模式 备忘录模式完成的就是状态的恢复类似于回滚，他在游戏开发中非常常见，比如副本挑战失败后回到挑战前的状态再次挑战，这时候我们就需要备忘录模式来完成了。备忘录模式分为白箱备忘录和黑箱备忘录模式，两者中后者安全性更好，但是无论是哪一种，他们的实现都是通过建立一个保存状态的备忘录对象用来存储到备忘录管理者对象中以便随时取出状态备忘录进行状态的恢复。现在假设游戏中的某个场景，一个游戏角色有生命力、攻击力和防御力等数据，在打boss前和打boss后一定会不一样，我们允许玩家如果感觉与boss决斗的效果不理想时让游戏恢复到决斗之前的状态，这就使用了备忘录模式，首先我们用白箱备忘录模式实现。 白箱备忘录模式 我们可以看到GameRole角色类可以存储状态，这个存储状态的数据对象就是RoleStateMento类的一个实例，但是我们知道可能有时候会存储许多个状态，允许多次回滚因此我们需要一个状态备忘录管理者即RoleStateCaretaker聚合了RoleStateMmento，用一个列表存储了许多个状态，当GameRole恢复时只需要从他这里获取即可。代码如下 Client.javaGameRole.javaRoleStateMemento.javaRoleStateCaretaker.java123456789101112131415161718192021public class Client &#123; public static void main(String[] args) &#123; System.out.println(&quot;------------大战boss前----------&quot;); GameRole gameRole = new GameRole(); gameRole.initState();//初始化状态的操作 gameRole.stateDisplay(); //将游戏角色状态进行备份 RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker(); roleStateCaretaker.setRoleStateMemento(gameRole.saveState()); System.out.println(&quot;------------大战boss后----------------&quot;); //损耗严重 gameRole.fight(); gameRole.stateDisplay();// System.out.println(&quot;-------------恢复之前的状态-------------------&quot;); gameRole.recoverState(roleStateCaretaker.getRoleStateMemento()); System.out.println(&quot;--------------恢复之后的状态---------------------&quot;); gameRole.stateDisplay(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//游戏角色类，发起人角色public class GameRole &#123; private int vit;//生命力 private int atk;//攻击力 private int def;//防御力 //初始化内部状态方法 public void initState() &#123; this.vit = 100; this.atk = 100; this.def = 100; &#125; //战斗的方法 public void fight() &#123; this.vit = 0; this.atk = 0; this.def = 0; &#125; //保存角色状态功能 public RoleStateMemento saveState() &#123; return new RoleStateMemento(vit, atk, def); &#125; //恢复角色状态 public void recoverState(RoleStateMemento roleStateMemento) &#123; //将备忘录对象中存储的状态赋值给当前对象的成员 this.vit = roleStateMemento.getVit(); this.atk = roleStateMemento.getAtk(); this.def = roleStateMemento.getDef(); &#125; //展示状态功能 public void stateDisplay() &#123; System.out.println(&quot;角色生命力：&quot; + vit); System.out.println(&quot;角色生命力：&quot; + atk); System.out.println(&quot;角色生命力：&quot; + def); &#125; public int getVit() &#123; return vit; &#125; public void setVit(int vit) &#123; this.vit = vit; &#125; public int getAtk() &#123; return atk; &#125; public void setAtk(int atk) &#123; this.atk = atk; &#125; public int getDef() &#123; return def; &#125; public void setDef(int def) &#123; this.def = def; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839//备忘录角色类public class RoleStateMemento &#123; private int vit;//生命力 private int atk;//攻击力 private int def;//防御力 public RoleStateMemento(int vit, int atk, int def) &#123; this.vit = vit; this.atk = atk; this.def = def; &#125; public RoleStateMemento() &#123; &#125; public int getVit() &#123; return vit; &#125; public void setVit(int vit) &#123; this.vit = vit; &#125; public int getAtk() &#123; return atk; &#125; public void setAtk(int atk) &#123; this.atk = atk; &#125; public int getDef() &#123; return def; &#125; public void setDef(int def) &#123; this.def = def; &#125;&#125; 12345678910111213//备忘录管理对象public class RoleStateCaretaker &#123; //声明RoleStateMemento类型的变量 private RoleStateMemento roleStateMemento; public RoleStateMemento getRoleStateMemento() &#123; return roleStateMemento; &#125; public void setRoleStateMemento(RoleStateMemento roleStateMemento) &#123; this.roleStateMemento = roleStateMemento; &#125;&#125; 我们思考一下上面的这个白箱备忘录模式有没有什么缺陷，很明显，这个状态存储对象是有被修改的风险的！比如我们在存储当前状态为一个RoleStateMemento对象以后他是携带着对生命值、攻击力和防御力等数值的修改方法的，那么也就意味着他在传递的过程中可能会被恶意拦截然后修改数值的，这会造成我们的游戏存在被外挂恶意修改的风险，所以白箱备忘录有一个很明显的缺陷即安全性太低。因此我们接下来引入了黑箱备忘录模式。 黑箱备忘录模式 我们会发现此时RoleStateMemento类称为了GameRole类的私有类，同时他在传递保存的状态时使用了上层的接口Memento来实现的，而Memento接口确实一个没有任何方法的接口，这也就意味着在传递过程中使用的是Memento类型来传递保存的状态，那么由于Memento接口无方法，也就不可能直接对状态进行修改了。但是你肯定会反驳说只要把Memento强转为RoleStateMemento不就又可以进行数值修改了吗？但是实际上这是做不到的，原因有二： 此时我们是以上帝视角来看设计的，因此我们知道Memento可以强转为RoleStateMemento类的，但是在实际上传输中，由于恶意拦截者并不是开发者，因此他并不知道Memento下的具体实现类类名是什么。 即使恶意拦截者恰巧蒙对了，那他也无权在传输过程中进行强转修改，因为RoleStateMemento是GameRole的私有类。只有当Memento安全传到GameRole以后才能由GameRole进行强转，因此不存在恶意修改的风险了。 Client.javaGameRole.javaMemento.javaRoleStateCaretaker.java123456789101112131415161718192021public class Client &#123; public static void main(String[] args) &#123; System.out.println(&quot;------------大战boss前----------&quot;); GameRole gameRole = new GameRole(); gameRole.initState();//初始化状态的操作 gameRole.stateDisplay(); //将游戏角色状态进行备份 RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker(); roleStateCaretaker.setMemento(gameRole.saveState()); System.out.println(&quot;------------大战boss后----------------&quot;); //损耗严重 gameRole.fight(); gameRole.stateDisplay();// System.out.println(&quot;-------------恢复之前的状态-------------------&quot;); gameRole.recoverState(roleStateCaretaker.getMemento()); System.out.println(&quot;--------------恢复之后的状态---------------------&quot;); gameRole.stateDisplay(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102//游戏角色类，发起人角色public class GameRole &#123; private int vit;//生命力 private int atk;//攻击力 private int def;//防御力 //初始化内部状态方法 public void initState() &#123; this.vit = 100; this.atk = 100; this.def = 100; &#125; //战斗的方法 public void fight() &#123; this.vit = 0; this.atk = 0; this.def = 0; &#125; //保存角色状态功能 public RoleStateMemento saveState() &#123; return new RoleStateMemento(vit, atk, def); &#125; //恢复角色状态 public void recoverState(Memento memento) &#123; RoleStateMemento roleStateMemento = (RoleStateMemento) memento; //将备忘录对象中存储的状态赋值给当前对象的成员 this.vit = roleStateMemento.getVit(); this.atk = roleStateMemento.getAtk(); this.def = roleStateMemento.getDef(); &#125; //展示状态功能 public void stateDisplay() &#123; System.out.println(&quot;角色生命力：&quot; + vit); System.out.println(&quot;角色生命力：&quot; + atk); System.out.println(&quot;角色生命力：&quot; + def); &#125; public int getVit() &#123; return vit; &#125; public void setVit(int vit) &#123; this.vit = vit; &#125; public int getAtk() &#123; return atk; &#125; public void setAtk(int atk) &#123; this.atk = atk; &#125; public int getDef() &#123; return def; &#125; public void setDef(int def) &#123; this.def = def; &#125; private class RoleStateMemento implements Memento &#123; private int vit;//生命力 private int atk;//攻击力 private int def;//防御力 public RoleStateMemento(int vit, int atk, int def) &#123; this.vit = vit; this.atk = atk; this.def = def; &#125; public int getVit() &#123; return vit; &#125; public void setVit(int vit) &#123; this.vit = vit; &#125; public int getAtk() &#123; return atk; &#125; public void setAtk(int atk) &#123; this.atk = atk; &#125; public int getDef() &#123; return def; &#125; public void setDef(int def) &#123; this.def = def; &#125; &#125; 1234//备忘录接口，对外提供窄接口public interface Memento &#123;&#125; 1234567891011121314151617//备忘录管理对象public class RoleStateCaretaker &#123; //声明RoleStateMemento类型的变量 private Memento memento; public Memento getMomento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125; public Memento getMemento() &#123; return memento; &#125;&#125; 解释器模式 这个模式并不常见也很难理解实现，他会将许多不同的原子操作进行文法定义，然后在调用时传进相对应的解释操作完成复杂的操作。我们以实现加减法的软件开发为例，UML图如下 这里我们假设一个计算式为a-(b+(c-d)，那么很明显我们可以采用Minus(left,right)和Plus(left,right)两个基础操作叠加完成： 1new Minus(a, new Plus(b, new Minus(c, d))) 但是我们知道Minus的两个参数并不一定是参数，可能是一个子计算式，因此此时我们就需要引入解释器模式了，他可以对函数的参数进行解释，如果是一个变量，那么可以在一个解释查找表map中查找到对应的数值，将变量解释成对应的数值，如果没有查找到那么就是计算式，需要进一步拆分。因此每一步interpret解释我们都需要一个解释查找表即context，自此我们就设计完成了加减法软件 Client.javaAbstractExpression.javaContext.javaMinus.javaPlus.javaVariable.java12345678910111213141516171819public class Client &#123; public static void main(String[] args) &#123; //创建环境对象 Context context = new Context(); //给环境对象存储变量 Variable a = new Variable(&quot;a&quot;); Variable b = new Variable(&quot;b&quot;); Variable c = new Variable(&quot;c&quot;); Variable d = new Variable(&quot;d&quot;); context.assign(a, 1); context.assign(b, 2); context.assign(c, 3); context.assign(d, 4); //获取抽象语法树 AbstractExpression abstractExpression = new Minus(a, new Plus(b, new Minus(c, d))); int result = abstractExpression.interpret(context); System.out.println(abstractExpression + &quot;=&quot; + result); &#125;&#125; 1234//抽象表达式类public abstract class AbstractExpression &#123; public abstract int interpret(Context context);&#125; 12345678910111213141516//环境角色类public class Context &#123; //定义一个Map集合用来存储变量及对应的值 private Map&lt;Variable, Integer&gt; map = new HashMap&lt;Variable, Integer&gt;(); //添加变量的功能 public void assign(Variable variable, Integer value) &#123; map.put(variable, value); &#125; //根据变量获取对应的值的方法 public int getValue(Variable variable) &#123; return map.get(variable); &#125;&#125; 123456789101112131415161718192021public class Minus extends AbstractExpression &#123; //减号两边的表达式 private AbstractExpression left; private AbstractExpression right; public Minus(AbstractExpression left, AbstractExpression right) &#123; this.left = left; this.right = right; &#125; @Override public int interpret(Context context) &#123; //将左边表达式的结果和右边表达式的结果进行相减 return left.interpret(context) - right.interpret(context); &#125; @Override public String toString() &#123; return &quot;(&quot; + left.toString() + &quot;-&quot; + right.toString() + &quot;)&quot;; &#125;&#125; 12345678910111213141516171819202122//加发表达式类public class Plus extends AbstractExpression &#123; //加号两边的表达式 private AbstractExpression left; private AbstractExpression right; public Plus(AbstractExpression left, AbstractExpression right) &#123; this.left = left; this.right = right; &#125; @Override public int interpret(Context context) &#123; //将左边表达式的结果和右边表达式的结果进行相加 return left.interpret(context) + right.interpret(context); &#125; @Override public String toString() &#123; return &quot;(&quot; + left.toString() + &quot;+&quot; + right.toString() + &quot;)&quot;; &#125;&#125; 12345678910111213141516171819202122//变量类，用于封装变量的类public class Variable extends AbstractExpression &#123; //声明存储变量名的成员变量 private String name; public Variable(String name) &#123; this.name = name; &#125; @Override public int interpret(Context context) &#123; //直接返回变量的值 return context.getValue(this); &#125; @Override public String toString() &#123; return name; &#125;&#125; 状态模式 我们与状态模式的转换最先想到的办法就是多个if-else判断来实现，但是当状态多大百种时，在使用这种方法肯定不太合适了，而且每一次增加新状态都需要修改源代码，更别谈有时候不同的状态还有条件的限制，因此此时我们可以将每一个状态设置为一个类，然后使用类之间方法的调用实现状态的转换，同时每一个状态限制条件写到对应的类中即可，分成多个模块方便维护，最重要的是当天价新状态时我们无需频繁的去更改主函数代码。现在我们就以电梯来演示一下，假设电梯有开门，关门，运行和停止四个状态，同时要求电梯在开门时点击运行是无效的，运行过程中点击开门也是无效的，并且电梯频繁的在四个状态中进行切换，UML图如下 Client.javaContext.javaLiftState.javaOpeningState.javaRunningState.javaStoppingState.javaClosingState.java123456789101112public class Client &#123; public static void main(String[] args) &#123; //创建环境角色对象 Context context = new Context(); //设置当前电梯状态 context.setLiftState(new RunningState()); context.open(); context.close(); context.run(); context.stop(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637//环境角色类public class Context &#123; //定义对应状态的对象常量 public final static OpeningState OPENING_STATE = new OpeningState(); public final static ClosingState CLOSING_STATE = new ClosingState(); public final static RunningState RUNNING_STATE = new RunningState(); public final static StoppingState STOPPING_STATE = new StoppingState(); //当前状态变量 private LiftState liftState; public LiftState getLiftState() &#123; return liftState; &#125; public void setLiftState(LiftState liftState) &#123; this.liftState = liftState; //设置当前状态对象中的Context对象 this.liftState.setContext(this); &#125; public void open() &#123; this.liftState.open(); &#125; public void close() &#123; this.liftState.close(); &#125; public void run() &#123; this.liftState.run(); &#125; public void stop() &#123; this.liftState.stop(); &#125;&#125; 123456789101112131415161718192021//抽象状态类public abstract class LiftState &#123; //环境角色类变量 protected Context context; public void setContext(Context context) &#123; this.context = context; &#125; //电梯开启操作 public abstract void open(); //电梯关闭操作 public abstract void close(); //电梯运行操作 public abstract void run(); //电梯停止操作 public abstract void stop();&#125; 12345678910111213141516171819202122232425public class OpeningState extends LiftState &#123; @Override public void open() &#123; System.out.println(&quot;电梯开启&quot;); &#125; @Override public void close() &#123; super.context.setLiftState(Context.CLOSING_STATE); //调用当前状态中的context中的对应的close方法 super.context.close(); &#125; @Override public void run() &#123; &#125; @Override public void stop() &#123; &#125;&#125; 1234567891011121314151617181920212223public class RunningState extends LiftState &#123; @Override public void open() &#123; &#125; @Override public void close() &#123; &#125; @Override public void run() &#123; System.out.println(&quot;电梯开始运行&quot;); &#125; @Override public void stop() &#123; super.context.setLiftState(Context.STOPPING_STATE); super.context.stop(); &#125;&#125; 123456789101112131415161718192021222324public class StoppingState extends LiftState &#123; @Override public void open() &#123; super.context.setLiftState(Context.OPENING_STATE); super.context.open(); &#125; @Override public void close() &#123; super.context.setLiftState(Context.CLOSING_STATE); super.context.close(); &#125; @Override public void run() &#123; super.context.setLiftState(Context.RUNNING_STATE); super.context.run(); &#125; @Override public void stop() &#123; System.out.println(&quot;电梯停止&quot;); &#125;&#125; 123456789101112131415161718192021222324public class ClosingState extends LiftState &#123; @Override public void open() &#123; super.context.setLiftState(Context.OPENING_STATE); super.context.open(); &#125; @Override public void close() &#123; System.out.println(&quot;电梯门关闭&quot;); &#125; @Override public void run() &#123; super.context.setLiftState(Context.RUNNING_STATE); super.context.run(); &#125; @Override public void stop() &#123; super.context.setLiftState(Context.STOPPING_STATE); super.context.stop(); &#125;&#125; 我们发现这种模式下，假设现在要添加一个停电和通电状态无需修改源代码，而只需要再添加新的状态。 策略模式 假设现在有一家百货公司在定年度的促销活动，针对不同的节日（春节、中秋节、圣诞节）推出不同的促销活动，由促销员将促销活动展示给客户。那么我们可以如下设计： 由于三种策略拥有的方法性质是一样的，只是实现不同，因此我们可以统一实现一个Strategy接口，然后售货员来聚合所有的策略，根据具体的情况来动态切换，这就是策略模式，非常容易理解。 Client.javaSalesMan.javaStrategy.javaStrategyA.javaStrategyB.javaStrategyC.java1234567891011121314public class Client &#123; public static void main(String[] args) &#123; //春节来了，使用春节促销活动 SalesMan salesMan = new SalesMan(new StrategyA()); salesMan.salesManShow(); System.out.println(&quot;==============&quot;); //中秋节来了，使用中秋节活动 salesMan.setStrategy(new StrategyB()); salesMan.salesManShow(); //圣诞节来了，使用圣诞节活动 salesMan.setStrategy(new StrategyC()); salesMan.salesManShow(); &#125;&#125; 123456789101112131415161718//环境类public class SalesMan &#123; //聚合策略类对象 private Strategy strategy; public SalesMan(Strategy strategy) &#123; this.strategy = strategy; &#125; //由促销员展示促销活动给普通用户 public void salesManShow() &#123; strategy.show(); &#125; public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125;&#125; 1234//抽象策略类public interface Strategy &#123; void show();&#125; 1234567public class StrategyA implements Strategy &#123; @Override public void show() &#123; System.out.println(&quot;买一送一&quot;); &#125;&#125; 1234567public class StrategyB implements Strategy &#123; @Override public void show() &#123; System.out.println(&quot;满200减50&quot;); &#125;&#125; 1234567public class StrategyC implements Strategy &#123; @Override public void show() &#123; System.out.println(&quot;满1000元加一元购买任意200元以下商品&quot;); &#125;&#125; 职责链模式 职责链模式也很好理解，他有点类似于OS中的索引表，我们用一个请假的案例来学习：现在需要开发一个请假流程控制系统，请假一天以下的假只需要小组长同意即可，请假1天到3天的假还需要部分经理统一，请假3天到7天还需要总经理统一，请假7天以上不存在（想什么呢！请这么长时间的假你是想被开除吗😒）。同时当请假的天数超过审批者权限时，审批者会默认统一，因为反正你还需要由上级去判定你是否能请假成功，因此假设你要请假4天，那么小组长是一定会同意的，但是他还会将你的请假信息上报给部门经理，如果部门经理不同意，那么即使现在小组长同意了你也是请假失败。UML类图如下 我们要注意每一个审批者都继承了Handler抽象类，然后他们都存储了上一级实例，以便向上级报告，但是他并不会存储上上级甚至上上上级的信息，即职责链模式是禁止跨级的，这也体现了迪米特原则。 Client.javaHandler.javaGroupLeader.javaManager.javaGeneralManager.javaLeaveRequest.java123456789101112131415public class Client &#123; public static void main(String[] args) &#123; //创建请假条 leaveResquest leaveResquest = new leaveResquest(&quot;小明&quot;, 6, &quot;身体不适&quot;); //创建各级领导对象 GroupLeader groupLeader = new GroupLeader(); Manager manager = new Manager(); GeneralManager generalManager = new GeneralManager(); //设置处理链 groupLeader.setNextHandler(manager); manager.setNextHandler(generalManager); //提交请假条 groupLeader.submit(leaveResquest); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class Handler &#123; protected final static int NUM_ONE = 1; protected final static int NUM_THREE = 3; protected final static int NUM_SEVEN = 7; //该领导处理的请假天数区间 private int numStart; private int numEnd; //声明后继者（声明上级领导） private Handler nextHandler; public Handler(int numStart) &#123; this.numStart = numStart; &#125; public Handler(int numStart, int numEnd) &#123; this.numStart = numStart; this.numEnd = numEnd; &#125; //设置上级领导对象 public void setNextHandler(Handler nextHandler) &#123; this.nextHandler = nextHandler; &#125; //各级领导处理请假条的方法 protected abstract void handlderLeave(leaveResquest leaveResquest); //提交请假条 public final void submit(leaveResquest leaveResquest) &#123; //领导先进性审批是否通过 if (this.nextHandler != null &amp;&amp; leaveResquest.getNum() &gt; this.numEnd) &#123; //提交给上级领导进行审批 System.out.println(&quot;提交至上级审核&quot;); this.nextHandler.submit(leaveResquest); &#125; else &#123; this.handlderLeave(leaveResquest); System.out.println(&quot;流程结束！&quot;); &#125; &#125;&#125; 12345678910111213//小组长类public class GroupLeader extends Handler &#123; public GroupLeader() &#123; super(0, Handler.NUM_ONE); &#125; @Override protected void handlderLeave(leaveResquest leaveResquest) &#123; System.out.println(leaveResquest.getName() + &quot;请假&quot; + leaveResquest.getNum() + &quot;天,理由是&quot; + leaveResquest.getContent()); System.out.println(&quot;小组长审批，审批同意&quot;); &#125;&#125; 1234567891011public class Manager extends Handler &#123; public Manager() &#123; super(Handler.NUM_ONE, Handler.NUM_THREE); &#125; @Override protected void handlderLeave(leaveResquest leaveResquest) &#123; System.out.println(leaveResquest.getName() + &quot;请假&quot; + leaveResquest.getNum() + &quot;天,理由是&quot; + leaveResquest.getContent()); System.out.println(&quot;部门经理审批，审批同意&quot;); &#125;&#125; 1234567891011public class GeneralManager extends Handler &#123; public GeneralManager() &#123; super(Handler.NUM_THREE, Handler.NUM_SEVEN); &#125; @Override protected void handlderLeave(leaveResquest leaveResquest) &#123; System.out.println(leaveResquest.getName() + &quot;请假&quot; + leaveResquest.getNum() + &quot;天,理由是&quot; + leaveResquest.getContent()); System.out.println(&quot;总经理审批，审批同意&quot;); &#125;&#125; 1234567891011121314151617181920212223242526272829//请假条public class leaveResquest &#123; //请假人员姓名 private String name; //请假天数 private int num; //请假内容 private String content; public leaveResquest(String name, int num, String content) &#123; this.name = name; this.num = num; this.content = content; &#125; public String getName() &#123; return name; &#125; public int getNum() &#123; return num; &#125; public String getContent() &#123; return content; &#125;&#125; 访问者模式 现在养宠物的人很多，当然宠物有狗、猫等等，要给宠物喂食的话，主人可以喂食，其他人也可以喂食，因此此时每一个宠物都会被许多访问者访问，但是我们不可能为每一个人都创建一个接口，此时就需要使用访问者模式了，他可以允许使用有限个方法使得该类实例被多种多样的实例所访问。UML图如下 Client.javaAnimal.javaCat.javaDog.javaPerson.javaOwner.javaSomeone.javaHome.java12345678910public class Client &#123; public static void main(String[] args) &#123; //创建Home对象 Home home = new Home(); home.add(new Dog()); home.add(new Cat()); Owner owner = new Owner(); home.action(owner); &#125;&#125; 1234567//抽象元素角色类public interface Animal &#123; //接收访问者访问的功能 void accept(Person person);&#125; 12345678public class Cat implements Animal &#123; @Override public void accept(Person person) &#123; //访问者喂食宠物猫 person.feed(this); System.out.println(&quot;好好吃，喵喵喵&quot;); &#125;&#125; 123456789public class Dog implements Animal &#123; @Override public void accept(Person person) &#123; //访问者喂食宠物猫 person.feed(this); System.out.println(&quot;好好吃，汪汪汪&quot;); &#125;&#125; 1234567//抽象访问者角色类public interface Person &#123; //喂食宠物 void feed(Cat cat); void feed(Dog dog);&#125; 123456789101112public class Owner implements Person &#123; @Override public void feed(Cat cat) &#123; System.out.println(&quot;主人喂猫&quot;); &#125; @Override public void feed(Dog dog) &#123; System.out.println(&quot;主人喂狗&quot;); &#125;&#125; 1234567891011public class Someone implements Person &#123; @Override public void feed(Cat cat) &#123; System.out.println(&quot;其他人喂猫&quot;); &#125; @Override public void feed(Dog dog) &#123; System.out.println(&quot;其他人喂狗&quot;); &#125;&#125; 12345678910111213141516public class Home &#123; //声明一个集合对象用来存储元素对象 private List&lt;Animal&gt; nodeList = new ArrayList&lt;Animal&gt;(); //添加元素的功能 public void add(Animal animal) &#123; nodeList.add(animal); &#125; public void action(Person person) &#123; //遍历集合，获取每一个元素对象。让访问者访问每一个元素 for (Animal animal : nodeList) &#123; animal.accept(person); &#125; &#125;&#125; 您可以点击左上方链接获取上面教程所使用的代码,同时可以参考本篇博客完成homework03实验巩固学习😊"},{"title":"传输介质与设备","path":"/wiki/计算机网络笔记/传输介质与设备/index.html","content":"传输介质 传输介质也称为传输媒体/传输媒介，他就是数据传输系统在发送设备和接收设备之间的物理通路。传输介质可以分为导向传输介质和非导向传输介质。在导向传输介质中，电磁波被导向沿着固体媒介（铜线或光纤）传播，而对于非导向传输介质可以是空气、真空或者海水等。 我们要注意传输媒体并不属于物理层，传输媒体在物理层的下面，因为物理层是体系结构中的第一层，因此有时也称传输媒体为第0层。在传输媒体中传输的是信号，但是传输媒体却并不知道传输的信号是什么意思。而物理层规定了电气特性，因此能够识别所传送的比特流。 思考：传输媒体和物理层的主要区别？ 在传输媒体中传输的是信号，但是传输媒体并不知道所传输的信号是代表什么，也就是说，传输媒体不知道信号什么时候是1什么时候是0.但是物理层由于规定了电气特性，因此能够识别所传送的比特流。 导向性传输介质 双绞线 双绞线是最古老、又最常用的传输介质，它采用两根采用一定规则并排绞和、相互绝缘的铜导线组成。 绞和可以减少对相邻导线之间的电磁干扰。为了进一步提高抗电磁干扰能力，我们还可以在双绞线的外面再加上一个由金属丝编织而成的屏蔽层，这就是屏蔽双绞线（STP），无屏蔽层的双绞线就称为非屏蔽双绞线（UTP)。 双绞线价格便宜，是最常用的传输介质之一，在局域网和传统电话网中普遍使用。模拟传输和数字传输都可以使用双绞线，其通信距离一般为几公里到几十公里，距离太远时，对于模拟传输，要使用放大器放大衰减的信号，对于数字传输，要使用中继器将失真的信号整型。 同轴电缆 同轴电缆由导体铜质芯线、绝缘层、网状编址屏蔽层和塑料外层组成。按特性阻抗数值的不同，通常将同轴电缆分为两类：50Ω同轴电缆和75Ω同轴电缆。其中，50Ω同轴电缆主要用于传送基带数字信号，又称为基带同轴电缆，他在局域网中得到广泛应用，而75Ω同轴电缆主要用于传送宽带信号，又称为宽带同轴电缆，主要用于有线电视系统。 由于外导体屏蔽层的作用，同轴电缆抗干扰特性比双绞线好，被广泛应用于传输较高速率的数据，其传输距离更远，但是价格也比双绞线更高。 光纤 光纤导线就是利用光导纤维（简称光纤）传输光脉冲来进行通信。有光脉冲表示1，无光脉冲表示0。而可见光的频率大概是10^8dMHz,因此光纤通信系统的带宽远远大于目前其他各种传输媒体的带宽。 光纤在发送端有光源，可以采用发光二极管或者半导体激光，他们在电脉冲作用下能产生出光脉冲，在接收端用光电二极管做成光检测器，在检测时还可还原出电脉冲。 光纤主要由纤芯（实心的）和包层构成，光波通过纤芯进行传导，包层较纤芯有较低的折射率。当光纤从高折射率的介质射向较低折射率的介质时，其折射角大于入射角。因此，如果入射角足够大，就会出现全反射，即光纤碰到包层时就会折射回纤芯、这个过程不断重复，光也就沿着光纤传输下去。 光纤传输又分为多模光纤和单模光纤： 多模光纤：只要从纤心射到纤心表面的光纤的入射角大于某个临界角度，就会产生全反射。因此，从不同角度入射的多束光线可在一条光纤中传输，这种光纤称为多模光纤。多模光纤的光源为发光二极管。光脉冲在多模光纤中传输时会逐渐展宽，造成失真，因此多模光纤只适合于近距离传输。 单模光纤：光纤的直径减小到一个光波长度时，光纤就像一根波导那样，可使光线一直向前传播，而不会产生多次反射，这样的光纤就是单模光纤。单模光纤的纤心很细，直径只有几微米，制造成本高。同时单模光纤的光源为定向性很好的激光二极管，因此单模光纤的衰减较小，适合于远距离传输。 我们可以总结光纤有如下特点: 传输损耗小，中继距离长，对远距离传输特别经济 抗雷电和电磁干扰性能好 无串音干扰，保密性好，也不易被窃听和截取数据 体积小，重量轻 非导向性传输介质 无限通信已广泛应用于移动电话领域，构成蜂窝式无线电话网。随着便携式计算机的出现，以及在军事、野外等特殊场合下移动通信联网的需要，促进了数字化移动通信的发展，现在无线局域网产品的应用已经非常普遍。 无线电波 无线电波穿透能力强，可以传输很长的距离，所以被广泛应用于通信领域，如无线手机通信、计算机网中的无线局域网（WLAN）等。因为无线电波使信号向所有方向散播，因此有效距离范围内的接受设备无需对准某个方向接收，就可以与无线电波发射者进行通信连接，大大简化了通信连接。这也是无线电传输的最重要的优点之一。 微波、红外线和激光 目前高宽带的无线通信技术就是微波、红外线和激光这三种通信技术。他们都需要发送方和接收方之间存在一条视线通路，有很强的方向性，都沿直线传播，有时这三者又统称为视线介质。不同的是，红外线通信和激光通信把要传输的信号分别转换为各自的信号格式，即红外线信号和激光信号，再直接在空间中传播。 微波通信的频率较高，频段范围也很宽，载波频率通常为2~40GHz，因而通信信道的容量大。例如一个带宽为2MHz的频段可以容纳500条的语音线路，若用来传输数字信号，数据率可达Mb/s的级别。与通常的无线电波不同，微波通信的信号是沿直线传播的，因此在地面的传播距离有限，超过一定距离后需要中继站来接力。 但是微波信号在卫星通信中作用极大，卫星通信利用地球同步卫星作为中继来转发微波信号，可以克服地面微波通信距离的限制。三颗相隔120°的同步卫星几乎能覆盖整个地球表面，因而能够实现全球通信。卫星通信的优点是通信容量大、距离远、覆盖广，缺点是端到端的传播时延长，一般为250~270ms。 物理层设备 中继器 中继器诞生的原因就是解决线路上由于损耗而导致信号衰减甚至失真的问题的。它能够对信号进行再生和还原，对衰减的信号进行放大，保持与原数据相同，以增加信号传输的距离，延长网络的长度。 中继器两端的网络部分是网段，而不是子网，适用于完全相同的两类网络的互联，且两个网段速率要相同。中继器只将任何电缆段上的数据发送到另一段电缆上，它仅作用于信号的电气部分，并不管数据中是否有错误数据或不适用于网络的数据。同时中继器可以连相同的媒体，也可以连不同的媒体。只要中继器两端的网段一定要是同一个协议即可，同时中继器不会存储转发（傻🤣）。 所谓网段就是指一个计算机网络中使用同一物理层设备（传输介质，中继器，集线器等）直接通讯的那一部分。比如从一个IP到另一个IP好比 从192.168.0.1到192.168.255.255这之间就是一个网段 网络标准中都对信号的延迟范围作了具体的规定（5-4-3规则），因而中继器只能在规定的范围内进行，否则会出现网络故障。 所谓的5-4-3规则就是指在10M以太网中，网络总长度不得超过5个网段，4台网络延长设备，且5个区段中只有3个区段可接网络设备。如上图我们发现有5个线段表示5个网段，4个蓝色矩形表示4台中继设备，和三个可以接入这个以太网的网络设备。 集线器（多口中继器） 集线器的功能是对信号进行再生放大转发，对衰减的信号进行放大，接着转发到其他所有（除了输入端口）处于工作状态的端口上（优点类似于广播），以增加信号的传输距离，延长网络的长度。因此也说明他不具备定向传送能力，是一个共享式设备。 物理层接口的特性 物理层考虑的是如何在连接到各台计算机的传输媒体上传输数据比特流，而不指具体的传输媒体。物理层应尽可能屏蔽各种物理设备的差异，使数据链路层只考虑本层的协议和服务。物理层的主要任务可以描述为确定与传输媒体的接口有关的一些特性： 机械特性：主要定义为物理连接的边界点，即接插装置。规定物理连接时所采用的的规格、引线的数目、引脚的数量和排列情况。 电气特性：规定传输二进制位时，线路上信号的电压高低、阻抗匹配、传输速率和距离限制等。 功能特性：指明某条线上出现的某一电平的电压表示何种意义，接口部件的信号线（数据线、控制线、定时线等）的用途。 规程特性：主要定义各物理线路的工作规程和时序关系。 常用的物理层接口标准有EIA RS-232-C、ADSL和SONET/SDH等。 总结 自此我们大体上学习完了物理层的所有知识点，一下是知识脑图："},{"title":"DL层功能与组帧","path":"/wiki/计算机网络笔记/DL层功能与组帧/index.html","content":"从本讲开始我们将开始学习数据链路层的知识，数据链路层主要的功能是向网络层提供数据帧封装的信息，他会涉及到差错检测，共享信道中冲的突解决以及滑动窗口选择重传的问题，此章是考察的重难点，要透彻理解每一个知识点。 数据链路层概念 数据链路层的功能 数据链路层在物理层的服务的基础上向网络层提供服务，他的主要作用就是加强物理层传输比特流的功能，将物理层提供的可能出错的物理连接改造为逻辑上无差错的数据链路，使之对网络层表现为一条无差错的链路。对于网络层而言，数据链路层的基本任务就是将源机器中来自网络层的数据传输到目标机器的网络层。他可以向网络层提供如下服务： 数据链路层接收文件并登记重传4,5号帧 无确认的无连接服务：源机器发送数据帧时不需要先建立链路连接，目的机器收到数据帧时不需要发回确认信息，对丢失的帧，数据链路层不负责重发而是直接交给上层处理。适用于实时通信或者误码率比较低的通信，比如以太网。 有确认的无连接服务：源机器发送数据帧时不需要先建立连接，但是目的机器接收到数据帧后需要发回确认。源机器在所规定的时间内未收到确定信号时，就会重传丢失的帧，以提高数据传输得可靠性。这种服务适用于误码率较高的通信，比如无线通信。 有确认的面向连接服务：帧传输过程分为三个阶段：建立数据链路、传输帧、释放数据链路。目的机器对收到的每一帧都要给出确认，源机器收到确认后才发送下一帧，因而该服务的可靠性最高，但是成本也高。这种服务适用于通信要求（可靠性、实时性）较高的场合。 一定要注意实际上数据链路层传输数据帧是会有丢帧的，但是它能够立刻进行重传，因此对于网络层来看，数据链路层好像提供了可靠的逻辑上无差错的数据通路，而实际上其对应的物理层是发生了丢失比特流数据或者比特流数据是有错误的，但是物理层就不会检测错误也不会重传，而是直接交付给数据链路层，所以说物理层是傻子 同时数据链路层还有如下功能： 链路管理，即数据链路的建立、维持和释放（用于面向连接的服务时使用） 组帧（将从网络层传下来的数据报进行封装得到帧以便在数据链路上传送） 流量控制（保证传送的数据不会过快也不会过慢，并且仅会限制发送方） 差错控制（帧错/位错都会检测到，然后可能重传以保证无差错交付给网络层） 数据链路层的组成 节点：主机、路由器（一定要注意对于数据链路层，路由器也是他的服务对象） 链路：网络中两个节点之间的物理通信，链路的传输介质有双绞线、光纤和微波。分为有线链路和无线链路。 数据链路：网络中两个节点之间的逻辑通道，把实现控制数据传输协议的硬件和软件加到链路上就构成了数据链路。 帧：链路层的协议数据单元，封装网络层数据报而来。 数据链路负责通过一个链路从一个节点向另一个物理链路直接相连的物理链路直接相连的相邻节点传送数据报。 思考：链路和数据链路的本质区别？ 链路就是通常所说的物理数据信道。而数据链路是虚拟的概念，他不是一个具象的实物，他是在物理链路的基础上绑定了一系列协议实现的一种逻辑信道，他和物理链路的最大区别就是物理链路上会出现数据丢失或者数据错误以及链路故障，但是在数据链路中他通过协议为网络层提供了一种传输的数据不会出错（实际上是出错了就重传）的链路。因此数据链路层的服务本质上还是由物理层提供的，我们还要注意数据链路由于是基于链路实现的，因此如果两个节点的物理链路不相连，那么它们之间也就没有数据链路可连。 链路管理 数据链路层连接的建立、维持和释放过程称为链路管理，它主要用于面向连接的服务。链路两端的节点要进行通信，必须首先确认对方已处于就绪状态，并且交换一些必要的信息以对帧序号初始化，然后才能建立连接，在传输过程中还要维持这种连接，而在传输完毕后要释放该连接。在多个站点共享同一个物理信道的情况下（例如局域网）如何在要求通信的站点间分配和管理信道也属于数据链路层管理的范畴。 从上面的介绍中我们可以得到一个信息，数据链路上的连接并不是持续存在的，他只在需要数据传输时才建立；而物理链路上的连接却是一直存在的，除非物理链路发生了损坏导致链路断路，两个节点之间的链路连接才会消失。 帧定界、帧同步与透明传输 在两个工作站之间进行信息传输时，必须将网络层的分组进行封装成帧，以帧的格式进行传送。将一段数据的前后分别添加首部和尾部，就构成了帧。 首部和尾部中含有许多控制信息，他们的一个重要作用就是确定帧的帧界限，即帧定界。而帧同步就是指接收方能从接收到的二进制比特流中区分出帧的起始与终止。如在HDLC通信规程中，用标志位F（01111110）来标识一个帧的开始和结束。如在通信过程中，检测到帧标识位F即认为是帧的开始，然后一旦再检测到帧标识位F即表示帧的结束。如下图是HDLC标准帧的格式： 对应的位数是： 但是此时有一个小问题，如果数据中恰好出现与帧定界符相同的比特组合（会误认为传输结束而丢弃后面的数据），那么就需要采用一种有效的措施来解决这个问题，即透明传输。透明传输就是不管所传送的数据是什么样的比特组合，都应当能够在链路上传送。 思考：透明传输是如何解决上述问题的？ 由于透明传输是要求所有的比特组合都能在信道上传输的，即遇到帧停止标识符后并不会导致后面的数据不再接收，那么接收方就可以判断出此时的01111110到底是停止标识符还是中间数据了，由于每两个帧之间传输不是连续的，而是有间隔的，因此如果立刻收到了一个好像01111110的停止标识位时接收方会继续等待接手新的帧，而又由于透明传输保证了比特组合不会被拒绝接收，因此后面部分的数据会紧接着抵达接收方，接收方发现这段数据开头不是标识位，那么就可以断定之前的那个0111110不是停止标识位了。 流量控制 由于收发双方的各自工作速率和缓存空间不同，可能出现发送方的发送能力大于接收放的接受能力的现象，如果此时不适当限制发送方的发送速率（即链路上的信息流量），那么前面来不及接受的帧将会被后面的不断发送的帧&quot;淹没&quot;，造成帧的丢失而出错。因此流量控制实际上就是限制发送方的数据流量，使其发送帧的速率不超过接收方的能力。 我们要注意即使后面的帧挤掉了前面的帧，但是由于数据链路层中接收方是有序接收的，新挤上来的帧也不会被接收方接受的，这样就会导致后面所有再发送的帧都会被丢弃造成资源的浪费。 这个过程的实现需要某种反馈机制是发送方能够知道接收方是否能够跟上自己的节奏，并且很明显这个过程是动态变化的，并不是稳定的，因此需要有一些规则每隔一段时间就使得发送方知道在什么情况下可以接着发送下一帧，而在什么情况下必须暂停发送，以等待收到某种反馈信息后继续发送。 这里介绍一种最简单的实现方法，即当接收方收不下时就不回复给发送方反馈信息，发送方再没有收到下一个反馈信息之前不发送下一个帧，而当接收方可以接收时就回复确认来告诉发送方可以发送下一个帧了。这种方法实现简单，但是也到了许多问题，首先每次都需要反馈信息，效率低，其次这也导致了数据链路收发双方帧的传输只能是如上图的这种格式一个一个有序的传输。 同时我们要注意流量控制并不是数据链路层特有的功能，许多高层协议中也提供此功能，只不过控制的对象不同而已。对于数据层来说，控制的是相邻两节点之间数据链路上的流量即点对点形式，而对于传输层来说，流量控制是端到端形式的，同时传输层就对流量控制的实现进行了优化，不再是一个一个的有序接收传输了，而是接收端发送一个动态的窗口公告来持续的通知发送方自己的缓存区空间大小。 差错控制 由于信道噪声等各种原因，帧在传输过程中是可能出现错误的。使发送方确定接收方是否正确收到其发送的数据的方法称为差错控制。通常这些错误都是位错（位数反转）或者帧错。 位错指帧中某些位出现了差错，通常采用循环冗余校验码（CRC）方式或者海明码方式发现位错并进行纠正，或者通过自动重传请求（Automatic Report reQuest,ARQ)通知发送方重传错误帧。具体做法是让发送方将要发送的数据帧附加一定的CRC冗余检错码一并发送，接收方根据检错码对数据帧进行差错检测，若发现错误则丢弃，发送方（未在规定时间收到反馈信息）内超时重传该数据帧。这种差错控制方法称为ARQ法，ARQ法只需返回很少的控制信息就可以有效地确认发送数据帧是否被正确接收。具体的CRC检测步骤请参考这里： CRC检错https://coolchong.cn/2021/01/31/comsys-note2/ 帧错指帧的丢失、重复或者失序等错误。在数据链路层引入定时器和编号机制，能够保证每一帧最终都能有且仅有一次正确地交付给目的节点。 组帧（封装成帧） 数据链路层之所以要将比特组合成帧为传输单位，就是为了在出错时之重发出错的帧，而不需要重新发全部数据，提高了传输的效率。为了使接收方能够正确的接受并检查所传输的帧，发送方必须依据一定的规则把网络层递交的分组封装成帧（称为组帧）。组帧主要解决帧定界、帧同步、透明传输等问题。 封装成帧就是在一段数据的前后端加上首部和尾部，这样就构成了一个帧。接收端在收到物理层上交的比特流数据后，就能根据首部和尾部的标记，从收到的比特流中识别一段帧的开始和结束。 思考：为什么组帧时需要在数据的首部和尾部都进行包装？ 在网络中信息是以帧为最小单位进行数据传输的，所以接收端要正确的接收帧，必须能够清楚帧在一串比特流中从哪里开始和到哪里结束（因为接收端收到的只是一串比特流，没有首部和尾部就不能正确的区分帧），而分组（即IP数据报）仅是包含在帧中的数据部分（后面将详细讲解），所以不再需要增加尾部来定界。 我们把接收方应当能从接收到的二进制比特流中区分出帧的开始和结束的过程称为帧同步 组帧有四种方法：①字符计数法②字符（节）填充法③零比特填充法④违规编码法，下面我们注意介绍这几种组帧方法的步骤 字符计数法 这种方法实现简单，原理也很简单。帧首部使用一个计数字段（第一个字节，八位）来标明帧内字符数（计数长度包含首部）。如上图，第一个帧我们从第一个字节的首部可得知长度是5，因此第一个帧就是51234，然后下一个字节就是属于第二个帧的首部了，因此第二个帧长度也是5，因此第二个帧时56789，以此类推，第三个帧、第四个帧等等都可以得到区分。 我们思考一下这种方法的缺点有哪些，其实我们很容易就可以看出来，他把好多帧都连在一起了，即鸡蛋放在同一个篮子里了，当有其中的任意一个帧的计数首部字段发生错误时，会导致连锁反应，造成许多段无法得到正确的区分。即帧边界划分依据不太好，很容易造成帧的结束位和下一帧的开始位混乱，收发双方将失去同步，从而造成灾难性后果。 字符填充的首位定界符法 字符填充法是使用一些特定的字符来定界一帧的开始和结束（DLE STX）与结束（DLE ETX），这个思路跟我们上面介绍透明传输时使用的帧分割的思路一致，即使用特殊的帧开始和停止标识位，但是我们就面临了一个问题，即如何能够使信息位中出现的特殊字符不会被误判为帧的首位定界符？ 之前我们介绍过一个解决策略即透明传输，即在特殊字符前填充一个转义字符（DLE）来加以区分（注意，转义字符是ASCII码中的控制字符，是一个字符而不是&quot;D&quot;,“L”,&quot;E&quot;三个字符的组合），以实现数据的透明传输。接收方收到转义字符后，就知道其后面紧跟的是数据信息，而不是控制信息。 当传送的帧是由文本文件组成时（文本文件的字符都是从键盘上输入的，因此都是对应着ASCII码），因此都可以放到帧中传输，即透明传输。当传送的帧时由非ASCII码的文本文件（二进制程序或者图像文件），那么就要采用字符填充方法实现透明传输。 如上图就是一个包含转义信息的帧的组帧发送和接受的过程。我们发现在从网络层传下来的数据中有EOT、SOH、ESC等需要转义的内容，因此发送方除了在首部添加SOH首部和EOT尾部后还需要对中间的内容进行转义，因此插入了蓝色转义内容ESC（我们要注意内容中的转义字段也需要再转义，如上图中的ESC需要再转义）。而接收方再得到数据后会删除插入的转义字段，结果得到的是原始数据，这就是字符（节）填充法组帧的由来。 零比特填充的首位标志法 我们思考一下实际上字符填充的首位定界符法已经可以很完美的解决帧定界的问题了，但是他的性能可以进一步提升，在字符填充的首位定界符法中操作的对象是ASCII码，但是我们完全可以将操作对象进一步简化到比特流数据，这样更偏向硬件层，性能肯定也更佳（毕竟任何一个数据本质上都是一段比特流数据）。零比特填充法允许数据帧包含任意个数的比特，也允许每个字符的编码包含任意个数的比特。他使用一个特定的比特模式，即01111110来标志一帧的开始和结束，因此他也面临解决中间数据内容部分不会被误判的问题，但是他的解决策略并不是进行转义，而是对数据进行修改操作使得中间的数据比特流内容不可能出现标志位形式。为了不使信息位中出现比特流01111110被误判为帧的首位标志，发送方的数据链路层在信息位中遇到5个连续的1时，就会自动在其后插入一个0，而接收方做该过程的逆操作，即每收到5个连续的1时，自动删除后面紧跟的0，以恢复原信息。 这样就保证了透明传输，在传送的比特流组合中可以传送任意比特组合，而不会引起对帧边界的判断错误。这种方法很容易由硬件来实现，性能要优于字符填充法。 违规编码法 在物理层进行比特编码时，通常采用违规编码法，例如使用曼彻斯特编码方式将数据比特&quot;1&quot;编码成&quot;高-低&quot;电平对，将数据比特&quot;0&quot;编码成&quot;低-高&quot;电平对，而&quot;&quot;高-高电平对和&quot;低-低&quot;电平对在数据比特中是违规的（即没有被采用表示数据），我们可以借用这些违规编码来定界帧的起始为和终止位。例如局域网IEEE 802标准就采用了这种方法。 违规编码法不需要采用任何填充技术，便能实现数据传输的透明性，他是它只适用于采用冗余编码的特殊编码环境。 总结 组帧方法 特点 优缺点 字符计数法 用首部计数段区分不同帧 原理简单，但是脆弱 字符填充法 使用转义字符使得标志位形式的数据不会被误判 安全但是复杂且不兼容 零比特填充法 使数据部分不可能出现标志位组合 实现简单且稳定 违规编码 使用违规电平作为帧的标志位 实现简单且稳定 由于字节计数法中计数字段的脆弱性和字符填充法实现上的复杂性和不兼容性，目前常用的组帧方法是比特填充法和违规编码法。"},{"title":"什么是计算机网络","path":"/wiki/计算机网络笔记/什么是计算机网络/index.html","content":"计算机网络基本概念 一般的，我们认为计算机网络是一个将分散的、具有独立功能的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。总结来说，计算机网络就是一些互联的、自治的计算机系统的集合。一定要注意计算机网络是一种系统的集合，所以其根本是系统的集合。 思考：什么是互联，自治？ 互联就是互联互通，通信链路，自治就是无主从关系，比如macO,Windows等电脑系统设备以及IOS和Android等手机系统设备都会通过许多协议和计算机网络服务设备连接，但是其自身和服务区无主从关系，一个设备是可以自己做到独立工作的。 在计算机网络的发展阶段，人们对计算机网络给出了不同的定义，这些定义反映了当时网络技术发展的水平，具体定义可以分为三类： 广义观点 广义观点认为，只要是能够实现远程信息处理的系统或进一步达到资源共享的系统，都是计算机网络。广义的观点定义了一个计算机通信网络，他在物理结构上具有计算网络的雏形，但是资源贡献能力弱，是计算机网络的低级阶段。 资源共享观点 这种观点认为，计算机网络是“以能够相互共享资源的方式互联起来的自治计算机系统的集合”。这个定义包含着三层含义：①目的：资源共享②组成单元：分布在不同地理位置的多台独立的“自治计算机”③网络中的计算机必须遵循的统一规则–网络协议。这个定义符合目前计算机网络的基本特征。 用户透明观点 这种观点认为，存在一个能为用户自动管理资源的网络操作系统，它能够调用用户所需要的资源，而整个网络就像一个大的计算机系统一样对用户是透明的，用户使用网络就像使用一台单一的超级计算机，无需了解网络的存在、资源的位置信息。用户透明性观点的定义描述了一个分布式系统，他是网络未来发展的追求的目标 思考：三个观点的变化？ 在广义观点中，只是认为计算机网络是一个能够处理互联远程信息的系统，但是仅仅由一个系统来处理，共享性弱。所以提出来了计算机网络是所有能够相互共享资源的自治计算机系统的集合，此时每一个自治计算机系统皆是计算机网络组成的一部分，共享性更强了，但由于每一个计算机只是计算机网络的一部分，所以单独拿出来不是一个计算机网络系统。所以提出了分布式的概念，实际上分布式概念可以参考github，我们本地计算机同时都可以视为是一个计算机网络用户，我们的计算机可以接受互联共享服务使用计算机网络操作系统，同时也可以看成是一个完整的计算机网络系统，是一个提供互联服务的计算机操作系统。 计算机网络的组成 角度一：组成部分 从组成部分分析，我们可以将计算机网络分成硬件、软件、协议三大部分，并且三者缺一不可。 硬件主要由主机（也称端系统）、通信链路（如双绞线，光纤）、交换设备（如路由器、交换机）和通信处理机（如网卡）等组成。 软件主要包括各种实现资源共享的软件和方便用户使用的各种工具软件（如网络操作系统、邮件收发程序、FTP程序、聊天程序等）。软件部分多属于应用层。 协议是计算机网络的核心，如同交通规则制约汽车驾驶一样，协议规定了网络传输数据时所要遵循的规范。 角度二：工作方式 计算机网络（主要指Internet)可以分为边缘部分和核心部分。边缘部分由所有连接到因特网上，供用户直接使用的主机组成，用来进行通信（如传输数据音频或视频）和资源共享。核心部分由大量的网络和连接这些网络的路由器组成，它为边缘部分提供连通性和交换服务。如下图所示： 网络的一个结构如下图： 这里的比特流可以看成是不同协议的互联传送信息的数据信号，网络里面确实是许许多多多主机系统的集合。 角度三：功能组成 计算机网络由通信子网和资源子网组成，通信子网由各种传输介质、通信设备和相应的网络协议组成，他使网络具有数据传输、交换、控制和存储的能力，实现联网计算机之间的数据通信。资源子网是实现资源共享功能的设备及其软件的集合，向网络用户提供共享其他计算机上的硬件资源、软件资源和数据资源的服务。 计算机网络的功能 计算机网络的功能有许多，现今的很多应用都与网络有关。主要由以下五大功能 数据通信 他是计算机网络最基本和重要的功能，用来实现联网计算机之间的各种信息的传输，并将分散在不同地理位置的计算机联系起来，进行统一的调配、控制和管理。比如，文件传输、电子邮件等应用，离开了计算机网络都是无法实现的，所以数据通信是计算机网络连通性的体现。 资源共享 资源共享可以是软件共享，数据共享甚至是硬件共享。使计算机网络中的资源互通有无分工协作，从而极大的提高了硬件资源、软件资源和数据资源的利用率。最直观莫过于有道翻译、在线画思维导图等应用实现了资源共享。 分布式管理 当计算机网络中某个计算机系统负荷过载时，可以将其处理的某个复杂任务分配给网络中的其他计算机系统，从而利用空闲计算机资源以提高整个系统的利用率。因此多台计算机各自承担同一工作任务的不同部分，比如Hadoop平台 提高可靠性 计算机网络中的各台计算机可以通过网络互为替代机 负载均衡 将工作任务均衡的分给计算机网络中的各台计算机（很像操作系统） 计算机网络的分类 角度一：按照分布范围分类 广域网（WAN） 广域网的任务是提供长距离通信，运送主机所发送的数据，其覆盖范围通常为几十千米到几千千米的区域，因而也称为远程网。广域网是因特网的核心部分、链接广域网的各节点交换机的链路一般是告诉链路，具有较大的通信容量。所以WAN一般使用交换技术。 城域网（MAN） 城域网的覆盖范围可以跨越几个截取甚至整个城市，覆盖范围约为5~50km。城域网大多采用以太网技术，因此有时也常并入局域网的范围进行讨论。 局域网（LAN） 局域网一般用微机或工作站通过高速线路连接，覆盖范围小，通常为几十米到几十千米的区域。局域网在计算机配置的数量上没有太多的限制，少的可以只有两台（最经典的就是两人通过局域网联机MC），多的可以有几百台（大型图书馆热点局域网）。在传统上，局域网使用广播技术。 个人区域网（PAN） 个人区域网在个人工作地方将消费电子设备（平板电脑，智能手机等）用无线技术链接起来的网络，也常称为无限个人区域网（WPAN），其覆盖范围的区域直径约为10m。 注意：若中央处理器之间的距离非常近（如1m的数量级或者更小），则一般就称之为多处理系统，而不称为计算机网络 角度二：按传输技术分类 广播式网络 所有联网计算机都共享一个公共通信信道。当一台计算机利用共享通信信道发送报文分组时，所有其他的计算机都会“收听”到这个分组。接收到改分组的计算机将通过检查目的地址来决定是否接收该分组。 局域网基本上都采用广播式通信技术，广域网中的无线、卫星通信网路也采用广播式通信技术。 点对点网络 每条物理线路连接一对计算机。如果通信的两台主机之间没有直接连接的线路，那么它们之间的分组传输就要通过中间节点的接收、存储和转发，直至目的节点。 是否采用分组存储转发与路由选择机制是点对点式网络与广播式网络的重要区别，广域网基本都属于点对点网络。 角度三：按拓扑结构分类 网络拓扑结构是指由网中节点（路由器、主机等）与通信线路（网线）之间的几何关系（如总线形，环形）表示的网状结构，主要指通信子网的拓扑结构。 按网络的拓扑结构，主要分为总线形，星形，环形和网状形网络等，如下图： 星形和环形网络多用于局域网都是广播式结构，网状网多用于广域网都是点对点式结构。 总线形网络：用单根传输线把计算机连接起来。总线形网络的优点是建网容易、增减节点方便、节省线路。缺点是重负载时通信效率不高、总线任意一处对故障敏感（可以理解为串联）。 星形网络：每个终端或计算机都以单独的线路与中央设备相连，中央设备早期是计算机，现在一般是交换机或路由器。星形网络便于集中控制与管理，因为端用户之间的通信必须经过中央设备。缺点是成本高、中心节点对故障敏感。 环形网络：所有计算机接口连成一个环状，环形网络最典型的例子是令牌环局域网。环可以是单环，也可以是双环，但是环中信号是单向传输的。 网状形网络：一般情况下，每个节点至少有两条路径与其他节点相连，多用于广域网中，有规则和非规则两种。优点是可靠性高，缺点是控制复杂，线路成本高。 当然上面这四种网络可以再相互连接组合，称为更加复杂的网络。 角度四：按使用者分类 公用网（Public Network）：顾名思义就是电信公司斥资建造的大型网络，“公用”的意思是指所有愿意按电信公司的规定缴纳费用的人都可以使用这种网络，因此称为公众网。一般我们使用的WIFI都是公用局域网 专用网（Private Network）：一般是某个部门为满足单位特殊业务的需要而建造的网络，这种网络不向本单位以外的任何人提供服务。例如铁路，电力，军队等部门使用的专用内网。 角度五：按交换技术分类 交换技术是指各台主机之间、各通信设备之间或主机与通信设备之间为交换信息所采用的数据格式和交换装置的方式。按交换技术可将网络分为以下几种： 电路交换技术：在源节点与目的节点之间建立一条专用的通道用于传送数据，包括建立链接、传输数据和断开连接三个阶段。最典型的电路交换网是传统电话网络。这种网络的主要特点是整个报文的比特流连续地从源节点直达终点，好像是在一条管道中传送。优点是数据直接传送，时延小。缺点是线路利用率低、不能充分利用线路容量、不便于进行差错控制。 报文交换网络：用户数据加上源地址、目的地址和校验码等辅助信息，然后封装成报文。整个报文文件传送到相邻节点，全部存储后，再转发给下一个节点，重复这一过程直到到达目的节点。每个报文可以单独选择到达目的节点的路径。报文交换网络也称为存储-转发网络，主要特点是整个报文先传送到相邻节点，全部存储后查找转发表，转发到下一个节点。优点是可以充分地利用线路容量，可以实现不同链路之间的不同数据率的转换，可以实现格式转换，可以实现一对多，多对一的访问，可以实现差错控制。缺点是增大了资源开销（如辅助信息导致处理时间和存储资源的开销），增加了缓冲时延，需要额外的控制机制来保证多个报文的顺序不乱，缓冲区也难以管理（因为报文的大小不确定，接收方在接收到报文之前不能预知报文的大小）。 分组交换网络：也称为包交换网络。原理是将数据分成较短的固定长度的数据块，在每个数据块上加上目的地址，源地址等辅助信息组成分组（包），以存储-转发方式传输。其主要特点是单个分组（他只是整个报文的一部分）传送到相邻接点，存储后查找转发表，转发到下一个节点。除具备报文交换网络的优点外，分组交换网络还具有自身的优点：缓冲易于管理，包的平均时延更小，网络占用的平均缓冲区更小，更易于标准化，更适用于应用。现在的主流网络基本上都使用分组交换网络。实际上分组交换网络相较报文交换网络，就是解决了他的缺点，将大小不确定的报文切割成多个固定大小的包来传输。 角度六：按传输介质分类 传输介质分为有线和无线两大类，因此网络可以分为有线网络和无线网络。有线网络有分为双绞线网络、同轴电缆网络等。无线网络可分为蓝牙、微波、无线电等类型。 总结"},{"title":"结构型模式","path":"/wiki/设计模式笔记/结构型模式/index.html","content":"UML图基本概念 在学习结构型模式之前，我们先来学习一下UML图。肯定会有人问我们为什么要学习这些鬼画符似的图谱？实际上学习UML图后不会增强我们的coding能力，但是他可以有助于我们快速把握理解一个代码设计的整体架构特点，也就是易于大家互相理解对方的代码设计逻辑，因此学习UML图是很有必要的，并且UML图非常简单，学习20%的概念以后我们就可以解决超过80%的应用场景，还不快和我学起来😁？ 本部分参考了肖继潮大大的《30分钟学会UML类图》文章，特此鸣谢！ UML图表示法 首先我们要学会如何表示一个类或者一个接口。每一个类或者接口一般对应一个java文件，因此我们可以通过类和接口的表示快速把握多个java文件之间的内部联系。 UML图表示具体类 类在类图中使用矩形框表示，同时矩形框分成三层，从上到下依次是类名、类的成员变量、类的方法。同时成员变量和方法前的修饰符可以用下面的三个符号表示： +表示public -表示private #表示protected 不带符号表示default UML图表示抽象类 抽象类实际上和具体类写法很类似，仅仅是类名以及抽象的方法名使用斜体字表示而已，但是我们在绘制时很难区分正体和斜体字，为了不混淆具体类和抽象类，我们还可以在抽象类类名下方最右侧加上abstract字样。 UML图中表示接口 接口只有两层即接口名称和需要实现类重写的方法，同时在接口名称上面我们还要加上&lt;&lt;interface&gt;&gt;字样表示接口。 UML图中表示包 了解即可一般用不到。 UML图表示关系 类图之间存在不同的关系，我们可以将其整体上划分成5种主要关系。这部分内容肖继潮大大介绍的十分详细，我这里仅仅使用简洁的语言总结一下不同关系的特点和区分方法。 实现关系 不用多做介绍也知道什么意思，可以直接对应java中的关键字implements，实现接口的类矩形指向接口矩形框。 泛化关系 也不用多做介绍，就是对应java中关键字extends，即父子类的关系，子类指向父类。 依赖关系 依赖关系是一种弱关联关系，如果A依赖于B，那么就是A类指向B类，一般可以用A use a B来表示这种弱关系，具体表现形式一般为B是A的构造器或方法中的局部变量、方法或构造器的参数、方法的返回值等，或者A调用B的静态方法。 聚合关系 聚合关系比依赖关系联系性要强，如果A聚合B，那么就是白菱形在A这边，箭头(可画可不画)指向B，一般可以用A has a B表示，即A类的对象内部使用了B类的实例作为成员变量，同时这个B是可以被多个实例聚合，即B不独属于A且A不需要知道B的生命周期也无需负责B的声明周期。 组合关系 又被称为强聚合关系，因此联系性比聚合关系更强，如果A组合B，那么就是黑菱形在A这边，箭头(可画可不画)指向B，一般可以用A contains a B表示，即A类的对象内部使用B类的对象作为成员变量，同时这个B是A的一部分且独属于A，即只有这个A完全拥有B，其他对象的B和A的B不是一个存储地址，并且A知道B的声明周期且负责B的声明周期。 组合关系和聚合关系通常很难区分。我们可以把聚合关系理解为雇员和雇主的关系，一个雇员可以有多个雇主，并且雇员随时可以离开雇主并且不会影响到雇主，而组合关系类似于人和器官的关系，一个器官只能属于一个人，并且这个器官通常是不能转移的并且离开后会影响到人的生活。通常在画UML图时当我们不确定是聚合或组合关系时，使用聚合关系总是不会出错的😁~ 结构型模式 上一节我们详细学习了5种创建型模式。本章我们继续学习7种重要的结构型模式，结构型模式可以分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，而后者采用组合或者聚合来组合对象。由于组合关系或聚合关系比继承关系耦合度低，满足合成复用原则，因此我们接下来介绍的模式大多都是对象结构型模式 我们首先给出7种结构型模式的特点和主要功能，方便我们在学习时能随时带着问题思考，感悟他们的特点： 适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类在一起工作，主要就是解决兼容性问题。 桥接模式：将抽象与现实分离，使他们可以独立变化。他是使用组合关系代替继承关系来实现的，从而降低了抽象和显示着两个可变维度的耦合度，使得两个维度独立变化互不影响。 装饰模式：动态的给对象增加一些职责而不会修改原对象，即增加其额外的功能，解决功能扩展性问题。 组合模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。 外观模式：为多个复杂的子系统提供一个一致的接口，使得外部可以更加容易的去访问操作这些子系统。 享元模式：运用共享技术来有效地支持大量细粒度对象的复用，解决的是复用缩小空间浪费的问题。 代理模式：为对象提供一种代理以控制对该对象的访问，即客户端通过代理间接地访问该对象，从而限制、增强或修改对象的一些特征，类似于封装分层的模型以解决直接访问源对象。 适配器模式 适配器模式有分成了类适配器模式和对象适配器模式，类适配器模式使用了继承关系来获取第三方库的功能，而对象适配器使用聚合关系来获取第三方库的功能。两者最终达到的目的是一致的，但是对象适配器的可扩展性更好，更加符合合成复用原则。 现在我们以一个案例来具体学习一下适配器模式，假设现在我们有一台电脑，他只能读取SD卡，但是现在我们需要读取TF卡中的内容，显然现在TF卡提供的读数据接口并不能被电脑所使用，即第三方接口无法被客户主机兼容，那么我们就需要引入适配器了即SDAdapterTF适配器，他可以读取TF卡中的数据，然后再为电脑提供SD卡接口，电脑此时通过适配器就可以获取到TF卡中的数据了。 类适配器模式 上面就是类适配器的UML图了，后面的Client都表示测试程序即含有main()方法的测试文件。代码如下： Client.javaComputer.javaSDCard.javaSDCardImpl.javaTFCard.javaTFCardImpl.javaSDAdapterTF.java1234567891011121314151617//类适配器违背了合成复用原则public class Client &#123; public static void main(String[] args) &#123; Computer computer =new Computer(); //读取sd卡中的数据 String msg=computer.readSD(new SDCardImpl()); System.out.println(msg); System.out.println(&quot;==============================&quot;); //使用该计算机去读取TFCard中的数据，明显需要适配器 //定义适配器类 String msg1=computer.readSD(new SDAdapterTF()); System.out.println(msg1); &#125;&#125; 1234567891011/计算机只能读sd卡public class Computer &#123; //从SD卡读取数据 public String readSD(SDCard sdCard)&#123; if(sdCard==null)&#123; throw new NullPointerException(&quot;sd card can not be null&quot;); &#125; return sdCard.readSD(); &#125;&#125; 1234567//目标者接口public interface SDCard &#123; //从SD卡中读取数据 String readSD(); //向SD卡写数据 void writeSD(String msg);&#125; 123456789101112public class SDCardImpl implements SDCard &#123; @Override public String readSD() &#123; String msg = &quot;SDCard read msg: hello world!&quot;; return msg; &#125; @Override public void writeSD(String msg) &#123; System.out.println(&quot;SDCard write msg:&quot; + msg); &#125;&#125; 1234567//适配者类的接口public interface TFCard &#123; //从TF卡中读取数据 String readTF(); //向TF卡中写数据 void writeTF(String msg);&#125; 12345678910111213//实现适配者接口public class TFCardImpl implements TFCard&#123; @Override public String readTF() &#123; String msg=&quot;TFCard read msg: hello world TFCard!&quot;; return msg; &#125; @Override public void writeTF(String msg) &#123; System.out.println(&quot;TFCard write msg: &quot;+msg); &#125;&#125; 1234567891011121314151617//适配器//使用继承不太好，造成了违背合成复用原则public class SDAdapterTF extends TFCardImpl implements SDCard &#123; @Override public String readSD() &#123; System.out.println(&quot;adapter read tf card&quot;); //实际上适配器是去读TF卡中的数据 return readTF(); &#125; @Override public void writeSD(String msg) &#123; System.out.println(&quot;adapter write tf card&quot;); writeTF(msg); &#125;&#125; 我们思考一下类适配器的缺点有什么？很明显这里类适配器使用的是继承TFCardImpl来获取到具体的调用readTF()方法读取TF卡中的数据，但是由于java中是单继承的，因此当前和这个适配器只能适配SD2TF的类型了，假设现在我们需要一个适配器，他能同时支持多种卡数据转SD接口的功能，那么显然此时类适配器做不到，因为他不可能继承多个不同卡型的类，因此类适配器的扩占性并不好。因此我们引出了对象适配器的模式。 对象适配器模式 此时我们使用了聚合的方法来获取到TFCard的接口方法，那么由于我们聚合是将TFCard实例作为一个Adapter的成员变量，因此此时如果需要进行多个卡型的适配，也是可以做到的，无非就是在Adapter类中对每一种卡型都初始化一个实例作为成员变量即可了，需要读取K型卡的数据，就调用K实例的readK()方法即可了。代码如下 Client.java Computer.javaSDCard.javaSDCardImpl.javaTFCard.javaTFCradImpl.javaSDAdapterTF.java1234567891011121314151617//比类适配器要好public class Client &#123; public static void main(String[] args) &#123; Computer computer = new Computer(); //读取sd卡中的数据 String msg = computer.readSD(new SDCardImpl()); System.out.println(msg); System.out.println(&quot;==============================&quot;); //使用该计算机读取TFCard中的数据 //创建适配器类对象 SDAdapterTF sdAdapterTF = new SDAdapterTF(new TFCardImpl()); String msg1 = computer.readSD(sdAdapterTF); System.out.println(msg1); &#125;&#125; 1234567891011//计算机只能读sd卡public class Computer &#123; //从SD卡读取数据 public String readSD(SDCard sdCard)&#123; if(sdCard==null)&#123; throw new NullPointerException(&quot;sd card can not be null&quot;); &#125; return sdCard.readSD(); &#125;&#125; 1234567//目标者接口public interface SDCard &#123; //从SD卡中读取数据 String readSD(); //向SD卡写数据 void writeSD(String msg);&#125; 123456789101112public class SDCardImpl implements SDCard &#123; @Override public String readSD() &#123; String msg = &quot;SDCard read msg: hello world!&quot;; return msg; &#125; @Override public void writeSD(String msg) &#123; System.out.println(&quot;SDCard write msg:&quot; + msg); &#125;&#125; 1234567//适配者类的接口public interface TFCard &#123; //从TF卡中读取数据 String readTF(); //向TF卡中写数据 void writeTF(String msg);&#125; 12345678910111213//实现适配者接口public class TFCardImpl implements TFCard &#123; @Override public String readTF() &#123; String msg=&quot;TFCard read msg: hello world TFCard!&quot;; return msg; &#125; @Override public void writeTF(String msg) &#123; System.out.println(&quot;TFCard write msg: &quot;+msg); &#125;&#125; 123456789101112131415161718192021222324//适配器//不需要使用继承public class SDAdapterTF implements SDCard &#123; //声明适配者类 private TFCard tfCard; public SDAdapterTF(TFCard tfCard) &#123; this.tfCard = tfCard; &#125; @Override public String readSD() &#123; System.out.println(&quot;adapter read tf card&quot;); //实际上适配器是去读TF卡中的数据 return tfCard.readTF(); &#125; @Override public void writeSD(String msg) &#123; System.out.println(&quot;adapter write tf card&quot;); tfCard.writeTF(msg); &#125;&#125; 学习完上面的案例后，我们对适配器模式有了透彻的了解，他可以帮助我们解决兼容性问题，此时客户可以通过适配器调用一切第三方模块了。同时通过类适配器模式和对象适配器模式的对比我们感受到了聚合关系相较于继承关系的优越性，这也是合成复用原则优点的体现。 桥接模式 我们现在看一个案例，假设现在我们需要开发一个跨平台视频播放器，可以在不同操作系统平台（如Windows、Mac、Lnux等）上播放多种格式的视频文件，常见的视频格式包括RMVB、AVI等类型。每一个系统都支持这两种类型视频的解码播放，假设我们现在对于具体的操作系统类和抽象的视频文件类两个维度都使用继承来实现，那么会如下图所示： 此时有一个很明显的弊端，无论是新增添一种视频解码类型还是一种新的操作系统，都会至少需要添加2个子类，即无论是操作系统维度还是视频解码类型维度变化，都会造成另外一个维度的变化，从而导致子类的变化过多，不易维护使用。因此我们引入了代理模式的概念，他的根本目的就是为了保证两个维度之间的变化互补干涉，从而减少重复子类的创建，如下图就是桥接模式下对该案例的设计： 此时视频解码方法使用了实现接口的方式，然后最重要的是操作系统具体类聚合了视频解码类，这样又符合了合成复用原则，我们发现此时任意一个维度的变化都不会影响另一个维护，因此每一次增加也只会新添加一个子类，非常的简单易维护。代码如下 Client.javaOperatingSystem.javaWindows.javaMac.javaVideoFile.javaRmvbFile.javaAviFile.java123456789public class Client &#123; public static void main(String[] args) &#123; //创建mac系统对象 OperatingSystem system = new Mac(new AviFile()); //开始使用操作系统播放视频文件 system.play(&quot;战狼3&quot;); &#125;&#125; 1234567891011//抽象的操作系统类，抽象化角色public abstract class OperatingSystem &#123; //声明VideoFile变量 protected VideoFile videoFile; public OperatingSystem(VideoFile videoFile) &#123; this.videoFile = videoFile; &#125; public abstract void play(String fileName);&#125; 1234567891011//扩展抽象化角色public class Windows extends OperatingSystem &#123; public Windows(VideoFile videoFile) &#123; super(videoFile); &#125; @Override public void play(String fileName) &#123; videoFile.decode(fileName); &#125;&#125; 12345678910public class Mac extends OperatingSystem &#123; public Mac(VideoFile videoFile) &#123; super(videoFile); &#125; @Override public void play(String fileName) &#123; videoFile.decode(fileName); &#125;&#125; 123456//视频文件格式，实现化角色public interface VideoFile &#123; //解码功能 void decode(String fileName);&#125; 1234567//rmvb视频文件类，具体实现化角色public class RmvbFile implements VideoFile &#123; @Override public void decode(String fileName) &#123; System.out.println(&quot;rmvb视频文件：&quot; + fileName); &#125;&#125; 123456789//avi视频文件，具体的实现化角色public class AviFile implements VideoFile &#123; @Override public void decode(String fileName) &#123; System.out.println(&quot;avi视频文件：&quot; + fileName); &#125;&#125; 装饰模式 装饰模式在游戏开发中是经常使用的第一个模式，比如角色切换装备会实时刷新角色的属性值，就是使用的装饰模式。但是我们不用游戏角色的案例来学习，因为那个太复杂了，我们以炒饭🍚和炒面🍜为例，假设现在有一个快餐店，提供炒饭和炒面这些快餐，同时可以额外附加鸡蛋、火腿、培根等配菜，当然添加配菜需要额外价钱，同时每一种配餐的价钱通常也不一样，那么计算总价会变得非常复杂，此时我们就可以使用装饰模式来完成。首先我们看一下UML图 可以看到比较复杂，我这里简单讲解一下，我们一定要注意Garnish装饰者并不是向Fastfood添加配菜，而是聚合Fastfood即拿到炒饭或者炒菜进行添加配菜处理，最终返还的一个添加好配菜的炒饭或者炒面。因此这里的Egg和Bacon最终返还的不是鸡蛋或者培根，而是添加了鸡蛋或者培根的炒饭、炒面。接下来我们看一下代码 Client.javaFastFood.javaFriedRice.javaFriedNoodles.javaGarnish.javaEgg.javaBacon.java12345678public class Client &#123; public static void main(String[] args) &#123; //创建mac系统对象 OperatingSystem system = new Mac(new AviFile()); //开始使用操作系统播放视频文件 system.play(&quot;战狼3&quot;); &#125;&#125; 123456789101112131415161718192021222324252627282930313233//快餐类,抽象构建角色public abstract class FastFood &#123; private float price;//价格 private String desc;//具体的描述 public abstract float cost(); public FastFood() &#123; &#125; public FastFood(float price, String desc) &#123; this.price = price; this.desc = desc; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125;&#125; 1234567891011//炒饭，具体构建角色public class FriedRice extends FastFood&#123; public FriedRice()&#123; //基础价格和描述 super(10,&quot;炒饭&quot;); &#125; @Override public float cost() &#123; return getPrice(); &#125;&#125; 123456789101112//炒面，具体构建角色public class FriedNoodles extends FastFood &#123; public FriedNoodles() &#123; super(12, &quot;炒面&quot;); &#125; @Override public float cost() &#123; return getPrice(); &#125;&#125; 123456789101112131415161718192021222324//装饰类,抽象，因为会有许多不同的具体装饰配料，抽象装饰public abstract class Garnish extends FastFood &#123; //声明快餐类变量 private FastFood fastFood; public FastFood getFastFood() &#123; return fastFood; &#125; public void setFastFood(FastFood fastFood) &#123; this.fastFood = fastFood; &#125; public Garnish(FastFood fastFood) &#123; this.fastFood = fastFood; &#125; public Garnish(FastFood fastFood, float price, String desc) &#123; super(price, desc); this.fastFood = fastFood; &#125;&#125; 12345678910111213141516//第一个装饰配料鸡蛋，具体装饰者角色public class Egg extends Garnish &#123; public Egg(FastFood fastFood) &#123; super(fastFood, 1, &quot;鸡蛋&quot;); &#125; @Override public float cost() &#123; return getPrice() + getFastFood().cost(); &#125; @Override public String getDesc() &#123; return super.getDesc() + getFastFood().getDesc(); &#125;&#125; 12345678910111213141516//第二个装饰配料培根，具体装饰者角色public class Bacon extends Garnish &#123; public Bacon(FastFood fastFood) &#123; super(fastFood, 2, &quot;培根&quot;); &#125; @Override public float cost() &#123; return getPrice() + getFastFood().cost(); &#125; @Override public String getDesc() &#123; return super.getDesc() + getFastFood().getDesc(); &#125;&#125; 我们可以看到此时即使是多重装饰的应用场景，装饰模式也可以应对自如，同时并不需要重复的创建子类，因此满足合成复用原则。使用装饰模式后，代码的复用性很高，值得学习。 组合模式 初读组合模式很难理解用户对单个对象和组合对象具有一致的访问性这句话的含义，并且也很难联想到应用场景。实际上有一个我们日常可见的应用就是使用组合模式完美实现的，那就是文件目录，假设我们在访问一些管理系统时，经常可以看到类似的菜单，一个菜单可以包含菜单项（菜单项是指不在包含其他内容的菜单条目），也可以包含带有其他菜单项的菜单文件夹，此时虽然菜单项和菜单形式上略有区别，但是他们的访问权限是一致的刚好和组合模式很恰当。现在有一个需求是针对一个菜单，打印出其包含的所有菜单项以及子菜单下的菜单项。我们第一个想到的方法就是递归打印，但是实际上使用了组合模式后，由于文件之间已经隐含了树的关系，因此我们可以轻松的根据树展开完成需求而无需再使用递归。 由于菜单和菜单项的用户访问性是一致的并且他们有很多共同的方法和属性，因此他们都继承了一个核心MenuComponent组件，然后再在其基础上重写了自己特有的方法。这就是组合模式，关系很简单，代码如下： Client.javaMenuComponent.javaMenu.javaMenuItem.java1234567891011121314151617181920212223242526272829public class Client &#123; public static void main(String[] args) &#123; //创建菜单树 MenuComponent menu1 = new Menu(&quot;菜单管理&quot;, 2); menu1.add(new MenuItem(&quot;页面访问&quot;, 3)); menu1.add(new MenuItem(&quot;展开菜单&quot;, 3)); menu1.add(new MenuItem(&quot;编辑菜单&quot;, 3)); menu1.add(new MenuItem(&quot;删除菜单&quot;, 3)); menu1.add(new MenuItem(&quot;新增菜单&quot;, 3)); MenuComponent menu2 = new Menu(&quot;权限管理&quot;, 2); menu2.add(new MenuItem(&quot;页面访问&quot;, 3)); menu2.add(new MenuItem(&quot;提交保存&quot;, 3)); MenuComponent menu3 = new Menu(&quot;角色管理&quot;, 2); menu3.add(new MenuItem(&quot;页面访问&quot;, 3)); menu3.add(new MenuItem(&quot;新增角色&quot;, 3)); menu3.add(new MenuItem(&quot;修改角色&quot;, 3)); MenuComponent component = new Menu(&quot;系统管理&quot;, 1); component.add(menu1); component.add(menu2); component.add(menu3); //打印菜单名称，如果有子菜单一同打印 //不用再使用递归了，直接一步打印即可 component.print(); &#125;&#125; 123456789101112131415161718192021222324252627282930//菜单组件，属于抽象根节点public abstract class MenuComponent &#123; //菜单组件的名称 protected String name; //菜单组件的层级 protected int level; //添加子菜单 public void add(MenuComponent menuComponent) &#123; throw new UnsupportedOperationException(); &#125; //移除子菜单 public void remove(MenuComponent menuComponent) &#123; throw new UnsupportedOperationException(); &#125; //获取指定的子菜单 public MenuComponent getChild(int index) &#123; throw new UnsupportedOperationException(); &#125; //获取菜单或者菜单项的名称 public String getName() &#123; return name; &#125; //打印菜单名称(包含所有子元素) public abstract void print();&#125; 1234567891011121314151617181920212223242526272829303132333435363738//菜单类，属于树枝节点角色public class Menu extends MenuComponent &#123; //菜单可以有多个子菜单或者子菜单项 private List&lt;MenuComponent&gt; menuComponentList = new ArrayList&lt;MenuComponent&gt;(); public Menu(String name, int level) &#123; this.name = name; this.level = level; &#125; @Override public void add(MenuComponent menuComponent) &#123; menuComponentList.add(menuComponent); &#125; @Override public void remove(MenuComponent menuComponent) &#123; menuComponentList.remove(menuComponent); &#125; @Override public MenuComponent getChild(int index) &#123; return menuComponentList.get(index); &#125; @Override public void print() &#123; //因为是菜单，所以要先打印菜单名称 for (int i = 0; i &lt; level; i++) &#123; System.out.print(&quot;--&quot;); &#125; System.out.println(name); //然后还要打印子菜单或者子菜单项名称 for (MenuComponent component : menuComponentList) &#123; component.print(); &#125; &#125;&#125; 123456789101112131415//菜单项类，叶子节点角色public class MenuItem extends MenuComponent &#123; public MenuItem(String name, int level) &#123; this.name = name; this.level = level; &#125; public void print() &#123; for (int i = 0; i &lt; level; i++) &#123; System.out.print(&quot;--&quot;); &#125; System.out.println(name); &#125;&#125; 一定要注意组合模式总是有一个基础的公共组件抽象类被所有实现类继承，这样保证了所有的实现类都有类似的性质，访问性一致同时对于具有存储功能的实现类还要再聚合这个抽象类实例。 外观模式 外观模式或者门面模式很好理解，他就是将许多复杂的子系统接口封装成了一个统一的外部接口被其控制，这样简化了客户的操作难度。比如现在假设小明的爷爷已经60岁了，一个人在家生活，每次回到家都需要打开灯、打开电视、打开空调，睡觉时需要关闭灯、关闭电视、关闭空调。操作起来比较麻烦，因此小明给爷爷买了智能音箱，可以通过语音直接控制这些智能家电的开启和关闭，此时就可以使用外观模式，其UML图如下： 这个应用很简单，模式设计也很好理解，就是使用Facade去聚合所有的子系统实例，然后由他来操作完成这些复杂的步骤，而只向客户提供一个统一的操作接口，这样就大大简化了用户的操作难度。代码如下 Client.javaLight.javaTV.javaAirCondition.java123456789public class Client &#123; public static void main(String[] args) &#123; //创建一个智能音箱即可 SmartApplianceFacade smartApplianceFacade = new SmartApplianceFacade(); smartApplianceFacade.say(&quot;我想打开家电&quot;); System.out.println(&quot;=========================&quot;); smartApplianceFacade.say(&quot;我困了，想关闭家电&quot;); &#125;&#125; 1234567891011//电灯类public class Light &#123; //开灯方法 public void on() &#123; System.out.println(&quot;打开电灯&quot;); &#125; public void off() &#123; System.out.println(&quot;关闭电灯&quot;); &#125;&#125; 123456789public class TV &#123; public void on()&#123; System.out.println(&quot;打开电视&quot;); &#125; public void off()&#123; System.out.println(&quot;关闭电视&quot;); &#125;&#125; 12345678910public class AirCondition &#123; public void on() &#123; System.out.println(&quot;打开空调&quot;); &#125; public void off() &#123; System.out.println(&quot;关闭空调&quot;); &#125;&#125; 享元模式 享元模式实际上优点类似于共享自行车的概念，他就是将基础的公共组件提供给不同的用户，然后用户用这个公共的组件进行进一步的处理完成功能，因此这些功能肯定都是极其类似的，这样共享的好处就是省去了许多重复相似类的创建节省了大量的空间。 我们以俄罗斯方块为例，在俄罗斯方块游戏中，每个不同的方块都是一个实例对象，这些对象就要占很多的内存空间，同时不同的方块有不同的颜色，如果我们为每一个不同颜色不同类型的方块都创建一个类，那么空间多道无法想象，此时我们就可以使用享元模式完成这个需求。UML图如下 这个BoxFactory可千万不要理解为一个不断创建实例的工厂！他并不是真的一直在创建实例，而仅仅是为每一个形状的方块类只实例化了一个单例，然后一直在不断地根据传入的参数重复的返还这三个实例😲，因此节省了许多的空间。代码如下： Client.javaAbstractBox.javaIBox.javaLBox.javaOBox.javaBoxFactory.java12345678910111213141516171819public class Client &#123; public static void main(String[] args) &#123; //获取I图形 AbstractBox box1 = BoxFactory.getInstance().getShape(&quot;I&quot;); box1.display(&quot;灰色&quot;); AbstractBox box2 = BoxFactory.getInstance().getShape(&quot;L&quot;); box2.display(&quot;绿色&quot;); AbstractBox box3 = BoxFactory.getInstance().getShape(&quot;O&quot;); box3.display(&quot;红色&quot;); AbstractBox box4 = BoxFactory.getInstance().getShape(&quot;O&quot;); box4.display(&quot;黄色&quot;); System.out.println(&quot;两次获取到的O图形对象是否为同一个对象&quot; + (box3 == box4)); //颜色是外部状态，并不会真正的修改内部的状态，同一个形状类型的对象共享，节省空间 &#125;&#125; 12345678910//抽象享元角色public abstract class AbstractBox &#123; //获取图形的方法 public abstract String getShape(); //显示图形和颜色 public void display(String color) &#123; System.out.println(&quot;方块形状:&quot; + getShape() + &quot;,&quot; + &quot;颜色：&quot; + color); &#125;&#125; 1234567public class IBox extends AbstractBox &#123; @Override public String getShape() &#123; return &quot;I&quot;; &#125;&#125; 1234567public class LBox extends AbstractBox &#123; @Override public String getShape() &#123; return &quot;L&quot;; &#125;&#125; 12345678public class OBox extends AbstractBox &#123; @Override public String getShape() &#123; return &quot;O&quot;; &#125;&#125; 1234567891011121314151617181920212223242526//工厂类，将该类设计为单例public class BoxFactory &#123; public HashMap&lt;String, AbstractBox&gt; map; //在构造方法中进行初始化操作 //单例，因此工厂私有 private BoxFactory() &#123; map = new HashMap&lt;String, AbstractBox&gt;(); map.put(&quot;I&quot;, new IBox()); map.put(&quot;L&quot;, new LBox()); map.put(&quot;O&quot;, new OBox()); &#125; public static BoxFactory getInstance() &#123; return boxFactory; &#125; //饿汉式 private static BoxFactory boxFactory = new BoxFactory(); //根据名称获取图形对象 public AbstractBox getShape(String name) &#123; return map.get(name); &#125;&#125; 一定要注意享元模式的最大特点就是许多对象是共用的，比如上面的两个不同颜色的O形方块，实际上他们都是先从工厂拿到了同一个存储地址的O形方块然后进一步上了不同的颜色而已。因此上面的代码案例中仅仅使用了三个对象，即使是有上万种颜色，也仅仅使用了三个对象的空间！享元模式的优越性不言而喻。 代理模式 静态代理模式 注意代售点是聚合了火车站，因此实际上他调用的还是火车站的sell()方法，即代售点并不是最终修改票数的操作者，实际上还是火车站进行火车票数的修改，因此这和CSR三层封装模型很类似，代理只不过是基于最底层的类进行了封装代理而已，最终的根本操作还是由底层类实现。代码如下 Client.javaTrainStation.javaSellTicket.javaProxyPoint.java1234567public class Client &#123; public static void main(String[] args) &#123; //创建代售点对象 ProxyPoint proxyPoint = new ProxyPoint(); proxyPoint.sell(); &#125;&#125; 1234567//火车站类public class TrainStation implements SellTicket &#123; @Override public void sell() &#123; System.out.println(&quot;火车站卖票&quot;); &#125;&#125; 1234//卖火车票的接口public interface SellTicket &#123; void sell();&#125; 1234567891011//火车票代售点public class ProxyPoint implements SellTicket &#123; //声明火车站类对象 private TrainStation trainStation = new TrainStation(); @Override public void sell() &#123; System.out.println(&quot;代售点收取一定的服务费用&quot;); trainStation.sell(); &#125;&#125; JDK动态代理模式 我们发现上面的代理类是写死的，即这个代售点就只能代理火车站的卖票功能，但是现实生活中我们知道售报亭等小摊也是可以买到火车票的，同时他们还是报刊代售点、充值卡代售点，即集成了多个功能的复杂代理对象，显然静态代理实现不了，因此我们此时可以借用jdk提供的Proxy类实现动态代理，我们还是以代售点代售火车票为例，代码如下 Client.javaTrainStation.javaSellTicket.javaProxyFactory.java1234567891011public class Client &#123; public static void main(String[] args) &#123; //获取代理对象 //1.创建代理工厂对象 ProxyFactory factory = new ProxyFactory(); //2.使用factory对象的方法获取代理对象 SellTicket proxyObject = factory.getProxyObject(); //3.调用卖调用的方法 proxyObject.sell(); &#125;&#125; 1234567//火车站类public class TrainStation implements SellTicket &#123; @Override public void sell() &#123; System.out.println(&quot;火车站卖票&quot;); &#125;&#125; 1234//卖火车票的接口public interface SellTicket &#123; void sell();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940//获取代理对象的工厂类public class ProxyFactory &#123; //声明目标对象 private TrainStation trainStation = new TrainStation(); //获取代理对象的方法 public SellTicket getProxyObject() &#123; //返回代理对象 //jdk提供的动态代理方法 /* ClassLoader loader: 类加载器,用于加载代理类,可以通过目标对象获取类加载器 Class&lt;?&gt;[] interfaces: 代理类实现的接口字节码对象 InvocationHandler h :代理对象调用处理程序 */ SellTicket proxyObject = (SellTicket) Proxy.newProxyInstance( trainStation.getClass().getClassLoader(), trainStation.getClass().getInterfaces(), new InvocationHandler() &#123; @Override /* Object proxy: 代理对象，和proxyObject是同一个对象，在invoke方法中基本不用 Method method:对接口中的方法进行封装的method对象 Object[] args:调用方法的实际参数 返回值就是调用方法的返回值 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;// System.out.println(&quot;invoke方法执行了&quot;); System.out.println(&quot;代售点收取一定的服务费用(jdk)动态代理&quot;); //执行目标对象的方法 //此时sell方法无传递值，因此args是空 Object obj = method.invoke(trainStation, args); //由于sell方法没有返回值，因此实际上obj这里就是null return obj; &#125; &#125; ); return proxyObject; &#125;&#125; 动态代理还有一种就是CGLIB代理，这里我就不讲了。如果您对此感兴趣可以自行搜索学习。 思考：静态代理模式和装饰者模式的区别？ 我们发现静态代理模式和装饰者模式的UML图非常类似，他们有如下相同点： 都要实现与目标类相同的业务接口 在两个类中都要声明目标对象（即聚合目标对象） 都可以在不修改目标类的前提下增强目标方法（比如炒饭加鸡蛋增加费用，代售点售票还要多收服务费） 那么两者难道不是一样的吗？显然是有区别，首先两者的目的不同，装饰者模式添加额外的功能是为了增强目标对象，而静态代理模式是为了保护和隐藏目标对象才要添加新的代码，同时两者的获取目标对象构建的地方也不同，我们回忆一下装饰模式他的目的对象并不是提前在内部定义好的，而是由外界传进来的，这也是装饰模式可以重复装饰的原因，而静态代理模式的目标对象却是在代理类内部创建的，即代理对象实例化创建后就已经聚合了写死的目标对象实例。因此两者区别还是大大滴~ 您可以点击左上方链接获取上面教程所使用的代码,同时可以参考本篇博客完成homework02实验巩固学习😊"},{"title":"数据生成与交换","path":"/wiki/计算机网络笔记/数据生成与交换/index.html","content":"编码调制 概念定义 首先我们要知道数据和信号是两个不同的概念，并且上面的一讲中我们学习过数据和信号都有“数字”和“模拟”之分，数字是离散的，模拟是连续的。而数据无论是数字的还是模拟的，最终都要转换成信号以后才能在信道上进行传输。我们把数据变换为模拟信号的过程称为调制，把数据变换为数字信号的过程称为编码。 信号是数据的具体表现形式，他和数据有一定的关系的，但是又不完全相同。数字数据可以通过数字发送器转换为数字信号传输，也可以通过调制器转换为模拟信号进行传输，同样的模拟数据可以通过PCM编码器转换成数字信号传输，也可以通过放大器调制器转换成模拟信号进行传输。如上图就是4中不同的调制编码方式。接下来我们信息讲解一下上面的四中不同转换方式。建议在学习一下内容时，先复习一下基带传输和宽带传输。 数字数据编码为数字信号 数字数据编码用于基带传输中，即在基本不改变数字数据信号的频率下，直接传输数字信号。而具体使用什么样的数字信号表示0和用什么样的数字信号表示1就是所谓的编码。编码的规则有多种，只要能够有效的把1和0区分开即可，常用的编码有下面的几种： 归零编码(RZ) 在归零编码(RZ)中,用高电平代表1，低电平代表0(或者相反)，每一个时钟周期的中间均跳变到低电平0（归零）。接收方根据该跳变调整本方的时钟基准，这就为传输双方提供了自同步机制。但是由于归零需要占用一部分的带宽，而此段时间并没有实际的数据传输作用，因此传输速率受到了一定的影响，如果想要提升传输速率，那么需要尽可能的缩短归零所占的带宽。 非归零编码(NRZ) 和归零编码唯一不同的地方就在于一个周期内可以全部用来传输数据，不需要跳变零的过程，这样整个周期的带宽全部用来传输数据了，传输效率理论上会更高，但是这又会导致发送方和接受方的时钟难以同步，因为缺少了传递时钟同步信号的机制。因此如果想要进一步传输高速同步数据，那么需要带有时钟线。 思考：同步机制有何作用？ 我们在信道中传输信号是要求两端能够同时开始和结束接受数据，如果同步机制难以保证，很容易再传输过程中出现混乱从而导致两端发送和接受数据时间不同步从而造成数据的丢失。比如接收端在传输过程中逐渐快于发送端，那么发送端还没有停止发送数据，接收端就已经提起结束了接受导致数据传输的丢失，因此保证时钟的同步非常重要。 反向非归零编码(NRZI) 反向非归零编码又进一步对非归零编码进行了优化，他尝试解决时钟不同步的问题。在反向非归零编码中用信号的翻转代表0,，信号保持不变为代表1。翻转信号既可以有效实现0和1两种不同信号的传递，并且还可以作为一个通知机制来时刻维持两端的时钟同步，这种编码方式结合了前两种编码的优点，既能传输时钟信号又能尽可能的不损失系统带宽。USB2.0通信的编码方式就是使用了这种编码方式。 曼彻斯特编码(Manchester Encoding) 曼彻斯特编码将一个码元分成两个相等的间隔，前一个间隔为高电平后一个间隔为低电平表示码元1；码元0的表示方法则刚好相反。当然，也可以采用相反的规则制定，效果都是一样的。这种编码方式，使得每一个码元的中间都有一个跳变，位中间的跳变既作为时钟信号（可用于同步），有作为数据信号**，但是它所占的频带宽度是原始基带宽度的两倍，每一个码元都被调成两个电平导致数据传输速率仅仅是调制速率的1/2**。在以太网中使用的编码方式就是曼彻斯特编码。 差分曼彻斯特编码 差分曼彻斯特编码常用于局域网编码，其规则是：若码元为1，则前半个码元的电平与上一个码元的后半部分码元的电平相同，若码元为0，则情形相反。这种编码的特点是，在每一个码元的中间都有一次电平的跳转，可以实现自同步，且抗干扰性能良好强于曼彻斯特编码。 4B/5B编码 将欲发送的数据每4位作为一组，然后按照4B/5B编码规则将其转换成相应的5位码。5位码共32中组合，但是只采用其中的16种对应的16种不同的4位码，其他的16种作为控制码（帧的开始和结束、线路的状态信息等）或保留。 总结 编码方式 是否能够保证同步 传输速率 归零编码 √ 快 非归零编码 × 快 反向非归零编码 √ 快 曼彻斯特编码 √ 较慢 差分曼彻斯特编码 √ 快 4B/5B编码 √ 快 数字数据调制为模拟信号 数字数据调制技术在发送端将数字信号转化为模拟信号，在接收端将模拟信号还原为数字信号，分别对应于调制调节器的调制和解调过程。基本的调制方法如下： 幅移键控(调幅ASK)：通过改变载波信号的振幅来表示数字1和0，而载波的频率和相位都不改变。这种方法比较容易实现，但是抗干扰能力差。 频移键控(调频FSK)：通过改变载波信号的频率来表示数字1和0，而载波的振幅和相位都不改变。容易实现，抗干扰能力强，目前应用比较广泛。 相移键控(调相PSK)：通过改变载波信号的相位来表示数字1和0，而载波的振幅和频率都不改变。同时他又进一步分为绝对调相和相对调相。 正交振幅调剂(QAM）:在频率相同的前提下，将ASK和PSK相结合，形成叠加信号。设波特率为B，采用m个相位，每一个相位有n中振幅，则QAM技术的数据传输R为： R=Blog2(mn)(b/s)R=Blog_2(mn)(b/s) R=Blog2​(mn)(b/s) 实际上上面的计算公式的原理还是码元传输率和数据传输率转换关系。 上图演示了前三种调制方法。在2ASK中，用载波有振幅和无振幅来表示数字数据的‘1’和‘0’。2FSK中，用两种不同频率分别表示数字数据‘1’和‘0’。2PSK中用相位0和相位π表示数字数据的‘1’和‘0’。 思考：看完两种信号的图示后，请说明数字信号和模拟信号的区别？ 数字信号是一个离散稳定的电平脉冲信号，而模拟信号是一种连续性的变化信号。两者同时也有共同点，比如都用一个固定的周期时间来区分一个码元。 模拟数据编码为数字信号 这种编码方式最典型的例子是常用于对音频信号进行编码的脉码调制（PCM）。它主要包括采样、量化和编码三个过程来将一个连续的模拟数据转换为有限个数字表示的离散序列（也就是所说的音频数字化）。 采样：对模拟信号进行周期性扫描，把时间上连续的信号变成时间上离散的信号。这里我们学习一下采样定理（又称为奈奎斯特定理）：在通信领域，带宽是指对信号最高频率与最低频率之差，单位为Hz.因此，将模拟信号转换成数字信号时，假设原始信号中的最大频率为f，那么采样频率f采样必须大于等于最大频率f的两倍，这样才能保证采样后的数字信号完整保留原始模拟信号的信息。公式如下： f采样频率&gt;=2∗f信号最高频率f_{采样频率}&gt;=2*f_{信号最高频率} f采样频率​&gt;=2∗f信号最高频率​ 因此只有满足上面的公式时，才能保证信号可以无失真地代表被采样的模拟数据。 量化：把采样取得的电平幅值按照一定的分级标度转化为对应的数字值并且取整数，这样就把连续的电平幅值转化为了离散的数字量。采样和量化的实质就是分割和转换。 编码：把量化的结果转换为与之对应的二进制编码。 模拟数据调制为模拟信号 为了实现传输的有效性，可能需要较高的频率，但是可用的较高频率范围是有限的，因此调制方式可以使用频分复用的技术，来充分利用带宽资源。在电话和本地交换机所传输的信号是采用模拟信号传输模拟数据的方式，模拟的声音数据是加载到模拟的载波信号中传输的。 思考：什么是频分复用？ 说白了就是将通信信道中的带宽频率分割给许多传送数据使用，这样就做到了充分利用信道带宽资源的效果。比如有一个信道的带宽是0-92Hz，A,B,C三个人同时要打电话，那么可能他们三个人的模拟数据分别调制到了三个不同的频段上，然后再封装处理使得他们在传输信道上互不干扰以及加密安全不会被拦截。之后三个模拟信号上一个信道上，这样这个信道上就同时再传输三个模拟数据对应的模拟信号，节省了信道的开销成本（原本上时需要三个信道）。但是我们要注意这三个模拟信号在信道上传输时还是混合到了一起，因此到达D,E,F接受端时还需要进行剥离得到自己需要的模拟信号。这就是频分复用（FSM）。类似的还有时分复用，码分复用等等目的都是类似的，详细的讲解请参考： 复用与多址技术https://blog.csdn.net/m0_46204224/article/details/106062968 数据交换技术 数据的交换过程可以分为下面三大类： 电路交换 对于电路交换，在进行数据传输前，两个节点之间必须先建立一条专用（双方独占）的物理通信路径（由通信双方之间的交换设备和链路逐段连接而成），该路径可能经过许多个中间节点。但是这一路径在整个数据传输期间一直被独占，直到通信结束才被释放供其他设备使用。因此电路交换技术分为三个阶段：①连接建立②数据传输③连接释放。 电路交换的原理就是在数据传输期间，源节点和目的节点之间有一条中间节点构成的专用物理连接线路，在数据传输结束之前，这条线路一直被保持独占。因此即使双方不进行数据的传输这个线路也不能供其他传输信号使用。 从通信资源的分配角度来看，“交换”就是按照某种方式动态的分配传输线路的资源。电路交换的特点就是在数据传输的过程中，用户始终占用端到端的固定传输带宽。对于电路交换技术的优缺点如下： 优点 通信时延小。由于通信线路为通信双方用户专用，数据直达，因此传输数据的时延非常小。当传输的数据量非常大时，这一优点非常明显。 有序传输。双方通信时按发送顺序传输数据，不存在失序问题。 没有冲突。不同的通信双方拥有不同的信道，因此不会出现频分复用等复用交换技术所存在的争用物理信道的问题。 适用范围广。电路交换技术既适用于传输模拟信号，也适用于传输数字信号。 实时性强。通信双方之间的物理通路一旦建立，双方就可以随时通信。 控制简单。电路交换的设备（交换机等）及控制比较简单。 全双工通信，连接的双发都可以同时发送接受数据，连接建立后数据传输效率很高。 缺点 建立连接时间长。电路交换的平均建立时间对计算机通信来说太长了，长到传输时间节省的时间优势无法体现。 线路独占。这个很致命，导致传输效率低。电路交换连接建立后，物理通路被通信双方独占，即使通信线路空闲，也不能供其他用户使用，因而信道利用率低。最典型的例子，双方打电话互不说话，信道也一直被占用。 灵活性差。只要在通信双方建立的通路中的任何一点出现了故障，就必须重新拨号建立新的连接，这对十分紧急和重要的通信是很不利的。 难以规格化。电路交换时，数据直达，但是不同类型、不同规格、不同速率的终端很难相互进行通信，也难以在通信过程中进行差错控制。 但是我们要注意在电路交换中，是没有所谓的存储转发所耗费的时间概念的，因为电路建立后，除了源节点和目的节点以外，电路上的任何节点都采取“直通方式”接受数据和发送数据。同时我们还要注意区分信道利用率和信道内数据传输率的区别，电路交换技术对建立连接后的信道内数据传输率很高，但是同时整体上看对信道的使用分配却不合理导致信道的利用率低。 报文交换 数据交换的单位变成了报文，报文携带有目标地址、源地址等信息，他是网络中交换与传输的数据单元，即站点一次性要发送的数据块，通常长短不一致，根据内容大小和头部包装复杂程度有关。报文交换在交换节点是存储转发的传输方式。 报文交换的原理是无需在两个站点之间建立一条专用的通道，其数据传输的单位是报文，传送过程采用存储转发方式即走一步看一步，那条路现在可行合适就选择下一条的路径。经过多次存储转发跳转后就到达了目的站点。但是也由于需要在多个站点等待存储转发路径不固定且可能再次被封装，因此需要进行一下差错检验以保证信息没有在传输过程中发生错误。 优点 无需建立连接。报文交换不需要为通信双方预先建立一条专用的通信线路，不存在建立连接时延，用户可以随时发送报文。 动态分配线路，当发送方把报文交给交换设备时，交换设备会先存储整个报文，然后选择一条合适的空闲线路，将报文发送出去。 提高线路可靠性。如果某条传输路径发生故障，那么可以重新选择另一条路径传输数据，因此提高了传输的可靠性。 提高线路利用率。通信双方不是固定的占有一条通信线路，而是在不同的时间段一段一段的部分占有这条物理通道，因而大大提高了通信线路的利用率。 提供多目标服务。一个报文可以同时发送给多个目的地址，这在电路交换中是很难实现的。 在存储转发中容易实现代码转换和速率匹配，甚至收发双方可以处于不同的状态（异步传输）。这样就便于类型、规格和速度不同的计算机之间进行通信。 缺点 由于数据进入交换节点要经历存储、转发这一过程，因而会引起转发时延（包括接收报文，检验正确性、排队、发送时间等）。 报文交换对报文的大小没有限制，这就要求网络节点需要有较大的缓存空间。当缓存区不能满足要求时，那么报文会被丢弃，造成信息的丢失或者无可选路径传输。 思考：为什么需要交换设备有很大的缓冲区？ 我们知道报文大小是没有限制的，而报文又是一个基本数据单元不能分割，只能一次性转发，但是缓冲区总是相对某些报文来说更小的。假如某一个地带的交换设备缓冲区大概都是5M，而报文大小却有7M，那么此时就会出现无转发路径可选的问题。即使恰巧此时报文大小为5M，也会极可能造成拥塞的问题，因此报文交换的弊端较为明显，需要改进。 报文交换主要使用在早期的电报通网中，现在较少使用，通常被较为先进的分组交换方式所取代。 分组交换 和报文交换的思路大致相同，分组交换也采用存储转发的方式，但是他解决了报文交换中大报文传输的问题。分组交换限制了每次传送的数据块大小的上限，把大的数据块划分为了更加合理的小数据块，同时再为每一个小数据块加上一些必要的控制信息（如源地址、目的地址、编号信息等），构成分组（Packet)。网络节点根据控制信息把分组送到下一个节点，下一个节点接受到分组后，暂时保存并排队等待传输，然后根据分组的控制信息选择它的下一跳的节点，直到到达目的节点。 分组交换的原理与报文交换的原理基本一致，都采用了存储转发的方式，形式上的主要差别就是分组交换网中要限制所传输的数据单位的长度，一般选为128B。发送节点首先对从终端设备送来的数据报文进行接收、存储，然后将报文切割划分成一定长度的分组，并以分组为单位进行传输和交换。接收节点将收到的分组组装成信息或报文。 思考：接收端怎样能够将乱序的分组组装成报文信息？ 很简单，我们可以对每一个分组都设置一个独立连续的组号，那么接收端就可以根据号码来拼接收到的分组组装成报文信息。 优点 无需建立连接。报文交换不需要为通信双方预先建立一条专用的通信线路，不存在建立连接时延，用户可以随时发送分组。 线路利用率高。通信双发不是固定占有一条通信线路，而是在不同的时间一段一段的部分占有物理通路，因而大大提高了通信线路的利用率。 简化了存储管理（相对于报文交换）。因为分组的长度是固定的，因此相应的缓冲区的大小也是固定的，在交换节点中存储器的管理通常简化为对缓冲区的管理，相对比较容易。 加速传输。分组是逐个传输的，可以使够一个分组的存储操作与前一个分组的转发操作并行，这种流水线方式减少了报文的传输时间。此外，传输一个分组所需要的缓冲区比传输一个报文所需的缓冲区大小小的多，这样因缓冲区不足而等待发送的概率及时间也必然少的多。 减少了出错概率和重发数据量。因为分组较短，其出错概率也必然减少，所以每次重发的数据量也就大大减少，这样不仅提高了可靠性，也减少了传输时输。 适用于突发式数据通信，相较于电路交换和报文交换，更能够迅速的发送突发紧急信息。 缺点 存在传输时延。尽管分组交换比报文交换的传输时延少，当相对于电路交换仍存在存储转发时延，而且其节点交换机必须具有更强的处理能力。 需要传输额外的信息量。每个小数据块都要加上源地址、目的地址和分组编号等信息。从而构成分组，因此使得传送的信息量增大了5%~10%，一定程度上降低了通信效率，增加了处理的时间，是控制更加复杂，时延增加。 当分组交换采用数据报服务时，可能会出现失序、丢失或重复分组，分组到达目的节点时，要对分组按编号进行排序等工作，因此很麻烦。如果采用虚电路服务，虽无失序问题，但有呼叫建立、数据传输和虚电路释放三个过程。 总结 交换方式 是否乱序抵达 是否有转发时延 对缓冲区要求 信道利用率 电路交换 否 否 低 低 报文交换 是 是 高 高 分组交换 是 是 中 高 传送数据最大，且传送时间元远大于呼叫时，优先选择使用电路交换。电路交换传输时延最小。 当端到端的通路有很多段的链路组成时，采用分组交换传送数据较为合适。 从信道利用率上来看，报文交换和分组交换优于电路交换，其中分组交换比报文交换的时延小，尤其适合与计算机之间的突发式数据通信。 我们要注意这三种交换技术只是三个不同的数据传输的策略，并不一定只在物理层体现。比如电路交换虽然在物理层上实现的电话应用上应用广泛，但是实际上电路交换的思想也在传输层中的TCP有所体现。而报文交换现在基本上不常用，已经被更加优秀的分组交换所替代，而分组交换在网络层，传输层都有应用，例如UDP。 同时三种不同的交换方式也会有不同的传输延迟，对比如下： 我们假设上图中报文大小都是一样大的，且一个报文可以被整除分割成四个分组。那么上图中的图形象的体现出下图普遍规律： V电路交换&lt;V报文交换&lt;V分组交换V_{电路交换}&lt;V_{报文交换}&lt;V_{分组交换} V电路交换​&lt;V报文交换​&lt;V分组交换​ 我们假设一个报文的传输需要一个RTT，那么很显然在电路交换中文件的传输只需要一个RTT，但是他的连接建立和连接释放的时间也很长，导致整体上使用时间大概是2.5个RTT。而报文交换连续发送三个报文，整体的时间才3个RTT，也就是只有每一个报文对应需要一个RTT时间，没有其他的连接建立、连接释放的额外开销，当然还会存在很短的转发时延，但是对于一个较大的报文传输来说其大小可以忽略。而对于分组传输，3个报文被分割成了12个分组，他们采用流水线的方式进行传输，即第一个分组离开第一个中间节点时，第二个分组也已经发送向第一个中间节点，这种流水线式的传输方式极大的缩减了整体的传输时间，其实我们观察每一个由4个分组组成的报文信息传输时间还是用一个RTT，但是整体上的时间却只用了大约1.5个RTT。所以分组交换的传输优势非常明显，得到了广泛的应用，但是电路交换又凭借其大文件传输效率更高，有序抵达且丢包率低而始终能够在传输领域占据一席之地。 数据报与虚电路 前面一讲的最后我们学习了三种数据交换方式，其中分组交换现在被广泛应用。而分组交换根据其通信子网端点系统提供的服务，可以进一步分为面向连接的虚电路方式和无连接的数据报方式。这两种方式都由网络层提供。但是我们要注意数据报方式和虚电路方式都是分组交换的两种不同方式。 数据报方式 当通信子网用户的端系统发送一个报文时，在端系统中实现的高层协议首先会把报文拆成若干个有序的数据单元，然后在网络层加上地址等控制信息形成数据报分组（即网络层的PDU）。中间节点存储分组一段时间后，找到最佳的路由后，就会尽快转发每一个分组。注意不同的分组可以走不同的路径。也可以按照顺序抵达目的节点。如下图是一个主机A向主机B发送报文的一个例子： 步骤如下： 主机A先将分组发往与他直接相连的交换节点A（我们后面学习到网络层就知道一般这种主机唯一相连的一个通向通信子网的节点对应的设备就是默认网关路由）。交换节点A缓存接收到的分组。 A节点接收到分组后首先会进行差错检测确保数据还是正确的，然后节点A查找自己的转发表，由于不同时刻的网络状态不同，因此转发表的内容在时刻发生变化，内容可能不是固定不动的，而是不同时刻完全不同的，因此所有的分组可能转发的路径是不同的，比如有的分组下一跳可能会转发到C，也有的分组会转发到D,F。 网络中的其他中间节点接收到分组后，类似的存储转发分组直到分组最终到达主机B。 思考：如果在转发过程中发生了错误怎么处理？ 这里涉及到了选择重传机制的相关知识，我们简单描述一下这种重传的过程。我们要知道每次分组完成一跳后接收分组的节点都会对分组信息首先进行差错检测，而发送方此时并不会立刻从他的缓冲区中丢弃这个已发送分组的副本，而是会先保留直至接收到接收方节点反馈的信息（ACK或者NAK）。接受节点发现接收到的分组信息已经出错，那么就会反馈NAK告诉上一个发送节点，此时发送节点会重传这个分组，直至接收到ACK才会丢弃已发送分组的副本。如上图假设节点A接收到P1检测正确，那么会发送ACK告诉主机A成功接收分组P1，然后主机A会将缓冲区中的P1副本丢弃。此时节点A会保留P1副本，假设下一跳是C，那么C接收分组后同样要进行差错检测，很不幸发现数据错误，那么会反馈NAK，节点A受到NAK后会重传P1，这就是选择重传机制。 我们要注意当分组在链路上传送时，并不会占用网络中的其他部分资源，因为采用了存储转发的技术，因此资源都是共享的，所有当A发送分组时，主机B也可以同时向其他主机发送分组，并且此时通信网络中的中间节点也在时刻存储转发其他分组。 我们通过上面的例子，可以总结出数据报服务具有如下的特点: 数据报方式为网络层提供无连接服务，发送方可随时发送分组，网络中的节点可以随时接收分组，并且在存储转发过程中，并不会事先为分组的传输确定一条专有路径，每一个分组都是独立确定一条传输路径，因此不同分组传输路径不同，因此抵达时是乱序的。 网络尽最大努力交付，传输不保证可靠性，所以可能在传输过程中丢失或者在环路中循环直至失效，因此分组并不一定能够抵达目的节点。 发送的分组中包括了发送端和接收端的完整地址，以便可以独立传输。 分组在交换节点存储转发时，需要排队等候处理，这会带来一定的时延。通过交换节点的通信量较大或者网络发生拥塞时，这种时延会大大增加，交换节点还可以根据情况丢弃部分分组。 网络具有冗余路径，当某一交换节点或者某一段链路发生故障时，可相应的更新转发表，寻找另一条路径转发分组，对故障的适应能力增强，适用于突发性通信，但是不适用于长报文、会话式通信。 存储转发的时延一般很小，提高了网络的吞吐量。 收发双方不独占某一条链路，因此资源利用率高。 虚电路方式 虚电路方式试图将数据报方式和电路交换方式结合起来，充分发挥两种方法的优点，以达到最佳的数据交换效果。在分组发送之前，要求在发送方和接收方之间要建立一条逻辑上相连的虚电路，并且连接一旦建立，就固定了虚电路对应的物理路径。与电路交换类似，整个通信过程分为三个阶段：虚电路建立、数据传输和虚电路释放。 在虚电路方式中，端系统每次要建立虚电路时，选择一个未用过的虚电路号分配给虚电路，以区别于本系统的其他虚电路。在传送数据时，每个数据分组不仅要有分组号、校验和等控制信息，还要有他要通过的虚电路号，以区别于其他虚电路上的分组。并且在虚电路网络中的每一个节点都要维持一张虚电路表，表中的每项记录了一个打开的虚电路的信息，包括在接受链路和发送链路上的虚电路号、前一节点和下一节点的标识。数据的传输时双向进行的，上述信息是在虚电路的建立过程中确定的。 这里我们同样给出一个主机A向主机B发送数据的例子： 首先为进行数据传输，主机A与主机B之间先建立一条逻辑通路，主机A发出一个特殊的呼叫请求分组，该分组通过中间节点数据报的方式送往主机B，如果主机B同意连接，则发送呼叫应答请求分组予以确认。 虚电路建立后，就形成了一条固定的物理路径供双发发送数据，例如上图的虚电路时主机A-&gt;节点A-&gt;节点B-&gt;节点C-&gt;节点D-&gt;主机B，这样主机A就可以一直通过这条逻辑虚电路向主机B发送数据，同时主机B也可以在这条虚电路上向主机A发送数据。 当所有分组都有序的抵达主机B后，传送结束后，A发送通过虚电路方式释放请求分组来拆除虚电路，逐段断开整个连接。 我们要注意无论是数据报方式还是虚电路方式，在数据传输过程中都是有确认的传输（由高层实现，主机B收到分组后要发回相应分组的确认。但是网络中的传输是否有确认机制与网络层提供的两种服务是没有任何关系的，也就是说明基于数据报方式和虚电路方式实现的服务未必就是有确认机制的，他需要额外的机制来确认。 思考：为什么建立时是数据报方式，而释放时确实虚电路方式？ 实际上很难好像，首先建立前还没有确定虚电路，因此只能通过数据报的方式发送请求连接的分组。但是当释放连接分组发送时，却已经有现成的虚电路了，并且释放连接分组按照虚电路的路径传送也可以顺便通知虚电路对应的物理路径上的各个交换节点释放对应的虚电路表上的虚电路号表项。 思考：虚电路方式和电路交换的区别？虚电路方式为什么是分组交换的一种，体现在哪里？ 我们可能学习完虚电路方式后会混淆他和电路交换方式。实际上很好理解分辨两者的区别。首先电路交换方式是直接建立一条独占专用的物理信道路径收发双方使用，并且数据并不需要切割必须使用特定大小的分组来传输，因为电路交换方式是直接使用了一个信道的所有带宽，是非常充足的，完全没有必要分割的。而虚电路方式是仅仅形式上和电路交换类似，但是本质上还是分组交换的特点，首先一点，他就是必须使用分组进行传输，同时建立一条专用的逻辑虚电路和电路交换方式中的建立一条专用的物理信道电路区别很大。这里的虚电路仅仅强调的是对应物理路径是确定的即必须经过特点的交换节点，而不受占用一条物理路径，这也就意味着对于主机A-&gt;节点A-&gt;节点B-&gt;节点C-&gt;节点D-&gt;主机B这要路径上的交换节点并不是只能服务与这一条虚电路，他还可以服务与其他虚电路，比如还有一条虚电路是主机A-&gt;节点A-&gt;节点B-&gt;节点G-&gt;节点F-&gt;主机C，此时的节点A，节点B和节点C同时服务了两条虚电路，但是逻辑上这两条虚电路是专用于某一个收发双方的数据传输的，这就是虚电路的特点。也正是由于一个中间节点可能需要服务于多条虚电路，因此他需要区分不同的虚电路，因此我们需要为每一条虚电路分配一个独一无二的虚电路号从而在交换节点的虚电路表中加以区分。 思考：虚电路方式借鉴了电路交换的哪些优点? 首先当然就是更加安全稳定，并且分组是有序到达的。同时他也有类似于全双工的数据传输特点，但是同时，他又避免了电路交换中信道利用率低的特点。从每一个信道的视角来看，每一个信道的带宽都能够被充分利用服务与多条虚电路的服务，但是从每一个虚电路交换的数据传输视角来看，他自身确实在使用一条逻辑专用通道，完美复现了电路交换的优点。 因此我们可以总结电路交换有以下的特点： 虚电路方式为网络层提供连接服务，源节点与目的节点之间建立一条逻辑连接，而非物理连接的通道。因此首先需要为分组的传输确定传输路径（建立连接），然后沿该路径（连接）传输系列分组，系列分组传输路径相同，传输结束后拆除连接。 但是虚电路通信链路的建立和拆除需要时间开销，对交互式应用和小量的短分组情况显得很浪费，但对长时间、频繁的数据交换效率较高。 虚电路的路由选择体现在建立阶段，连接建立后，就确定了传输路径。 虚电路提供了可靠的通信功能，能保证每个分组正确有序到达。此外，还可以对两个数据端点的流量进行控制，当接收方来不及接收数据是，可以通知发送方暂缓发送。 虚电路有一个致命的弱点，即当网络中的某个节点或某条链路出现故障而彻底失效时，所有经过该节点或该链路的虚电路将遭到破坏。 分组首部并不包含目的地址，而包含虚电路标识符，相对数据报方式开销小。 虚电路之所以是虚的，就是因为这条电路不是专用的，每一个节点到其他节点之间的链路可能同时有若干虚电路通过，也可能同时与多个节点之间建立虚电路。每一条虚电路支持特定的两个端系统之间的数据传输，两个端系统之间也可以有多条虚电路为不同的进程服务，这些虚电路的实际路由可能相同也可能不同。 两种分组交换方式的对比 数据报服务 虚电路服务 连接的建立 不要 必须有 目的地址 每一个分组都有完整的目的地址 仅在建立阶段使用，之后每一个分组使用长度较短的虚电路号来确定路径 路由选择 每一个分组独立进行路由选择和转发 属于同一条虚电路的分组按照同一路由转发 分组顺序 不保证分组的有序到达 保证分组的有序到达 可靠性 不保证可靠通信，可靠性由用户主机来保证 可靠性由网络保证 对网络故障的适应性 出故障的节点丢失分组，其他分组路径选择发生变化，可正常传输 所有经过故障节点的虚电路均不能正常工作 差错控制和流量控制 由用户主机进行流量控制，不保证数据报的可靠性 可由分组交换网负责，也可由用户主及负责 最后我们要牢记数据报方式和虚电路交换方式都是分组交换的一种，他们分别应用于UDP和TCP中，并且各有千秋无优劣之分。"},{"title":"常见分层结构","path":"/wiki/计算机网络笔记/常见分层结构/index.html","content":"title: 计算机网络笔记–Part3 comments: false top: false date: 2021-03-27 19:35:05 tags: [408,计算机网络] categories: - [个人笔记,计算机网络] 这系列记录翀翀🤠学习计算机网络时的核心笔记以及自己的思考，作为408组成学科之一，一定要认真学习。赠一言与君共勉：一个人的一生总会遇到这样的时刻，一个人的战争。在这种时候，你的心被颠倒了，但在别人眼里，你只是比平时安静一点，没有人会觉得奇怪。这种战争注定是单枪匹马的。 协议、接口和服务 协议 协议是一些规则的集合。在网络中要做到有条不紊的交换数据，就必须遵循一些实现约定好的规则，这些规则明确规定了所交换的数据的格式和一些其他问题。这些为进行网络中的数据交换而建立的规则、标准和约定称为网络协议，他是控制两个或多个对等实体进行通信的规则的集合，是水平的。不定等实体之间是没有协议的，比如用TCP/IP协议栈通信的两个节点，节点A的传输层和节点B的传输层之间存在协议，但是节点A的传输层和节点B的网络层之间就不存在协议，网络协议也称为协议。 一个协议由语法、语义和同步三部分组成。语法规定了传输数据的格式，语义规定了所要完成的功能，即需要发出何种控制信息、完成何种动作以及做出何种应答，同步规定了执行各操作的条件、时序关系等，即事件实现顺序的详细说明。一个完整的协议通常应该具有线路管理（建立、释放连接）、差错控制。数据转转换等功能。 接口 接口是同一节点内相邻两层之间交换信息的连接点，是一个系统内部的规定。每层只能相邻的两层之间定义接口，不能跨层定义接口，在典型的接口上，同一节点的相邻两层的实体通过服务访问点（SAP）进行交互。服务是通过SAP提供给上层使用的，第n层的SAP就是第n+1层可以访问第n层的地方。每一个SAP都有一个能够标识他的地址。SAP是一个抽象概念，他实际上是一个逻辑接口（类似于信箱），与通常所说的两个设备之间的接口是不同的，即使一个区域为接口，并不是实体上的“接口”。 服务 服务是指下层为紧邻的上层提供的功能调用，他是垂直的，对等实体在协议的控制下，使得本层能为上一层提供服务，但要实现本层协议还需要下一层所提供的的服务。 上层使用下层所提供的服务时必须与下层交换一些指令，这些命令在OSI中称为服务原语，OSI服务原语可以分为下面四种： 请求（Request)：由服务用户发往服务提供者，请求完成某项工作。 指示（Indication)：由服务提供者发往服务用户，指示用户做某件事情。 响应（Response)：由服务用户发往服务提供者，作为对指示的响应。 证实（Confirmation)：由服务提供者发往服务用户，作为对请求的证实。 这四类原语用于不同的功能，如建立连接、传输数据和断开连接等，有应答服务包括全部4类原语，而无应答服务则只有请求和指示两类原语。我们用一个图来说明： 假设现在端系统A的n+1层向端系统Bn+1层进行了一个交换信息行为，那么n+1层需要先向n层发送请求，然后n层也一直向下发送请求直至物理层，然后物理层传输信号到达系统B的物理层再逐层向上传递指示。当端系统B的n+1层处理完信号以后，如果不需要响应，那么这次操作就完成了，否则B中的n+1层向n层发送响应，然后n层及以下层也是逐层向下发送响应，最后到达物理层通过传输到达系统A，再逐层向上传递证实。 我们一定要注意服务是上下相邻层之间才能进行的，即n+1层只能使用第n的服务，他不能跨层使用。当原语传递到n层后，继续再向上或向下传递就是通过第n层使用n-1层的服务了。此时就和n+1层没有直接关系了。 思考：协议、服务的区别？ 注意协议和服务概念上不同。首先，只有本层协议的实现才能保证向上一层提供服务，本层的服务用户只能看见服务而无法看见下面的协议，即下面的协议对上层的服务是透明的而协议不透明。其次协议是水平的，协议是控制对等实体之间通信的规则，而服务时垂直的，服务是由下层通过层间接口向上层提供的。另外，并非在一层内完成的全部功能都称为服务，只有能够被高层实体”看得见“的功能才是服务。 协议、接口、服务的关系如下图： 接口就是实体n+1和实体n之间能够交换原语的通道。 计算机网络提供的服务 面向连接服务与无连接服务 面向连接服务中，通信前双方必须先建立连接，分配相应的资源（如缓冲区等），以保证通信能够正常进行，传输结束以后释放连接和占用的资源。这种服务可以分为连接建立，数据传输和连接释放三个阶段，比如TCP就是一种面向连接服务的协议。 在无连接服务中，通信前双方不需要先建立连接，需要发送数据时可以直接发送，把每个带有目的地址的包（报文分组）传送到线路上，有系统选定路线进行传输，这是一种不可靠的服务。这种服务被描述为“尽最大努力交付”，他并不保证通信的可靠性。例如IP、UDP等就是一种无连接服务的协议。 我们可以总结出面向连接服务是一种可靠传输，而无连接服务是一种不可靠连接。 可靠服务和不可靠服务 可靠服务就是指网络具有纠错、检错、应答进制，能够保证数据正确、可靠地传送到目的地。 不可靠服务是指网络只是尽量正确、可靠地传送，而不能保证数据正确、可靠地传输到目的地，是一种尽力而为的服务。 对于提供不可靠服务的网络，网络的正确性、可靠性应该由应用或者用户来保证。例如：用户收到信息后要判断信息是否正确，如果不正确，那么用户要把出错信息报告给信息的发送者，以便发送者进行纠正措施。通过用户的这些措施，可以把不可靠的服务变成可靠的服务。 在一层内完成的全部功能并非都称为服务，只有那些能够被高一层实体“看得见”的功能才能成为服务。 有应答服务和无应答服务 有应答服务是指接收方收到数据以后向发送方给出相应的应答，该应答有传输系统内部自动实现，而不由用户实现。所发送的应答既可以是肯定的应答也可以是否定应答，通常在接收到的数据有错误时发送否定应答。例如：文件传输服务就是一种有应答服务。 无应答服务是指接收方收到数据后不自动给出应答。若需要应答，则由高层实现，例如：对于www服务，客户端收到服务器发送的页面文件后不给出应答。 ISO/OSI参考模型 我们在上一章中讲到计算机网络中会进行结构分层，这里就将以下网络体系的分层结构模型。第一种就是OSI参考模型。 OSI参考模型是由国际标准化组织（ISO）提出的网络体系结构模型，称为开放系统互联参考模型（OSI/RM），通常简称为OSI参考模型。OSI一共分为了7层，从下到上依次为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。第三层统称为通信子网，他是为了联网而附加的通信设备，完成数据的传输功能，高三层统称为资源子网，它相当于计算机系统，完成数据的处理功能。而传输层承上启下。OSI参考模型如下图： 我们前面还讲过打包的过程和拆包的过程以及PDU和SDU的关系： 我们通过上图可以看到在传输时实际上只是一直在通信子网传输，只有发送端和接收端会涉及到资源子网的上三层。并且上四层之间貌似是通过协议直接进行的数据交换，但是实际上都是通过通信子网的下三层呈现一个U型方向传送实现的。 只有源端和目的端的主机是7层，中继系统是3层或者3层以下。每一层之间通过OSAP接口实现连接。 思考：为什么中继系统最高位3层？ 我们在了解了一个分组信息的传输过程后就不难理解了，一个数据信息最终会分成分组在网络层进行转发，选择合适的路径进行通信网络间的传输，而转发需要在网络层实现（通过IP地址实现跨网），因此中继系统最高位3层。但是有些数据并不需要跨网传输，而仅仅需要在一个以太网下进行传输，因此不会用到网络层的服务，仅仅需要数据链路层即可，因此有些中继系统是2层。第二层的转发设备是交换机，第三层的转发设备是路由器。 思考：协议和服务的区别？通信子网（下三层）与资源子网（上三层）的区别？ 协议是水平的，服务是纵向的。对于上三层的协议是端到端的，点都点的或者C/S模型。而对于下三层的通信子网是跳到跳的，一般一个转发过程需要经过5-6跳经过许许多多个中继设备。 下面我们详细学习一下各个层的功能： 物理层（Physical Layer) 物理层的传输单位是比特，任务是透明的传输比特流，功能是在物理媒体上为数据端设备透明地传输原始比特流。 思考：什么是透明传输 透明传输是指不管是什么数据，都可以以一定的比特组合，在物理层链路上进行传送： 也就是说物理层可以承担传输所有数据的功能。 物理层主要是定义数据端设备（DTE）和数据通信设备（DCE）的物理与逻辑连接方法，所以物理层协议也称为物理层接口标准。由于在通信技术的早期阶段，通信规则称为规程，因此物理层协议也称为物理层规程。 物理层接口标准很多，如：EIA-232C、EIA/TIA RS-449、CCITT的X2.1等。下图表示了两个通信节点及它们间的一段通信链路，物理层主要研究以下内容： 通信链路与通信节点的链接需要一些电路接口，物理层规定了这些接口的一些参数，如机械形状和尺寸、交换电路的数量和排列等，例如：笔记本电脑上的网线接口，就是物理层规定的内容之一 物理层也规定了通信链路上传输的信号的意义和电气特征。例如物理层规定信号A代表数字0，那么当节点要传输数字0时，就会发送信号A，当节点接收到A信号以后，就知道在自己接收到的实际上是数字0. 注意传输信息所使用的一些物理媒介，如双绞线、光缆、无线信道等，并不在物理层协议之内而在物理层协议下面。因此物理媒体也常被称为第0层。 下面我们总结一下物理层的功能： 定义接口特性 定义传输模式（单工、半双工、双工） 定义传输速率 比特同步 比特编码 数据链路层（Data Link Layer) 数据链路层的传输单位是帧，任务是将网络层传来的IP数据报组装成帧。数据链路层的功能可以概括为成帧、差错控制、流量控制和传输管理等。 由于外界噪声的干扰，原始的物理连接在传输比特流时可能发生错误：左边节点想向右边节点传输数字0，于是发送了信号A，但是由于传输过程中受到了干扰，信号A变成了限号B，而信号B又刚好代表1，右边节点接收到信号B时，就会误以为左边节点传送了数字1，从而发生差错。这种差错我们称之为信号翻转，即0变成了1,1变成了0，其实我们在学习了数字逻辑以后就知道导致这种现象的原因是电平电压受噪音干扰发生了波动导致的。此时我们需要通过适当的办法避免这种错误的干扰，于是两个节点之间如果规定了数据链路层协议，那么就可以检测出这些数据翻转的差错，然后把收到的错误信息丢弃，这就是差错控制功能。因此差错控制功能是通过数据链路层完成的。 同时，在两个相邻接点之间传送数据时，由于两个节点的性能不同，可能节点A发送数据速率会快于节点B接受数据的速率，如果不加以控制，那么节点B就会丢弃很多来不及接受的正确数据，造成传输线路效率的下降。流量控制可以协调两个节点的速率，使节点A发送数据的速率刚好是节点B可以接受到的速率。总之就是A节点发送数据的速率要小于等于节点B接受数据的速率。 广播式网络在数据链路层还要处理新的问题（快速跳转-&gt;《广播式网络》），即如何控制对共享信道的访问，数据链路层的一个特殊的子层–介质访问子层，就是专门处理这个问题的以保证公共信道不会出现信息传输冲突。 典型的数据链路层协议有SDLC,HDLC,PPP,STP和帧中继等。 下面我们总结一下数据链路层的功能： 成帧（定义帧的开始和结束） 差错控制 流量控制 访问（介入）控制 网络层（Network Layer) 网络层的传输数据单位是数据报，它主要是实现通信子网间的数据传输运行控制，主要任务就是把网络层的协议数据单元（分组）从源端传送到目的端，为分组在交换网上的不同主机提供通信服务。我们一定要注意在网络层上端指的是服务端和客户端，即是主机，而不是端口，因此不区分是哪一个程序。网络层为了实现分组的传输的最短路径以及速率稳定，提供了以下功能：流量控制，拥塞控制，差错控制和网际互联等功能。 其中流量控制和数据链路层的流量控制类似，就是保证了发送端的速率和接收端的速率保持在一个合理的范围，使得两端的缓冲区不会出现溢出过多从而造成大量丢弃分组造成的浪费现象。而拥塞控制是网络层专属的功能，他主要是用来保证在子网传输的过程中不会出现子网间分组过多而造成的通信体系整体瘫痪通信功能下降的问题。差错控制还是进行错误的检测，当检测有错误后选择重传即可，常用的差错检测方法有奇偶校验，海明码，CRC循环冗余等，接收方根据这个规则保证向上传递的数据时无误的。 因特网是一个很大的互联网，他由大量的异构网络通过路由器（Router)相互连接起来。因特网的主要网络层协议是无连接的网际协议（Internet,IP)和许多路由选择协议，因此网络层也称为网际层或者IP层。 网络是许许多多多个子网构成的包含了路由器，主机等概念，因此他和我们生活中所理解的网络有一定的区别，是在计算机网络体系结构中使用的专属名词。在网络层常见的协议有IP、IPX、ICMP、IGMP、ARP、RARP和OSPF等。 我们总结一下网络层的功能： 数据报 流量控制，差错控制 特有的拥塞控制 传输层（Transport Layer) 传输层又称为运输层，传输数据单元是报文段（TCP）或者用户数据报（UDP），传输层是层负责主机中两个进程间的通信，功能是为端到端连接提供可靠的传输服务，为端到端提供流量控制、差错控制、服务质量、数据传输管理等服务。 数据链路层、网络层提供的是点到点的服务，即一个主机到另一个主机的数据通信，但是我们知道实际使用时许多个进程应用需要同时进行数据的传输，因此点到点需要进一步分化，也就是端到端，即每一个进程对应着同一个主机IP不同的端口号，实现不同的进程使用相同的IP+不同的端口号同时独立的进行数据的传输，彼此之间互不影响。而传输层和应用层就是实现端到端的服务。 我们可以这样理解点到点和端到端的区别，一个点就是指一个硬件地址或IP地址，同一个硬件上的应用显然IP地址相同，而一个端就是一个主机上的某一个软件进程的通信端口，因此同一个主机上的不用应用进程端口号不同。 使用传输层的服务，高层用户可以直接进行端到端的数据传输，从而忽略通信子网的存在。通过传输层的屏蔽，高层用户是看不到子网的交替和变化的。我们看下图就可以理解： 我们可以看到实际上传输层协议也是由下三层服务为基础实现的，但是在中继系统是不会涉及到传输层的协议的，就好像在传输过程中，传输层上面的协议服务是直接连接源端和目的端的，这就是所说的忽略通信子网的存在。 同时我们还要理解透明一词在计网这种的意思，它是指看不见的意思，就好像空气看不到的样子。而低层协议相对于高层协议就是透明的，即高层协议是通过低层协议提供的服务实现的更高层功能的，但是他只关心低层协议提供的服务，而不关心低层协议的服务具体是如何实现的。这就有点像OS中低层硬件层和高层软件层的关系，软件只关注如何使用硬件层提供的服务，而不关系硬件层如何实现这些功能的。因此高层协议是不知道低层协议的运行机制的。 因为传输层实现的是端到端服务，而一个主机可以有多个进程，因此传输层是具有复用和分用的功能。复用是指多个应用进程可同时使用下面传输层的服务，分用是指传输层把收到的信息分别交付给上面应用层中相应的进程。即复用是数据从上到下汇聚的过程，而分用是聚合的数据从下到上分开分别服务与对应进程的过程，两者是对立的概念、 传输层最主要的协议有TCP、UDP。 我们总结一下传输层的功能： 用户数据报和数据报文段 端到端传输 流量控制、差错控制、服务质量、数据传输管理 在不可靠传输基础上实现了可靠传输 复用分用 会话层（Session Layer) 会话层允许不同主机上的各个进程之间进行会话，会话层利用传输层提供的端到端服务，向表示层提供它的增值服务。他为表示层实体或用户进程建立连接并在连接上有序地传输数据，这就是会话，也称为建立同步（SYN)。会话层负责管理主机间的会话进程，包括建立、管理及终止进程间的会话，会话层可以使用检验点是通信会话在通信失效时从校验点继续恢复通信，实现数据同步。常用的协议是ADSP、ASP，适用于传输大文件。 表示层（Presentation Layer) 表示层主要处理两个通信系统交换信息的方式，不同机器采用的编码和表示方法可能不同，使用的数据结构也是不同的。为了使不同表示方法的数据和信息之间能够相互交换，表示层采用抽象的标准方法定义数据结构，并且采用标准的编码形式。数据压缩、加密和解密也是在表示层提供的数据变换功能。主要的协议有JPEG、ASII等。 在计网的OSI结构中，我们通常把7层结构简化为5层结构，而会话层和表示层通常被简化掉，因为他们的功能较为简单且偏向理论，在实际传输中并不常见，因此OSI结构有时也称为5层结构。 应用层（Application Layer) 表示层是OSI模型的最高层，是用户与网络的界面。应用层为特定类型的网络应用提供访问OSI环境的手段。因为用户的实际应用多种多样，这就要求应用层采用不同的应用协议来解决不同类型的应用要求，因此应用层是最复杂的一层，使用的协议也是最多的。典型的协议有用于文件传输的FTP、用于电子邮件的SMTP、用于万维网的HTTP等。同时在应用层还涉及到了两个模型即P2P和C/S模型我们在后面也会详细学习。 总结 自此我们简单的了解了OSI各个层之间的主要功能，那么我们就来横向对比以下各个层的区别： 层服务 传输数据单元 是否属于中继系统的组成部分 协议 物理层 比特 √ EIA-232C、EIA/TIA RS-449 数据链路层 帧 √ SDLC,HDLC,PPP,STP和帧中继，ALOHA,CSMA等 网络层 数据报 √ IP、IPX、ICMP、IGMP、ARP、RARP和OSPF 传输层 段 × TCP、UDP 会话层 / × ADSP、ASP 表示层 / × JPEG、ASII 应用层 最高层只接收数据 × RIP（特殊记忆），DNS,POP3,FTP,HTTP,SMTP 思考：为什么RIP是应用层协议？ 我们简单了解一下RIP协议，他是基于路径向量算法实现的一种路径选择协议，谈到路径选择，因此它主要是在网络层实现的，但是为什么属于应用层呢？ 我们要注意协议属于那一层不是由实现的层决定的，而是他针对于哪一层工作决定的，而RIP虽然由网络层实现的，但是他应用于应用层，因此RIP是应用层协议。 TCP/IP参考模型 前面一讲中我们重点学习了OSI7层模型以及对OSI7层模型简化后的5层模型，但是这种参考模型实际上只是在理论上被广泛的认可，并未广泛应用与商业中，究其原因是分层过于理想，偏向理论。因此APPA在研究ARPnet时提出了TCP/IP模型，这种模型从低到高依次为网络接口层（对应OSI参考模型中的物理层和数据链路层）、网际层、传输层和应用层（对应OSI中的会话层、表示层和应用层）。这种模型更加利于应用，因此得到了广泛的应用而成为了事实上的国际标准。TCP/IP的结构及各层的主要协议如下图： 网络接口层的功能与OSI的物理层和数据链路层类似。表示物理网络的接口，但是实际上TCP/IP并未真正描述这一部分的功能，只是指出主机必须使用某种协议与网络连接，以便在其上传递IP分组。具体的物理层网络可以是各种类型的局域网，比如以太网，令牌环网、令牌总线等，也可以是电话网、SDH等数据公共网络。总之网络接口层的作用就是从主机或节点接受IP分组，并把它们发送到指定的物理网络上。 **我们不难发现网际层（主机-主机）是TCP/IP体系结构的核心关键部分。**他和OSI网络层的功能非常类似。网际层将分组发送任何一个网络，并为之独立的选择合适的路由来实现跳转，但是每一个分组可能走的路径都是不同的，因此是乱序抵达的，不能保证分组是有序抵达目的主机的，因此各个分组的有序交付由高层负责。网际层定义了标准的分组格式和协议，即IP。他是唯一标识目的的地址，不会在中继系统的跳转中发生变化。当前我们采用的IP协议是第4版，即IPv4,但是现在IPv4地址已经快被使用耗尽了，因此正在向下一版IPv6转换。 传输层（应用-应用或者进程-进程）的功能同OSI模型的传输层类似，即使得发送端和目的端主机上的对等实体进行会话。传输层主要有以下两种协议： 传输控制协议（TCP），这种协议是面向连接的，数据传输的单位是报文段，能够提供可靠的交付即不出错。 用户数据包协议（UDP），这种协议是无连接的，数据传输的单位是用户数据报，不提供可靠的交付，只能提供尽最大努力交付，因此并不能保证数据的正确性，还需要高层进行进一步的差错检测。 而应用层（用户-用户）包含了所有的高层协议，如虚拟终端协议（Telnet)、文件传输协议（FTP）、域名解析服务（DNS）、电子邮件协议（SMTP）和超文本传输协议（HTTP)等。 我们连接了TCP/IP参考模型后可以看出IP协议是因特网中的核心协议，上层的一切服务都是依托于网际层的IP实现的。由于TCP/IP可以实现为各种应用提供服务，同时TCP/IP也允许IP协议在各种网络构成的互联网上运行（所谓的IP over everything)，因此因特网才能发展成巨大的规模，同时TCP/IP也能被广泛的应用于认可。 思考：参考模型的结构对比？ 如下图是不同的参考模型的直视对比图，相同颜色对应的功能是类似的： TCP/IP与OSI参考模型的比较 首先我们认同TCP/IP和OSI模型时有许多相似之处的，只不过一个偏向理想的模型，一个偏向于商业应用的便利。 相似点 两者都是采取分层的体系结构，将庞大且复杂的问题规划为若干个较容易处理的，范围较小的问题，而且分层的功能也相似。 其次，两者都是基于独立的协议栈的概念 最后，两者都可以解决异构网络的互联，实现世界上不同厂家生产的计算机之间的通信。 思考：什么是异构网络？两者都是如何实现异构网络的互联的？ 首先异构网络就是指组成结构不同的网络，例如A子网是星形结构，B可能是总线形结构，但是通过参考模型描述的功能都可以实现两者的数据通信，网间互联。归根结底，两个模型最终都是通过IP来实现的异构网络的互联的。 不同点 首先OSI模型的最大贡献就是精确的定义了三个主要概念：服务、协议和接口。服务是纵向相邻两层之间的概念，协议是水平源端和目的端对等实体之间的概念，而接口就是相邻两层数据交付的概念。这与现代的面向对象程序设计思想非常吻合。而TCP/IP模型在这三个概念上却没有明确的区分，不符合软件工程的思想。 其次，OSI模型产生在协议发明之前，没有偏向于任何特定的协议，通用性良好。但是由于设计者在协议方面没有充足的经验，不知道该把那些功能放到那一层更加合适，因此出现了不适应于商业应用的缺陷。而TCP/IP模型是在协议出现后提出的，因此不会出现协议不能匹配模型的情况。 第三，TCP/IP模型在设计之初就考虑到了多种异构网络的互联的问题，因此将网际协议（IP）作为了一个独立的重要层次。而OSI模型最初只考虑了利用一种标准的共用数据网络将不同的系统互联，因此OSI模型在认识到网际协议IP的重要性后，只好在网络层中又划分出了一个子层来完成类似于TCP/IP中IP的功能。 因此OSI参考模型的网络层实际上比TCP/IP参考模型的网际层功能范围更加广，结构也更加复杂。IP协议提供的服务是TCP/IP参考模型的核心也是主要功能，而对于OSI模型网络层还包括了RIP,OSPF等协议提供的服务。 最后，OSI模型在网络层支持无连接和面向连接的通信（TCP和UDP），但在传输层仅有面向连接的通信。而TCP/IP模型认为可靠性是端到端的问题，因此他在网际层仅有一种无连接的通信模式，但是传输层支持了无连接和面向连接的两种模式。这个不同点要牢记！ 层 ISO/OSI参考模型 TCP/IP参考模型 网络层 无连接+面向连接 无连接 传输层 面向连接 无连接+面向连接 面向连接和无连接的区别？ 面向连接分为三个阶段，第一是建立连接，在此阶段，发出一个建立连接的请求，只有在连接成功后，才能开始第二阶段的数据传输，第三阶段当数据传输完毕后，还需要释放连接。而无连接就没有这么复杂的过程，直接进行数据传输。因此面向连接的传输更加可靠但是开销也更大，无连接开销小更加广泛应用于数据传输（毕竟大部分应用对于数据的正确性并不是极高）。 五层结构的提出 我们发现OSI和TCP/IP协议都不是完美的，两者都有各自的优缺点。OSI模型试图建立一个全世界计算机网络都要遵循的统一标准，从技术角度来看是追求一种完美的理想状态，但是这也导致了基于OSI模型的软件效率极低，OSI模型缺乏市场与商业动力，结构复杂，实现周期长，运行效率低。而TCP/IP模型又对概念定义模糊，造成层与层之间的界限模糊，协议栈不发。因此我们要采取一种折中的方法，即综合两者的优点，也就提出了5层结构，我们熟知的物理层，数据链路层、网络层、传输层和应用层。 最后简单介绍一下使用通信协议栈进行通信的节点的数据传输过程。每一个协议栈的最顶端都是一个面向用户的接口。下面各层是通信服务的协议，用户传输一个数据报时，通常给出用户能够理解的自然语言，然后通过应用层，将自然语言转换成用于通信的通信数据。通信数据到达传输层，作为传输层的数据部分（传输层SDU），加上传输层的控制信息（传输层PCI），组成传输层的PDU,然后交付到网络层，传输层的PDU下放到网络层后，就成为了网络层的SDU，然后加上网络层的PCI，又组成了网络层的PDU，下方到数据链路层，数据链路层要同时在网络层的PDU头和尾都进行包裹形成数据帧，下放到物理层再进行包裹然后通过光缆信道传输。最后到达接收方节点协议栈，接收方再逆向逐层的将包裹拆开，然后把收到的数据交给用户。 一定要注意只有在数据链路层的成帧过程，是要在数据主体的首部和尾部都进行包裹，而其他层都只是在头部进行包裹。同时传输层是第一个要对信息进行切割分段的过程，当然网络层和数据链路层也可能会对其进一步再分割。 展望 我们现在对计网有了一个整体的认知，接下来我们将以五层参考模型展开进行每一层的协议、服务的详细讲解。通常在学习计网时有自上向下和自下向上的两种学习策略。在学校中我们是自上向下讲解的，但是我发现这样会造成在学习初期有许多疑惑不能理解，因此我在笔记中采用了自下向上的讲解策略，从最底层开始循序渐进的向上层进行学习，更方便于初学者透彻理解每一个协议、服务提出的作用，同时对整体有更全面的掌握。"},{"title":"计算机网络分层","path":"/wiki/计算机网络笔记/计算机网络分层/index.html","content":"计算机网络的标准化工作与相关组织 计算机网络的标准化对于计算机网络的发展和推广起着非常重要的作用。因特网的所有标准都要以RFC（Requestrian For Comments)的形式在因特网上发布，但并不是每个RFC都是因特网标准，RFC要上升为因特网的正式标准需要如下4个阶段。 因特网草案，这个阶段还不是RFC文档 建议标准，从这个阶段开始就是RFC文档了 草案标准 因特网标准 此外，还有实验的RFC和提供信息的RFC，各种RFC之间的关系如图： 而在国际上，负责制定，实施相关网络标准的标准化组织众多，主要有如下几个： 国际标准化组织（ISO）：制定的主要网络标准或规范有OSI参考模型，HDLC等。 国际电信联盟（ITU）：其前身为国际电话电报资讯委员会（CCITT），其下属机构ITU-T制定了大量有关远程通信的标准。 国际电气电子工程师协会（IEEE）：世界上最大的专业技术团队，由计算机和工程学专业人士组成，IEEE在通信领域最著名的研究成果就是802标准。 Internet工程任务组（IETF）：负责因特网相关标准的指定 RTCxxx 计算机网络的性能指标 速率（Speed) 即数据率或称数据传输率或比特率，是指链接到计算机网络上的主机在数字信道上传送数据位数的速率，单位为b/s,kb/s,Mb/s等。例如： 要注意区分速率和存储容量的进制是不同的，前者是10\\^3，后者是2^10，比如： 带宽（Bandwidth) 原本指某个信号具有的频带宽度，即最高频率与最低频率之差，单位是赫兹（Hz)。计算机网络中，带宽用来表示网络的通信线路传送数据的能力，。**我们一定要注意这里的带宽是文件传输速率而不是传播速率，即是文件数据上链路的速率，而不是在链路上传播的速率。**通常是指单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。单位是“比特每秒”而不是“Byte/s字节每秒&quot;，b/s,kb/s,Mb/s,Gb/s。 思考：带宽和速率有什么不同？ 带宽值得是最大速率，即是一个固定的峰值，而速率是实时动态改变的但是速率小于等于带宽。所以我们也可以推断带宽的进制肯定也是10^3。 吞吐量（Throughput） 吞吐量是指在单位时间内通过某个网络（或信道、接口）的数据量。一般会受到网络的带宽和网络的额定速率的限制。单位也是b/s,kb/s等。并且进制也是10^3。发送端到接收端传送数据速率，一段链路网的最大吞吐量取决于吞吐量最小的链路（类似于关键路径，水桶盛水问题）。 假如现在有一个数据传输链路如下图：服务端上传一个文件的某一个链路的传输带宽是Rs,中间的主干路汇聚了10个分支链路，总带宽是R，而某一个分支的主机下载文件的带宽是Rc 那么这段数据通信网的吞吐量主要取决于min{Rs,Rc和R/10} 时延（Delay) 指数据（一个报文或分组）从网络（或链路）的一端传送到另一端所需要的总时间，他由4部分组成:发送时延，传播时延，处理时延和排队时延。这里我们逐一了解： 发送时延：节点将分组的所有比特推向（传输）链路所需要的时间，即从发送分组的第一个比特算起，到改分组的最后一个比特发送完毕所需要的时间，因此也称之为传输时延，计算公式为 发送时延=分组长度/信道宽度发送时延=分组长度/信道宽度 发送时延=分组长度/信道宽度 传播时延：电磁波在信道中传播一定的距离需要花费的时间，即一个比特从链路的一端传播到另一端所需要的时间，计算公式为 传播时延=信道长度/电磁波在信道上的传播速率传播时延=信道长度/电磁波在信道上的传播速率 传播时延=信道长度/电磁波在信道上的传播速率 处理时延：数据在交换节点为存储转发而进行的一些必要的处理所花费的时间。例如：分析分组的首部，从分组中提取数据部分，进行差错检验或查找适当的路由等。 排队时延：分组在进入路由器后要现在输入队列排队等待处理。路由器确定转发端口后，还要在输出队列中排队等待转发，这就产生了排队时延。 处理时延和排队时延可能有许多个，因为现在多采用分组或者报文交换信息，需要经过过个相邻的转存节点经处理后再次转发。在做题时，排队时延和处理时延一般忽略不计，另外对于高速链路，提高的仅仅是数据发送速率而非比特在链路上的传播速率（毕竟电磁波在信道上的传播速率一般是自然界固定的无法提升）。提高数据的发送速率只是为了减少数据的发送时延。 时延带宽积 指发送端发送的第一个比特即将到达终点时，发送端已经发出了多少个比特，因此又称以比特为单位的链路长度。计算公式为： 时延带宽积=传播时延×带宽时延带宽积=传播时延×带宽 时延带宽积=传播时延×带宽 考虑一个代表链路的圆柱形管道，其长度表示链路的传播延时，横截面积表示链路带宽，则时延带宽积表示该管道可以容纳的比特数量。很明显由于带宽是10^3进制，因此这个也是。我们可以理解为时延带宽积是比特为单位的链路长度表示方法。 往返时延（Round-Tip Time,RTT） 指从发送端发送数据开始，到发送端收到来自接收端的确认（接收端受到数据后立即发送确认），总共经历的时延。在互联网中，往返时延还包括各中间节点的处理时延，排队时延以及转发数据时的发送时延。 一定要注意是接收端刚接收到数据的第一个Bit就发送确认信息了。 信道利用率 指出某一个信道有百分之多少的时间是由数据通过的，即 信道利用率=有数据通过时间/(有+无)数据通过时间信道利用率=有数据通过时间/(有+无)数据通过时间 信道利用率=有数据通过时间/(有+无)数据通过时间 网络利用率 计算机网络中会有许许多的信道，每一个信道利用率都不相同，为了宏观评估，对每一个信道根据不同的重要性赋予不同的加权，然后计算加权平均值： 网络利用率=信道利用率加权平均值=p1∗利用率1+p2∗利用率2+...+pn∗利用率n/p1+p2+...+pn网络利用率=信道利用率加权平均值=p_1*利用率1+p_2*利用率2+...+p_n*利用率n/p_1+p_2+...+p_n 网络利用率=信道利用率加权平均值=p1​∗利用率1+p2​∗利用率2+...+pn​∗利用率n/p1​+p2​+...+pn​ 丢包率 丢包率=丢包数量/已发分组数量×100%丢包率=丢包数量/已发分组数量×100\\% 丢包率=丢包数量/已发分组数量×100% 丢包率反映了一个子网的拥塞程度和流量传输控制是否合理，当丢包率过高时即说明这个传输网络拥塞了。 总结 计算机网络分层结构 两个系统中实体间的通信是一个很复杂的过程，为了降低协议设计和调试过程的复杂性，也为了方便于网络进行研究、实现和维护，促进标准化的工作，通常对计算机网络的体系结构进行分层。 我们将计算机网络的各层及其协议的集合称为网络的体系结构，计算机网络的体系结构就是把这个计算机网络及其所对应完成的功能的精确定义，他是计算机网络中的层次、各层的协议即层间接口的集合。 一定要注意这些层次的功能究竟是用何种硬件或软件完成的，则是一个遵循体系结构实现的问题，而体系结构是一个抽象问题，实现是具体问题，是真正在运行的计算机硬件和软件，在讨论分层体系结构时，我们只是研究抽象分层问题，不考虑具体实现。 那么计算机网络体系结构通常都有可分层的特性，他将复杂的大系统分成若干个较为容易实现的层次，分层的基本原则如下： 每层都实现一种相对独立的功能，降低大系统的复杂度 各层之间界面自然清晰，易于理解，相互交流尽可能的少 各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现 保持下层对上层的独立性，上层单向使用下层提供的服务 整个分层结构应能促进标准化工作 分层之后，各层之间相互独立，灵活性好，因而分层的体系结构易于更新（替换单个模块即可），易于调试，易于交流，易于抽象，易于标准化。但是层次越多，有些功能在不同层之间就会难免重复，产生额外的开销，导致整体的效率下降。层次越少，就会使得每一层的协议太过复杂，因此，分层时要考虑层次的清晰程度与运行效率之间的折中，层次数量的折中。 根据一定的规则，我们将分层后的网络从低到高依次称为第1层，第2层…第n层，通常还为每一层取一个特定的名字，比如第1层又称为物理层。 在计算机网络的分层结构中，第n层的活动元素称为n层实体，具体来说，实体可以是指任何发送或接受信息的硬件或软件进程，通常是一个特定的软件模块。不同机器上的同一层称为对等层，同一层的实体称为对等实体。n层实体实现的服务为n+1层所用（其实和操作系统中上层应用和底层硬件层的关系类似）。在这种情况下，n层被称为服务提供者，n+1层服务与用户。 一定要区分OS和计算机网络中的分层结构的区别，OS中，上层是下层的服务对象，同时上层也会调度下层的工作，但是在计算机网络中，下层就真的只是提供上层服务，上层也只是想用下层提供的服务，由于分层工作独立，他们不会互相影响对方的工作。 每一层还有自己传送的数据单位，其名称，大小和含义也不相同。在计算机网络体系结构中，每一个报文都分为两部分，一个是数据部分即SDU，还有一个是控制信息部分即PCI，他们共同组成了PDU协议数据单元。 SDU是服务数据单元，为完成用户所要求的功能而应传送的数据，第n层的数据服务单元称为n-SDU。 PCI是协议控制单元，他不是完成用户功能所要求的的信息，而是控制协议操作的信息，一般是层之间协议交换进行信息交流必须的信息（一般是头文件等），第n层的协议数据单元称为n-PCI。 PDU是协议数据单元，对等层次之间传送的数据单位称为该层的PDU，第n层的协议数据单元即为n-PDU，在实际的网络中，每层的数据协议单元都有一个通俗的名称，如物理层的PDU称为比特，链路层的PDU称为域，网络层的PDU称为分组，传输层的PDU称为报文。 在各层间传输数据时，把从第n+1层收到的PDU称为第n层的SDU，加上第n层的PCI就成为了第n层的PDU，交给第n-1层后作为SDU发送，接收方接收时做相反的处理，因此可以得到三者的关系为n-SDU+n-PCI=n-PDU=(n-1)SDU。什么意思？说明在发送端，从高层要发送的信息，需要先从最高层向最底层方向逐渐进行各种协议控制单元的加密，然后通过最底层物理层传输数据，接收端接受到信息后（实际上此时的信息还有之前的n层的协议控制信息PCI），需要在从最底层向最高层方向逐层的对信息进行解码，最终才能与发送端相同的对等层获得真正需要的SDU内容，如下图： A的5和B的5就是对等层，他们之间要交流的信息或者其他硬件层都是对等实体，当A的第5层要和B的第5层进行信息交流时，那么A的第5层需要先向下进行不断的协议加密即A5-&gt;A4-&gt;A3-&gt;A2-&gt;A1-&gt;B1-&gt;B2-&gt;B3-&gt;B4-&gt;B5,并且从上图中也可以发现，发送端数信息逐渐变长，但是实际上5-SDU并没有变长，只是前面加上了许多协议控制信息比如4-PCI,3-PCI等，而接收端B在向上层传送接受信息的过程中，信息会逐渐变短，这就是在进行头文件信息的解码处理，最终再对等层B5获得了需要的5-SDU。 上图就是我们所讲到的那个关系公式，n-SDU+n-PCI=(n-1)SDU。我们可以从上面的图中清晰的看到两个顶层应用的信息交流实际上需要进行很复杂的处理，才可以实现，而不是仅仅两个应用层单独进行信息交流，所有的信息交换都需要按照上面的层次次序进行。并且我们还可以总结出层次结构的特点： 第n层的实体不仅要使用n-1层的服务来实现自身定义的功能，还要向第n+1层提供本层的服务，该服务是第n层及其下面各层提供的服务总和。 最低层只提供服务，是整个层次结构的基础，中间各层既是低一层的服务使用者，又是高一层的服务提供者，最高层面也要提供服务，他是向用户提供服务。 上一层只能通过相邻层间的接口使用下一层的服务，而不能调用其他层的服务（即n层不能直接使用n-2层提供的服务），下一层所提供服务的实现细节对上一层透明。 两台主机通信时，对等层在逻辑上有一条直接信道，表现为不经过下层就把信息传送到对方(实际上还是需要经过下面的层的服务的，只是我们感官上是只有两个对等层在直接信息交流）。"},{"title":"通信基础","path":"/wiki/计算机网络笔记/通信基础/index.html","content":"从本讲开始我们将开始学习物理层的相关知识点，物理层是计网数据通信传输的根本，实际上本质上就是比特流的传输，但是其中涉及到了编码规则，传输方式等知识点，我们需要熟悉。 通信基础 物理层解决了如何在各种计算机的传输媒体上传输数据比特流，而不是具体的某一种传输媒体，因此物理层的数据传输应用广泛，是一切其他层服务的根基。他的主要任务就是确定与传输媒体接口有关的一些特性，又称为定义标准。所以物理层主要就是确定使用各种传输数据信号物理媒介的通用标准的，在传输比特流时，必须按照物理层定义的标准进行设计传输，这样才能保证不同计算机之间的数据传输。如下图是一个典型的数据通信模型，我们将要学习几个重要概念。 数据、信号和码元 数据是传送信息的实体，通常是有意义的符号序列。 信号就是数据的电气或者电磁表现，是数据在传输过程中的存在形式。数据与信号都可以使用“模拟的”和“数字的”等词语来修饰，模拟（数据）信号和数字（数据）信号区别如下： 码元是指一个固定时长的信号波形（数字脉冲）表示一位K进制数字，代表不同离散值的基本波形，是数字通信中数字信号的计量单位，这个时长内的信号称为K进制码元，而该时长称为码元宽度。1码元可以携带多个比特的信息，例如在二进制编码中（2进制码元），只有两种不同，码元：一种代表0状态，一种代表1状态。我们可以假设0状态用一段20ns的低电位波谷信号表示，1状态用一段20ns的高电位波峰信号表示。因此对于4进制码元，就是有4种不同的脉冲信号表示不同的数据值，因此有4个离散状态，也就对应着4中高低不同的信号波形：00,01,10,11。 信源、信道与信宿 信源和信宿 信源：产生和发送数据的源头。信宿是接受数据的终点。两者通常都是计算机或者其他数字终端装置。发送端信源发出的信号需要通过变换器转换成合适与在信道上传输的信号，同样的，通过信道传输到接收端的信号也先需要经过反变换器转换成原始信息，再发给信宿。 我们一定要注意，信源发送的是原始数据，信宿接受到的也是原始数据。而信道接收的是经过变换器将原始数据转换成的模拟信号，发送的也是模拟信号，到达接受端还需要反变换器进行处理才能被信宿接受。 思考：为什么原始数据需要经过变换才能上信道传输？ 首先我们知道在传输的过程中可能有噪声干导致信号受到干扰发生位数反转等错误从而造成传输的数据有误，因此数字信号并不利于在信道上进行传输，而经过变换器处理过的模拟信号更加适合传输，因为会减少被噪声的干扰。同时在传输时可能会被攻击或者窃听，我们需要对它进行加密处理从而保证其数据的安全性和隐私性。 如下图是一个通信系统的模型： 信道 信道是信号的传输媒介，一般用来表示向某一个方向传送信息的媒介，因此一条通信线路往往包含一条发送信道和一条接受信道。 同时信道还可以根据传输信号不同于传输介质不同划分： 基带信号和宽带信号 同时信道上传送的信号还有基带信号和宽带信号之分。基带信号将数字信号1和0直接用两种不同的电压表示，然后送到数字信道上进行传输称为基带传输。宽带信号就是将基带信号进行调制后形成频分复用模拟信号，然后传送到模拟信道上传输。 对比两种不同信号，当传输距离较近时，计算机网络采用基带传输方式，因为近距离衰减小，从而信号的内容不易发生变化，而在传输距离较远时，计算机网络采用宽带传输方式，因为远距离衰减大，当使用宽带信号时即使信号变化大也能最后过滤出基带信号。 思考：什么是基带传输、频带传输和宽带传输？三者的区别？ 在计算机内部或在相邻设备之间近距离传输时，可以不经过调制就在信道上直接进行传输方式就是基带传输。它适用于局域网，数字基带信号就是在信道中直接传输数字信号，且传输媒体的整个带宽都被基带占用，双向地传输信息。最简单的方法就是用两个高低电平来表示二进制数字，常用的编码方式有不归零编码和曼彻斯特编码。例如传输1010，低电平表示0，高电平表示1，那么在基带传输下，1010需要向通信线路传输（高-低-高-低电平）。 用数字信号对特定频率的载波进行调制（数字调制），将其变成适合于传送的信号后在进行传输，这种传输方式就是频带传输。远距离或者无线传输时，数字信号必须用频带传输技术进行传输。利用频带传输，不仅解决了电话系统传输数字信号的问题，而且可以实现多路复用（前面讲过），进而提高传输信道的利用率。同样传输1010，经过调制，一个码元对应4个二进制位，假设码元A代表啊1010，那么在模拟信道上传输码元A就相当于传输了1010，这就是频带传输。 而借助频带传输，可将链路容量分解成两个或多个信道，每一个信道可以携带不同的信号，这就是宽带传输。宽带传输中所有的信道能同时互不干扰地发送信号，链路容量大大增加。比如把信道进行频分复用，划分为2个互不相关的子信道，分别在两条子信道上同时进行频带传输，链路容量就大大增加了，这就是宽带传输。因此宽带传输实际上就是频带传输的优化，提高利用率。 通信传输方式 串行传输和并行传输 在数据的传输方式中我们又可以分为串行传输和并行传输。串行输入就是一个一个比特的按照时间传输的顺序进行传输，出于经济上的考虑，远距离通信通常使用串行传输。 而并行传输就是指多个比特通过多通信信道同时传输，效率高但是成本也高。 同步传输和异步传输 同步传输模式下，数据的传送是以一个数据区块为单位，因此同步传输又称为区块传输。在传送数据时，先发送1个或多个同步字符，然后再一次性送出整批的数据，如下图： 而异步传输就是将传送数据比特分成许多个小组进行传送，小组可以是8位的1个字符或更长。发送方可以在任何时刻发送这些比特组，而接受方不知道他们会在什么时候到达。传送数据时，加一个字符的起始位和一个字符终止符： 思考：同步通信和异步通信区别？ 上面我们只是讲解了以下两者实现上的区别，但是在实际上的传输过程中还有哪些区别呢？对于同步通信，收发双发必须先建立同步，即双方的时钟要调整到同一个频率。收发双方不停地发送和接收同步比特流。全网同步要求一个非常精确的主时钟对全网所有节点上的时钟进行同步。另一种准同步则允许各节点之间的时钟有微小的误差，然后采用其他措施实现同步传输。同步传输数据率高，但是实现的代价也很高。而异步通信在发送字符时，所发送的字符之间的时间间隔可以是任意的，但是接收端必须时刻做好接受的准备。发送端可以在任何时刻发送字符，因此必须在每一个字符的开始和结束的地方加上标志即起始位和终止为，以便接收端能够正确的接受每一个字符。异步通信也可以以帧为发送的单位，这是帧的首部和尾部必须设有一些特殊的比特组合，使得接收端能够找出一帧的开始（即帧定界）。异步通信的通信设备简单、便宜，但是传输效率低（因为标志的开销所占比例大）。下图是以字符、帧为单位的异步通信示意图： 单工、半双工和全双工 上图就很好地描述了三者的区别，这里我们给出三种通信交互方式的具体定义： 单工通信：只有一个方向的通信而没有反方向的交互，仅需要一条信道。例如无线电广播、电视广播等就是这种通信类型。 半双工通信：通信的双方都可以发送或接受信息，但是任何一方都不能同时发送和接受数据，需要两条信道实现。 全双工通信：通信双方可以同时发送和接受信息，也需要两条信道实现。 信道的极限容量就是指信道的最高码元传输速率或信道的极限传输速率。 一定要注意半双工和全双工通信方式都是需要两个信道实现的，我们可以借助OS中的管道来帮助记忆，在OS中管道一旦设定就只能用于一个方向，因此单工通信只需要一个信道，因为数据的传输方向永远是单向的无交互相应的。而半双工和全双工通信方式都是需要交互的，也就是两个方向都有数据传输，因此需要两个信道来完成，但是两者的区别是半双工要求端系统只能发送/接受二选一，而全双工可以同时进行。 速率、波特和带宽 在数字通信系统中数据传输速率有两种表示方法。速率称为数据率，指的是数据的传输速率，表示单位时间内传输的数据量。可以使用码元传输速率和信息传输速率来表示。 码元传输速率 码元传输速率别名码元速率、波形速率、调制速率或者符号速率。他表示单位时间内数字通信系统所传输的码元个数（也称为脉冲个数或者信号变化的次数），单位就是波特、一波特表示数字通信系统每秒传输一个码元或者一个脉冲信号或者一个离散数据值。例如2s内传4800个码元，那么码元传输速率就是2400B**（注意这里的B不是字节而是波特）** 同时我们要注意码元可以是多进制的，也可以是二进制的，但是码元速率与进制数无关，只与码元长度T有关： RB=1/T(B)R_B=1/T(B) RB​=1/T(B) 思考：为什么码元速率只与码元长度有关？ 我们假设一个码元的长度是20ms，那么一秒内可以传输50个码元，但是如果一个码元长度是1s，那么每秒就只能传输一个码元。因此很显然码元速率与码元长度有关，但是我们并不关系这个码元对应代表的是何种进制数，他并不会影响码元传输速率。 信息传输速率 信息传输速率别名信息速率、比特率，表示单位时间内数字通信系统传输的二进制码元个数（即比特数），单位是bit/s。 码元传输速率和信息传输速率的关系 可能我们看完两者的定义会有所混淆，实际上两者的划分单位是不同的，我们首先很容易理解信息传输速率就是通俗上的速率，也就是看信道每秒传输的比特数。而码元就是一段比特数的抽象符号，并且这个抽象符号可以人为的定义是用一个多少秒的电位表示。就好像a=010,010就是一个3比特的数据，而a就一个人为定义的抽象符号，我们可以定义使用一个2ms的0.4V的电压来表示a，因此码元更加灵活。这样我们就可以推出下面的关系公式，对于一个码元携带n比特的信息量，则M波特的码元传输速率对应的信息传输速率就是M×nbit/s。 习题一 某个数字通信系统传输的是四进制码元，4s传输了8000个码元，求系统的码元传输速率是多少？信息传输速率又是多少？如果另一个通信系统是16进制码元，6s传输了7200个码元，求它的码元传输速率和信息传输速率又是多少？并指出那个系统的传输速率更快？ 对于四进制码元的通信系统，码元传输速率是2000Baud,又因为4进制码元有4个状态分别是00,01,10,11，也就是每一个码元携带了2个比特，因此信息传输速率就是4000b/s。而对于16进制码元的通信系统，码元的传输速率是1200Baud，16进制码元每一个码元携带了4个比特位，因此信息传输速率是4800b/s。因此四进制码元通信系统的码元传输速率快于16进制码元的通信系统，而信息传输速率却慢于16进制码元的通信系统。系统传输的是比特流，因此通常使用信息传输速率来衡量信道传输的快慢，因此16进制码元的通信系统的传输速率要更快。 码元传输速率快，未必信息传输速率快，因为还与码元的进制有关。信息传输速率是衡量一个数字通信系统传输快慢的常用指标。 习题二 已知八进制的数字信号的传输速率是1600B,试问变换成二进制数字信号时的信息传输速率是多少？ 首先我们需要知道一个通信系统信道的传输比特速度是不变的。因此二进制数字信号时的信息传输速率与八进制的数字信号的传输速率是相同的，八进制码元时的码元传输速率是1600B，因此信息传输速率是1600×3=4800b/s。 我们要知道对于同一个信道，他的信息传输速率是不变的，变化的是码元传输速率，因为他和人为定义的码元长度有关。当已知码元进制，码元传输速率和信息传输速率中三者的任意两者，都可以推算出另一个值。 习题三 已知二进制码元的数字通信系统的传输速率是2400b/s，那么当这个信道变换使用四进制数字信号时，码元传输速率是多少？ 因为使用的是四进制码元，因此每一个码元携带2位比特位，因此码元传输速率=信息传输速率/每一个码元携带的比特位数=2400/2=1200B。 带宽 这里的带宽和之前所讲的带宽不同，物理层的带宽指的是信号所具有的频带宽度，单位是赫兹Hz。在模拟信号系统中，当输入的信号频率高或低到一定程度时，使得系统的输出功率称为输入功率的一半时，即最高频率与最低频率间的差值就是同频带宽。也就是说有效频率的宽度。 而我们之前所讲的带宽单位是比特每秒，他表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”即单位时间内通过链路的比特数量，通常是用来表示网络的通信线路所能传输数据的能力。 通信两大定理 失真现象 在学习两大定理之前，我们先考虑一个问题，在实际生活中信道传输总是会受到噪声的干扰，导致波形发生变形，当变形很大时，我们就很难得到争取的数据了，如下图： 这种受到噪声干扰出现变形的情况就成为失真。当噪声影响较小时，当我们对每一个值设置一定的可变范围时，还是可以正确得到传输的数据的，但是当失真很严重时，即使我们增加了信号的可缓冲区，但是仍然会难以得到正确的数据。 如上图，当频率处于300-3300Hz时，信号比较清晰，可以得到识别经处理后得到正确的数据，但是当频率过低或者过高时，就会导致接收端收到的信号波形失去了码元之间较为清晰界限从而无法正确转换得到准确的传输数据的现象，这种现象就成为码间串扰，他是一种常见的失真现象，我们要尽可能避免这种现象的发生，从而提高信道的传输效率。 奈奎斯特定理（奈氏准则） 奈奎斯特（Nyquist）定理又称为奈氏准则，他指出在理想低通（没有噪声、带宽有限）的信道中，极限码元传输率是2W波特，其中W是理想低通信道的带宽（单位为Hz)。如果用V来表示每个码元离散电平的数目（等价于有多少种不同的码元类型，比如16进制的码元，那么就有16中不同的码元，那么V=16），则极限数据传输数据率就是 理想低通信道下的极限数据传输率=2×W×log2V(b/s)理想低通信道下的极限数据传输率=2×W×log_2V(b/s) 理想低通信道下的极限数据传输率=2×W×log2​V(b/s) 我们根据奈氏准则可以得到以下结论： 在任何信道中，码元传输速率都是有上限的，同理也就说明码元的长度不能无限减小。若码元传输速率超过上限，就会出现严重的码间串扰问题（接收端受到的信号波形失去了码元之间的清晰界限），也就导致接收端接收到的码元信号不能正确识别造成转换后的接受数据有错误。 信道的带宽越宽（即通过的信号高频分量越高），那么可用更高的速率进行码元的有效传输。 奈氏准则准确给出了码元传输速率的限制，但是却并没有对信息传输速率给出限制即未对一个码元可以对应多少个二进制位给出限制。因此只要我们提升V，信息传输速率还是可以进一步提升的。 由于码元的传输速率受奈氏准则的制约，所以要提高数据的信息传输速率，我们就必须设法使每一个码元能携带更过个比特的信息量，这样就需要采用多元制的调制方法。 思考：奈氏准则确实有极限数据传输率，为什么说没有给出上限？ 我们要知道奈氏准则只是精确的给出了码元传输率的上限，然后根据码元传输率与信息传输率的转换公式求得了一个根据极限码元传输率计算出来的极限信息传输率。因此并不是数据传输率的上限，毕竟V理论上可以无限增大，那么极限数据传输率岂不是可以无限增大没有上限了？只有香农定理给出了数据传输率是有最大上限的定量计算公式。 习题 假设在无噪声的理想情况下，某个通信链路的带宽为3KHz，采用4个相位，每个相位具有4中振幅的QAM调制技术，则该通信链路的最大数据（信息）传输速率是多少？ 首先我们知道一共有4×4=16中波形变化，因此可以表示16中离散值，因此V=16，所以 最大数据（信息）传输率=2×3k×log216=24kb/s最大数据（信息）传输率=2×3k×log_216=24kb/s 最大数据（信息）传输率=2×3k×log2​16=24kb/s 我们要注意码元的离散电平数目V不仅仅可以根据码元的进制数来得知，究其根本V就是可以表示的不同离散状态数，因此上题4个相位，每一个相位有4个不同的振幅可以表示16种不同的离散状态，因此也可以得知V=16。 香农定理 我们前面学习了奈奎斯特定理，他表明在理想无干扰的信道上码元传输速率是有限的，但是却并未说明信息传输速率的极限。那么说难道信息传输速率真的可以做到无限增大吗？即一个码元所携带的二进制位数真的可以无限大吗？实际上是不可能的，在有噪声干扰的电子设备和通信信道中，由于噪声随机产生，并且瞬时值有时会很大，因此噪声会使接收端对码元的判断产生错误。但是噪声的影响是相对的，如果信号极强，那么噪声的影响也就会相对较小。因此信噪比这个指标就很重要，应该在传输速率公式中参与计算。 而香农(Shannon)定理给出了带宽受限且有高斯白噪声干扰的信道的极限信息传输率。当使用此速率进行传输时，就可以做到不产生误差，即噪声的相对影响降到了可以忽略的地步，从而保证了信道的可靠性，但是相应的信息传输速率也就受到了限制，香农定理定义如下： 信道的极限数据传输率=Wlog2(1+S/N)(bit/s)信道的极限数据传输率=Wlog_2(1+S/N)(bit/s) 信道的极限数据传输率=Wlog2​(1+S/N)(bit/s) 式中，W是信道的带宽，S为信道所传输信号的平均功率，N为信道内部的高斯噪声功率。S/N即为信噪比，即信号的平均功率与噪声的平均功率的比值。信噪比的单位是dB,计算公式如下： 信噪比=10log10(S/N)(dB)信噪比=10log_{10}(S/N)(dB) 信噪比=10log10​(S/N)(dB) 例如当S/N=10时，信噪比为10dB,而当S/N=1000时，信噪比就是30dB。 注意S/N就是信噪比，如S/N=10那么信噪比就是10，但是在计网中我们引入了一个新的单位来衡量表示信噪比就是dB。1dB=10log10(S/N)1dB=10log_{10}(S/N) 1dB=10log10​(S/N) 思考：信噪比为S/N，为什么还要取对数10lg(S/N)? 数字形式表示信噪比就是S/N，即一般数值，如噪声功率为1，信号功率为100，那么信噪比就是100/1=100。 以分贝形式表示，同样还是上面这些数字，以分贝形式表示的信噪比为10lg(S/N)=10lg(100)=20dB 两者的区别在于前者（数值)是没有单位的，而后者必须加上dB,代表分贝。两者数值上等价，采用分贝表示的原因是，很多时候信号要比噪声强得多，比如信号是噪声的10亿倍，那么如果使用数值的话，1后面9个0不易表示，而采用分贝表示仅为90dB，要简单的多不易出错。分贝对特别大或者特别小的数值都极为有利，这种表示方式在电子通信领域用途广泛。 所以在香农定理中极限信息传输率加入了信噪比因素使得计算出的极限传输速率更加偏向应用场景。我们根据香农定理可以得到如下结论： 信道的带宽或信道中的信噪比越大，则信息的传输速率也就越高。 对一定的传输带宽和一定的信噪比，信息传输速率的上限就确定了。 只要信息的传输速率低于信道的极限传输速率，那么就能找到某种方法使得信道实现无差错的传输。 香农定理得出的是极限传输速率，实际信道能达到的传输速率要比他低不少。 我们从香农定理可以看出，如果信道的带宽W或者信道的信噪比S/N没有上限（实际上信道当然不可能这样），那么信道的极限传输速率也是没有上限的。 例题 电话系统的典型参数是信道带宽为3000Hz,信噪比为30dB,那么这个系统的最大数据传输率是多少？ 首先我们根据信噪比30dB可以计算出S/N=1000，因此带入香农定理的公式可以得到信道的极限传输速率是Wlog2(1+S/N)≈30kb/s。 两大定理的对比 定理 内容 特点 奈氏准则 理想情况下，极限码元速率定量给出。极限信息传输速率受W和V两者影响 并未给出极限信息传输速率的上限 香农定理 有高斯白噪声，极限信息传输速率定量给出。极限传输速率受W和S/N两者影响 极限传输速率一下保证信道无误传输 思考：两大定理公式的联系？ 我们首先给出两个定理的计算公式： {奈氏准则：极限数据传输率=2×W×log2V(b/s)香农定理：极限数据传输率=Wlog2(1+S/N)(b/s)\\begin{cases} 奈氏准则：极限数据传输率=2×W×log_2V(b/s)\\\\ 香农定理：极限数据传输率=Wlog_2(1+S/N)(b/s) \\end{cases} {奈氏准则：极限数据传输率=2×W×log2​V(b/s)香农定理：极限数据传输率=Wlog2​(1+S/N)(b/s)​ 我们根据香农定理可以得信息传输率是有上限的，因此把这条推论应用到奈氏准则中可以得知当带宽一定时，码元传输率是有上限的，信息传输率也是有上限的，因此V并不能一直无限增大，即一个码元所携带的二进制位数（或者称为离散电平数目）是有上限的，不能无限增大。同时我们也知道了若想提高极限信息传输率，方法有①提升信道的带宽②提升信道的信噪比。而如果是提升信息传输率，还有一个额外的方法就是尽可能的提升一个码元的携带比特数，也就是可能增加码元的离散电平数目使得有更多的状态。 思考：两大定理公式的区别？ 奈氏准则指出码元传输的速率有限，不能任意提高，否则在接收端就无法正确判定码元所携带的比特是1还是0（因为码元之间存在干扰）。奈氏准则是在理想环境下推导出来的，因此实际上条件下，最高码元传输速率要低得多。而电信技术人员就是要在实际环境下，寻找出较好的传输码元的波形，将比特转换为较为合适的传输信号。但是我们一定要注意奈氏准则并未限制信息传输速率（b/s），要提高信息传输速率，就必须使每个码元能够代表许多比特的信息，这就需要很好的编码技术，但是码元所在的比特数确定后，信道的极限数据率也就确定了， 但是仅仅按照奈氏准则，我们理论上是可以无限增大码元携带比特的数量的从而无上限提高数据率，但是这个猜想被香农定理否决了，香农定理给出了信息传输速率的极限，即对于一定的传输宽带（Hz)和一定的信噪比，信息传输速率的上限就确定了，这个极限是不能突破的。要提高信息的传输率，就必须设法提高带宽或者信噪比了，没有其他的办法。 例题 某二进制信号在信噪比为127:1的4Hz信道上传输，最大的数据率可达到多少/ 首先我们根据奈氏准则求解出极限码元传输率对应的极限数据传输率是 Nice:2×4000×log22=8000b/sNice:2×4000×log_22=8000b/s Nice:2×4000×log2​2=8000b/s 然后在根据香农定理求解出极限数据传输时 香农：4000∗log2(1+127)=28000b/s香农：4000*log_2(1+127)=28000b/s 香农：4000∗log2​(1+127)=28000b/s 此时我们得到了两个极限数据传输率，选择小的作为结果，因此极限数据传输率是8000b/s。 思考：为什么要选择小的极限数据传输率作为结果？ 我们知道奈氏准则求解出来的极限数据传输率对应的是极限码元传输率，而香农定理计算出来的是实际上可以达到的最大极限数据传输率，但是此时我们要取两者的最小值。即这个极限数据传输率既不能超过香农定理计算出来的极限数据传输率同时还要满足对应的最大码元传输率不超过奈氏准则的结果。因为根据两个定理的前提，当超过奈氏定理的最大码元传输率或者香农定理的极限数据传输率都会导致信道上的传输不再准确。因此我们时刻要取两者的最小值。"},{"title":"I/O管理概述","path":"/wiki/操作系统笔记/I/O管理概述/index.html","content":"I/O设备的基本概念与分类 接下来我们介绍以下I/O设备管理的知识，首先我们学习认识一下I/O设备 什么是I/O设备 顾名思义，就是输入/输出设备（Input/Output)。I/O设备可以将数据传入到计算机，或者可以接受计算机输出数据的外部设备，属于计算机的硬件部分。 这里的输入和输出都是以计算机的视角来看的。所以显示器是计算机线束输出数据所以为输出设备。在UNIX系统中将外部设备抽象为了一种特殊的文件，用户可以使用与文件操作系统相同的方式对外部设备进行操作。例如write操作就是向外部设备输出数据，read操作就是从外部设备读入数据。 I/O设备根据使用特性的分类 可以分为： 人机交互类外部设备（数据传输速度慢） 存储设备（数据传输速度快） 网络通信设备（数据传输速度介于两者之间） I/O设备根据传输速度分类 低速设备 中速设备 高速设备 I/O设备根据信息交换的单位分类 块设备（传输速率较高，可以寻址，即对他可以随机的读/写任意一块） 字符设备（传输速率慢，不可寻址，在输入输出时常采用中断驱动方式） 总结 I/O控制器 I/O控制器主要由机械部件和电子部件组成，这里我们依次介绍。 I/O设备的机械部件 I/O的机械部件主要用于执行具体的I/O操作，如鼠标/键盘的按钮，显示器的LED屏，移动硬盘的磁臂，磁盘盘面等。 而I/O的电子部件通常是一块插入主板扩充槽的印刷电路板。 I/O设备的电子部件（I/O控制器） CPU无法直接控制I/O设备的机械部件，因此I/O设备还要有一个电子部件作为CPU和I/O设备机械部件之间的桥梁，勇于实现CPU对设备的控制，这个电子部件就是I/O控制器，又称为设备控制器。CPU可以控制I/O控制器，所以可以通过I/O控制器来控制设备的机械部件。 I/O控制器主要有以下功能： 接受和识别CPU发出的命令（如CPU发来的read/write命令，I/O控制器中会有相应的控制寄存器来存放命令与参数） 向cpu报告设备的状态（I/O控制器有相应的状态寄存器，用于记录I/O设备的当前状态，1表示空闲，0表示忙碌，当然也有的控制器为1表示忙碌，0表示空闲，这个看厂商的设定） 数据交换（I/O控制器会设置相应的数据寄存器。输出时，数据寄存器用于暂存CPU发来的数据，之后再由控制器传达给IO设备。输入时，数据寄存器暂存设备发来的数据，之后CPU从数据寄存器中取走数据） 地址识别（类似于内存的地址，为了区分不同设备控制器中的各个寄存器，也需要给各个寄存器设置一个特定的寄存器，I/O控制器通过CPU提供的地址来判断CPU要读/写的是哪一个寄存器） I/O控制器的组成 所以①一个I/O可能会对应多个设备②数据寄存器，控制寄存器，状态寄存器等可能会有多个（例如每一个控制/状态寄存器对应一个具体的设备），且这些寄存器都要有相应的地址，才能方便CPU的操作。有的计算器会让这些寄存器占用内存地址的一部分，称为内存映像I/O，另外一些计算机则采用I/O专用地址即寄存器独立编址。 思考：两种寄存器地址组成形式有什么区别？ 所以我们可以看出内存映像I/O貌似性能更好。 总结 I/O控制方式 那么I/O控制器具体通过什么方法来控制I/O设备呢？我们也会有多种形式其中主要会影响到读/写操作的流程，CPU的干预频率，数据传送的单位，数据流向等问题。 程序直接控制 我们以读操作为例 ①CPU向控制器发出读数据的命令。于是I/O控制器设备启动并且状态寄存器设置为1（未就绪）然后开始做准备工作让输入设备准备输入数据同时控制器自身准备接受数据到数据寄存器 ②CPU轮询检查控制器的状态是否就绪，即CPU时刻准备与控制器进行工作 ③输入设备准备好数据后将数据传给控制器同时报告自身状态 ④控制器将输入的数据放到数据寄存器，并且将自身的状态更改为0（表示已就绪和CPU进行交换工作） ⑤CPU发现控制器设备已经就绪，那么就将数据寄存器中的数据读入到CPU的寄存器中同时把CPU寄存器中的内容放到内存以便进行数据交换 ⑥如果还要继续读入数据，那么CPU继续发出读的指令 CPU干预频率：这样的方式CPU的干预频率很频繁，I/O操作开始之前，完成之后需要CPU介入，并且等待I/O完成的过程中需要不断地轮询检查。 数据传送单位：每次读/写一个字 数据流向： 读操作（数据输入）：I/O设备-&gt;CPU(包括CPU寄存器)-&gt;内存 写操作（数据输出）：内存-&gt;CPU(包括CPU寄存器)-&gt;I/O设备 每个字的读/写都需要CPU的帮助 优点：实现简单，在读/写指令后加上循环检查的一系列指令即可。 缺点：CPU和I/O设备只能串行工作，CPU需要一直轮询检查，长期处于忙碌状态，CPU利用率低。 中断驱动方式 引入中断机制，由于I/O设备很慢，因此CPU发出读/写命令以后可以将等待I/O的进程阻塞，先切换到其他进程。当I/O设备完成后，控制器会向CPU发送一个中断信号，CPU检测到中断信号后保存当前进程的运行环境信息，然后转去执行中断处理程序来处理中断。处理中断的过程中，CPU从I/O控制器中读一个字的数据传送到CPU寄存器，再写入主存。接着，CPU恢复等待I/O的进程（或其他进程）的运行环境，然后继续执行。 这样就不是cpu主动一直询问控制器设备是否就绪了，而是当控制器就绪后主动告诉CPU。这里我们要注意： ①CPU会在每个指令周期的末尾检查中断 ②中断处理过程中需要保存，恢复进程的运行环境，这个过程是需要一定的时间开销的。可见，如果中断发生的频率也会降低系统性能。 CPU干预频率：每次I/O操作开始之前，完成之后需要CPU的介入。等待I/O完成的过程中CPU可以切换到别的进程执行。 数据传送单位：每次读/写一个字 数据的流向： 读操作（数据输入）：I/O设备-&gt;CPU(包括CPU寄存器)-&gt;内存 写操作（数据输出）：内存-&gt;CPU(包括CPU寄存器)-&gt;I/O设备 每个字的读/写都需要CPU的帮助 优点：和程序直接控制方式相比，CPU不用一直不停的轮询，CPU和I/O设备可以并行工作，CPU利用率得到明显的提升 缺点：每个字在I/O设备和内存之间的传输，都需要经过CPU。并且频繁的中断也会消耗较多的CPU时间。 DMA方式 与“中断驱动方式”相比，DMA（Direct Memory Access,直接存储器存取，主要用于块设备的I/O控制）有这样几个改进： 数据的传送是“块”，不再是一个字，一个字的传送 数据流向是设备直接放到内存，或者内存到设备，不再需要CPU的帮助 仅在传送一个或多个数据块的开始和结束时，才需要CPU干预 DMA控制器 所以这个方法需要DMA控制器来服务。DMA控制器结构如下： DR(Data Register,数据寄存器)：暂存从设备到内存，或者从设备到内存的数据 MAR(Memory Address Register,内存地址寄存器)：在输入时，MAR表示数据应该放到内存中的什么位置，输出时MAR表示要输出的数据放在内存中的什么位置 DC(Date Counter,数据计数器)：表示剩余要读/写的字节数 CR（Command Register,命令/状态寄存器)：用于存放CPU发来的I/O命令，或设备的状态信息。 CPU干预频率：仅在传送一个或多个数据块的开始和结束时，才需要CPU干预 传送数据的单位：每次读/写一个或多个块（注意每次读写的都是连续的多个块，且这些块读入内存后在内存中也必须是连续的） 数据流向（不需要CPU帮助）： 读操作（数据输入）：I/O设备-&gt;内存 写操作（数据输出）：内存-&gt;I/O设备 优点：数据时以“块”为单位，CPU介入频率进一步降低。数据的传输不在需要经过CPU在写入内存，数据效率高。CPU和I/O设备的并行性也进一步提升。 缺点：CPU每发出一条I/O指令，只能读/写一个或多个连续的数据块。如果要读/写多个离散的存储块，或者将数据分别写到不同的内存区域时，CPU要分别发出多条I/O指令，进行多次中断处理才能完成。 通道控制方式 通道：一种硬件，可以理解为“弱鸡版CPU”，也是可以识别并执行一系列通道指令 和CPU相比，通道可以执行的指令很单一，并且通道程序是放在主机内存中的，也就是说通道与CPU共享内存。 CPU干预频率：极低，通道会根据CPU的知识执行相应的通道程序，只有完成一组数据块的读/写操作后才需要发出中断信号，请求CPU干预 数据传送的单位：每次读/写一组数据块 数据的流向（在通道的控制下进行）： 读操作（数据输入）：I/O设备-&gt;内存 写操作（数据输出）：内存-&gt;I/O设备 优点：CPU,通道，I/O设备并行工作，资源利用率很高 缺点：实现复杂，需要专门的通道硬件支持 总结 控制方式 完成一次读/写的过程 CPU干预频率 每次I/O的数据传输单位 数据流向 程序直接控制方式 CPU发出I/O命令后需要不断轮询 极高 字 设备-&gt;CPU-&gt;内存内存-&gt;CPU-&gt;设备 中断驱动方式 CPU发出I/O命令后可以做其他事，本次I/O完成后设备控制器发出中断信号 高 字 设备-&gt;CPU-&gt;内存内存-&gt;CPU-&gt;设备 DMA方式 CPU发出I/O命令后可以做其他事，本次I/O完成后，DMA控制器发出中断信号 中 块 设备-&gt;内存内存-&gt;设备 通道控制方式 CPU发出I/O命令后可以做其他事，通道会执行通道程序以完成I/O，完成后通道向cpu发出中断信号 低 一组块 设备-&gt;内存内存-&gt;设备 每一个阶段的优点都是上一个阶段的最大缺点，总体来看，整个发展过程就是尽量减少CPU干预，把CPU从繁杂的I/O控制事务中解脱出来，以便更多的完成数据处理任务。"},{"title":"流量传输与可靠传输","path":"/wiki/计算机网络笔记/流量控制与可靠传输/index.html","content":"流量控制 我们在前面的流量控制中学习到流量控制涉及对链路上的帧的发送速率的控制，以便使接收方能够有足够的缓冲时间来接收每一个帧。例如：在面向帧的自动重传请求系统中，当待确认帧的数量增加时，有可能就会超出缓冲存储空间而造成过载。此时流量控制的基本方法是由接收方控制发送方发送数据的速率，常见的方法有两种：①停止-等待协议②滑动窗口协议 停止-等待协议流量控制原理 在停止-等待协议中每发送一个帧，都要等待接收方的应答信号，之后才能发送下一个帧，接收方每接收一个正确信息的帧，都要反馈一个应答信号，表示可以接收下一个帧，如果接收方不反馈应答信号或者应答信号在传输过程中丢失，那么发送方就必须一直等待应答信号。这种协议的原理很简单，每次只允许发送一个帧，然后就陷入等待接收方确认信息的过程中，因此传输的效率很低。 一定要牢记上面接收方的特点，他说明了以下几种情况：接收方只要收到数据正确的帧，就发送一次ACK并且发送的ACK所携带的序列号是最近一次接收到的正确的帧的序列号 2. 接收方当收到数据错误的帧时，不会发送任何应答信息，保持沉默 3. 接收方收到重传的已经接收过的正确数据帧时，会丢弃这个重传帧，并且发送应答信息 思考：已经有差错检测机制了，为什么还需要停-等协议？ 帧除了出现比特差错（可以直接被校验和检测）以外，还可能出现帧错，即底层信道出现了丢包问题，此时需要停-等协议来实现流量控制。 丢包：物理线路故障、设备故障、病毒攻击、路由信息错误等原因都会导致数据包的丢失 思考：研究停-等协议的前提？它属于哪一层的协议？ 虽然现在常用全双工通信方式，即双方可以同时发送消息，但是这里为了方便讨论，仅考虑一方发送数据（发送方）和接收数据（接收方）。因为是在讨论可靠传输的原理，因此并不考虑数据是在哪一个层次上传送。在不同的参考书中，停-等协议以及滑动窗口协议被分别划分到了数据链路层、网络层或者传输层等。 思考：停-等协议有几种应用情况? 两种：①无差错情况②有差错情况。所谓的无差错情况就是理想情况，即传送的帧不会丢失并且数据必定无错误，此时的传送情况如下图： 而在实际的传输中，经常会伴随着差错的出现因此有差错情况的传送更加普遍： 我们从上图可以看出在有差错情况下的停-等协议中加入了计时器功能，当发送帧在中途丢失时或者接收的数据帧有错误时接收方都不会发送应答信息，当经过一个时钟周期后计时器可以报错给发送方请求重发从而解决收发双方陷入死循环的情况。 同时帧到达接收方后可能发生了数据的错误而被接收方丢弃，此时帧也需要重发，因此发送方在发送了一个帧后并不会立刻丢弃这个副本，而是保留这个帧的副本以便重发之需，只有当接收到应答信息ACK后才会丢弃这个已发送帧的副本。 我们要特别特别注意接收方的特点，当发生帧错或者比特错误时接收方都不会发送应答信息，当双方会保持一段时间的僵局（即双方都等待对方的消息），然后计时器超时发送方打破僵局重传刚刚发送的帧。 思考：还有没有其他可能出现的差错情况？ 当然有，可能ACK会发生丢失，此时如下图： 或者还有可能出现ACK迟到的问题： 此时发送方已经成功接收到了重传以后的0帧的ACK0了并且开始下一个1帧的发送了，此时却刚刚收到之前迟到的ACK0，此时发现要等待接收的应答消息ACK序列号和接收到的应答信息ACK序列号不同那么就丢弃继续等待正确的ACK序列号。 思考：停-等协议仅仅使用了0和1可以完成所有的数据帧的传输吗？ 当然可以，因为在停-等协议中我们是一帧一帧的发送，因此我们只需要将当前帧和下一个帧区分开即可，因此一个用0一个用1就可以完美的区分当前帧和下一帧。 思考：序列号相同的帧数据一定相同？ 很明显不是。我们要透彻理解序列号的作用，他不是一个独一无二的标识唯一帧的标志，而仅仅是区分当前发送帧和下一个要发送帧的。比如现在有如下帧A,B,C,D，我们从0开始标号，那么它们的序列号分别是0(A)，1(B)，0©，1(D)即A和D的序列号都是0，因此序列号不同的数据帧数据可能是不同的。ACK的序列号同理。 由于每次传输只涉及当前帧和下一帧两个状态，因此序列号相同而数据不同的帧不可能在一个停-等传输过程中同时出现。如A和D不可能出现在一个传输RTT中，因此0和1序列号就可以完美实现停-等协议的功能了。 思考：接收双方的特定总结？ 接收方必须是收到正确数据的帧时才会发送应答信息，当收到重复的正确帧时丢弃重复的帧并且由于此时这个重复帧也是正确的数据，因此接收方也会发送应答信息 接收方每次发送的应答信息都是最近一次成功接收到的正确数据帧的序列号 发送方有以下状态 发送一个帧后会先保留帧的副本，然后等待与发送帧的序列号相同的ACK，当收到的ACK序列号和要等待的相同，那么发送成功，丢弃这个刚刚发送的帧的副本 发送一个帧后会先保留帧的副本，然后等待与发送帧的序列号相同的ACK，当发生了帧丢失或者帧数据错误时，由于接收方会保持沉默，因此计时器超时后发送方重发刚刚的帧 发送一个帧后会先保留帧的副本，然后等待与发送帧的序列号相同的ACK，当收到的ACK序列号和要等待的不同时，说明此时出现了ACK迟到的情况，因此这个序列号不对的ACK是上一个已经成功完成传输的帧的应答信息，发送方直接丢弃这个序列号不对的ACK，继续等待正确的ACK抵达 思考：将数据帧信息错误的情况改进为下面这种方式是否合理？ 我们发现在帧发生比特错误的情况下接收方并不会应答导致了很长时间的等待出现，那么我们能不能将其改进，让接收方应答，此时收发双方的特点变成了这样，请问是否合理？ 接收方无论是否接收到了正确的帧数据，都要传达一个应答信息，这个应答信息是他最近接收到的正确的帧的序列号 接收方只有对正确无误的数据帧进行接收，而对于由比特错误的帧要丢弃，但是仍然会发送一个应答信息，显然这个应答信息是上一个正确的数据帧的序列号 发送方有两个状态： 等待接收的ACK序列号和已发送的帧的序列号相同时，说明刚刚发送的帧无错误在抵达接收方后被成功接收了 等待接收的ACK序列号和已发送的帧的序列号不同时，说明刚刚发送的帧有错误在抵达接收方后被丢弃了，此时需要重传刚刚发送的帧 我们乍一看感觉没有毛病呀😀，这种对策可以有效减少因比特翻转导致的帧数据错误时的等待时间，但是实际上上面这种策略时有很大缺陷的，即他会导致和下面的ACK迟到情况区分不开而造成一系列的错误链式反应： 如果按照上面的策略，那么此时发送方接收到这个迟到的ACK0时会误认为刚刚发送的1帧错误了而导致发送方又要重传1帧。而对于之前的策略，发送方接收到这个迟到的ACK时是直接丢弃的，这样就不会出现发送方重传1帧的情况了，因此这种优化策略是错误的。即接收方收到错误的数据帧时保持沉默是必要且正确的最优策略。 一定要注意上面刚刚所介绍的改进策略是错误的，不要和前面所讲的停-等协议的策略混淆 思考：停-等协议的优缺点？ 很明显停-等协议的优点就是原理简单，实现起来很容易，但是缺点过于明显，无论是帧丢失还是帧的数据错误都会触发很长时间的等待僵局从而造成信道利用率过低： 信道利用率公式： 信道利用率=传输时间/传输周期信道利用率=传输时间/传输周期 信道利用率=传输时间/传输周期 即 信道利用率=（L/R)/T=TD/TD+RTT+TA信道利用率=（L/R)/T=T_D/T_D+RTT+T_A 信道利用率=（L/R)/T=TD​/TD​+RTT+TA​ 这里我们从时间角度对信道利用率进行了定义：即对发送方而言，值指发送方在一个发送周期的时间内，有效的发送数据所需要的时间占整个发送周期的比率。并且信道吞吐率与信道利用率有如下关系： 信道吞吐率=信道利用率×发送方的发送速率信道吞吐率=信道利用率×发送方的发送速率 信道吞吐率=信道利用率×发送方的发送速率 例题 一个信道的数据传输了为4kb/s，单向传播时延为30ms，如果使停止-等待协议的信道最大利用率达到80%，要求数据帧的长度至少为多少字节？ 我们设数据帧的长度为L，那么有以下公式： 80%=(L/4)/(L/4+2×30ms)80\\%=(L/4)/(L/4+2×30ms) 80%=(L/4)/(L/4+2×30ms) 可以解得L=960bit=120B,因此数据帧的长度至少为120字节。 滑动窗口协议流量控制原理 我们思考一下能否对停-等协议进行优化，上面的策略之所以传输效率低有两方面的原因：①一次性只传输一个帧导致效率低②错误全依赖于计时器超时重发机制，接收方不会主动报错造成长时间的等待。 我们前面讲过了接收方对于错误信息不能主动报错这是为了和迟到ACK加以区分，因此我们只能着眼于第一个缺陷加以优化，此时我们可以借鉴流水线的机制： 流水线协议 在停-等协议中并没有使用流水线机制，因此传输的过程图如下图，传输效率低： 而我们可以引入流水线机制如下图，此时传输效率就大大提升了： 可以看到效率提升了将近40倍，因此我们再引入了流水线机制后就提出了一个新的流量控制策略–滑动窗口协议 思考：滑动窗口协议加入了流水线机制后和停-等协议有什么区别？ 在介绍滑动窗口之前，首先我们从序列号和收发双方的缓冲区大小就可以比较出区别了。由于停-等协议一次只发送一个帧，因此只有当前发送的一个帧和下一个要发送的帧需要加以区分，因此只需要序列号0和1即可，但是很明显在滑动窗口中由于使用了流水线机制，一个RTT中会有许多个帧在同时传输，因此仅仅用0和1肯定是不够的了，我们需要扩充序列号范围，相应的收发双方的缓冲区大小也要从1扩大。 滑动窗口协议 在任意时刻，发送方都维持一组连续的允许发送的帧的序号，称为发送窗口，同时接收方也维持一组连续的允许接收帧的序号，称为接收窗口。发送窗口用来对发送方进行流量控制，而发送窗口的大小Wt代表在还未收到对方确认信息的情况下发送方最多还可以发送多少个数据帧。同理，在接收端设置接收窗口是为了控制可以接收那些数据帧和不可以接收那些数据帧。在接收方，只有收到的数据正确的帧的序号落入接收窗口内时，才允许将该数据帧收下。如果接收到的数据正确的帧在接收窗口之外或者接收到的帧数据发生了错误，则一律丢弃。如下图： 对于接收方窗口，大小可以自定义，这里我们给出接收窗口大小Wr为1的图: 发送端每收到一个确认帧，发送窗口就向前滑动一个帧的位置，当发送窗口内没有可以发送的帧（即窗口内的帧全部都是已发送但未收到确认的帧）时，发送方就会停止发送，直到收到接收方发送的确认帧使窗口一移动，窗口内有可以发送的帧后，才开始继续发送。而接收端收到正确数据帧后，将窗口向后移动一个位置，并发回确认帧，若收到的正确数据帧落在接收窗口外，一律丢弃。 发送方的窗口不是在发送帧后滑动，而是在收到待确认的信息后滑动。接收方的窗口不是在接收到帧时滑动，而是在接收到正确数据的且序列号在接收窗口的帧时滑动并发送应答信息。 我们还可以总结出如下规律： 只有接收窗口向前滑动（同时接收方发送了确认帧）时，发送窗口才有可能（只有发送方收到确认帧后才一定）向前滑动 从滑动窗口的概念看，停止-等待协议、后退N帧协议（GBN）和选择重传协议（SR）都是滑动窗口协议的一种形式，只是窗口大小和确认帧的形式上有所区别 停止-等待协议：发送窗口大小=1，接收窗口大小=1 后退N帧协议：发送窗口大小&gt;1，接收窗口大小=1 选择重传协议：发送窗口大小&gt;1，接收窗口大小&gt;1 接收窗口大小为1时，可以保证帧的有序接收 数据链路层的滑动窗口协议中，窗口的大小在传输过程中是固定的（一定要注意与传输层的滑动窗口区分开来，传输层的滑动窗口大小是动态变化的） 可靠传输机制 数据链路层的可靠传输通常使用确认个超时重传两种机制来完成。确认是一种无数据的控制帧，这种控制帧使得接收方可以让发送方知道那些内容被正确接收。有些情况下为了提高传输效率，将确认捎带在一个回复帧中，称为稍待确认。超时重传是指发送方在发送某个数据帧后就开启一个计时器，在一定时间内如果没有得到发送的数据帧的确认帧，那么就重新发送该数据帧，知道发送成功为止。 自动重传请求（ARQ）通过接收方请求发送方重传出错的数据帧来恢复出错的帧，是通信中用于处理信道所带来差错的方法之一。传统的自动重传请求分为3种，即①停止-等待ARQ②后退N帧ARQ③选择重传ARQ。后两种协议是滑动窗口技术与请求重发技术的结合，由于窗口尺寸开到足够大时，帧在线路上可以连续地流动，因此又称为连续ARQ协议。在数据链路层，流量控制和可靠传输是交织在一起的。 单帧滑动窗口与停止-等待协议 前面我们已经详细的介绍了停-等协议的运作原理了，实际上就是单帧滑动窗口的工作过程，他的发送窗口大小和接收窗口大小都为1。 对于帧的丢失和帧的数据错误的情况，停-等协议中接收方都是保持沉默不发送任何消息，待计时器超时后自动触发发送方重传帧。而对于已经成功接收的帧，窗口会向前滑动一个帧的位置，但是此时如果他有接收到正确的重复的该帧，那么由于此时这个帧的序列号已经不再接收窗口内部了，因此他会丢弃这个帧，但是同时这也意味着之前的确认帧并没有正确的被发送方接收，为了能够保证发送方的窗口能够正常滑动，接收方需要重发一下之前的确认帧： 由于单帧滑动滑动窗口中每次只发送一个帧，因此序列号仅用0和1两个数即可，也就是序列号占用1bit二进制位即可，因此此时的帧的序列标志位长度为1bit。 在停止-等待协议中，如果连续出现相同发送序号的数据帧时，说明发送端进行了超时重传，意味着①数据帧在传输信道中丢失了或者②确认帧在传输信道中丢失了亦或者是③信道中干扰太大，很不幸发送的数据帧一直连续在传输信道中出现数据错误。 在停止-等待协议中，如果连续出现相同序号的确认帧时，表示接收端一直在收到重复的数据正确的帧，那么也就意味着确认帧一直没能正确的抵达发送方。 由于此协议的信道利用率过低，因此为了克服这一个缺点，产生了另外两个更加高效的后退N帧协议和选择重传协议。 多帧滑动窗口与后退N帧协议（GBN） 在后退N帧式ARQ中，发送方无须在收到上一个帧的ACK后才能开始发送下一帧，而是可以连续发送帧。当接收方检测出失序的信息帧后，要求发送方重发最后一个正确接收的信息帧之后的所有未被确认的帧。或者当发送方发送了N个帧后，如果发现N个帧的前一个帧在计时器超时后仍未返回确认信息，则该帧被判定为出错或者丢失，此时发送方不得不重传该出错帧及随后的N个帧。也就是说，接收方只允许按顺序接收帧。 其实很好理解GBN为何是按顺序接收帧，毕竟他的接收窗口大小仅仅为1，必须接收到当前顺序抵达的帧才能下滑到下一个接收帧位置，因此GBN一定是顺序接收帧的。 发送方窗口划分 我们来规定一下后面讲解时GBN发送方窗口的定义： 在GBN发送方窗口中我们将其分成四个区域，其中send_base指向的是窗口的最末端，nextseqnum指向的是窗口的最前端。两者之间（包括这两个边缘端存储的帧）时窗口的大小，内部的黄色部分是已经发送出去的帧但是还没有收到确认帧的部分，而蓝色部分是还可以发送帧的部分。send_base左端的绿色部分是已经成功发送并且收到确认消息的部分，而nextseqnum右侧的白色部分就是暂时存储到发送方缓存区等待发送的部分，只有当窗口滑动到这部分时，这部分白色区域会变成蓝色区域即有资格等待发送了。而黄色部分伴随着窗口滑动会变成绿色部分即收到确认帧后的部分。 GBN发送方必须响应的三件事 在了解GBN协议实现的过程之前，我们先来说明GBN发送方必须响应的三件事： 上层的调用：上层要发送数据时，发送方先检查发送窗口是否已满，如果未满，则产生一个帧并将其发送，如果窗口已满，那么发送方只需将数据返回给上层，暗示上层窗口已满，请上层等待一段时间后在发送。（但是在实际的实现中，发送方是可以缓存这些数据的即上面图示中的白色区域，窗口不满时在发送帧） 收到一个ACK(n)：在GBN协议中，对n号帧的确认采用累积确认的方式，即ACK(n)表示接收方已经顺序接收到n号帧及他以前的全部帧。 超时时间：协议的名字为后退N帧，来源于出现丢失和时延过长帧时发送方的行为，就像在停-等协议中一样，定时器会再次用于恢复数据帧或确认帧的丢失。如果确认出现超时，发送方会重传所有已发送但是还未被确认的帧。 一定要注意超时后发送方并不是发送所有帧，而是所有已发送过一次但是未被确认的帧，即窗口滑动后新进入的帧此时仍然不能发送，只能等待下一波。 GBN接收方要做的事 同样的GBN协议中接收方也有必须响应的事情： 如果正确到n号帧，并且按序，那么接收方为n帧发送一个ACK(n)确认帧给发送方改制发送方前n号帧（包括第n号帧)都已经成功接收，并将该帧中的数据部分交付给上层。 其余情况下错误或者未按序抵达的帧一律丢弃，并为最近按序接收的帧重新发送ACK，接收方无需缓存任何失序帧（毕竟他的接收窗口仅为1），只需要维护一个信息：expectdseqnum(下一个按序接收的帧序号) 我们要注意GBN协议规定接收方不一定每收到一个数据很就要发送一个ACK确认信息，而可以在连续收到好几个正确的数据帧后，才对最后一个数据帧发送确认消息。或者在自己有数据要发送时才将对以前正确收到的帧加以捎带确认发送给发送方。 静态图讲解 如上图是一个GBN协议的具体工作图，这里假设的发送窗口大小是9，那么上图所演示的工作步骤如下： 首先发送方一次性发送窗口内所有未发送的帧即0-8号帧（上图从左往右看时间线，因此算一次性发送但是还是有顺序的，0-8号帧肯定是0号帧先出窗口，然后1,2…8） 然后接收方进行接收，他陆续的接收0,1，然后发现抵达的2号帧数据错误，因此会像停-等协议中的发送方一样丢弃错误的2号帧后保持沉默，但是一段时间接收方检查发现1号之前的帧都以按序成功接收，因此发送ACK(1)。(这里为了方便演示，每一次成功接收都发送ACK。) 紧接着3,4,5,6,7,8都陆续抵达，但是由于接收方为正确收到2号帧，因此接收方的窗口就停在了2号位置，又因为接收窗口大小仅为1，因此后面陆续抵达的帧都不能被缓存起来，只能全部被丢弃。 然后就陷入了僵局，双方都在等待对方的消息，接收方等待发送方的正确的2号帧，发送方收到了之前接收方发送的ACK(1)后知道0和1都已经成功被接收，因此窗口向前滑动2个帧，即此时send_base指向了2，nextseqnum指向了10，然后继续等待收到的ACK确认帧。 长时间没有ACK消息，用来记录第一组帧的发送计时器超时了此时发送方必须相应打破僵局，他发现此时send_base指向了2，因此他发送此时窗口内部所有已发送未被确认的帧即2-8号帧，一定要注意9和10号帧虽然此时也已经进入了发送端的滑动窗口内，但是仍然不能发送只能等待下一组发送。 接收方如愿以偿接收到了正确的2号帧，然后继续接收3-10号帧，在一段时间检查后发现前10个帧都已经顺序接收了因此又发送ACK(10)。 发送方收到ACK(10)，知道0-10都已经成功的发送，窗口继续滑动，send_base指向11，nextseqnum指向了19，然后发送方重置计时器发送11-19号帧 动态图讲解 可能上面的不太好理解，这里我们再给出一种动图的讲解： 我们这里演示的时候假设发送方的发送窗口大小为4，我们可以看到起初发送0-4帧，而2号帧丢失了，那么此时接收方的接收窗口停在了2号帧的位置，即使收到了正确的3和4号帧也是直接抛弃的。然后发送了ACK(1)因此发送方窗口滑动，起始端移动到了2号帧，待计时器超时后发送方重新发送之前发送过但是未确认的2-4号帧**，一定要注意即使此时5,6号帧在发送方发送窗口内也是不能跟着这组发送的，必须等待下一组**。然后接收方正确接收了2-4号帧后发送了ACK(4)，发送方接收到ACK(4)以后发送窗口继续向前滑动，此时send_base指向了5，nextseqnum指向了8，然后发送方此时重置计时器后再次发送新的一组帧即5-8号。 之前所讲解是发送方发送的2号帧丢失的情况，而现在上图所演示的在接收方全部正常接收0-4号帧以后，返还的ACK2丢失的情况，我们可以看到虽然ACK2丢失了，但是ACK3和ACK4都成功抵达了发送方，根据GBN协议对ACK是累计确认的机制，发送方可以判断出0-4号帧都已经被成功接收了，因此sned_base直接滑动到了5号。 规律总结 我们从上面的步骤中可以总结出一下几个特点： 接收方仍然是在收到错误帧保持沉默，不会主动报告发送方错误帧序列号，而是选择使用超时机制解决这种情况，原因和之前讲解的停-等协议一样为了能够与ACK迟到情况区分 GBN协议一次性发送一组帧，但是实际上这组帧并不是同时抵达接收方，还是有一定的时间差，而接收方也刚好利用这段时间差为每一个抵达的帧进行接收前的差错检测和丢弃错误帧、发送ACK等操作。但是从宏观角度上来看好像发送方一次性&quot;同时&quot;发送了许多帧，而接收方一次性&quot;同时&quot;接收了许多帧，但是微观上实际接收窗口仅为1，只是在不断的滑动而已。 GBN协议中个发送方仅仅需要使用一个计时器为每一次一组的帧计时即可再ACK的帮助下和send_base指引下顺利找到下一次发送一组帧的起始序列号 接收方发送的确认消息携带的序列号是按序抵达的最大的帧的序列号 发送方状态转换图 上图是发送方的一次传输的状态转换图，我们来再分析一下伪代码描述的过程： 首先一开始send_base为1，nextseqnum也为1，即此时发送方还没有收到上层传递下来的数据，因此并不需要缓冲任何数据 然后顺时针看，rdt_send(data)表示上层向数据链路层的发送方传递了数据data,发送方进行判断发现窗口的nextsqnum&lt;send_base+N,则说明窗口还没有放足够的数据（这里的N是窗口大小）即还有蓝色区域可以盛放数据，因此发送方接收上层传递的数据并且存储到蓝色区域即等待发送的区域并对数据帧进行编号,然后发送这些数据，并且此时send_base==nextseqnum==1即发送方窗口还在起始状态，此时他发送了数据data因此需要启动计时器start_timer同时将nextseqnum++因为此时data占据了一个帧位，nextseqnum不再为1。否则说明窗口不够大或者已满，即蓝色区域不能盛放上层传递下来的数据，那么发送方暂时拒绝接收数据暗示上层窗口暂时已满无法承载了refuse_data(data)等待一段时间后再重复此步骤。 然后到达第三个状态，即不断的发送许多组数据帧，并且每次发送一组帧的时候都需要重启计时器start_timer，如果超时了那么就重复此步骤，由于nextseqnum再次状态过程中并未发生变化，因此这个状态表示的是发送方不断重传发送但是还未被确认的帧 当收到确认消息rdt_rcv(rcvpkt)并且确认消息正确无误notcorrupt(rcvpkt)，那么窗口就可以滑动了即base=getacknum(rcvpkt)+1。如果base==nextseqnum，那么说明所有已发送待确认的帧都已经成功接收，即又一波帧全部完成了传输，那么就可以停止计时器了stop_timer，否则还要继续重传那些发送带还没有被确认的分组并且重启计时器start_timer 最终就是所有的帧都已经成功发送并被接收端接收 GBN协议中发送方的窗口滑动只可能发生在接收到确认帧的时候即send_base起始端移动的时候，而nextseqnum增大时未必send_base发生变化即窗口可能不滑动仅仅是蓝色区域增多而已，但是无论多大都不可能超过send_base+N 接收方状态转换图 上图是接收方的一次传输的状态转换图，我们来再分析一下伪代码描述的过程： 起初期待的接收帧的序列号就是1即expectedseqnum=1同时制作ACK(1)的消息，由于ACK也可能发生位数反转等错误，因此在制作ACK的时候也需要加上校验和sndpkt=make_pkt(expectedseqnum,ACK,chksum) 然后就是在一段时间后默认default自动发送ACK消息给发送方udt_send(sndpkt) 当接收到帧rdt_rcv(rcvpkt)并且帧无损坏notcurrupt(rcvpkt)并且抵达的帧的序列号是期望的序列号即按该帧的序列号是按序抵达的在接收窗口内的hasseqnum(rcvpkt,expectedseqnum)那么接收方就整理最近接收到的顺序的帧数据并打包extract(rcvpkt,data)然后交付给上层deliver_data(data)同时继续制作ACK确认消息sndpkt=make_pkt(expectedseqnum,ACK,chksum)并发送给发送方udt_send(sndpkt)同时滑动接收窗口expectedseqnum++ 发送窗口大小限制 我们知道在GBN协议中接收窗口就是1，那么发送窗口大小可以随便定义吗，实际上是不可以的。如果采用n比特二进制位对帧进行编号，那么发送窗口的大小应该始终小于等于编号标志位所能表示的最大值2^n-1，即有以下公式： 1≤WT+1≤2n1≤W_T+1≤2^n 1≤WT​+1≤2n 我们可以用一句话概括即窗口内永远不能出现两个相同序号的帧或者发送窗口大小+接收窗口大小不得超过编号标志位所能表示的最大值，因此就有上图规律。 思考：为什么要满足上式规律？ 如果不满足上面的公式，那么就会造成接收方无法分辨新帧和旧帧，比如假设用3位来对帧序号编码，那么最大值就是7，因此发送窗口的最大值为7，但是假设此时发送窗口大小为8。那么初始时发送方一次性发送0-7号八个数据帧，因为发送窗口已满，因此暂停发送。假设这8个数据帧都已经正确到达接收端，并且对每一个数据帧，接收端都能发送出确认帧，那么现在下面这两种情况将无法区分： 第一种情况：所有确认帧都能够正确的到达发送端，那么此时发送端滑动窗口后将会发送新的8个数据，但是编号还是0-7。 第二种情况：所有确认帧都丢失了，那么经过一段时间后计时器超时，发送端重发之前发送的8个旧数据帧序号也是0-7。 显然这两种情况的0-7编号的数据帧所包含的数据时不同的，但是接收方此时却不能区分，因此不满足上面的规律是不行的。假设此时满足规律将窗口大小设为了7，那么此时第一种情况新发送的数据帧编号将不再是0-7而是8,0,1,2,3,4,5,6显然就可以和第二种情况的0-7区分开来了。 GBN性能分析 首先我们不难看出后退N帧协议通过连续发送数据帧肯定是提高了信道的利用率同时仅仅需要一个计时器实现起来比较简单，但是另一方面在重传时必须把原来已经传送正确的数据帧进行重传（仅仅因为这些数据帧的前面有一个数据帧出了错），这种做法既使传送效率降低了同时又造成了极大的资源郎芬。由此可见当信道的传输质量很差导致误码率较大时，GBN协议并不是最优策略，可能性能上还不如停止-等待协议。为了解决这一缺陷，又提出了选择重传机制。 例题 数据链路层采用了后退N帧（GBN）协议，发送方已经发送了编号为0-7的帧，如果发送方只收到了0,2,3号帧的确认，则发送方需要重放的帧数是？ 重发帧数是4，即序号为4,5,6,7的帧。虽然此时窗口滑动后8,9,10,11已经在窗口内部的待发区域，但是超时造成的重传只会重传发送过但还未被确认的帧即4,5,6,7号帧。 多帧滑动窗口与选择重传协议（SR） 为了进一步提高信道的利用率，可以设法只重传出现错误的数据帧或者计时器超时的数据帧，但是此时我们就必须加大接受窗口大小，以便接收方可以暂时缓存收下那些序号不连续但是仍然处在接受窗口的数据帧（即错误帧后面的正确数据帧不会被丢弃了，而是可以被暂时存储在接受窗口内部）。当等待所缺的序号的数据帧收到后就可以和后面暂时存储的数据帧组成一组连续序号的帧组了，此时接收方再将其一并上交给上层，这就是选择重传ARQ协议。 很明显，此时再使用一个计时器肯定是不够的了，选择重传ARQ协议要对每一个数据帧单独计时，因此需要很多个计时器，一般计时器的数量与发送窗口大小相同。并且在选择重传协议中使用了一个更加有效的差错处理策略，即一旦接收方怀疑帧出错，就会发送一个NAK给发送方，要求发送方对NAK指定的数据帧进行重传（了解即可，一般讲解和做题时还是默认接收方对错误帧保持沉默）。 发送方、接收方窗口划分 在讲解GBN协议中我们只介绍了发送方窗口的划分，这是因为GBN协议中的接收方窗口大小仅仅为1，但是在SR协议中发送方和接收方窗口大小都不为1，并且通常情况下发送窗口和接收窗口大小相同，下面是SR协议对窗口的区域划分： 在SR协议中发送窗口的划分和GBN的发送窗口划分规则相同，不再介绍。这里我们详细了解一下接受窗口的划分，同样的，接受窗口也划分为4部分，其中rcv_base指向的是缺少的希望获得的序号的数据帧。而离散形势的红色部分是乱序到达，即在错误帧或者丢失帧序号后面的正确帧存储。蓝色部分是还可以接收的乱序帧的区域。白色区域就是不能接收的区域。 上图是另一种形式对窗口功能的介绍。 SR发送方必须响应的三件事 在了解SR协议实现的过程之前，我们先来说明GBN发送方必须响应的三件事： 上层的调用：从上层收到数据后，SR发送方检查下一个可用于该帧的序号，如果序号位于发送窗口内，则发送该帧。否则就像GBN一样要么暂时缓存数据，要么返回给上层暗示上层窗口暂时已满。 收到一个ACK：在SR中对ACK采取单一确认机制，即ACKn只表示第n号帧被成功接收。如果发送方收到了ACKn，且该帧号n在窗口内，则SR发送方将那个被确认的帧标记为已接收然后丢弃这个帧的副本。如果这个帧序号是窗口的下界（最左边第一个窗口的序号），那么窗口向前滑动到具有最小序号未被确认的帧处。如果窗口移动了以后并且有序号在窗口内的等待发送的帧，那么就发送这些帧。 超时事件：每一个帧都有自己的定时器，一个超时事件只会触发该超时帧的重传。 思考：GBN和SR发送方触发重传的响应事件相同吗？ 不相同，在GBN中窗口滑动后即使内部有可以发送的待发送帧，也不会发送，而是必须等待之前的那一组发送的帧全部被确认后才会再发送一组新的帧，当窗口滑动后还有之前发送后未被确认的帧，那么超时后就只重传之前未被确认的帧，新加入的帧必须等待下一波发送。而在SR协议中，只要窗口滑动后内部有新的待发送帧出现，就可以发送了，而当有某个帧超时时也只是重传超时帧而已。我们可以用下面的语句概括两者的特点：GBN一组一组发送，SR一个一个发送。 SR接收方要做的事 同样的SR协议中接收方也有必须响应的事情，SR接收方将确认一个正确接受的帧而不管这个帧是否按序抵达。失序的帧将被缓存，并返回给发送方一个该帧的确认帧即收谁确认谁，知道所有帧（即序号最小的帧）皆被收到为止，这时才将一批帧按序交付给上层，然后向前滑动窗口。 如果收到了窗口序号外（小于窗口下界的帧），那么就意味着出现了确认帧ACK丢失的情况，因此导致了发送方误以为接收方还没有成功接收该帧因此出现了这种情况，此时只需要返回一个该帧的ACK即可。 思考：为什么停-等协议和SR协议在ACK丢失时要重传ACK而GBN却不需要？ 原因很简单，SR和停-等协议都是单帧确认机制，而GBN是累计确认机制，即GBN中接收方即使ACKn没有成功抵达发送方，但是ACK(n+1)抵达发送方时也可以向发送方传达n号帧被成功接收。但是在停-等协议和SR中只有ACKn抵达发送方才能想发送方传达n号帧被接收。 静态图讲解 上图是一个发送窗口和接受窗口都为4的SR工作流程，我们具体分析一下： 首先发送方发送0-3号帧，但是2号帧在信道传输过程中丢失了，但是0,1,3号帧都成功抵达了，此时接受窗口接收0,1,3号帧并且发送ACK0,ACK1和ACK3同时窗口向前滑动但是只能滑动到rcv_base指向2号帧的位置，因此接收方还没有成功接收到2号帧 发送方收到3个确认帧以后同样进行窗口滑动滑动到send_base指向2的位置并且将1,3号帧的位置标记为已接收确认帧状态，因为2号帧的确认消息还没有接收到，但是此时窗口内又加入了新的等待发送的4号和5号帧，因此4和5号号帧可以发送了，发送方发送4号和5号帧 接收方还有位置可以接收4号和5号帧，因此接收4号和5号帧并返还ACK4和ACK5，但是由于期待的2号帧还是没有接收到，因此窗口仍然不会滑动并且此时窗口已经满了，此时即使抵达6,7…号帧，接收方也不会再接收了只能等待2号帧了 发送方收到了4号帧和5号帧的确认消息后发现窗口也已经满了并且由于2号帧的确认消息还是没有抵达因此send_base还是只能呆在2号帧位置，此时他的发送窗口也已经满了不能继续发送新的帧了，因此发送方只能等待2号帧的确认帧了 双方陷入僵局，都在等待对方的消息 一段时间后2号计时器超时，触发发送方重传2号帧，发送方重新发送2号帧打破僵局 接收方收到2号帧，将2-5号帧一并上交给上层，同时滑动窗口，rcv_base移动到了6号帧的位置等待接收6,7,…号帧 发送方终于收到了2号帧的确认消息，滑动窗口向前滑动到send_base指向6号帧的位置同时发送6,7,8,9号帧 最终一直循环上面的过程完成所有数据帧的传输 动态图讲解 我们同样给出SR的动态图演示： 上图演示的是在发送过程2号帧丢失的过程，我们可以看见接收方还是接收了丢失帧2号帧后面抵达的3号帧，而不是像GBN一样直接丢弃3号帧。发送方收到确认帧滑动窗口后有可以发送的新的帧就会立刻发送也不会像GBN那样必须等待所有之前发送的帧都被确认后才能发送新的待确认的帧。 上图演示的是SR中ACK2丢失的情况，此时发送方即使收到了ACK3和ACK4也不能确认2号帧被成功接收，因此窗口滑动只能移动到2号帧的位置，待超时后重传2号帧。 规律总结 我们从上面的步骤中可以总结出一下几个特点： 接收方仍然是在收到错误帧保持沉默，不会主动报告发送方错误帧序列号，而是选择使用超时机制解决这种情况 SR协议一次性发送一组帧，但是实际上这组帧并不是同时抵达接收方，还是有一定的时间差，而接收方也刚好利用这段时间差为每一个抵达的帧进行接收前的差错检测和丢弃错误帧、发送ACK等操作。但是从宏观角度上来看好像发送方一次性&quot;同时&quot;发送了许多帧，而接收方一次性&quot;同时&quot;接收了许多帧。 SR协议中发送方需要为每一和帧都单独设置一个计时器，然后借助ACK消息判断未被确认的帧，并且在超时时只重传某个出错帧或者某个超时帧 接收方发送的确认消息携带的序列已接收的帧的序号，未必是按序抵达的 发送窗口与接收窗口大小限制 同样的，在SR中发送窗口和接收窗口的大小也不能随便定义，需要满足一定的规律。他们需要满足的规律就是发送方和接收方的窗口内部都不能出现序列号相同而数据不同的帧，因此有以下规律： 1≤WT+WR≤2n1≤W_T+W_R≤2^n 1≤WT​+WR​≤2n 如果Wt==Wr，那么我们可以进一步推得如下规律： WTmax=WRmax=2n−1W_{Tmax}=W_{Rmax}=2^{n-1} WTmax​=WRmax​=2n−1 我们可以用一句话概括即窗口内永远不能出现两个相同序号的帧或者发送窗口大小+接收窗口大小不得超过编号标志位所能表示的最大值，因此就有上图规律。 思考：为什么要满足上式规律？ 原理和GBN中介绍的一样。如果不满足上式，就会出现接收方无法区分旧帧和新帧，如上图编号最大值为4，但是收发窗口大小却设置为了3，那么此时 WT+WR=6&gt;4=窗口极限值W_T+W_R=6&gt;4=窗口极限值 WT​+WR​=6&gt;4=窗口极限值 很明显没有满足限制公式，因此此时上图的这两种情况第二个0号帧接收方将无法辨别是旧帧还是新帧。左图0号帧是重传的旧帧，而右图是新的数据不同的0号帧，但是在接收方视角接收方都将按照新帧来接收这明显会造成灾难性的结果。 例题 数据链路层采用了选择重传（SR）协议，发送方发送了0-3号帧，现在已经收到了1号帧的确认，而0,2号帧依次超时，则发送方需要重传的帧数是多少？ 需要重传0号和2号两个帧。所以重传帧数是2。 性能分析 选择重传协议可以避免重复传送那些本可以正确到达接收端的数据帧，但是在接收端即需要设置具有相当容量的缓冲区来暂存那些未能按序正确收到的帧。虽然SR相对于GBN减少了帧的重传数量从而减少了资源的浪费，但是相应的他需要额外的接受窗口容量以及更多的单帧计时器。因此SR和GBN两者各有优劣点。 总结 我们在学习完了三种可靠传输的机制后进行一个简单的对比总结。 协议 窗口大小 效率 显著特点 停止-等待协议 单帧窗口 低 原理简单，只需要一位的序列号 回退N帧协议 多帧窗口但是接受窗口大小为1 较高 流水线机制，累计确认 选择重传协议 多帧窗口 高 流水线机制，单帧确认 我们发现实际上SR本质上相当于许多个并行执行的停止-等待协议，从单个帧的角度上来看实际上SR和停止-等待协议很相似。而GBN的重传机制很特别，一定要特别注意GBN重传时只重传那些已经发送过但是还未被确认的帧。"}]