[{"title":"Hello World","path":"/2023/01/06/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","tags":["年后","法法","发顺丰三"],"categories":["新文章"]},{"title":"这是分页标题","path":"/wiki/GAMES191笔记/index.html","content":"fff ggg"},{"title":"科研学习","path":"/notes/index.html","content":"技术加油站 W3schoolhttps://www.w3school.com.cn/C语言中文网http://c.biancheng.netcs-Noteshttp://www.cyc2018.xyzRoad2Codinghttps://r2coding.com/OI WIKIhttps://oi-wiki.org/廖雪峰的技术网站https://www.liaoxuefeng.com/Quick Referencehttps://quickref.cn/图形学与混合现实平台https://games-cn.org/git bookhttps://git-scm.com/book/zh/v2leetcode bookhttps://books.halfrost.com/leetcode/GAMES101课件https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html南瓜书https://datawhalechina.github.io/pumpkin-book/ 闭关修炼室 LeetCodehttps://leetcode.cn/?utm_source=LCUS&utm_medium=ip_redirect&utm_campaign=transfer2china拼题Ahttps://pintia.cn/homeCodeForceshttps://codeforces.com/KuangBIN刷题https://vjudge.net/article/371 情报收集处 中国知网https://www.cnki.net/ARXIVhttps://arxiv.org/CHATGPThttps://chat.openai.com/chatStackOverFlowhttps://stackoverflow.com/ 秘传功法阁 搬书匠http://www.banshujiang.cn/鸠摩搜书https://www.jiumodiary.com/谷粉想学术http://chongbuluo.glgooo.top/muchong.html艾思科蓝https://www.ais.cn/ 上古神器室 CNKI学术翻译https://dict.cnki.net/index有道文档翻译https://pdf.youdao.com/?src=fanyiwebHighCharts演示图https://www.hcharts.cn/demo/highchartsLatex公式编辑器https://www.latexlive.com/Slager Latex模板https://www.slager.link/#/home妙写论文排版https://www.miaowrite.com/latex表格生成器https://www.tablesgenerator.com/亿图图示https://www.edrawmax.cn/Latex公式转图片https://latex.vimsky.com/论文查重http://www.papertime.cn/矩阵计算器https://zh.numberempire.com/matrixcalculator.php3D计算器https://www.geogebra.org/calculator"},{"path":"/intro/index.html","content":"冬夜读书示子聿陆游古人学问无遗力，少壮工夫老始成。纸上得来终觉浅，绝知此事要躬行。2023年1月1日随想录分类卷标签集归档册言堂序 关于本站关于博主站点说明你好，欢迎参观我的学习博客“学圃堂” ，也许你已经发现了这个博客非常简洁只记录了我科研学习的笔记，这也是我的博客名称由来，因此我建立这个网站的初衷就是存放学习笔记、疑难点以及一些小技巧，这也就意味着这个博客更新面向我自己，文章更多的是用我自己看得懂的方式书写，如果你也对内容感兴趣并且在阅读过程中有任何疑惑欢迎在下方进行留言探讨！当然如果你想更加深入的了解我还请前往我的主站!来自于七里台男子职业技术学院的软件工程专业在读大四学生😆 热爱cg的科研小白，立志于成为冉冉升起的科研新星😂 在逃社恐人员，害怕工作的家里蹲一枚😨 学习能力堪忧，除了八股文啥也不会，未能保研的菜菜🥺 正在为研究生学位焦虑奋斗的考研人(等待来自于2.21的审判版)😳本站使用百度统计记录访问者的ip、浏览页面、浏览时间等信息。 本站部分资源来源网络，如因传播、转载、商用等导致纠纷，与本站无关； 本站文章引用或转载会严格遵循转载协议，尊重原作者的创作成果，如发现侵权等问题，及时联系处理； 本站提供非实名制评论功能，站长有权在未告知用户的前提下，修改、删除任何评论内容，所以请和谐留言； 本站非特别注明，均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。 最终解释权归本站所有。"},{"title":"处理工具","path":"/notes/处理工具/index.html","content":"在线文件处理 ConvertIO文件转换器https://convertio.co/zh/aConvert图片转换https://www.aconvert.com/cn/image/webp-to-gif/RemoveBG抠图https://www.remove.bg/zh?from=thosefree.com改图宝压缩裁剪https://www.gaitubao.com/#图片生成pdfhttps://smallpdf.com/cn/jpg-to-pdftinypnghttps://tinypng.com/ 设计素材模板 Canvas可画https://www.canva.cn/IconFonthttps://www.iconfont.cn/fontAwesomehttps://fontawesomelib.cn/FlatUIColorhttps://flatuicolors.com/ 代码文档共享 代码高亮https://tool.oschina.net/highlight代码生成图片https://carbon.now.sh/代码分享https://paste.org.cn/金山文档https://www.kdocs.cn/latest 有用但没大用 emoji文档https://www.emojiall.com/zh-hans在线画板https://www.suxieban.com/index.html美寄词云https://www.moage.cn/wordartMonkeyTypehttps://monkeytype.com/login键帽设计https://www.zfrontier.com/mykb/editor缩略图设计http://xsdggw.cn/t/tool/wylst/mockuphonehttps://mockuphone.com/device?type=ios#iphone12"},{"title":"建站必备","path":"/notes/建站必备/index.html","content":"云数据存储 七牛云KODO存储https://www.qiniu.com/products/kodo阿里云ecshttps://www.aliyun.com/product/ecs?spm=5176.19720258.J_3207526240.33.542176f4vcfDVPvercelhttps://vercel.com/leancloudhttps://leancloud.app/ 网站自维护 百度流量统计https://tongji.baidu.com/web5/welcome/login域名解析https://cloud.tencent.com/product/cns网站测速https://tool.chinaz.com/speedtest/github.com"},{"title":"函数基础","path":"/wiki/Python学习笔记/函数基础/index.html","content":"Python函数用法详解 函数就是将一个复杂的需要多次调用的步骤进行封装以便后期复用，在Python中除了可以使用内置函数以外，我们还可以自定义函数，将一段有规律的、可重复使用的代码定义成函数，从而达到一次编写、多次调用的目的。 123456789101112#自定义 len() 函数def my_len(str): length = 0 for c in str: length = length + 1 return length#调用自定义的 my_len() 函数length = my_len(&quot;http://c.biancheng.net/python/&quot;)print(length)#再次调用 my_len() 函数length = my_len(&quot;http://c.biancheng.net/shell/&quot;)print(length) 运行结果： 123029 注意，Python中的函数既可以接收多个(&gt;=0)参数，还可以返还多个(&gt;=0)返回值。 Python函数的定义 Python中使用def关键字实现对一个自定义函数的声明，具体格式如下： 123def 函数名(参数列表): //实现特定功能的多行代码 [return [返回值]] 其中，用 [] 括起来的为可选择部分，即可以使用，也可以省略。当不设置返回值时，默认返回None。注意，在创建函数时即使不需要参数，也必须保留一对空的&quot;()&quot;，否则Python解释器将提示&quot;invalid syntax&quot;错误。同时如果想要定义一个没有任何功能的空函数，可以使用pass语句作为占位符。 另外值得一提的是，函数中的 return 语句可以直接返回一个表达式的值： 12def str_max(str1,str2): return str1 if str1 &gt; str2 else str2 Python函数的调用 1[返回值] = 函数名([形参值]) 要注意创建的函数有多少个形参，那么调用时即需要传入多少个值，并且顺序必须和创建函数时一致，即使该函数没有参数，函数名后面的小括号也不能省略。 为函数提供说明文档 我们通过调用Python的help()内置函数或者__doc__属性，就可以查看到某个函数的使用说明文档。无论是Python提供给我们的函数，还是自定义的函数，其说明文档都需要设计该函数的程序猿自己编写。 本质上，函数的说明文档就是一段字符串，只不过作为说明文档。字符串的放置位置是有讲究的，函数的说明文档通常位于函数内部、所有代码的最前面。 123456789#定义一个比较字符串大小的函数def str_max(str1,str2): &#x27;&#x27;&#x27; 比较 2 个字符串的大小 &#x27;&#x27;&#x27; str = str1 if str1 &gt; str2 else str2 return strhelp(str_max)#print(str_max.__doc__) 运行结果： 1234Help on function str_max in module __main__:str_max(str1, str2) 比较 2 个字符串的大小 Python函数值传递和引用传递 在Python中，根据实际参数的类型不同，函数传递的方式有两种，分别为值传递和引用传递(地址传递)。 值传递：适用于实参类型为不可变类型（字符串、数字、元组）； 引用（地址）传递：适用于实参类型为可变类型（列表，字典）； 值传递和应用传递的特点是，函数参数进行值传递以后，如果形参的值发生改变，不会影响实参的值。而函数参数继续使用引用传递以后，改变形参的值，实参的值也会一同发生改变。 12345678910111213def demo(obj) : obj += obj print(&quot;形参值为：&quot;,obj)print(&quot;-------值传递-----&quot;)a = &quot;C语言中文网&quot;print(&quot;a的值为：&quot;,a)demo(a)print(&quot;实参值为：&quot;,a)print(&quot;-----引用传递-----&quot;)a = [1,2,3]print(&quot;a的值为：&quot;,a)demo(a)print(&quot;实参值为：&quot;,a) 运行结果： 12345678-------值传递-----a的值为： C语言中文网形参值为： C语言中文网C语言中文网实参值为： C语言中文网-----引用传递-----a的值为： [1, 2, 3]形参值为： [1, 2, 3, 1, 2, 3]实参值为： [1, 2, 3, 1, 2, 3] Python底层了解函数参数传递机制 Python函数参数的值传递机制 12345678910def swap(a , b) : # 下面代码实现a、b变量的值交换 a, b = b, a print(&quot;swap函数里，a的值是&quot;, \\ a, &quot;；b的值是&quot;, b)a = 6b = 9swap(a , b)print(&quot;交换结束后，变量a的值是&quot;, \\ a , &quot;；变量b的值是&quot;, b) 运行结果： 12swap函数里，a的值是 9 ；b的值是 6交换结束后，变量a的值是 6 ；变量b的值是 9 如上所示，在swap()函数中，a和b的值分别是9,6，交换结果后，变量a和b的值依然是6和9，从这个运行结果可以看出，程序中实际定义的变量a和b，并不是swap()函数中的a和b。因为swap()函数中的a和b只是主程序变量a和b的复制品，如下图所示： 上面程序开始定义了 a、b 两个局部变量，这两个变量在内存中的存储示意图如图 1 所示。 当程序执行swap()函数时，系统进入swap()函数，并且将主程序的a、b变量作为参数传入swap()函数，但是传入swap()函数的只是a、b的副本，而不是a、b本身。进入swap()函数以后，系统中产生了4个变量，这4个变量在内存中的存储示意图如图2所示： 当在主程序中调用swap()函数时，系统分别为主程序和swap()函数分配两块栈区，用于保存他们的局部变量。将主程序中的a、b变量作为参数值传入swap()函数，实际上是在swap()函数栈区中重新生成了两个变量a、b，并且将主程序栈区中a、b变量的值分别赋值给swap()函数栈区中的a、b参数（就是对swap()函数中的a、b两个变量进行初始化）。此时，系统存在两个a变量、两个b变量，只是存在与不同的栈区中而已。 程序在swap()函数中交换a、b两个变量的值，实际上是对图2中灰色区域中的a、b变量进行交换。交换结束以后，输出swap()函数中a、b变量的值，可以看到a的值为9，b的值为6,此时在内存中的存储示意图如图3所示： 对比图3和图1，可以看到两个示意图中主程序栈区中a、b的值并未有任何变化，程序改变的仅仅是swap()函数栈区中a、b的值。这既是值传递的实质，当程序开始执行函数时，系统对形参进行初始化，就是把实参变量的值赋给函数的形参变量，在函数中操作的并不是实际上的实参变量。 Python函数参数的引用传递 如果实际参数的数据类型是可变对象（列表、字典），则函数参数的传递方式将采用引用传递方式，需要注意的是，引用传递方式的底层实现，采用的依然是值传递的方式。 123456789def swap(dw): # 下面代码实现dw的a、b两个元素的值交换 dw[&#x27;a&#x27;], dw[&#x27;b&#x27;] = dw[&#x27;b&#x27;], dw[&#x27;a&#x27;] print(&quot;swap函数里，a元素的值是&quot;,\\ dw[&#x27;a&#x27;], &quot;；b元素的值是&quot;, dw[&#x27;b&#x27;])dw = &#123;&#x27;a&#x27;: 6, &#x27;b&#x27;: 9&#125;swap(dw)print(&quot;交换结束后，a元素的值是&quot;,\\ dw[&#x27;a&#x27;], &quot;；b元素的值是&quot;, dw[&#x27;b&#x27;]) 运行结果： 12swap函数里，a元素的值是 9 ；b元素的值是 6交换结束后，a元素的值是 9 ；b元素的值是 6 如上所示，在swap()函数中，dw字典的a,b两个元素的值被交换成功，不仅如此，当swap()函数执行结束后，主程序中dw字典的a、b两个元素的值被交换了，这很容易造成一种错觉，即在调用swap()函数时，传入swap()函数的就是dw字典本身，而不是它的复制品。但这是一种错觉，下面我们还是结合示意图来说明程序的执行过程。 程序开始创建了一个字典对象，并且定义了一个dw引用变量（其实就是一个指针），指向字典变量，这意味着此时内存中有两个东西，对象本身和指向该对象的引用变量。此时系统内存中的存储示意图如下所示： 接下来当主程序开始调用swap()函数时，dw变量作为参数传入swap()函数，这里依然采用值传递方式，把主程序中dw变量的值赋给swap()函数的dw形参，从而完成swap()函数的dw参数的初始化。值的指出的是，主程序中的dw是一个引用变量（也就是一个指针），他保存了字典对象的地址值，当把dw的值赋给swap()函数的dw参数后，就是让swap()函数也保存这个地址值，即也会引用到同一个字典对象，图5显示了dw字典传入swap()函数后的存储示意图。 从图5来看，这种参数传递方式是不折不扣的值传递方式，系统一样复制了dw的副本到swap()函数，但由于dw只是一个引用变量，因此系统复制的是dw变量，并未复制字典本身。 当程序在swap()函数中操作dw参数时，由于dw只是一个引用变量，故实际操作的还是字典对象。此时，不管是操作主函数中的dw变量，还是操作swap()函数里的dw参数，其实操作的都是他们共同引用的字典对象，他们引用的是同一个字典对象。因此，当在swap()函数中交换dw参数所引用字典对象的a,b两个元素的值后，可以看到在主程序中dw变量所引用字典对象的a、b两个元素的值也被交换了。 为了更好地证明主程序中的dw和swap()函数中的dw是两个变量，在swap()函数的最后一行增加如下代码： 12#把dw 直接赋值为None，让它不再指向任何对象dw = None 运行上面代码，结果是swap()函数中的dw变量不再指向任何对象，程序其他地方没有任何变化。主程序调用swap()函数后，再次访问dw变量的两个元素，依然可以输出9、6。可见，主程序的dw变量并没有受到任何影响。实际上，当在sawp()函数中增加dw=None代码后，在内存中的存储示意图如下所示： 我们可以看出，把swap()函数中的dw赋值为None后，在swap()函数中失去了对字典对象的引用，不可再访问该字典对象，但是主程序中的dw变量不受任何影响，依然可以使用该字典对象，所以依然输出字典对象的a、b元素的值。 我们通过上面的学习，可以得到如下两个结论： 不管什么类型的参数，在 Python 函数中对参数直接使用“=”符号赋值是没用的，直接使用“=”符号赋值并不能改变参数。 如果需要让函数修改某些数据，则可以通过把这些数据包装成列表、字典等可变对象，然后把列表、字典等可变对象作为参数传入函数，在函数中通过列表、字典的方法修改它们，这样才能改变这些数据。 Python位置参数 实参和形参数量必须一致 位置参数，有时也被称为必备参数，指的是必须按照正确的顺序将实际参数传到函数中，换句话说，调用参数时传入实际参数的数量和位置必须和定义函数时保持一致。 在调用函数，指定的实际参数的数量，必须和形式参数的数量一致（传多传少都不行）。否则Python解释器会抛出TypeError异常，并提示缺少必要的位置参数。 1234def girth(width , height): return 2 * (width + height)#调用函数时，必须传递 2 个参数，否则会引发错误print(girth(3)) 运行结果： 1234Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(girth(3))TypeError: girth() missing 1 required positional argument: &#x27;height&#x27; 1234def girth(width , height): return 2 * (width + height)#调用函数时，必须传递 2 个参数，否则会引发错误print(girth(3,2,4)) 运行结果： 1234Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(girth(3,2,4))TypeError: girth() takes 2 positional arguments but 3 were given 实参和形参位置必须一致 在调用函数时，传入实际参数的位置必须和形式参数的位置一一对应，否则就会产生以下2中结果： 抛出 TypeError 异常 当实际参数类型和形式参数类型不一致，并且在函数种，这两种类型之间不能正常转换，此时就会抛出 TypeError 异常。 123def area(height,width): return height*width/2print(area(&quot;hhhh&quot;,3)) 运行结果： 123456Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 3, in &lt;module&gt; print(area(&quot;hhh&quot;,3)) File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 2, in area return height*width/2TypeError: unsupported operand type(s) for /: &#x27;str&#x27; and &#x27;int&#x27; 以上显示的异常信息，就是因为字符串类型和整形数值做除法运算。 产生的结果和预期不符 调用函数时，如果指定的实际参数和形式参数的位置不一致，但是他们的数据类型相同，那么程序并不会抛出异常，只不过导致运行结果和预期不符。 例如，设计一个求梯形面积的函数，并利用此函数求上底为 4cm，下底为 3cm，高为 5cm 的梯形的面积。但如果交互高和下低参数的传入位置，计算结果将导致错误： 1234def area(upper_base,lower_bottom,height): return (upper_base+lower_bottom)*height/2print(&quot;正确结果为：&quot;,area(4,3,5))print(&quot;错误结果为：&quot;,area(4,5,3)) 运行结果： 12正确结果为： 17.5错误结果为： 13.5 Python函数关键字参数及用法 之前我们学习的一直是位置参数，即实参和形参位置要一一对应，顺序不能出现错误。但是当参数过多时，使用位置参数就较为复杂，因此我们可以使用关键字参数。关键字参数是指使用形式参数的名字来确定输入的参数值，通过此方式来指定函数实参时，不再需要与形参的位置完全一致，只需要将参数名写正确即可。 12345678def dis_str(str1,str2): print(&quot;str1:&quot;,str1) print(&quot;str2:&quot;,str2)#位置参数dis_str(&quot;http://c.biancheng.net/python/&quot;,&quot;http://c.biancheng.net/shell/&quot;)#关键字参数dis_str(&quot;http://c.biancheng.net/python/&quot;,str2=&quot;http://c.biancheng.net/shell/&quot;)dis_str(str2=&quot;http://c.biancheng.net/python/&quot;,str1=&quot;http://c.biancheng.net/shell/&quot;) 运行结果： 123456str1: http://c.biancheng.net/python/str2: http://c.biancheng.net/shell/str1: http://c.biancheng.net/python/str2: http://c.biancheng.net/shell/str1: http://c.biancheng.net/shell/str2: http://c.biancheng.net/python/ 我们发现函数在传参时，可以单独使用位置参数，也可以单独使用关键字参数传参，甚至还可以混用传参的参数方法。 但是一定要注意，混用两者时，所有关键字参数必须位于所有的位置参数之后。 如下的写法就是错误的 12# 位置参数必须放在关键字参数之前，下面代码错误dis_str(str1=&quot;http://c.biancheng.net/python/&quot;,&quot;http://c.biancheng.net/shell/&quot;) Python解释器会报如下错误： 1SyntaxError: positional argument follows keyword argument Python函数默认参数设置 我们可以为Python中的函数设置默认值，这样的话，即使调用函数时没有给拥有默认值的形参传递参数，该参数可以直接使用定义函数时设置的默认值。 12def 函数名(...，形参名，形参名=默认值)： 代码块 要注意，在使用此格式定义函数时，指定有默认值的形式参数必须在所有没有默认参数的后面，否则会产生语法错误。同时要注意默认参数必须指向不变对象。 如下写法就是错误的： 123#语法错误def dis_str(str1=&quot;http://c.biancheng.net/python/&quot;,str2,str3): pass 显然，str1 设有默认值，而 str2 和 str3 没有默认值，因此 str1 必须位于 str2 和 str3 之后。 接下来我们看一个正确使用函数默认值的例子： 123456#str1没有默认参数，str2有默认参数def dis_str(str1,str2 = &quot;http://c.biancheng.net/python/&quot;): print(&quot;str1:&quot;,str1) print(&quot;str2:&quot;,str2)dis_str(&quot;http://c.biancheng.net/shell/&quot;)dis_str(&quot;http://c.biancheng.net/java/&quot;,&quot;http://c.biancheng.net/golang/&quot;) 运行结果： 1234str1: http://c.biancheng.net/shell/str2: http://c.biancheng.net/python/str1: http://c.biancheng.net/java/str2: http://c.biancheng.net/golang/ 上面程序中，dis_str() 函数有 2 个参数，其中第 2 个设有默认参数。这意味着，在调用 dis_str() 函数时，我们可以仅传入 1 个参数，此时该参数会传给 str1 参数，而 str2 会使用默认的参数，如程序中第 6 行代码所示。当然在调用 dis_str() 函数时，也可以给所有的参数传值（如第 7 行代码所示），这时即便 str2 有默认值，它也会优先使用传递给它的新值。 同时，结合关键字参数，以下 3 种调用 dis_str() 函数的方式也是可以的： 123dis_str(str1 = &quot;http://c.biancheng.net/shell/&quot;)dis_str(&quot;http://c.biancheng.net/java/&quot;,str2 = &quot;http://c.biancheng.net/golang/&quot;)dis_str(str1 = &quot;http://c.biancheng.net/java/&quot;,str2 = &quot;http://c.biancheng.net/golang/&quot;) 你可能会疑惑，对于自己自定义的函数，我们可以轻易知道那个参数有默认值，但是如果使用Python提供的内置函数，又或者其他第三方提供的函数，我们怎么知道那些参数有默认值呢？ 在Python中，我们可以使用函数名.__defaults__查看函数的默认参数的当前值，其返回值是一个元组，以本节中的 dis_str() 函数为例，在其基础上，执行如下代码： 1print(dis_str.__defaults__) 程序执行结果为 1(&#x27;http://c.biancheng.net/python/&#x27;,) Python函数传入任意个参数(进阶) *args接收任意个位置参数 *args是可变参数，args接收的是一个元组tuple,可变参数允许传入0个或者任意个参数，这些可变参数在函数调用时被组装为一个元组，如下所示： 123456def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 例如我们要传入0个或者多个不可变参数 12345calc（）可传入0到多个参数值&gt;&gt;&gt; calc(1, 2)5&gt;&gt;&gt; calc()0 但是如果此时我们要传递一个列表中的所有元素或者元组中的所有元组又该怎么写呢？我们可以如下书写： 123&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(nums[0], nums[1], nums[2])14 但是如果列表或者元组的元素过多时，操作就会过于繁琐，此时Python允许我们在list或者tuple前面加一个*号，把list或者tuple传入： 123&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(*nums)14 **kw接收任意个关键字参数 **kw是关键字参数，kw接收的是一个字典，关键字参数允许你传入0个或者任意个含参数名的参数，这些关键字参数会在函数内部自动组装成一个字典。 12def person(name, age, **kw): print(&#x27;name:&#x27;, name, &#x27;age:&#x27;, age, &#x27;other:&#x27;, kw) 假设现在我们传入任意个关键字参数 123456&gt;&gt;&gt; person(&#x27;Michael&#x27;, 30)name: Michael age: 30 other: &#123;&#125;&gt;&gt;&gt; person(&#x27;Bob&#x27;, 35, city=&#x27;Beijing&#x27;)name: Bob age: 35 other: &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;&#125;&gt;&gt;&gt; person(&#x27;Adam&#x27;, 45, gender=&#x27;M&#x27;, job=&#x27;Engineer&#x27;)name: Adam age: 45 other: &#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125; 但是如果此时需要传递许多个关键字参数，操作也会很繁琐，因此Python允许我们传递一个字典，只需要在字典dict前加上**符号，如下所示： 123&gt;&gt;&gt; dict=&#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125;&gt;&gt;&gt; person(&#x27;Adam&#x27;, 45, **dict)name Adam age 45 other &#123;&#x27;gender&#x27;: &#x27;M&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125; 我们要注意由于*args和**kw都是可以吸收任意个参数，因此一般置于后面，同时根据关键字参数总是要位于位置参数后面，如果同时有*args和**kw存在，**kw要置于后面。 命名关键字参数 我们还可以进一步限制传入的关键字参数的名字，并且一旦声明了命名关键字参数，那么就必须出现否则会报错。 如下所示，如果我们使用**kw来接收任意个关键字参数，那么传入的参数名字可以是任意的，我们可以在函数内部对kw进行校验寻找我们要求出现的关键字参数，但是这样的话仍然会造成传入了许多不需要的关键字参数如下所示： 12345678910111213def person(name, age, **kw): if &#x27;city&#x27; in kw: # 有city参数 pass if &#x27;job&#x27; in kw: # 有job参数 pass print(&#x27;name:&#x27;, name, &#x27;age:&#x27;, age, &#x27;other:&#x27;, kw)但是调用者仍可以传入不受限制的关键字参数：# addr,zipcode完全不需要，但是也传进来了&gt;&gt;&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;Beijing&#x27;, addr=&#x27;Chaoyang&#x27;, zipcode=123456)name: Jack age: 24 other: &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;, &#x27;addr&#x27;: &#x27;Chaoyang&#x27;, &#x27;zipcode&#x27;: 123456&#125; 我们发现上面的代码中我们只是需要两个关键字参数即city和job，但是此时使用kw却接收了许多没用的关键字参数。那么我们如何实现只接收指定的关键字参数呢？这时就要使用命名关键字参数，他的写法如下： 12def person(name, age, *, city, job): print(name, age, city, job) 此时我们指定接收4个参数，name和age都是位置参数，而特殊分隔符*表示后面的所有参数都是指定命名关键字参数（注意此时city和job不再是位置参数了）。那么我们在为person函数传递参数时就必须传递两个关键字参数city和job了。此时指定了两个必须传进的指定名称的关键字参数，多了或者少了都不行 1234567891011121314151617181920&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;)Jack 24 chengdu auditor# 少job报错&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;)TypeError: person() missing 1 required keyword-only argument: &#x27;job&#x27;# 多sex也报错&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;,sex=&quot;male&quot;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, city=&#x27;chengdu&#x27;, job=&#x27;auditor&#x27;,sex=&quot;male&quot;)TypeError: person() got an unexpected keyword argument &#x27;sex&#x27;# 使用位置参数来传递city和job肯定也是不行的&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, &#x27;chengdu&#x27;,&#x27;auditor&#x27;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 4, in &lt;module&gt; person(&#x27;Jack&#x27;, 24, &#x27;chengdu&#x27;,&#x27;auditor&#x27;)TypeError: person() takes 2 positional arguments but 4 were given 命名关键字参数可以简单地理解为必须使用关键字参数的形式传进来的键名必须一致的参数。 但是如果我们已经为命名关键字参数设置了默认值，那么此时可以选择不传： 123456def person(name, age, *, city=&#x27;chengdu&#x27;, job): print(name, age, city, job)由于命名关键字参数city具有默认值，调用时，可不传入city参数：&gt;&gt;&gt; person(&#x27;Jack&#x27;, 24, job=&#x27;tester&#x27;)Jack 24 chengdu tester 思考：下面这样的写法错在了哪里？ 12def person(name, age, **kw, *，city, job): print(name, age,kw, city, job) 我们发现此时**kw这个可以接收任意个关键字参数的形参写在了city和job这两个命名关键字参数前面，那么很显然无论我们传入多少个关键字参数都会被kw吸收，甚至是city换入job命名关键字参数也会被kw吸收，因此形参city和job永远不可能被赋值，因此上面的写法错误，我们可以如下改写即为正确： 1234def person(name, age, *, city, job, **kw,): print(name, age, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24, city=&quot;beijing&quot;, job=&quot;auditor&quot;, sex=&#x27;male&#x27;, addr=&#x27;big house&#x27;)Jack 24 beijing auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;, &#x27;addr&#x27;: &#x27;big house&#x27;&#125; 也就是说**kw永远不能写到命名关键字形参前面 思考：如果可变位置参数*args写在关键字命名参数前面会怎样？ 虽然**kw不能写到命名关键字参数前面，但是*args是可以写到前面的，并且此时命名关键字参数前面就无需在加上特殊分隔符*了，如下所示： 1234def person(name, age, *args, city, job, **kw,): print(name, age,args, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,&quot;a cool boy&quot;,&quot;500&quot;,city=&quot;beijing&quot;, job=&quot;auditor&quot;, sex=&#x27;male&#x27;, addr=&#x27;big house&#x27;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) beijing auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;, &#x27;addr&#x27;: &#x27;big house&#x27;&#125; 此时person函数先通过位置参数的方法获取了name和age变量，然后又通过args获取了2个位置参数，紧接着就是两个命名关键字参数city和job，然后最后面又使用了kw接收剩余的关键字参数sex和addr。因此总体上来看，函数接收参数的顺序总是先接收所有的位置参数，然后再接收所有的关键字参数。 思考：为什么*args在命名关键字前面时就无需再使用*特殊分隔符号了？ 原因很简单，之前我们之所要在命名关键字参数前加上特殊分隔符*是为了区分位置参数和命名关键字参数，但是当我们使用了*args那么所有的位置参数都已经吸收了，后面紧跟着的形参很明显一定是关键字参数了，因此此时我们就无需再使用*进行区分了。 思考：下面这样的写法错在了哪里？ 12def person(*, city, job,name, age, *args, **kw,): print(name, age,args, city, job, kw) 我们发现此时city和name命名关键字反而写到了位置关键字的前面，很明显违背了所有关键字参数要位于所有位置参数后面的原则，那么为什么此时命名关键字参数不能写到前面呢？原因很简单，此时name和age语义就不明确了，我们无法区分他们到底是位置参数还是命名关键字参数了。 因此一定要记住再复杂的函数传参也一定要保证所有的位置参数在所有关键字参数的前面，顺序可以总结为：1def func(位置参数，默认参数，*args，命名关键字参数，默认参数，**kw) 例如如下就是一些包含了所有传参形式的例子，如果你可以理解那么恭喜你进阶成功！ 1234567def person(name, age=18, *args, city=&quot;chengdu&quot;, job, **kw,): print(name, age,args, city, job, kw)&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,&quot;a cool boy&quot;,&quot;500&quot;, job=&quot;auditor&quot;, sex=&quot;male&quot;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) chengdu auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;&#125;&gt;&gt;&gt;person(&#x27;Jack&#x27;, 24,*(&quot;a cool boy&quot;,&quot;500&quot;), job=&quot;auditor&quot;, **&#123;&quot;sex&quot;:&quot;male&quot;&#125;)Jack 24 (&#x27;a cool boy&#x27;, &#x27;500&#x27;) chengdu auditor &#123;&#x27;sex&#x27;: &#x27;male&#x27;&#125; Python None(空值) 在Python中，有一个特殊的常量None(N必须大写)。他和False,0,[],(),{},&quot;&quot;等都不同，None有自己的数据类型，我们可以在IDLE中使用type()函数查看它的类型： 12&gt;&gt;&gt; type(None)&lt;class &#x27;NoneType&#x27;&gt; 可以看到，它属于NoneType类型，None是NoneType数据类型的唯一值（其他变成语言可能将这个值称为null,nll或者undifined）。也就是说None表示为初始化赋值的一个状态。对于任何函数，如果没有return返回值，或者return关键字后面不带任何值，那么Python默认函数都返回None，比如print()函数 1234&gt;&gt;&gt; spam = print(&#x27;Hello!&#x27;)Hello!&gt;&gt;&gt; None == spamTrue Python函数返回多个值 实际上Python就是只能反会有一个值，只不过我们可以使用列表，元组，字典甚至对象将多个返回值进行封装，然后一次性返回封装结果即可实现返回多个值的效果。 使用对象返回 123456789101112class Test: def __init__(self): self.str = &quot;hello world!&quot; self.x = 20 # 返回一个对象def fun(): return Test()t = fun() print(t.str)print(t.x) 运行结果： 12hello world!20 使用列表返回 123456789# 返回一个列表def fun(): str = &quot;hello&quot; x = 20 return [str, x]; list = fun() print(list) 运行结果： 1[&#x27;hello&#x27;, 20] 使用元组返回 123456789# 返回一个元组def fun(): str = &quot;你好！&quot; x = 2022 return str, x;str, x = fun() # Assign returned tupleprint(str)print(x) 运行结果： 12你好！2022 使用字典返回 123456789# 返回一个字典def fun(): d = dict(); d[&#x27;name&#x27;] = &quot;欧阳克&quot; d[&#x27;age&#x27;] = 25 return dd = fun() print(d) 运行结果： 1&#123;&#x27;name&#x27;: &#x27;欧阳克&#x27;, &#x27;age&#x27;: 25&#125;"},{"title":"函数进阶","path":"/wiki/Python学习笔记/函数进阶/index.html","content":"Python partial偏函数 简单的理解偏函数，他是对原始函数的二次封装，是将现有函数的部分参数预先绑定为指定值，从而得到一个新的函数，这个函数就成为偏函数。相比原函数，偏函数具有较少的可变参数，从而降低了函数调用的难度。 偏函数的定义需要使用关键字partial（位于模块functools中）。他的语法格式如下： 1偏函数名 = partial(func, *args, **kwargs) 我们在学习了函数的各种接收方法以后，很容易就可以理解后两个参数的意思。*args用来接收所有的位置参数，而**kwargs用来接收所有的关键字参数，如下是一个偏函数的应用例子： 1234567from functools import partial#定义个原函数def display(name,age): print(&quot;name:&quot;,name,&quot;age:&quot;,age)#定义偏函数，其封装了 display() 函数，并为 name 参数设置了默认参数GaryFun = partial(display,name = &#x27;Gary&#x27;)#由于 name 参数已经有默 运行结果： 1name: Gary age: 13 我们要注意，对于第8行代码，必须采用关键字参数的形式给age形参传值，因为如果以无关键字参数的方式，该实参将试图传递给name形参，Python编辑器会报TypeError错误。 为了方便正确设置默认值，一般情况下我们最好在对偏函数定义设置默认值时使用关键字参数形式，然后调用再使用位置参数的形式。 当然如果你对参数的传递非常熟悉，那么可以使用位置参数传递，如下是一个使用位置参数为偏函数设置参数默认值的例子： 1234567from functools import partialdef mod( n, m ): return n % m#定义偏函数，并设置参数 n 对应的实参值为 100mod_by_100 = partial( mod, 100 )print(mod( 100, 7 ))print(mod_by_100( 7 )) 运行结果: 1222 注意此时mod_by_100相当于只需要再接收一个m参数了，n并不需要在接收了，因此此时如果像下面这样调用会出错： 12345&gt;&gt;&gt;print(mod_by_100( 100,7 ))Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 8, in &lt;module&gt; print(mod_by_100( 100,7 ))TypeError: mod() takes 2 positional arguments but 3 were given 因此我们可以理解为此时mod_by_100是一个新函数，他只需要接收一个参数，然后就会计算出100%n的值，只不过他的具体实现是基于mod实现的。因此它实现了函数的参数截取。 结合上面的例子，我们不难看出实际上偏函数的运行本质上还是调用了原始函数，只不过是对，原始函数进行了封装，将原函数的一些不需要改变的形参设置了默认值，然后对外部用户只暴露剩下的参数。这种通过将任意数量（顺序）的参数，转化为另一个带有剩余参数的函数对象，从而实现了截取函数功能（偏向）的效果。在实际应用中，可以使用一个原函数，然后将其封装多个偏函数，在调用函数时全部调用偏函数，一定程度上可以提高程序的可读性。 Python函数递归 函数递归 函数递归就是一个函数不断的调用自身的过程，他往往需要一个终止条件以便能够跳出递归继续向下执行代码。但是有时候我们会由于代码逻辑的缺陷问题，导致函数递归缺失终止条件，那么此时程序并不会真的一直向下递归调用执行，而是在递归调用997次以后停止并报错RecursionError。这是因为在Python中，默认的最大递归次数是997次。 12345678count=0def func(): global count count+=1 print(count) func()func()#最大打印出997，最后报错 如果我们需要修改默认的最大递归次数，方法如下： 12import syssys.setrecursionlimit(修改后的值) 递归实例 我们以二分法查找列表l中数字num的索引熟悉一下函数的递归 123456789101112131415def search(l, num, start=None, end=None): start = start if start else 0 end = end if end else len(l)-1 mid = (end-start)//2+start if l[mid] &gt; num: return search(l, num, start, mid-1) elif l[mid] &lt; num: return search(l, num, mid+1, end) elif l[mid] == num: return mid# 默认要寻找的数存在，否则会报错l = [2, 3, 5, 10, 15, 16, 18, 22, 26, 30, 32, 35, 41, 42, 43, 55, 56, 66, 67, 69, 72, 76, 82, 83, 88]print(search(l, 67)) 我们只需要记住，递归需要一个终止条件同时还要注意最大递归次数即可。 Python变量作用域 Python局部变量 在函数内部定义的变量，他的作用域也仅限于函数内部，出了函数就不能使用了，我们将这样的变量称为局部变量。 当函数被执行时，Python会为其分配一块临时的存储空间，所有在函数内部定义的变量，都会存储在这块空间中。而在函数执行完毕后，这块临时存储空间随即会被释放并回收，该空间中存储的变量自然也就无法再被使用。 12345def demo(): add = &quot;hello&quot; print(&quot;函数内部 add =&quot;,add)demo()print(&quot;函数外部 add =&quot;,add) 运行结果： 12345函数内部 add = helloTraceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 6, in &lt;module&gt; print(&quot;函数外部 add =&quot;,add)NameError: name &#x27;add&#x27; is not defined 我们可以看到，如果试图在函数外部访问其内部定义的变量，那么Python解释器会报NameError错误，并且提示我们没有定义要访问的变量，这也证实了当函数执行完毕后，其内部定义的变量会被销毁并回收。 我们还要注意，函数接收的参数也属于局部变量，只能在函数内部使用： 123456def demo(name,add): print(&quot;函数内部 name =&quot;,name) print(&quot;函数内部 add =&quot;,add)demo(&quot;Python教程&quot;,&quot;http://c.biancheng.net/python/&quot;)print(&quot;函数外部 name =&quot;,name)print(&quot;函数外部 add =&quot;,add) 运行结果： 123456函数内部 name = Python教程函数内部 add = http://c.biancheng.net/python/Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 7, in &lt;module&gt; print(&quot;函数外部 name =&quot;,name)NameError: name &#x27;name&#x27; is not defined 我们可以看到name变量和add变量形参只能在函数内部使用，外部也是无法使用的。因为函数执行完成以后会立即销毁存储这些函数相关变量的存储空间。 Python全局变量 除了在函数内部定义变量，Python还允许我们在所有函数的我外部定义变量，这样的变量我们成为全局变量。和局部变量不同，全局变量的默认作用域是整个程序，即全局变量既可以在各个函数的外部使用，也可以在各函数内部使用。 定义全局变量的方式有以下两种： 一、在函数体外部定义的变量 12345add = &quot;http://coolchong.cn&quot;def text(): print(&quot;函数体内访问：&quot;,add)text()print(&#x27;函数体外访问：&#x27;,add) 运行结果： 12函数体内访问： http://coolchong.cn函数体外访问： http://coolchong.cn 二、 在函数体内定义全局变量 我们可以使用global关键字对变量进行修饰，这样这个变量就变成了全局变量，即使此时他是在函数内部定义的： 123456ef text(): global add add= &quot;http://coolchong.cn/&quot; print(&quot;函数体内访问：&quot;,add)text()print(&#x27;函数体外访问：&#x27;,add) 运行结果： 12函数体内访问： http://coolchong.cn/函数体外访问： http://coolchong.cn/ 我们要注意使用global关键字修饰变量时，不能直接给变量赋初值，否则会引发语法错误。 获取指定作用域范围中的变量 在一些特定场景中，我们可能需要某个作用域内（全局范围内或者局部范围内）所有的变量，Python中提供了一下3种方式： 1）globals()函数 globals()函数为Python的内置函数，他可以返还一个包含全局范围内所有的变量的字典，该字典中的每个键值对，键为变量名，值为该变量的值。 12345678#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot;print(globals()) 运行结果： 1&#123; ...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ......&#125; 注意globals()函数返还的字典中，不仅仅包含我们定义的全局变量，还有许多默认包含的变量，他们是Python主程序内置的，我们可以不用理会。 可以看到，通过调用globals()函数我们可以得到一个包含所有全局变量的字典，并且通过字典，我们可以访问指定的全局变量，如果需要，我们还可以修改它的值： 123print(globals()[&#x27;Pyname&#x27;])globals()[&#x27;Pyname&#x27;] = &quot;Python入门教程&quot;print(Pyname) 运行结果： 12Python教程Python入门教程 2）locals()函数 locals()函数也是Python内置函数之一，通过调用这个函数，我们可以得到一个包含当前作用域内所有变量的字典。当在函数内部调用locals()函数，会得到包含所有局部变量的字典，而在全局范围内调用locals()函数，其功能就和globals()函数功能完全相同。 123456789101112#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot; print(&quot;函数内部的 locals:&quot;) print(locals())text()print(&quot;函数外部的 locals:&quot;)print(locals()) 运行结果： 1234函数内部的 locals:&#123;&#x27;Sheadd&#x27;: &#x27;http://c.biancheng.net/shell/&#x27;, &#x27;Shename&#x27;: &#x27;shell教程&#x27;&#125;函数外部的 locals:&#123;...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ...... &#125; 但是我们要注意，当使用locals()函数获得所有局部变量组成的字典时，可以像globals()函数那样，通过指定键访问对应的变量值，但是我们无法对变量值进行修改 1234567891011#全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;def text(): #局部变量 Shename = &quot;shell教程&quot; Sheadd= &quot;http://c.biancheng.net/shell/&quot; print(locals()[&#x27;Shename&#x27;]) locals()[&#x27;Shename&#x27;] = &quot;shell入门教程&quot; print(Shename)text() 运行结果： 12shell教程shell教程 3）vars(object) vars()函数也是Python内置函数之一，其功能是返回一个指定object对象范围内所有变量组成的字典，如果不传入object参数，vars()和globals()的作用完全相同。 12345678910 #全局变量Pyname = &quot;Python教程&quot;Pyadd = &quot;http://c.biancheng.net/python/&quot;class Demo: name = &quot;Python 教程&quot; add = &quot;http://c.biancheng.net/python/&quot;print(&quot;有 object：&quot;)print(vars(Demo))print(&quot;无 object：&quot;)print(vars()) 运行结果： 1234有 object：&#123;...... , &#x27;name&#x27;: &#x27;Python 教程&#x27;, &#x27;add&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ......&#125;无 object：&#123;...... , &#x27;Pyname&#x27;: &#x27;Python教程&#x27;, &#x27;Pyadd&#x27;: &#x27;http://c.biancheng.net/python/&#x27;, ...... &#125; Python在函数内部使用同名的全局变量 首先我们要明确，函数可以直接不接收参数就直接使用全局变量如下所示： 123456name = &#x27;Charlie&#x27;def test (): # 直接访问name全局变量 print(name) # Charlietest()print(name) 运行结果： 12CharlieCharlie 此时写法是正确的，相当于test()函数直接打印了全局变量name，同时在函数外部主程序内又打印了一遍全局变量name，因此两个输出结果均为Charlie。 同时当函数内部出现了同名的局部变量，那么局部变量会覆盖之前的全局变量的值，即函数默认将同名变量视为局部变量进行使用，因此如下所示 123456name = &#x27;Charlie&#x27;def test (): name=&quot;wenchong&quot; print(name) # wenchongtest()print(name) 运行结果： 12wenchongCharlie 此时test()函数内部声明了一个name局部变量并且将值设置为了wenchong，因此此时输出结果如下所示，即在test()函数内部局部变量name覆盖掉了全局变量name。但是我们假如将name=&quot;wenchong&quot;放到print(name)下方会怎样？ 123456name = &#x27;Charlie&#x27;def test (): print(name) name=&quot;wenchong&quot;test()print(name) 运行结果： 1UnboundLocalError : local variable ‘name’ referenced before assignment 我们发现此时报错了！原因是此时test()会将namne视为局部变量，那么很显然print(name)代码打印的是局部变量的值，但是此时局部变量name还未进行赋值，因此报错了。 实际上此时上面的代码本意是打印全局变量name的值，然后再声明一个全局变量name并且赋值为字符串wenchong,那么此时怎么实现呢？很显然我们并不能直接在函数内部将name声明为global全局变量类型，因为这样会导致函数执行结束以后全局变量name也发生了改变导致输出的结果为 12Charliewenchong 但是实际上我们希望输出的结果为 12CharlieCharlie 即在test()函数内部定义了局部变量name赋值为wenchong，同时两次打印使用的都是全局变量name，那么此时我们就会用到之前我们学习的globals()函数了，代码改为： 1234567name = &#x27;Charlie&#x27;def test (): print(globals()[&#x27;name&#x27;]) # Charlie #也可以写为 print(globals.getr(&#x27;name&#x27;)) name=&quot;wenchong&quot;test()print(name) #Charlie 为了验证此时函数内部的name确实为局部变量，我们可以使用如下代码测试： 1234567name = &#x27;Charlie&#x27;def test (): print(globals().get(&#x27;name&#x27;)) # wenchong name=&quot;wenchong&quot; print(name)test()print(name) 运行结果： 123CharliewenchongCharlie Python局部函数详解 通过前面的学习我们已经知道Python支持局部变量了，那么Python是否支持局部函数呢？即Python函数内部可以在定义函数吗？答案是可以得。Python支持在函数内部定义函数，此类函数就被成为局部函数。 123456789#全局函数def outdef (): #局部函数 def indef(): print(&quot;hello world&quot;) #调用局部函数 indef()#调用全局函数outdef() 运行结果： 1hello world 和全局函数返回其局部变量从而扩大这个变量的作用域一样，通过将局部函数函数作为函数的返回值，也可以扩大局部函数的使用范围，比如： 1234567891011#全局函数def outdef (): #局部函数 def indef(): print(&quot;调用局部函数&quot;) #调用局部函数 return indef#调用全局函数new_indef = outdef()调用全局函数中的局部函数new_indef() 运行结果： 1调用局部函数 此时这个局部函数作用域就扩大了，他可以脱离父函数作用而在全局内使用。因此我们可以总结出以下规律： 如果所在函数并没有返还局部函数，那么这个局部函数的可用范围仅限于所在函数内部 反之，如果所在函数将局部函数作为返回值，那么局部函数的作用域就会扩大，既可以在函数内部使用，也可以在所在函数的作用域中使用。 同时我们要注意一个问题，局部函数内部是一个新的作用域，因此如果局部函数中定义了和所在函数中变量同名的变量，也会发生遮蔽问题。 12345678910#全局函数def outdef (): name = &quot;所在函数中定义的 name 变量&quot; #局部函数 def indef(): print(name) name = &quot;局部函数中定义的 name 变量&quot; indef()#调用全局函数outdef() 此时indef()函数内是一个新的作用域，并且此时在内部又定义了一个新的局部变量name，因此此时很明显会报错，Python解释器会报如下错误： 1UnboundLocalError: local variable &#x27;name&#x27; referenced before assignment 那么为了解决这个问题，我们应该怎么样修改代码呢？ 很明显此时无论是使用global关键字还是内置函数globals()、locals()都无法解决错误。此时我们需要使用Python提供的关键字nonlocal，顾名思义不是局部变量，那么此时他就会取消遮蔽效果获取到局部函数所在父函数作用域的变量name的值： 123456789101112#全局函数def outdef (): name = &quot;所在函数中定义的 name 变量&quot; #局部函数 def indef(): nonlocal name print(name) #修改name变量的值 name = &quot;局部函数中定义的 name 变量&quot; indef()#调用全局函数outdef() 运行结果： 1所在函数中定义的 name 变量 Python函数高级使用方法 前面我们已经学习函数的基础用法，接下来我们再学习一些高级用法。首先Python允许直接将函数赋值给变量，这样做的效果是，程序也可以用其他变量来调用函数，更加灵活。 123456def my_def (): print(&quot;正在执行 my_def 函数&quot;)#将函数赋值给其他变量 other = my_def#间接调用 my_def() 函数other() 运行结果： 1正在执行 my_def 函数 不仅如此，Python还支持将函数以参数的形式传入其他函数，例如： 1234567891011def add (a,b): return a+bdef multi(a,b): return a*bdef my_def(a,b,dis): return dis(a,b) #求 2 个数的和print(my_def(3,4,add))#求 2 个数的乘积print(my_def(3,4,multi)) 运行结果： 12712 我们可以看到上面的代码中my_def接收的第三个参数是一个函数，然后将前两个接收的参数传给第三个函数参数去执行，因此函数可以作为参数传递。 Python闭包函数 闭包，又称为闭包函数或闭合函数，其实和前面我们学习的嵌套函数类似，不同之处在于，闭包中外部函数返回的不是一个具体的值，而是一个函数。一般情况下， 返回的函数会赋值给一个变量，这个变量可以在后面被继续执行调用。 例如，现在我们要实现一个计算数的n次幂的函数，那么用闭包可以如下实现： 123456789#闭包函数，其中 exponent 称为自由变量def nth_power(exponent): def exponent_of(base): return base ** exponent return exponent_of # 返回值是 exponent_of 函数square = nth_power(2) # 计算一个数的平方cube = nth_power(3) # 计算一个数的立方print(square(2)) # 计算 2 的平方print(cube(2)) # 计算 2 的立方 运行结果： 1248 在上面的程序中，外部函数nth_power()的返回值是函数exponent__of()，而不是一个具体的数值。这个返还的exponent_of函数还需要接收一个base变量，nth_power()只是将exponent_of内部的exponent变量进行了赋值。 因此，在执行完square=nth_power(2)和cube=nth_power(3)后，外部函数nth_power()的参数exponent会和内部函数exponent_of一起赋值给square和cube，这样在之后调用square(2）和cube(2)时，程序就能顺利的输出结果，而不会报错exponent变量没有定义 但是你可能会疑惑我们为什么非要使用闭包来实现上面的功能呢？完全可以下面这种简单的形式： 12def nth_power_rewrite(base, exponent): return base ** exponent 上面的程序确实也可以实现相同的功能，不过使用闭包，可以让程序变得更加简洁易读。设想一下，比如我们现在需要计算很多个数的平方，那么闭包函数的写法明显更好： 123456789# 不使用闭包res1 = nth_power_rewrite(base1, 2)res2 = nth_power_rewrite(base2, 2)res3 = nth_power_rewrite(base3, 2)# 使用闭包square = nth_power(2)res1 = square(base1)res2 = square(base2)res3 = square(base3) 采用闭包的第二个形式，表达更为简单，每次调用函数时，我们都可以少输入一个参数。 思考：闭包还有什么优势？ 如果仅仅是减少输入参数，貌似闭包优点大材小用了，毕竟闭包很难构思，难道优势仅仅是降低操作的难度吗？当然不是，闭包的优点和缩减嵌套函数的优点类似，我们知道每一个函数开头都需要做一些额外工作，那么当多次调用该函数时，每次都需要重复初始化工作，但是如果我们将这些额外工作统一放置到外部函数中，用闭包返还内部函数，就可以减少多次调用导致的不必要的开销，提高程序的运行效率。 Python闭包的__closure__属性 闭包函数比普通的函数多了一个__closure__属性，这个属性记录着自由变量的地址。当闭包被调用时，系统就会根据该地址找到对应的自由变量，完成整体的函数调用。 以nth_power()为例，当其被调用时，可以通过__closure__属性获取自由变量（也就是程序中的exponent参数）存储的地址，例如： 1234567def nth_power(exponent): def exponent_of(base): return base ** exponent return exponent_ofsquare = nth_power(2)#查看 __closure__ 的值print(square.__closure__) 运行结果： 1(&lt;cell at 0x0000014454DFA948: int object at 0x00000000513CC6D0&gt;,) 可以看到，显示的内容是一个int整数类型，这就是square中自由变量exponent的初始值，还可以看到，__closure__属性的类型是一个元组，这表明闭包可以支持多个自由变量的形式。 Python lambda表达式(匿名函数） 对于一个简单的函数，Python还提供了另外一种方法，即lambda表达式。lambda表达式，又称为匿名函数，常用来表示内部仅包含一行表达式的函数。如果一个函数的函数体仅有一行表达式，那么这个函数就可以使用lambda表达式来代替。 lambda表达式的语法格式如下： 1name = lambda [list] : 表达式 其中，定义lambda表达式时，必须使用lambda关键字，[list]作为可选参数，等同于定义函数时指定的参数列表或者元组用来接收参数，name为表达式的名称。 如果将lambda表达式转换为普通函数的形式就如下方所示： 123def name(list): return 表达式name(list) 接下来我们尝试使用一个lambda表达式解决求两个数之和的问题： 12add = lambda x,y:x+yprint(add(3,4)) 运行结果： 17 使用lambda表达式的优势有： 对于单行函数，使用lambda表达式可以省去定义函数的过程，让代码更加简洁 对于不需要多次复用的函数，使用lambda表达式可以在用完之后立即释放，提高程序执行的性能 Python eval()和exec()函数 eval()和exec()函数都属于Python内置函数，两个函数的功能是类似的，都可以执行一个字符串形式的Python代码（代码以字符串的形式提供），相当于一个Python的解释器。而这不同之处在于，eval()执行完要返回结果，而exec()执行完不返回结果。 eval()和exec()的用法 eval()函数的语法格式如下： 1eval(source, globals=None, locals=None, /) 而exec()函数的语法格式如下： 1exec(source, globals=None, locals=None, /) 两者除了函数名不同，其他都相同，各个参数的具体含义为： expression：这个参数是一个字符串，代表要执行的语句。该语句受后面两个字典类型参数globals和locals的限制，只有在globals字典和locals字典作用域内的变量和函数才能被执行。 globals：这个参数管控的是一个全局的命名空间，即expression可以使用全局命名空间中的函数。如果只是提供了globals参数，而没有提供自定义的 __builtins__，则系统会将当前环境中的__builtins__复制到自己提供的globals中，然后才会进行计算。如果连globals这个参数都没有被提供，那么使用Python的全局命名空间。 locals：这个参数管控的是一个局部命名空间，和globals类似，当它和globals中有重复或冲突时，以locals为准。如果locals没有被提供，那么默认为globals。 注意，\\_\\_builtins\\_\\_是 Python 的内建模块，平时使用的 int、str、abs 都在这个模块中。通过 print(dic[__builtins__]) 语句可以查看 __builtins__ 所对应的 value。 123456dic=&#123;&#125; #定义一个字dic[&#x27;b&#x27;] = 3 #在 dic 中加一条元素，key 为 bprint (dic.keys()) #先将 dic 的 key 打印出来，有一个元素 bexec(&quot;a = 4&quot;, dic) #在 exec 执行的语句后面跟一个作用域 dic#全局域字典dic很明显会增加一个新的全局变量aprint(dic.keys()) #exec 后，dic 的 key 多了一个 运行结果： 12dict_keys([&#x27;b&#x27;])dict_keys([&#x27;b&#x27;, &#x27;__builtins__&#x27;, &#x27;a&#x27;]) 上面的代码是在作用域 dic 下执行了一句 a = 4 的代码。可以看出，exec() 之前 dic 中的 key 只有一个 b。执行完 exec() 之后，系统在 dic 中生成了两个新的 key，分别是 a 和__builtins__。其中，a 为执行语句生成的变量，系统将其放到指定的作用域字典里；__builtins__是系统加入的内置 key。 我们再看一个例子： 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;, g, t)) #定义一个字典 116 运行结果： 1116 为什么结果为116呢？首先我们设置了eval()函数的全局域为&#123;'a':6, 'b':8&#125;，然后又设置了局部域为&#123;'b':100, 'c':10&#125;。但是根据之前的讲解，当globals和locals有冲突时，会产生局部域遮蔽全局域冲突变量的情况，因此此时实际上a+b+c执行的时候，a用全局域中的6，b和c都是使用局部域中的100和10，因此最终结果为116。 我们会发现eval函数中执行代码时变量的值与eval所处的域中变量值并不同，这是因为我们重新为其传入了globals和locals，假设此时我们不设置globals如下所示，那么此时eval()的globals将会继承当前的全局域，因此a为10，代码执行结果为120 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;, None, t)) #定义一个字典 120 以此类推，假设此时我们globals和locals都不设置，那么运行结果将是60 123456a=10b=20c=30g=&#123;&#x27;a&#x27;:6, &#x27;b&#x27;:8&#125; #定义一个字典t=&#123;&#x27;b&#x27;:100, &#x27;c&#x27;:10&#125; #定义一个字典print(eval(&#x27;a+b+c&#x27;)) #定义一个字典 60 exec()和eval()的区别 前面我们讲过，eval()执行完结果会返还，而exec()执行完并不会返还结果，举个例子： 1234567a = 1exec(&quot;a = 2&quot;) #相当于直接执行 a=2print(a)a = exec(&quot;2+3&quot;) #相当于直接执行 2+3，但是并没有返回值，a 应为 Noneprint(a)a = eval(&#x27;2+3&#x27;) #执行 2+3，并把结果返回给 aprint(a) 运行结果： 1232None5 当我们为eval()里放置一个没有结果返回的语句时，Python解释器将会报SyntaxError错误 12345678&gt;&gt;&gt;a= eval(&quot;a = 2&quot;)Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 1, in &lt;module&gt; a= eval(&quot;a = 2&quot;) File &quot;&lt;string&gt;&quot;, line 1 a = 2 ^SyntaxError: invalid syntax eval()和exec()函数的应用场景 在使用Python开发服务端程序时，两个函数应用的非常广泛，例如客户端向服务端发送一段字符串代码，服务端无需关心具体的内容，直接通过 eval() 或 exec() 来执行，这样的设计会使服务端与客户端的耦合度更低，系统更易扩展。 另外，如果以后接触 TensorFlow 框架，就会发现该框架中的静态图就是类似这个原理实现的： TensorFlow 中先将张量定义在一个静态图里，这就相当将键值对添加到字典里一样； TensorFlow 中通过 session 和张量的 eval() 函数来进行具体值的运算，就当于使用 eval() 函数进行具体值的运算一样。 需要注意的是，在使用 eval() 或是 exec() 来处理请求代码时，函数 eval() 和 exec() 常常会被黑客利用，成为可以执行系统级命令的入口点，进而来攻击网站。解决方法是：通过设置其命名空间里的可执行函数，来限制 eval() 和 exec() 的执行范围。 Python函数式编程 所谓函数式编程，就是指代码中每一块都是不可变的，都由纯函数的形式组成。这里的纯函数，是指函数本身相互独立、互相影响，对于相同的输入，总会有相同的输出。 函数式编程的一大特点，就是允许把函数本身作为参数传入另一个函数，还允许返回一个函数。 假设现在我们想让列表中的元素值都变为原来的两倍，可以使用如下函数实现： 1234def multiply_2(list): for index in range(0, len(list)): list[index] *= 2 return list 要注意，这段代码并不是一个纯函数的形式，因为列表中的元素的值都被改变了，如果多次调用multiply_2()函数，那么每次得到的结果都是不一样的。 而如果想让multiply_2()成为一个纯函数的形式，就得重新创建一个新的列表并返回，也就是写成下面这种形式： 12345def multiply_2_pure(list): new_list = [] for item in list: new_list.append(item * 2) return new_list 对比上面两种写法，我们可以发现第一种写法中是直接修改了输入列表的元素，而第二种写法是返回了一个新的列表，新的列表存储了操作后的结果元素，并未修改原列表。**第二种写法无论传入多少次list，返回的结果都是一样的。**函数式编程的优点，就是其纯函数和不可变的特性使程序更加健壮，易于调试和测试，但是缺点是限制多，难写。 纯粹的函数式编程语言（比如Scala)，其编写的函数中是没有变量的，因此可以保证，只要输入是确定的，输出就是确定的。而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，因此同样的输入，可能也会得到不同的输出。 Python允许使用变量，所以他并不是一门纯函数式编程语言。Python仅对函数式编程提供了部分支持，主要包括map()，filter()和reduce()这3个函数。他们通常都和lambda匿名函数一起使用。 Python map()函数 1map(function, iterable) 其中，fucntion参数表示要传入一个函数，其可以是内置函数、自定义函数或者lambda匿名函数，iterable表示一个或者多个可迭代对象，可以是列表、字符串等。 map()函数的功能是对每一个可迭代对象中的每个元素，都调用指定的函数，并且返回一个map()对象。由于返回的是一个map()对象，因此不能直接输出，可以通过for循环或者list()函数来显示。 我们还是实现对列表中的每一个元素都乘2的功能： 123listDemo = [1, 2, 3, 4, 5]new_list = map(lambda x: x * 2, listDemo)print(list(new_list)) 运行结果： 1[2， 4， 6， 8， 10] 并且map()支持传入多个可迭代对象作为参数 1234listDemo1 = [1, 2, 3, 4, 5]listDemo2 = [3, 4, 5, 6, 7]new_list = map(lambda x,y: x + y, listDemo1,listDemo2)print(list(new_list)) 运行结果： 1[4, 6, 8, 10, 12] 由于map()函数是直接使用C语言写的，运行时不需要通过Python解释器间接调用，并且内部做了诸多优化，所以相比其他方法，此方法的运行效率更高。 Python filter()函数 1filter(function, iterable) 此格式中，fucntion参数要传入一个函数，iterable表示一个可迭代对象。 filter()函数的功能是对iterable中的每一个元素，都使用function函数判断，并返回True或者False，最后将True的元素组成一个新的可遍历的集合。即元素筛选。 123listDemo = [1, 2, 3, 4, 5]new_list = filter(lambda x: x % 2 == 0, listDemo)print(list(new_list)) 运行结果： 1[2, 4] Python reduce()函数 reduce() 函数通常用来对一个集合做一些累积操作，其基本语法格式为： 1reduce(function, iterable) function参数必须是一个包含两个参数的函数，iterable表示可迭代对象。 注意，由于reduce() 函数在 Python 3.x 中已经被移除，放入了 functools 模块，因此在使用该函数之前，需先导入 functools 模块。 假设我们要计算某个列表所有元素的乘积 1234import functoolslistDemo = [1, 2, 3, 4, 5]product = functools.reduce(lambda x, y: x * y, listDemo)print(product) 运行结果: 1120 总结 通常来说，当对集合中的元素进行一系列操作时，如果操作非常简单，比如累加、累积这种，那么优先考虑使用map()，filter()，reduce()等实现，另外，在数据量非常多的情况下（比如机器学习的应用），一般更倾向于使用函数式编程的表示，因为效率更高。 当然，在数据量不多的情况下，使用for循环等方式也是可以的，不过，如果要对集合中的元素做一些比较复杂的操作，考虑到代码的可读性，通常会使用for循环。"},{"title":"元组、字典与集合","path":"/wiki/Python学习笔记/元组、字典与集合/index.html","content":"Python tuple元组详解 元组（tuple)是Python中另一个重要的序列结构，和列表类似，元组也是由一系列按特定顺序排列的元组组成。但是他和list列表又有所区别如下： 列表的元素是可以更改的，包括修改元素值，删除和插入元素，所以列表是可变序列； 而元组一旦被创建，它的元素就不可更改了，所以元组是不可变序列。 元组可以看成是不可变的列表，因此他不提供append()，remove()等方法同时也不支持del tuple[idx]删除元组的方法。 1234&gt;&gt;&gt; tup=(1,2,3)&gt;&gt;&gt; del tup(0) File &quot;&lt;stdin&gt;&quot;, line 1SyntaxError: cannot delete function call 通常情况下，元组用于保存无需修改的内容。从形式上看，元组的所有元素都放在一对小括号()中，相邻元素之间用逗号,分隔，如下所示： 1(element1, element2, ... , elementn) 其中 element1~elementn 表示元组中的各个元素，个数没有限制，只要是 Python 支持的数据类型就可以。因此元组中也可以存储若干个类型不同的数据，但是为了提高可读性，一般也存储相同类型的数据。 1(&quot;c.biancheng.net&quot;, 1, [2,&#x27;a&#x27;], (&quot;abc&quot;,3.0)) 要注意元组tuple和列表list是两种不同的数据结构，他们的type类型并不相同！ 12&gt;&gt;&gt; type( (&quot;c.biancheng.net&quot;,1,[2,&#x27;a&#x27;],(&quot;abc&quot;,3.0)) )&lt;class &#x27;tuple&#x27;&gt; Python创建元组 Python中元组的创建和list类似也有两种创建方法 1）使用()创建 通过()创建元组以后，一般使用=将它赋值给某个变量，具体格式为： 1tuplename = (element1, element2, ..., elementn) 其中，tuplename表示变量名，element1~elementn表示元组存储的元素。如下所示： 123num = (7, 14, 21, 28, 35)course = (&quot;Python教程&quot;, &quot;http://coolchong.cn&quot;)abc = ( &quot;Python&quot;, 19, [1,2], (&#x27;c&#x27;,2.0) ) 在Python中，元组通常都是使用一对小括号将所有元素包围起来的，但是小括号不是必须的，只要将各元素用逗号分隔，Python就会将其视为元组，如下也是元组： 12course = &quot;Python教程&quot;, &quot;http://coolchong.cn&quot;print(course) 运行结果： 1(&#x27;Python教程&#x27;, &#x27;http://coolchong.cn&#x27;) 要特别注意，当创建的元组中只有一个字符串类型的元素时，该元素后面必须要加一个逗号,，否则Python解释器会将它视为字符串，如下所示： 123456&gt;&gt;&gt; a=(&quot;https://coolchong.cn/&quot;,)&gt;&gt;&gt; print(type(a))&lt;class &#x27;tuple&#x27;&gt;&gt;&gt;&gt; b=(&quot;https://coolchong.cn/&quot;)&gt;&gt;&gt; print(type(b))&lt;class &#x27;str&#x27;&gt; 2)使用tuple()函数创建元组 除了使用()创建元组外，Python还提供了一个内置的函数tuple()，可以用来将其他数据类型转换为元组类型。tuple()的语法格式如下： 1tuple(data) 其中data表示可以转换为元组的数据，包含字符串、元组、range()对象等。 1234567891011121314151617#将字符串转换成元组tup1 = tuple(&quot;hello&quot;)print(tup1)#将列表转换成元组list1 = [&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;]tup2 = tuple(list1)print(tup2)#将字典转换成元组dict1 = &#123;&#x27;a&#x27;:100, &#x27;b&#x27;:42, &#x27;c&#x27;:9&#125;tup3 = tuple(dict1)print(tup3)#将区间转换成元组range1 = range(1, 6)tup4 = tuple(range1)print(tup4)#创建空元组print(tuple()) 运行结果： 12345(&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;)(&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;)(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;)(1, 2, 3, 4, 5)() Python访问元组元素 和列表一样，我们也可以使用索引(Index)访问元组的某个元素（得到的是一个元素的值），也可以使用切片访问元组的一组元素(得到的是一个新的子元组)。 1234#访问单个元素tuplename[i]#访问一组元素tuplename[start : end : step] 12345678url = tuple(&quot;http://c.biancheng.net/shell/&quot;)#使用索引访问元组中的某个元素print(url[3]) #使用正数索引print(url[-4]) #使用负数索引#使用切片访问元组中的一组元素print(url[9: 18]) #使用正数切片print(url[9: 18: 3]) #指定步长print(url[-6: -1]) #使用负数切片 运行结果： 12345pe(&#x27;b&#x27;, &#x27;i&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;c&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;n&#x27;, &#x27;g&#x27;)(&#x27;b&#x27;, &#x27;n&#x27;, &#x27;e&#x27;)(&#x27;s&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;) Python修改元组 前面我们已经介绍过元组是无法修改的，因此我们只能是为变量赋值一个新元素来改变变量的元组值如下所示： 12345tup = (100, 0.5, -36, 73)print(tup)#对元组进行重新赋值tup = (&#x27;Shell脚本&#x27;,&quot;https://coolchong.cn/&quot;)print(tup) 运行结果： 12(100, 0.5, -36, 73)(&#x27;Shell脚本&#x27;, &#x27;https://coolchong.cn/&#x27;) 同时我们也可以使用+拼接元组生成一个新的元组，但是也不会改变原元组： 12345tup1 = (100, 0.5, -36, 73)tup2 = (3+12j, -54.6, 99)print(tup1+tup2)print(tup1)print(tup2) 运行结果： 123100, 0.5, -36, 73, (3+12j), -54.6, 99)(100, 0.5, -36, 73)((3+12j), -54.6, 99) Python删除元组 我们并不能删除元组中的某一个元素，但是我们可以删除不再使用的整个元组，如下： 1234tup = (&#x27;Java教程&#x27;,&quot;http://coolchong.cn/&quot;)print(tup)del tupprint(tup) 运行结果： 12345(&#x27;Java教程&#x27;, &#x27;http://coolchong.cn&#x27;)Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(tup)NameError: name &#x27;tup&#x27; is not defined Python 自带垃圾回收功能，会自动销毁不用的元组，所以一般不需要通过 del 来手动删除。 Python中元素和列表的区别 看完前面对元组和列表的介绍以后，我们可以发现两者有很多共同点，但是列表中的元素可以任意修改，就好比是用铅笔在纸上写的字，写错了还可以擦除重写，而元组中的元素无法修改，除非将元组整体替换掉，就好比是用圆珠笔写的字，写了就擦不掉除非换一张纸。 可以将元组tuple理解为一个只读版本的列表list即可 由于两者的存储特性不同，因此存储方式也是不同的： 123456&gt;&gt;&gt; listdemo = []&gt;&gt;&gt; listdemo.__sizeof__()40&gt;&gt;&gt; tupleDemo = ()&gt;&gt;&gt; tupleDemo.__sizeof__()24 可以看出虽然列表和元组都是空的，但是元组却比列表少占用了16个字节，这是因为列表是动态的，需要存储指针指向对应的元素（占用8个字节），另外，由于列表是可变的，所以需要额外存储已经分配的长度大小（占用8个字节）。但是对于元组，他由于不可变，长度固定 ，因此存储空间也是固定的，不需要指针和额外的空间因此相较于列表更加轻量级，性能也要略优于列表。 但是既然列表就可以实现元组的功能，我们为什么还要保留使用元组这个数据类型呢？这要从Python的垃圾回收机制讲起，在Python中如果一些变量不再使用，Python就会回收他们所占用的内存，返还给操作系统，以便其他变量或其他应用使用。但是对于一些静态变量，（比如元组），如果他占用的空间不大，那么Python会暂时缓存这些内存，这样的话，下一次再创建同样大小的元组时，Python就可以不用再向操作系统发出请求取寻找内存了，而是直接分配之前缓存的内存空间，大大提升程序的运行速度（大约快了5倍）。因此元组具有不可替代性。同时，元组还可以在映射（和集合的成员）中当做键使用，而列表是不行的。 Python dict字典 Python中字典(dict)是一种无序的、可变的序列，他的元组以键值对(key-value)的形式存储因此元素在底层并不是挨着存放的。相对地，列表和元组都是有序的序列，他们的元素在底层是挨着存放的。 字典类型是Python中唯一的映射类型，”映射“是数学中的术语，简单理解，他指的是元素之间相互对应的关系，即用过一个元素就可以唯一的找到另一个元素如下所示： 字典类型的特点就是： 主要特征 解释 通过键而不是通过索引来读取元素 字典类型有时也称为关联数组或者散列表（hash）。它是通过键将一系列的值联系起来的，这样就可以通过键从字典中获取指定项，但不能通过索引来获取。 字典是任意数据类型的无序集合 和列表、元组不同，通常会将索引值 0 对应的元素称为第一个元素，而字典中的元素是无序的。 字典是可变的，并且可以任意嵌套 字典可以在原处增长或者缩短（无需生成一个副本），并且它支持任意深度的嵌套，即字典存储的值也可以是列表或其它的字典。 字典中的键必须唯一 字典中，不支持同一个键出现多次，否则只会保留最后一个键值对。 字典中的键必须不可变 字典中每个键值对的键是不可变的，只能使用数字、字符串或者元组，不能使用列表。 Python中的字典类型相当于Java或者C中的Map对象，但是它比Map对象更加灵活，因为字典的键类型可以是任意的，而不像Java或者C中需要提前声明键的数据类型保证所有的键类型统一。 123&gt;&gt;&gt; a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125; #a是一个字典类型&gt;&gt;&gt; type(a)&lt;class &#x27;dict&#x27;&gt; Python创建字典 1）使用{}创建字典 由于字典中每一个元素都包含两个部分，分别是键（key）和值（value），因此创建字典时、键和值之间使用冒号:分隔，相邻元素之间使用逗号,分隔，所有元素放在大括号&#123;&#125;中。 1dictname = &#123;&#x27;key&#x27;:&#x27;value1&#x27;, &#x27;key2&#x27;:&#x27;value2&#x27;, ..., &#x27;keyn&#x27;:valuen&#125; 其中 dictname 表示字典变量名，keyn : valuen 表示各个元素的键值对。需要注意的是，同一字典中的各个键必须唯一，不能重复。当为已有键再次设定值的时候会将之前的值覆盖掉。 123456789#使用字符串作为keyscores = &#123;&#x27;数学&#x27;: 95, &#x27;英语&#x27;: 92, &#x27;语文&#x27;: 84&#125;print(scores)#使用元组和数字作为keydict1 = &#123;(20, 30): &#x27;great&#x27;, 30: [1,2,3]&#125;print(dict1)#创建空元组dict2 = &#123;&#125;print(dict2) 运行结果： 123&#123;&#x27;数学&#x27;: 95, &#x27;英语&#x27;: 92, &#x27;语文&#x27;: 84&#125;&#123;(20, 30): &#x27;great&#x27;, 30: [1, 2, 3]&#125;&#123;&#125; 可以看到，字典的键可以是整数、字符串或者元组，只要符合唯一和不可变的特性就行；字典的值可以是 Python 支持的任意数据类型。 2）通过fromkeys()方法创建字典 在Python中我们还可以使用dict字典类型提供的fromkeys()方法创建带有默认值的字典，具体格式如下： 1dictname = dict.fromkeys(list，value=None) 其中list参数表示字典中所有键的列表（因此必须各不相同），value参数表示所有值的默认值，如果不写，就会设置为空值None。 123knowledge = [&#x27;语文&#x27;, &#x27;数学&#x27;, &#x27;英语&#x27;]scores = dict.fromkeys(knowledge, 60)print(scores) 运行结果： 1&#123;&#x27;语文&#x27;: 60, &#x27;英语&#x27;: 60, &#x27;数学&#x27;: 60&#125; 3）通过dict()映射函数创建字典 通过dict()函数创建字典的写法有多种，如下所示几种写法都是等价的创建了同一个字典a 创建格式 注意事项 a = dict(str1=value1, str2=value2, str3=value3) str 表示字符串类型的键，value 表示键对应的值。使用此方式创建字典时，字符串不能带引号。这种方式创建会导致键都是统一的字符串类型 #方式1demo = [(‘two’,2), (‘one’,1), (‘three’,3)]#方式2demo = [[‘two’,2], [‘one’,1], [‘three’,3]]#方式3demo = ((‘two’,2), (‘one’,1), (‘three’,3))#方式4demo = ([‘two’,2], [‘one’,1], [‘three’,3])a = dict(demo) 向 dict() 函数传入列表或元组，而它们中的元素又各自是包含 2 个元素的列表或元组，其中第一个元素作为键，第二个元素作为值。 eys = [‘one’, ‘two’, ‘three’] #还可以是字符串或元组values = [1, 2, 3] #还可以是字符串或元组a = dict( zip(keys, values) ) 通过应用 dict() 函数和 zip() 函数，可将前两个列表转换为对应的字典。 注意，无论采用以上哪种方式创建字典，字典中各元素的键都只能是字符串、元组或者数字，不能是列表，因为列表是可变的，不能作为键。 123456789101112&gt;&gt;&gt; a=dict(name=&quot;langwenchong&quot;,height=190,age=20)&gt;&gt;&gt; pring(a)&#123;&#x27;name&#x27;: &#x27;langwenchong&#x27;, &#x27;height&#x27;: 190, &#x27;age&#x27;: 20&#125;&gt;&gt;&gt; demo=([1,&#x27;one&#x27;],[&#x27;two&#x27;,2])&gt;&gt;&gt; b=dict(demo)&gt;&gt;&gt; print(b)&#123;1: &#x27;one&#x27;, &#x27;two&#x27;: 2&#125;&gt;&gt;&gt; keys=((&#x27;name&#x27;,&#x27;age&#x27;),&#x27;height&#x27;)&gt;&gt;&gt; values=[&quot;langwenchong+20&quot;,190]&gt;&gt;&gt; c=dict(zip(keys,values))&gt;&gt;&gt; print(c)&#123;(&#x27;name&#x27;, &#x27;age&#x27;): &#x27;langwenchong+20&#x27;, &#x27;height&#x27;: 190&#125; 如果不为dict()函数传入任何参数，那么代表创建一个空的字典，如下： 123# 创建空的字典d = dict()print(d) 运行结果为： 1&#123;&#125; Python访问字典 列表和元组都是通过下表索引来访问元素的，而字典不同，他可以通过键来访问对应的值。因为字典中的元素都是无序的，每一个元素的位置都是不固定的，因此字典也不能像列表和元组那样，采用切片的方式一次性访问多个元素。 1234tup = ([&#x27;two&#x27;,26], [&#x27;one&#x27;,88], [&#x27;three&#x27;,100], [&#x27;four&#x27;,-59])dic = dict(tup)print(dic[&#x27;one&#x27;]) #键存在print(dic[&#x27;five&#x27;]) #键不存在 运行结果： 1234588Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(dic[&#x27;five&#x27;]) #键不存在KeyError: &#x27;five&#x27; 除了上面这种方式访问字典，Python更推荐使用get()方法来获取指定键对应的值，当指定的键不存在时，get()方法不会抛出异常。 1dictname.get(key[,default]) 其中，dictname 表示字典变量的名字；key 表示指定的键；default 用于指定要查询的键不存在时，此方法返回的默认值，如果不手动指定，会返回 None。 1234a = dict(two=0.65, one=88, three=100, four=-59)print( a.get(&#x27;one&#x27;) )print( a.get(&#x27;five&#x27;) )print( a.get(&#x27;five&#x27;, &#x27;该键不存在&#x27;) ) 运行结果： 12388None该键不存在 Python删除字典 1234a = dict(two=0.65, one=88, three=100, four=-59)print(a)del aprint(a) 运行结果： 12345&#123;&#x27;two&#x27;: 0.65, &#x27;one&#x27;: 88, &#x27;three&#x27;: 100, &#x27;four&#x27;: -59&#125;Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(a)NameError: name &#x27;a&#x27; is not defined Python字典基本操作 字典是一个可变序列，因此我们可以添加、修改、删除字典中的键值对，常见的字典操作有以下几种： 向现有字典中添加新的键值对。 修改现有字典中的键值对。 从现有字典中删除指定的键值对。 判断现有字典中是否存在指定的键值对。 Python字典添加键值对 1dictname[key] = value 12345678a = &#123;&#x27;数学&#x27;:95&#125;print(a)#添加新键值对a[&#x27;语文&#x27;] = 89print(a)#再次添加新键值对a[&#x27;英语&#x27;] = 90print(a) 运行结果： 123&#123;&#x27;数学&#x27;: 95&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125; Python字典修改键值对 Python字典中的键的名字是不能被修改的，但是我们可以修改键对应的值。由于字典中各元素的键是唯一的，因此，如果新添加元素的键与已存在的元素的键相同，那么键所对应的值就会被新的值替换掉，以此达到修改元素值的目的： 1234a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(a)a[&#x27;语文&#x27;] = 100print(a) 运行结果： 12&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 100, &#x27;英语&#x27;: 90&#125; Python字典删除键值对 如果要删除字典中的键值对，还是可以使用del语句 12345# 使用del语句删除键值对a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;del a[&#x27;语文&#x27;]del a[&#x27;数学&#x27;]print(a) 运行结果： 1&#123;&#x27;英语&#x27;: 90&#125; 判断字典中是否存在指定键值对 我们只能通过in和noe in运算符对键进行判断，而无法判断值是否在字典中即只能判断是否为字典的键而不能判断是否为字典的值，如下都是基于键key的判断 1234567a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;# 判断 a 中是否包含名为&#x27;数学&#x27;的keyprint(&#x27;数学&#x27; in a) # True# 判断 a 是否包含名为&#x27;物理&#x27;的keyprint(&#x27;物理&#x27; in a) # False# 这个判断是判断95是否为字典的键print(95 in a) #False 运行结果： 123TrueTrueFalse 思考：怎样判断字典是否包含某个值？ 我们可以通过dict.keys()和dict.values()获取所有的键和所有的值，这样我们可以使用in和dict.values()来实现值的查找 123&gt;&gt;&gt; d = &#123;&#x27;1&#x27;: &#x27;one&#x27;, &#x27;3&#x27;: &#x27;three&#x27;, &#x27;2&#x27;: &#x27;two&#x27;, &#x27;5&#x27;: &#x27;five&#x27;, &#x27;4&#x27;: &#x27;four&#x27;&#125;&gt;&gt;&gt; &#x27;one&#x27; in d.values()&gt;&gt;&gt; True 思考：能够根据值找到字典中的键？ 可以代码实现如下： 123&gt;&gt;&gt; d = &#123;&#x27;1&#x27;: &#x27;one&#x27;, &#x27;3&#x27;: &#x27;three&#x27;, &#x27;2&#x27;: &#x27;two&#x27;, &#x27;5&#x27;: &#x27;five&#x27;, &#x27;4&#x27;: &#x27;four&#x27;&#125;&gt;&gt;&gt; list(d.keys())[list(d.values()).index(&#x27;one&#x27;)] #根据字典值 返回对应的key&gt;&gt;&gt; &#x27;1&#x27; 根据上面的代码我们可以得出一个结论，即dict的键中的第k个键与值中的第k个值正好可以组成字典中的第k个键值对，即键和值的相对位置是对应的。 Python dict字典其他方法详解 前面我们学习了fromkeys()和get()，这里再介绍剩余的函数。 keys()、values()和items()方法 将这三个放在一起介绍，是因为他们都用来获取字典中特定数据： eys() 方法用于返回字典中的所有键（key）； values() 方法用于返回字典中所有键对应的值（value）； items() 用于返回字典中所有的键值对（key-value）。 1234scores = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(scores.keys())print(scores.values())print(scores.items()) 运行结果： 123dict_keys([&#x27;数学&#x27;, &#x27;语文&#x27;, &#x27;英语&#x27;])dict_values([95, 89, 90])dict_items([(&#x27;数学&#x27;, 95), (&#x27;语文&#x27;, 89), (&#x27;英语&#x27;, 90)]) 要注意，keys()、values()和items()返回值类型分别为dic_keys、dict_values、dict_items而并不是列表list或元组tuple或集合set。这是因为Python并不希望我们用户能直接操作这几个方法的返回值。 为了能够使用这三个方法返回的数据进行操作，我们有以下几种方案，但是无一例外都是使用的新数据，而并没有操作原字典 数据，即操作并不会影响改变字典 1）使用list()函数，将他们返回的数据转换成列表 12345a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;b = list(a.keys())print(b)a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;b = list(a.keys())print(b) 运行结果： 1[&#x27;数学&#x27;, &#x27;语文&#x27;, &#x27;英语&#x27;] 2）使用for in 循环遍历他们的返回值 123456789a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;for k in a.keys(): print(k,end=&#x27; &#x27;)print(&quot; ---------------&quot;)for v in a.values(): print(v,end=&#x27; &#x27;)print(&quot; ---------------&quot;)for k,v in a.items(): print(&quot;key:&quot;,k,&quot; value:&quot;,v) 运行结果： 1234567数学 语文 英语---------------95 89 90---------------key: 数学 value: 95key: 语文 value: 89key: 英语 value: 90 copy()方法 copy()方法返回一个字典的拷贝，也即返回一个具有相同键值对的新字典 123a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1,2,3]&#125;b = a.copy()print(b) 运行结果： 1&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3]&#125; 但是我们要注意此时copy()方法只是浅拷贝，即只是对最表层的键值对进行了深拷贝，也就是说它会再申请一块内存用来存放&#123;'one':1,'two':2,'three':[]&#125;,而对于某些列表类型的值来说，此方法对其做的是浅拷贝，也就是说，b中的[1,2,3]的值不是自己独有的， 而是和a共有指向的统一内存单元。 12345678910a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1,2,3]&#125;b = a.copy()#向 a 中添加新键值对，由于b已经提前将 a 所有键值对都深拷贝过来，因此 a 添加新键值对，不会影响 b。a[&#x27;four&#x27;]=100print(a)print(b)#由于 b 和 a 共享[1,2,3]（浅拷贝），因此移除 a 中列表中的元素，也会影响 b。a[&#x27;three&#x27;].remove(1)print(a)print(b) 运行结果： 1234&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3], &#x27;four&#x27;: 100&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1, 2, 3]&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [2, 3], &#x27;four&#x27;: 100&#125;&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [2, 3]&#125; 从运行结果不难看出，对a增加新键值对，b不变；而修改a某键值对中列表内的元素，b也会相应改变。 update()方法 update()方法可以使用一个字典所包含的键值对来更新已有的字典。在执行update()方法时，如果被更新的字典已包含对应的键值对，那么value会被覆盖，如果被更新的字典中不包含对应的键值对，那么键值对被添加进去。 123a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125;a.update(&#123;&#x27;one&#x27;:4.5, &#x27;four&#x27;: 9.3&#125;)print(a) 运行结果： 1&#123;&#x27;one&#x27;: 4.5, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3, &#x27;four&#x27;: 9.3&#125; 从运行结果可以看出，由于被更新的字典已经包含key为&quot;one&quot;的键值对，因此更改时键值对的value被改写，而被更新的字典中不包含key为“four&quot;的键值对，所以更新时会为原字典增加一个新的键值对。 pop()和popitem(）方法 pop和popitem()都用来删除字典中的键值对，不同的是，pop()用来删除指定的键值对，而popitem()用来随机删除一个键值对，他们得语法格式如下： 12dictname.pop(key)dictname.popitem() 123456a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;化学&#x27;: 83, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;print(a)a.pop(&#x27;化学&#x27;)print(a)a.popitem()print(a) 运行结果： 123&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;化学&#x27;: 83, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;生物&#x27;: 98, &#x27;物理&#x27;: 89&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;生物&#x27;: 98&#125; 思考：popitem()的底层原理？ 其实，说popitem()随机删除字典中的一个键值对是不准确的，虽然字典时一种无序的列表，但是键值对在底层也是有存储顺序的，popitem()总是弹出底层的最后一个key-value，这和列表的pop()方法类似，都实现了数据结构中的“出栈”的操作。 setdefault()方法 setdefault()方法用来返回字典中某个key对应的value值，但是他在返回前会进行以下操作： 如果该 key 存在，那么直接返回该 key 对应的 value； 如果该 key 不存在，那么先为该 key 设置默认的 defaultvalue（可以理解为插入了一个新的键值对，key-defaultvalue），然后再返回该 key 对应的 defaultvalue。 1234567891011a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;print(a)#key不存在，指定默认值a.setdefault(&#x27;物理&#x27;, 94)print(a)#key不存在，不指定默认值a.setdefault(&#x27;化学&#x27;)print(a)#key存在，指定默认值a.setdefault(&#x27;数学&#x27;, 100)print(a) 运行结果： 1234&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94, &#x27;化学&#x27;: None&#125;&#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90, &#x27;物理&#x27;: 94, &#x27;化学&#x27;: None&#125; 我们发现由于前两次调用setdefault()时传入的键都是在字典中不存在的，因此会在字典中加入这个新的键值对，值就是defaultvalue可以自定义或者默认为None，但是如果穿入的键存在，那么后面的defaultvalue将没有任何作用，直接返还字典key对应的value值。 Python使用字典格式化字符串 之前我们学习过使用转换说明符来格式化输出字符串，比如： 123name=&quot;小明&quot;age = 8print(&quot;%s已经%d岁了！&quot; % (name,age)) 运行结果： 1小明已经8岁了！ 但是这是变量比较少的情况，如果变量非常多，那么此时我们再使用这种形式格式化字符串就变得异常麻烦，因此我们接下来学习使用字典来格式化字符串： 12345678 字符串模板中使用keytemp = &#x27;教程是:%(name)s, 价格是:%(price)010.2f, 出版社是:%(publish)s&#x27;book = &#123;&#x27;name&#x27;:&#x27;Python基础教程&#x27;, &#x27;price&#x27;: 99, &#x27;publish&#x27;: &#x27;C语言中文网&#x27;&#125;# 使用字典为字符串模板中的key传入值print(temp % book)book = &#123;&#x27;name&#x27;:&#x27;C语言小白变怪兽&#x27;, &#x27;price&#x27;:159, &#x27;publish&#x27;: &#x27;C语言中文网&#x27;&#125;# 使用字典为字符串模板中的key传入值print(temp % book) 运行结果： 12教程是:Python基础教程, 价格是:0000099.00, 出版社是:C语言中文网教程是:C语言小白变怪兽, 价格是:0000159.00, 出版社是:C语言中文网 要注意对应的键是写在百分号%和转换符字母之间的，比如%(price)010.2f表示的是此处输出的字典中price键对应的值价钱应为一个小数，并且最小宽度为10（不足就前面补0），同时保留两位小数。 Python set集合详解 Python中的集合，与数学中的和概念一致，用来保存不重复的元素，即集合中的元素都是唯一的，互不相同。从形式上看，和字典类似，Python集合会将所有元素放在一对大括号&#123;&#125;中，相邻元素使用逗号,分开 1&#123;element1,element2,...,elementn&#125; 集合可以存储无限多个元素。**从内容上看，集合只能存储不可变的数据类型，包括整型、浮点型、字符型、元组。但是无法存储列表、字典、集合这些可变的数据类型，否则Python解释器就会抛出TypeError错误。**比如说： 123456789101112131415&gt;&gt;&gt; &#123;&#123;&#x27;a&#x27;:1&#125;&#125;Traceback (most recent call last): File &quot;&lt;pyshell#8&gt;&quot;, line 1, in &lt;module&gt; &#123;&#123;&#x27;a&#x27;:1&#125;&#125;TypeError: unhashable type: &#x27;dict&#x27;&gt;&gt;&gt; &#123;[1,2,3]&#125;Traceback (most recent call last): File &quot;&lt;pyshell#9&gt;&quot;, line 1, in &lt;module&gt; &#123;[1,2,3]&#125;TypeError: unhashable type: &#x27;list&#x27;&gt;&gt;&gt; &#123;&#123;1,2,3&#125;&#125;Traceback (most recent call last): File &quot;&lt;pyshell#10&gt;&quot;, line 1, in &lt;module&gt; &#123;&#123;1,2,3&#125;&#125;TypeError: unhashable type: &#x27;set&#x27; 要注意集合中的元素是唯一的，对于重复出现的数据元素，只会保留一份 12&gt;&gt;&gt; &#123;1,2,1,(1,2,3),&#x27;c&#x27;,&#x27;c&#x27;&#125;&#123;1, 2, &#x27;c&#x27;, (1, 2, 3)&#125; 由于Python中的set集合是无序的，因此每一次输出元素的排列顺序都是不同的。 其实Python中有两种集合类型，一种是set类型的集合，另一种是frozenset类型的集合，他们的唯一区别就是set类型集合可以做添加、删除元素的操作，而frozenset类型集合不行。 Python创建set集合 Python提供了2种创建set集合的方法，分别是使用{}创建和使用set()函数将列表、元组等类型数据转换为集合。 1）使用{}创建集合 在Python中，创建set集合可以像列表、元素和字典一样，直接将集合赋值给变量，从而实现创建集合的目的，其语法格式如下： 1setname = &#123;element1,element2,...,elementn&#125; 其中，setname 表示集合的名称，起名时既要符合 Python 命名规范，也要避免与 Python 内置函数重名。 12a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;print(a) 运行结果： 1&#123;1, &#x27;c&#x27;, (1, 2, 3)&#125; 2）set()函数创建集合 set()函数为Python的内置函数，其功能是将字符串、列表、元组、range()对象等可迭代对象转换成集合，该函数的语法如下： 1setname = set(iteration) 其中，iteration 就表示字符串、列表、元组、range 对象等数据。 123456set1 = set(&quot;c.biancheng.net&quot;)set2 = set([1,2,3,4,5])set3 = set((1,2,3,4,5))print(&quot;set1:&quot;,set1)print(&quot;set2:&quot;,set2)print(&quot;set3:&quot;,set3) 运行结果： 123set1: &#123;&#x27;a&#x27;, &#x27;g&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;n&#x27;, &#x27;h&#x27;, &#x27;.&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;e&#x27;&#125;set2: &#123;1, 2, 3, 4, 5&#125;set3: &#123;1, 2, 3, 4, 5&#125; 注意如果要创建空集合，只能使用set()函数实现，因为直接使用一对{}，Python解释器会将其视为一个空字典。 Python访问set集合元素 由于集合中的元素是无序的，因此无法像列表那样使用下表索引来访问元素，Python中，访问集合元素最常用的方法就是使用循环结构，将集合的数据逐一读取出来。 123a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;for ele in a: print(ele,end=&#x27; &#x27;) 运行结果： 11 c (1, 2, 3) Python删除set集合 1234a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;print(a)del(a)print(a) 运行结果： 12345&#123;1, &#x27;c&#x27;, (1, 2, 3)&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; print(a)NameError: name &#x27;a&#x27; is not defined Python set集合基础操作 向set集合中添加元素 我们要注意，使用add()方法向set集合添加元素时，只能是数字，字符串，元组或者布尔类型，不能添加列表、元组或者集合这些可变的数据，否则Python解释器会报TypeError错误。 12345a = &#123;1,2,3&#125;a.add((1,2))print(a)a.add([1,2])print(a) 运行结果： 12345&#123;(1, 2), 1, 2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.add([1,2])TypeError: unhashable type: &#x27;list&#x27; 从set集合中删除元素 使用remove()可以删除集合中的元素，但是我们要注意如果被删除的元素不包含在集合中，那么这个方法会抛出KeyError错误，例如： 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.remove(1)print(a) 运行结果： 12345&#123;2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.remove(1)KeyError: 1 如果使用此方法删除集合中元素，需要注意的是，如果被删除的元素就不包含在集合中，那么此方法就会抛出KeyError异常，例如： 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.remove(1)print(a) 运行结果为： 12345&#123;2, 3&#125;Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\1.py&quot;, line 4, in &lt;module&gt; a.remove(1)KeyError: 1 为了避免这种报错，我们可以哈斯用discard()方法，此方法和remove()方法的用法完全相同，唯一的区别就是当删除集合中元素失败时，此方法不会抛出任何错误。 12345a = &#123;1,2,3&#125;a.remove(1)print(a)a.discard(1)print(a) 运行结果： 12&#123;2, 3&#125;&#123;2, 3&#125; Python set集合做交集、并集、差集运算 集合最常用的操作就是交集、并集、差集以及对称差集运算，如下所示： 我们可以使用如下代码实现不同的集合运算： 运算操作 Python运算符 含义 例子 交集 &amp; 取两集合公共的元素 &gt;&gt;&gt; set1 &amp; set2 {3} 并集 丨 取两集合全部的元素 &gt;&gt;&gt; set1 丨 set2 {1,2,3,4,5} 差集 - 取一个集合中另一集合没有的元素 &gt;&gt;&gt; set1 - set2 {1,2} &gt;&gt;&gt; set2 - set1 {4,5} 对称差集 ^ 取集合 A 和 B 中不属于 A&amp;B 的元素 &gt;&gt;&gt; set1 ^ set2 {1,2,4,5} Python set集合方法大全 这里我们给出C语言编程网的Python中集合函数大全方便查阅： http://c.biancheng.net/view/4402.htmlhttps://scholar.coolchong.cn/set%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C%E5%A4%A7%E5%85%A8, Python frozenset set是一个可变序列，程序可以改变序列中的元素，而frozenset集合是不可变序列，程序是不能改变不可变序列中的元素的。set结合所支持的add()、remove()、discard()等方法frozenset一概不支持，而set中不改变集合本身的方法frozenset也支持。 我们在以下两种场景下会使用到frozenset，也正是这两个场景确立了frozenset的不可替代性： 当集合的元素不需要改变时，我们可以使用 fronzenset 替代 set，这样更加安全。 有时候程序要求必须是不可变对象，这个时候也要使用 fronzenset 替代 set。比如，字典（dict）的键（key）就要求是不可变对象。 一定要注意字典的键是不允许发生改变的，因此他不支持list,set这些可变序列数据类型的。 123456789s = &#123;&#x27;Python&#x27;, &#x27;C&#x27;, &#x27;C++&#x27;&#125;fs = frozenset([&#x27;Java&#x27;, &#x27;Shell&#x27;])s_sub = &#123;&#x27;PHP&#x27;, &#x27;C#&#x27;&#125;#向set集合中添加frozensets.add(fs)print(&#x27;s =&#x27;, s)#向为set集合添加子set集合s.add(s_sub)print(&#x27;s =&#x27;, s) 运行结果： 12345s = &#123;&#x27;Python&#x27;, frozenset(&#123;&#x27;Java&#x27;, &#x27;Shell&#x27;&#125;), &#x27;C&#x27;, &#x27;C++&#x27;&#125;Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 11, in &lt;module&gt; s.add(s_sub)TypeError: unhashable type: &#x27;set&#x27; 要注意，set集合本身的元素要求是不可变的，因此set的元素是不能为set的，即set集合不支持嵌套的，但是我们可以向set中加入frozenset的，因为他是不可变的集合类型。 深入底层了解Python字典和集合 在Python中字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作。我们首先拿列表介绍一下复杂度： 假设现在有一个存储产品信息（产品ID、名称和价格）的列表，现在的需求是，借助某件产品的ID找出其价格，则实现代码如下： 1234567891011def find_product_price(products, product_id): for id, price in products: if id == product_id: return price return Noneproducts = [ (111, 100), (222, 30), (333, 150)]print(&#x27;The price of product 222 is &#123;&#125;&#x27;.format(find_product_price(products, 222))) 运行结果： 1The price of product 222 is 30 如上查找列表时，如果列表有n个元素，因为查找的过程需要遍历列表，那么最坏的情况时间复杂度是O(n)。即使对列表进行了排序，再使用二分查找算法，也需要O(logn)的时间复杂度，更何况列表的排序还需要O(nlogn)的时间。 当如果用字典来存储这些数据，那么查找就会非常便捷高效，只需要O(1)的时间复杂度就可以完成，因为可以通过键的哈希值，找到对应的值，而不需要对字典做遍历操作，实现代码如下： 123456products = &#123; 111: 100, 222: 30, 333: 150&#125;print(&#x27;The price of product 222 is &#123;&#125;&#x27;.format(products[222])) 运行结果为： 1The price of product 222 is 30 如下是一个简单的列表查找和字典查找的速度对比，我们可以看到仅仅十万的数据量，两者的速度差异就如此之大： 123456789101112131415161718192021222324252627#统计时间需要用到 time 模块中的函数，了解即可import timedef find_unique_price_using_list(products): unique_price_list = [] for _, price in products: # A if price not in unique_price_list: #B unique_price_list.append(price) return len(unique_price_list)id = [x for x in range(0, 100000)]price = [x for x in range(200000, 300000)]products = list(zip(id, price))# 计算列表版本的时间start_using_list = time.perf_counter()find_unique_price_using_list(products)end_using_list = time.perf_counter()print(&quot;time elapse using list: &#123;&#125;&quot;.format(end_using_list - start_using_list))#使用集合完成同样的工作def find_unique_price_using_set(products): unique_price_set = set() for _, price in products: unique_price_set.add(price) return len(unique_price_set)# 计算集合版本的时间start_using_set = time.perf_counter()find_unique_price_using_set(products)end_using_set = time.perf_counter()print(&quot;time elapse using set: &#123;&#125;&quot;.format(end_using_set - start_using_set)) 运行结果： 12time elapse using list: 68.78650900000001time elapse using set: 0.010747099999989018 而往往企业的后台数据都有上亿乃至十亿数量级，因此如果使用了不合适的数据结构，很容易造成服务器的崩溃。因此字典和集合O(1)的复杂度可谓是相当快速了，加下来我们就了解一下他们的底层实现原理。 字典和集合的工作原理 字典和集合能如此高效，和他们的数据结构密不可分，不同于其他数据结构，字典和集合内部结构都是一张哈希表： 对于字典而言，这张表存储了哈希值（hash）、键和值这 3 个元素。 而对集合来说，哈希表内只存储单一的元素。 对于之前版本的Python，他的哈希结构如下： 12345678 | 哈希值 (hash) 键 (key) 值 (value). | ...0 | hash0 key0 value0. | ...1 | hash1 key1 value1. | ...2 | hash2 key2 value2. | ... 但是我们发现这种结构的弊端，是随着哈希表的扩张，他会变得越来越稀疏，比如有这样一个字典： 1&#123;&#x27;name&#x27;: &#x27;mike&#x27;, &#x27;dob&#x27;: &#x27;1999-01-01&#x27;, &#x27;gender&#x27;: &#x27;male&#x27;&#125; 那么他会存储为如下结构： 123456789entries = [[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;][-230273521, &#x27;dob&#x27;, &#x27;1999-01-01&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[1231236123, &#x27;name&#x27;, &#x27;mike&#x27;],[&#x27;--&#x27;, &#x27;--&#x27;, &#x27;--&#x27;],[9371539127, &#x27;gender&#x27;, &#x27;male&#x27;]] 三个键值对数据却需要哈希表开辟7个空间，显然非常浪费存储空间，为了提高存储空间的利用率，现在的哈希表除了字典本身的结构，会把索引和哈希值、键、值单独分开，也就是采用如下这种结构： 12345678910111213141516Indices----------------------------------------------------None | index | None | None | index | None | index ...----------------------------------------------------Entries--------------------hash0 key0 value0---------------------hash1 key1 value1---------------------hash2 key2 value2--------------------- ...--------------------- 这和数据结构中的索引表建立类似，此时哈希表内键哈希值不同的键值对存储到了相邻的存储单元，而我们使用indices来表示哈希表内的关系，这样就节省了大量的空间。因此此时上面的字典在新哈希表结构下的存储形式为： 123456indices = [None, 1, None, None, 0, None, 2]entries = [[1231236123, &#x27;name&#x27;, &#x27;mike&#x27;],[-230273521, &#x27;dob&#x27;, &#x27;1999-01-01&#x27;],[9371539127, &#x27;gender&#x27;, &#x27;male&#x27;]] 哈希表插入数据 当我们向字典中插入数据时，Python会首先根据键(key)计算出对应的哈希值（通过hash(key)函数计算)，而向集合中插入数据时，Python会根据元素本身计算对应的哈希值（通过hash(values)函数计算)。 1234dic = &#123;&quot;name&quot;:1&#125;print(hash(&quot;name&quot;))setDemo = &#123;1&#125;print(hash(1)) 运行结果： 1282301150420083146831 得到哈希值（例如hash)之后，再结合字典或集合要存储数据的个数（例如n),就可以得到该元素应该插入到哈希表中的位置（比如,可以用hash%n的方式) 如果哈希表中此位置是空的，那么此元素可以直接插入其中，反之如果此位置已经被其他元素占用，那么Python会比较这两个元素的哈希值和键是否相等： 如果相等，则表明该元素已经存在，再比较他们的值，不相等就进行更新； 如果不相等，这种情况称为哈希冲突（即两个元素的键不同，但求得的哈希值相同）。这种情况下，Python 会使用开放定址法、再哈希法等继续寻找哈希表中空余的位置，直到找到位置。 哈希表查找数据 在哈希表中查找数据，和插入操作类似，Python 会根据哈希值，找到该元素应该存储到哈希表中的位置，然后和该位置的元素比较其哈希值和键（集合直接比较元素值）： 如果相等，则证明找到； 反之，则证明当初存储该元素时，遇到了哈希冲突，需要继续使用当初解决哈希冲突的方法进行查找，直到找到该元素或者找到空位为止。 这里的空位，表示哈希表没有存储目标元素 哈希表删除元素 对于删除操作，Python会暂时对这个位置的元素赋予一个特殊的值，等到重新调整哈希表的大小时，再将其删除。 需要注意的是，哈希冲突的发生往往会降低字典和集合操作的速度。因此，为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有 1/3 的剩余空间。随着元素的不停插入，当剩余空间小于 1/3 时，Python 会重新获取更大的内存空间，扩充哈希表，与此同时，表内所有的元素位置都会被重新排放。 虽然哈希冲突和哈希表大小的调整，都会导致速度减缓，但是这种情况发生的次数极少。所以，平均情况下，仍能保证插入、查找和删除的时间复杂度为 O(1)。 Python深拷贝和浅拷贝详解 Python浅拷贝 常见的浅拷贝方法，是使用数据类型本身的构造器，比如下面两个例子： 12345678910list1 = [1, 2, 3]list2 = list(list1)print(list2)print(&quot;list1==list2 ?&quot;,list1==list2)print(&quot;list1 is list2 ?&quot;,list1 is list2)set1= set([1, 2, 3])set2 = set(set1)print(set2)print(&quot;set1==set2 ?&quot;,set1==set2)print(&quot;set1 is set2 ?&quot;,set1 is set2) 运行结果： 123456[1, 2, 3]list1==list2 ? Truelist1 is list2 ? False&#123;1, 2, 3&#125;set1==set2 ? Trueset1 is set2 ? False 在上面程序中，list2就是list1的浅拷贝，同理set2是set1的浅拷贝。当然，对于可变的序列，还可以通过切片操作符:来完成浅拷贝，例如： 12345list1 = [1, 2, 3]list2 = list1[:]print(list2)print(&quot;list1 == list2 ?&quot;,list1 == list2)print(&quot;list1 is list2 ?&quot;,list1 is list2) 运行结果： 123[1, 2, 3]list1 == list2 ? Truelist1 is list2 ? False 除此之外，Python 还提供了对应的函数 copy.copy() 函数，适用于任何数据类型。其用法如下： 123456import copylist1 = [1, 2, 3]list2 = copy.copy(list1)print(list2)print(&quot;list1 == list2 ?&quot;,list1 == list2)print(&quot;list1 is list2 ?&quot;,list1 is list2) 运行结果： 123[1, 2, 3]list1 == list2 ? Truelist1 is list2 ? False 不过要注意的是，对于元组，使用tuple()或者切片操作符:不会创建一个浅拷贝，相反他会创建一个指向相同元组的引用： 12345tuple1 = (1, 2, 3)tuple2 = tuple(tuple1)print(tuple2)print(&quot;tuple1 == tuple2 ?&quot;,tuple1 == tuple2)print(&quot;tuple1 is tuple2 ?&quot;,tuple1 is tuple2) 运行结果： 1231, 2, 3)tuple1 == tuple2 ? Truetuple1 is tuple2 ? True 此程序中，元组 (1, 2, 3) 只被创建一次，t1 和 t2 同时指向这个元组。 思考：什么时候构造器和切片返还的是引用？什么时候是新数据？ 这里有一个规律，就是凡是可变数据类型，那么构造器或者切片返还的就是一个新的浅拷贝数据；凡是不可变数据类型，那么构造器或者切片返还的就是一个指向原内存单元的引用 以下是验证，我们发现对于string还是frozenset最终返还的都是引用，而dict就是一个新的拷贝数据 12345678910111213&gt;&gt;&gt; s1=&quot;hello&quot;&gt;&gt;&gt; s2=s1[:]&gt;&gt;&gt; print(s2 is s1)True# frozenset不能切片，因此使用构造器&gt;&gt;&gt; fs1=frozenset([1,2,3])&gt;&gt;&gt; fs2=frozenset(fs1)&gt;&gt;&gt; print(fs2 is fs1)True# 字典不能切片，因此也使用构造器&gt;&gt;&gt; d1=&#123;&#x27;name&#x27;:&#x27;langwenchong&#x27;,&#x27;age&#x27;:20&#125;&gt;&gt;&gt; d2=dict(d1)&gt;&gt;&gt; print(d2 is d1) 思考：那么怎样才能让到d2和d1指向同一地址呢？ 很简单使用赋值即可，毕竟d1本身就是一个指向内存单元的指针： 123&gt;&gt;&gt; d2=d1&gt;&gt;&gt; print(d2 is d1)True 看到这里，也许你可能对浅拷贝有了初步的认识。浅拷贝，指的是重新分配一块内存，创建一个新的对象，但里面的元素是原对象中各个子对象的引用。 对数据采用浅拷贝的方式时，如果原对象中的元素不可变，那倒无所谓；但如果元素可变，浅拷贝通常会出现一些问题，例如： 1234567891011list1 = [[1, 2], (30, 40)]list2 = list(list1)list1.append(100)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[0].append(3)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[1] += (50, 60)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2) 运行结果为： 123456list1: [[1, 2], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40), 100]list2: [[1, 2, 3], (30, 40)]list1: [[1, 2, 3], (30, 40, 50, 60), 100]list2: [[1, 2, 3], (30, 40)] 再来看，list1[0].append(3) 表示对 list1 中的第一个列表新增元素 3。因为 list2 是 list1 的浅拷贝，list2 中的第一个元素和 list1 中的第一个元素，共同指向同一个列表，因此 list2 中的第一个列表也会相对应的新增元素 3。 最后是 list1[1] += (50, 60)，因为元组是不可变的，这里表示对 list1 中的第二个元组拼接，然后重新创建了一个新元组作为 list1 中的第二个元素，而 list2 中没有引用新元组，因此 list2 并不受影响。 通过这个例子，你可以很清楚地看到使用浅拷贝可能带来的副作用。如果想避免这种副作用，完整地拷贝一个对象，就需要使用深拷贝。所谓深拷贝，是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。 Python深拷贝 Python 中以 copy.deepcopy() 来实现对象的深度拷贝。比如上述例子写成下面的形式，就是深度拷贝： 123456789101112import copylist1 = [[1, 2], (30, 40)]list2 = copy.deepcopy(list1)list1.append(100)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[0].append(3)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2)list1[1] += (50, 60)print(&quot;list1:&quot;,list1)print(&quot;list2:&quot;,list2) 运行结果： 123456list1: [[1, 2], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40), 100]list2: [[1, 2], (30, 40)]list1: [[1, 2, 3], (30, 40, 50, 60), 100]list2: [[1, 2], (30, 40)] 不过，深度拷贝也不是完美的，往往也会带来一系列问题。如果被拷贝对象中存在指向自身的引用，那么程序很容易陷入无限循环，例如： 123456import copylist1 = [1]list1.append(list1)print(list1)list2 = copy.deepcopy(list1)print(list2) 运行结果为： 12[1, [...]][1, [...]] 此例子中，列表 x 中有指向自身的引用，因此 x 是一个无限嵌套的列表。但是当深度拷贝 x 到 y 后，程序并没有出现栈溢出的现象。这是为什么呢？ 其实，这是因为深度拷贝函数 deepcopy 中会维护一个字典，记录已经拷贝的对象与其 ID。拷贝过程中，如果字典里已经存储了将要拷贝的对象，则会从字典直接返回。通过查看 deepcopy 函数实现的源码就会明白： 12345678910111213def deepcopy(x, memo=None, _nil=[]): &quot;&quot;&quot;Deep copy operation on arbitrary Python objects. See the module&#x27;s __doc__ string for more info. &quot;&quot;&quot; if memo is None: memo = &#123;&#125; d = id(x) # 查询被拷贝对象 x 的 id y = memo.get(d, _nil) # 查询字典里是否已经存储了该对象 if y is not _nil: return y # 如果字典里已经存储了将要拷贝的对象，则直接返回 ..."},{"title":"列表","path":"/wiki/Python学习笔记/列表/index.html","content":"Python序列 所谓序列，就是一块可以存放多个值的连续内存空间，这些值按照一定的顺序排列，可以通过每一个值所在位置的编号（称为索引）访问他们。 在Python中，序列类型包括字符串、列表（也称为数组）、元组、集合与字典（也称为映射），这些序列支持以下几种通用的操作。但是特殊地是集合和字典不支持索引、切片、相加和相乘操作。 序列索引 这个很好理解，从左到右索引值从0开始递增，我们使用A[index]的形式就可以获取指定位置的序列元素： 除此之外，Python还支持索引值是负数，此时索引是从又向左计数，换句话说，从最后一个元素开始计数，从索引值-1开始向左递减，如下所示： 要注意，使用负值作为序列中各元素的索引值时，是从-1开始，而不是从0开始，因为-0就是0就是开头元素。 123str=&quot;你好呀大帅哥&quot;print(str[0],&quot;==&quot;,str[-6])print(str[5],&quot;==&quot;,str[-1]) 运行结果： 12你 == 你哥 == 哥 序列切片 切片操作是访问序列中元素的另一种方法啊，他可以访问一定范围内的元素，通过切片操作，可以生成一个新的序列。一定要注意切片并不是操作原序列，而是生成一个新序列。 1sname[start : end : step] 其中，各个参数的含义分别是： sname：表示序列的名称； start：表示切片的开始索引位置（包括该位置），此参数也可以不指定，会默认为 0，也就是从序列的开头进行切片； end：表示切片的结束索引位置（不包括该位置），如果不指定，则默认为序列的长度； step：表示在切片过程中，隔几个存储位置（包含当前位置）取一次元素，也就是说，如果 step 的值大于 1，则在进行切片去序列元素时，会“跳跃式”的取元素。如果省略设置 step 的值，则最后一个冒号就可以省略。 要注意切片的范围是左闭右开[start,end），同时step默认是1，想要隔k个元素取一个元素，那么step要设置为step+1 1234567str=&quot;你好呀大帅哥&quot;#取索引区间为[0,2]之间（不包括索引2处的字符）的字符串print(str[:2])#隔 1 个字符取一个字符，区间是整个字符串print(str[::2])#取整个字符串，此时 [] 中只需一个冒号即可print(str[:]) 运行结果： 123你好你呀帅你好呀大帅哥 序列相加 Python中支持两种类型相同的序列使用+运算符进行相加操作，他会将两个序列进行连接，但是并不会取出重复的元素，而是仅仅简单的拼接。同时要注意这里的类型相同指的是两侧序列要么都是列表类型，要么都是元组类型，要么都是字符串。 序列相乘 在Python中，使用数字乘以一个序列会生成新的序列，其内容为原来序列被重复n次的结果。例如： 12str=&quot;你好呀大帅哥&quot;print(str*3) 运行结果： 1&#x27;你好呀大帅哥你好呀大帅哥你好呀大帅哥&#x27; 同时比较特殊的，列表类型在进行乘法运算时，还可以实现初始化指定长度列表的功能。例如如下的代码，将创建一个长度为5的列表，列表中的每一个元素都是None，表示什么都没有。 123#列表的创建用 []，后续讲解列表时会详细介绍list = [None]*5print(list) 运行结果： 1[None, None, None, None, None] 检查元素是否包含在序列中 在Python中，可以使用in关键字检查某元素是否为序列的成员，其语法格式为： 1value in sequence 其中value表示要检查的元素，sequence表示指定的序列。如下代码所示： 12str=&quot;coolchong.cn&quot;print(&#x27;c&#x27; in str) 运行结果： 1True 同时还有一个not in 关键字，他可以用来检查元素是否不包含在指定的序列中，比如： 12str=&quot;coolchong.cn&quot;print(&#x27;c&#x27; not in str) 运行结果： 1False 和序列相关的内置函数 同时Python还提供了一些有关序列的内置函数，其功能如下,注意这些函数都不会直接操作原序列而是生成一个新的值： 函数 功能 len() 计算序列的长度，即返回序列中包含多少个元素。 max() 找出序列中的最大元素。 min() 找出序列中的最小元素。 list() 将序列转换为列表。 str() 将序列转换为字符串。 sum() 计算元素和。注意，对序列使用 sum() 函数时，做加和操作的必须都是数字，不能是字符或字符串，否则该函数将抛出异常，因为解释器无法判定是要做连接操作（+ 运算符可以连接两个序列），还是做加和操作。 sorted() 对元素进行排序。（类型不变） reversed() 反向序列中的元素。（类型会变成reversed，需要再使用list()、或者tuple()转换回去） enumerate() 将序列组合为一个索引序列，多用在 for 循环中。 思考：enumerate()方法的应用？ 1enumerate(sequence, [start=0]) sequence是一个输入序列，start是下标起始位置，方法返回的是一个枚举对象。 12345&gt;&gt;&gt; seasons = [&#x27;Spring&#x27;, &#x27;Summer&#x27;, &#x27;Fall&#x27;, &#x27;Winter&#x27;]&gt;&gt;&gt; list(enumerate(seasons))[(0, &#x27;Spring&#x27;), (1, &#x27;Summer&#x27;), (2, &#x27;Fall&#x27;), (3, &#x27;Winter&#x27;)]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, &#x27;Spring&#x27;), (2, &#x27;Summer&#x27;), (3, &#x27;Fall&#x27;), (4, &#x27;Winter&#x27;)] 在遍历一个序列（列表或者元组）时，我们可以如下遍历，这样就同时可以使用索引和元素值了： 1234567&gt;&gt;&gt; seq = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]&gt;&gt;&gt; for i, element in enumerate(seq):... print i, element...0 one1 two2 three 思考：sorted(list)与list.sort()的区别？ 首先两种写法都是正确的，可以对列表进行排序，但是两个方法略有不同。首先就是返还值不同，sorted()是返还一个新的列表并不会操作原序列，而list.sort()则是直接操作原序列进行排序并且返还一个值None 1234567&gt;&gt;&gt; lst=[1,3,2,4]&gt;&gt;&gt; a=sorted(lst)&gt;&gt;&gt; print(lst,a,sep=&#x27;\\t&#x27;)[1, 3, 2, 4] [1, 2, 3, 4]&gt;&gt;&gt; b=lst.sort()&gt;&gt;&gt; print(lst,b,sep=&#x27;\\t&#x27;)[1, 2, 3, 4] None 同时sorted()和list.sort()还都可以通过使用key参数指定排序规则，并且是稳定排序，也就是说对于指定规则不能涵盖的元素，本来谁在前面，排好以后谁还是在前面。如下所示我们对列表重新制定排序规则，通过使用lambd重新定义排序规则为按照元素转换成字符串以后的长度排序： 12345678&gt;&gt;&gt; lst=[1,2,3,13,7,11]&gt;&gt;&gt; c=sorted(lst,key=lambda x:len(str(x)))&gt;&gt;&gt; print(lst,c,sep=&#x27;\\t&#x27;)[1, 2, 3, 13, 7, 11] [1, 2, 3, 7, 13, 11]&gt;&gt;&gt; d=lst.sort(key=lambda x:len(str(x)))&gt;&gt;&gt; print(lst,d,sep=&#x27;\\t&#x27;)[1, 2, 3, 7, 13, 11] None&gt;&gt;&gt; 实际上sorted()和list.sort()都是在通过key的值比较进行递增排序，默认key=None的但是我们也可以重定义key，一般使用lambda进行重定义（后面会讲到lambda，这里了解即可） 思考：如何实现降序排序？ 实际上排序函数语法如下： 12sorted(iterable,key=None,reverse=False)list.sort(iterable,key=None,reverse=False) 因此降序我们只需要将reverse设置为True即可啦： 1234567&gt;&gt;&gt; lst=[1,2,3,4,45,6]&gt;&gt;&gt; e=sorted(lst,reverse=True)&gt;&gt;&gt; print(lst,e,sep=&#x27;\\t&#x27;)[1, 2, 3, 4, 45, 6] [45, 6, 4, 3, 2, 1]&gt;&gt;&gt; f=lst.sort(reverse=True)&gt;&gt;&gt; print(lst,f,sep=&#x27;\\t&#x27;)[45, 6, 4, 3, 2, 1] None Python列表(list) 在C和Java中我们通常是使用数组Array来存储多个相邻连接的数据，但是在Python中是没有数组的，而是提供了一个更加强大的列表类型，他可以按成数组的所有操作同时还具有一些更加强大的函数。从形似上看，列表就是将所有元素放到一个中括号[]中，相邻元素之间使用,分隔，如下： 1[element1,element2,element3,...,elementn] Python的列表没有个数限制，存储范围为无限大，同时内容可以是任何类型如下所示一个列表可以存储许多不同类型的元素： 1[&quot;http://coolchong.cn/&quot;, 1, [2,3,4] , 3.0] 但是为了提高代码可读性，我们通常默认推荐使用列表存放一些数据类型相同的元素 Python创建列表 在Python中有两种创建列表的方法： 1）使用[]直接创建列表 使用[]创建列表，同时使用=将列表赋值给一个变量： 123um = [1, 2, 3, 4, 5, 6, 7]name = [&quot;C语言中文网&quot;, &quot;coolchong.cn&quot;]program = [&quot;C语言&quot;, &quot;Python&quot;, &quot;Java&quot;] 创建一个空列表只需要用[]表示即可 1emptylist=[] 2）使用list()函数创建列表 使用内置函数lis()创建一个列表，使用它可以将其他数据数据类型转换为列表类型： 1234567891011121314151617#将字符串转换成列表list1 = list(&quot;hello&quot;)print(list1)#将元组转换成列表tuple1 = (&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;)list2 = list(tuple1)print(list2)#将字典转换成列表dict1 = &#123;&#x27;a&#x27;:100, &#x27;b&#x27;:42, &#x27;c&#x27;:9&#125;list3 = list(dict1)print(list3)#将区间转换成列表range1 = range(1, 6)list4 = list(range1)print(list4)#创建空列表print(list()) 运行结果： 12345[&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;][&#x27;Python&#x27;, &#x27;Java&#x27;, &#x27;C++&#x27;, &#x27;JavaScript&#x27;][&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;][1, 2, 3, 4, 5][] 注意对于字典转换为列表以后，只会存储key键，而映射值会丢失并不能存储到列表中 访问列表元素 列表是Python中序列的一种形式，因此我们可以使用索引来获取元素，同时也可以使用切片访问列表中的一组元素（得到的是一个新的子列表） 12345678url = list(&quot;http://c.biancheng.net/shell/&quot;)#使用索引访问列表中的某个元素print(url[3]) #使用正数索引print(url[-4]) #使用负数索引#使用切片访问列表中的一组元素print(url[9: 18]) #使用正数切片print(url[9: 18: 3]) #指定步长print(url[-6: -1]) #使用负数切片 运行结果： 12345pe[&#x27;b&#x27;, &#x27;i&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;c&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;n&#x27;, &#x27;g&#x27;][&#x27;b&#x27;, &#x27;n&#x27;, &#x27;e&#x27;][&#x27;s&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;] 一定要注意取元素一定是从左向右取，可以正/负索引搭配使用来划定要切片的范围，但是要保证范围是合法的 Python删除列表 对于不再使用的数据，我们统一使用del关键字进行删除，因此如果我们需要手动删除某个列表时使用del lst即可，如下： 1234intlist = [1, 45, 8, 34]print(intlist)del intlistprint(intlist) 运行结果： 12345[1, 45, 8, 34]Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 4, in &lt;module&gt; print(intlist)NameError: name &#x27;intlist&#x27; is not defined 思考：我们需要删除每一个不会再使用的变量吗？ 不需要，Python有自带的垃圾回收机制，当发现某个数据没有再被引用以后就会自动销毁，即使开发者不手动删除，Python也会自动将其回收。 Python list列表添加元素 我们直接尝试使用过+来拼接列表添加元素，如下所示： 123456language = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;]birthday = [1991, 1998, 1995]info = language + birthdayprint(&quot;language =&quot;, language)print(&quot;birthday =&quot;, birthday)print(&quot;info =&quot;, info) 运行结果： 123language = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]birthday = [1991, 1998, 1995]info = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, 1991, 1998, 1995] 但是我们会发现此时两个原列表并没有发生变化，拼接操作仅仅是将两个列表拼接生成一个新列表，但是我们如何修改原列表给他添加元素呢？ Python append()方法添加元素 append()方法就是用于在列表的末尾追加元素，该方法的语法格式如下： 1listname.append(obj) 其中listname就是要添加元素的列表，obj表示添加到列表末尾的数据，他可以是单个元素，也可以是列表、元组等。 1234567891011l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#追加元素l.append(&#x27;PHP&#x27;)print(l)#追加元组，整个元组被当成一个元素t = (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)l.append(t)print(l)#追加列表，整个列表也被当成一个元素l.append([&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l) 运行结果： 123[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;, (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;PHP&#x27;, (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;]] 我们会发现使用append()方法添加列表或者元组时得到的结果和我们预期略有不同，它仅仅是将列表或者元组整体追加到了后面，但是我们更希望把其内部的元素逐一取出添加到末尾。 Python extend()方法添加元素 extend()和append()的不同之处：extend()不会把列表或者元组视为一个整体，而是把它们包括的元素逐个添加到列表末尾。 1234567891011l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#追加元素l.extend(&#x27;C&#x27;)print(l)#追加元组，元祖被拆分成多个元素t = (&#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;)l.extend(t)print(l)#追加列表，列表也被拆分成多个元素l.extend([&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l) 运行结果： 123[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;, &#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;, &#x27;JavaScript&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;, &#x27;Ruby&#x27;, &#x27;SQL&#x27;] Python insert()方法插入元素 append()和extend()都只能在列表的末尾追加元素，但是如果我们希望在列表中间插入元素，那么次是就会使用到insert()方法，格式如下： 1listname.insert(index , obj) 其中，index表示指定位置的索引值，insert()会将obj插入到listname列表第index个元素的位置，更好理解的说就是新插入的元素在新标中的索引位置为index。同时我们要注意insert()也是将要插入的列表或者元组视为一个整体插入到列表中，这一点和append()一样。 1234567891011121314l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#插入元素l.insert(1, &#x27;C&#x27;)print(l)#插入元组，整个元祖被当成一个元素t = (&#x27;C#&#x27;, &#x27;Go&#x27;)l.insert(2, t)print(l)#插入列表，整个列表被当成一个元素l.insert(3, [&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l)#插入字符串，整个字符串被当成一个元素l.insert(0, &quot;http://coolchong.cn&quot;)print(l) 运行结果： 1234[&#x27;Python&#x27;, &#x27;C&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;], &#x27;C++&#x27;, &#x27;Java&#x27;][&#x27;coolchong.cn&#x27;, &#x27;Python&#x27;, &#x27;C&#x27;, (&#x27;C#&#x27;, &#x27;Go&#x27;), [&#x27;Ruby&#x27;, &#x27;SQL&#x27;], &#x27;C++&#x27;, &#x27;Java&#x27;] Python list列表删除元素 在Python列表中想要删除元素主要有以下三种场景： 根据目标元素所在位置的索引进行删除，可以使用 del 关键字或者 pop() 方法； 根据元素本身的值进行删除，可使用列表（list类型）提供的 remove() 方法； 将列表中所有元素全部删除，可使用列表（list类型）提供的 clear() 方法。 del:根据索引值删除元素 del是Python中的关键字，专门用来执行数据删除操作，他不仅可以删除列表整体，也可以删除列表中指定位置的元素。格式为： 1234#删除一个指定元素del listname[index]#删除[star,end)范围的元素del listname[start : end] 12345678910111213lang = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;, &quot;PHP&quot;, &quot;Ruby&quot;, &quot;MATLAB&quot;]#使用正数索引del lang[2]print(lang)#使用负数索引del lang[-2]print(lang)lang = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;, &quot;PHP&quot;, &quot;Ruby&quot;, &quot;MATLAB&quot;]del lang[1: 4]print(lang)lang.extend([&quot;SQL&quot;, &quot;C#&quot;, &quot;Go&quot;])del lang[-5: -2]print(lang) 运行结果： 1234[&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;PHP&#x27;, &#x27;Ruby&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;PHP&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;Ruby&#x27;, &#x27;MATLAB&#x27;][&#x27;Python&#x27;, &#x27;C#&#x27;, &#x27;Go&#x27;] 要注意dellistname[start,end]此时表示的就是删除原列表！ 思考：什么时候切片是新列表?什么时候是引用原列表？ 这个地方非常容易混淆，我们要注意：可以使用切片来截取列表中的任何部分，得到一个新列表，也可以通过切片来修改和删除列表中部分元素，甚至可以通过切片操作为列表对象增加元素。 只有在删除和=赋值的时候切片表示原引用列表，其他情况下都是一个新列表对象，如下所示： 12345678910111213&gt;&gt;&gt; lst=[1,2,3]#此时不是赋值，因此是为新列表添加元素，原列表不会发生变化&gt;&gt;&gt; lst[:].append(4)&gt;&gt;&gt; print(lst)[1, 2, 3]#此时是赋值修改，因此是原列表发生变化&gt;&gt;&gt; lst[:]=[1,2,3,4]&gt;&gt;&gt; print(lst)[1, 2, 3, 4]#删除操作直接删除原列表部分元素&gt;&gt;&gt; del lst[2:]&gt;&gt;&gt; print(lst)[1, 2] Pop():根据索引值删除元素 使用listname.pop(index)可以删除指定索引出的元素，如果不指定index那么默认删除的是列表的最后一个元素类似于数据结构中的出栈操作，此种方法不支持范围删除。 12345nums = [40, 36, 89, 2, 36, 100, 7]nums.pop(3)print(nums)nums.pop()print(nums) 运行结果： 12[40, 36, 89, 36, 100, 7][40, 36, 89, 36, 100] 要注意虽然Python中列表由pop()表示删除元素，但是插入元素可不是push()而是append() remove():根据元素值进行删除 除了使用del和pop()删除指定索引值的元素，我们还可以使用remove()来删除指定元素值，但是要注意他每一次只会删除第一个值匹配的元素，并且必须保证要删除的元素存在，否则会报异常 12345678910nums = [40, 36, 89, 2, 36, 100, 7]#第一次删除36nums.remove(36)print(nums)#第二次删除36nums.remove(36)print(nums)#删除78nums.remove(78)print(nums) 运行结果： 123456[40, 89, 2, 36, 100, 7][40, 89, 2, 100, 7]Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 9, in &lt;module&gt; nums.remove(78)ValueError: list.remove(x): x not in list clear():删除所有元素 Python可以使用clear()删除列表的所有元素，即清空列表但是此时列表自身还是存在的只是变成了一个空列表： 123url = list(&quot;http://c.biancheng.net/python/&quot;)url.clear()print(url) 运行结果： 1[] 思考：搜索并逐一删除元素的写法？ 假设现在有一个场景，是当列表中存在元素为1时，那我们就要将这个元素删除，此时你会怎么写？我猜测你的第一想法一定是： 1234lst=[1,1,1,2,1,1,1]for i in range(len(lst)): if(lst[i]==1): del lst[i] 我们会发现报错了，此时他报的错是列表访问越界： 1234Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 9, in &lt;module&gt; if(lst[i]==1):IndexError: list index out of range 这是为什么呢？原因是列表在删除过程中会逐渐变短，而i使用是在原列表长度的范围内进行递增，因此只要删除了一个或者多个元素，那么后面就一定会出现越界。我们以一个例子为例体会一下这个过程： 1234lst=[1,2,2,3,1,1,4]for i in range(len(lst)): print(i,lst[i],sep=&quot;|&quot;) del lst[i] 假设现在我们要遍历一个列表，每次都打印此次访问到的元素索引值和元素值，然后再删除这个元素，那么我们最终得到的结果如下： 123456789PS D:\\Pythoncode&gt; &amp; D:/Python/anaconda3/python.exe d:/Pythoncode/Algrithm/test.py 0|11|22|13|4Traceback (most recent call last): File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 3, in &lt;module&gt; print(i,lst[i],sep=&quot;|&quot;)IndexError: list index out of range 这个过程如上所示，因此我们发现这种方法删除元素是不可行的，为了解决这个问题，我们只需要让i倒着遍历列表并删除即可了： 12345lst=[1,2,2,3,1,1,4]#i的范围为[len(lst)-1,-1)，每一次i都减一for i in range(len(lst)-1,-1,-1): print(i,lst[i],sep=&quot;|&quot;) del lst[i] 运行结果： 12345678PS D:\\Pythoncode&gt; &amp; D:/Python/anaconda3/python.exe d:/Pythoncode/Algrithm/test.py6|45|14|13|32|21|20|1 我们可以使用remove()方法来实现类似的删除元素值的功能，他的写法如下： 123456lst=[1,2,2,3,1,1,4]#思考：这里为什么是lst的全范围切片？for el in lst[:]: if(el==1): lst.remove(el)print(lst) 运行结果： 1[2, 2, 3, 4] 这里我们要注意必须是遍历全范围切片，原因很简单和上面类似，如果我们直接在lst中遍历并删除也会造成数组越界的问题，为了解决这个问题，我们使用的策略是遍历一个lst的全范围切片子列表（可以看成是复制了一个列表），在里面寻找是否还有要删除的元素，如果有就调用一次lst.remove()删除，这样我们就保证了每一次调用lst.remove()时保证了一定还有可以删除的元素。同时由于遍历查找和删除的是两个不同的列表，因此就不会造成访问越界了，毕竟el遍历的切片子列表一直就没有变化。 Python list列表修改元素 修改单个元素 1234nums = [40, 36, 89, 2, 36, 100, 7]nums[2] = -26 #使用正数索引nums[-3] = -66.2 #使用负数索引print(nums) 运行结果： 1[40, 36, -26, 2, -66.2, 100, 7] 修改一组元素 Python 支持通过切片语法给一组元素赋值。在进行这种操作时，如果不指定步长（step 参数），Python 就不要求新赋值的元素个数与原来的元素个数相同；这意味，该操作既可以为列表添加元素，也可以为列表删除元素。 1234nums = [40, 36, 89, 2, 36, 100, 7]#修改第 1~4 个元素的值（不包括第4个元素）nums[1: 4] = [45.25, -77, -52.5]print(nums) 运行结果： 1[40, 45.25, -77, -52.5, 36, 100, 7] 如果对空切片（slice）赋值，就相当于插入一组新的元素： 1234nums = [40, 36, 89, 2, 36, 100, 7]#在4个位置插入元素nums[4: 4] = [-77, -52.5, 999]print(nums) 运行结果： 1[40, 36, 89, 2, -77, -52.5, 999, 36, 100, 7] 但是我们要注意使用切片语法赋值时，Python 不支持单个值（必须是一个列表才行），例如下面的写法就是错误的： 1234nums[4: 4] = -77File &quot;d:/Pythoncode/Algrithm/test.py&quot;, line 3, in &lt;module&gt; nums[4: 4] = -77TypeError: can only assign an iterable 只需要修改为 1nums[4: 4] = [-77] 但是如果使用字符串赋值，Python会自动把字符串转换成序列，其中的每个字符都是一个元素： 1234nums = [40, 36, 89, 2, 36, 100, 7]#在4个位置插入元素nums[4: 4] = &quot;xyz&quot;print(nums) 运行结果： 1[40, 36, 89, 2, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;, 36, 100, 7] Python list列表查找元素 index()方法 1istname.index(obj, start, end) listname表示列表名称，obj表示要查找的元素，start表示查找起始位置，end表示结束位置。index方法用来查找某个元素在[start,end)列表中首次出现的位置。 start 和 end 可以都不写，此时会检索整个列表； 如果只写 start 不写 end，那么表示检索从 start 到末尾的元素； 如果 start 和 end 都写，那么表示检索 start 和 end 之间的元素。 123456789nums = [40, 36, 89, 2, 36, 100, 7, -20.5, -999]#检索列表中的所有元素print( nums.index(2) )#检索3~7之间的元素print( nums.index(100, 3, 7) )#检索4之后的元素print( nums.index(7, 4) )#检索一个不存在的元素print( nums.index(55) ) 运行结果： 1234567356Traceback (most recent call last): File &quot;C:\\Users\\mozhiyan\\Desktop\\demo.py&quot;, line 9, in &lt;module&gt; print( nums.index(55) )ValueError: 55 is not in list 要注意当要查找的元素不存在时，则会导致ValueError错误，因此在使用index()之前最好使用count()方法判断一下 count()方法 1listname.count(obj) 其中listname是列表名称，obj是要统计的元素。count()方法用来统计某个元素在列表中出现的次数，我们可以使用这个方法来判断哪一个列表是否包含某个元素。如果count()返还0则说明列表中不存在这个元素。 12345678nums = [40, 36, 89, 2, 36, 100, 7, -20.5, 36]#统计元素出现的次数print(&quot;36出现了%d次&quot; % nums.count(36))#判断一个元素是否存在if nums.count(100): print(&quot;列表中存在100这个元素&quot;)else: print(&quot;列表中不存在100这个元素&quot;) 运行结果： 1236出现了3次列表中存在100这个元素 Python range()快速初始化数字列表 range()语法格式和切片很像，也有三个参数： 1range(start, stop[, step]) start是起始位置，stop是结束位置，step是步长，同时也是左闭右开[start,stop)，且当只填写一个数字时默认从0开始，但是我们要注意range()生成的元素组成的并不是列表list类型： 12print(type(range(5)))&lt;class &#x27;range&#x27;&gt; 因此如果我们想要视同range()快速初始化列表需要在最外侧转换成list类型，同时我们使用step步长可以初始化一些特殊列表： 比如1~10内的偶数组成的列表： 12even_numbers = list(range(2,11,2))print(even_numbers) 运行结果： 1[2, 4, 6, 8, 10] 思考：还有没有其他高级写法？ 列表推导(List Comprehension) 是一种数学家用来实现众所周知标记集合的Python方式。它由方括号组成，包含一个表达式，后跟一个for子句，后面跟一个可选的if子句。 表达式可以是我们想要放入列表中的任何类型的对象；由于我们用零初始化列表，因此我们的表达式将只为0。 1arr = [0 for i in range(1000)] 当然也可以用等价的写法： 1arr=[0]*1000 使用列表推导也可以写1-10以内的偶数组成的列表： 1even_numbers = [i for i in range(2,11,2)] Python 使用list模拟栈和队列 list模拟栈 栈stack的特点就是后进先出，因此我们必须保证pop()时弹出的是最后进来的元素，因此只需要插入元素使用append()即可模拟： 123456789 #定义一个空 list 当做栈stack = []stack.append(1)stack.append(2)stack.append(&quot;hello&quot;)print(stack)print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop()) 运行结果： 1234[1, 2, &#x27;hello&#x27;]取一个元素： hello取一个元素： 2取一个元素： 1 list模拟队列 队列queue特点是先进先出，因此我们必须保证pop()时弹出的是最先进来的元素，因此只需要保证插入元素使用insert(0,obj)即可模拟： 12345678910 #定义一个空列表，当做队列queue = []#向列表中插入元素queue.insert(0,1)queue.insert(0,2)queue.insert(0,&quot;hello&quot;)print(queue)print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop()) 运行结果： 1234[&#x27;hello&#x27;, 2, 1]取一个元素： 1取一个元素： 2取一个元素： hello"},{"title":"字符串","path":"/wiki/Python学习笔记/字符串/index.html","content":"Python字符串拼接 在Python中拼接字符串很简单，可以直接将两个字符串紧挨着写在一起即可： 1strname = &quot;str1&quot; &quot;str2&quot; strname 表示拼接以后的字符串变量名，str1 和 str2 是要拼接的字符串内容。使用这种写法，Python 会自动将两个字符串拼接在一起。要注意拼接并不会改变原先的字符串，仅仅是生成一个新的字符串而已。 1234str1 = &quot;Python教程&quot; &quot;http://c.biancheng.net/python/&quot;print(str1)str2 = &quot;Java&quot; &quot;Python&quot; &quot;C++&quot; &quot;PHP&quot;print(str2) 运行结果： 12Python教程http://c.biancheng.net/python/JavaPythonC++PHP 这种直接罗列紧挨着的字符串拼接仅限于拼接字符串常量，如果需要使用到变量，那么需要使用+进行拼接 1234name = &quot;C++教程&quot;url = &quot;http://c.biancheng.net/cplus/&quot;info = name + &quot;的网址是：&quot; + urlprint(info) 运行结果： 1C++教程的网址是：http://c.biancheng.net/cplus/ Python字符串和数字的拼接 在很多应用场景中，我们都需要将字符串和数字进行拼接，而Python是不允许直接拼接数字和字符串的，所以我们必须先将数字转换成字符串。可以借助str()和repr()函数将数字转换为字符串，他们的使用格式如下： 12str(obj)repr(obj) obj表示要转换的对象，他可以是数字、列表、元组、字典等多种类型的数据。 12345name = &quot;C语言中文网&quot;age = 8course = 30info = name + &quot;已经&quot; + str(age) + &quot;岁了，共发布了&quot; + repr(course) + &quot;套教程。&quot;print(info) 运行结果： 1C语言中文网已经8岁了，共发布了30套教程。 思考：str()和repr()的区别？ str() 用于将数据转换成适合人类阅读的字符串形式。 repr() 用于将数据转换成适合解释器阅读的字符串形式（Python 表达式的形式），适合在开发和调试阶段使用；如果没有等价的语法，则会发生 SyntaxError 异常。 1234567s = &quot;http://c.biancheng.net/shell/&quot;s_str = str(s)s_repr = repr(s)print( type(s_str) )print (s_str)print( type(s_repr) )print (s_repr) 运行结果: 1234&lt;class &#x27;str&#x27;&gt;http://c.biancheng.net/shell/&lt;class &#x27;str&#x27;&gt;&#x27;http://c.biancheng.net/shell/&#x27; 从上面的演示中，我们可以看到，s本身就是一个字符串，但是我们依然使用了str()和repr()来对他进行转换。从运行结果中我们可以看出，str()保留了字符串最原始的样子，而repr()使用引号将字符串包围起来，这就是Python字符串的表达形式。 另外，在Python交互变成环境中，输入一个字符串（变量、加减乘除、逻辑运算等）时，Python会自动使用repr()函数处理该表达式。 Python截取字符串（字符串切片） 本质上来看，字符串是由多个字符构成的，字符之间是有顺序的，这个顺序就是索引（index)。Python允许通过索引来操作字符串中的单个字符或者多个字符，比如获取指定索引处的字符，返回指定字符的索引值等。 获取单个字符 知道字符名以后，我们可以通过方括号[]中使用索引即可访问对应的字符，具体语法格式如下： 1strname[index] strname表示字符串名字，index表示索引值。 Python允许从字符串的两端使用索引： 当以字符串的左端（字符串的开头）为起点时，索引是从 0 开始计数的；字符串的第一个字符的索引为 0，第二个字符的索引为 1，第三个字符串的索引为 2 …… 当以字符串的右端（字符串的末尾）为起点时，索引是从 -1 开始计数的；字符串的倒数第一个字符的索引为 -1，倒数第二个字符的索引为 -2，倒数第三个字符的索引为 -3 …… 12345url = &#x27;http://c.biancheng.net/python/&#x27;#获取索引为10的字符print(url[10])#获取索引为 6 的字符print(url[-6]) 运行结果： 12iy 获取多个字符（字符串切片） 使用[]除了可以获取单个字符之外，我们还可以指定一个范围获取多个字符，也就是一个子串或者片段，具体格式如下： 1strname[start : end : step] strname：要截取的字符串； start：表示要截取的第一个字符所在的索引（截取时包含该字符）。如果不指定，默认为 0，也就是从字符串的开头截取； end：表示要截取的最后一个字符所在的索引（截取时不包含该字符）。如果不指定，默认为字符串的长度； step：指的是从 start 索引处的字符开始，每 step 个距离获取一个字符，直至 end 索引出的字符。step 默认值为 1，当省略该值时，最后一个冒号也可以省略。 123456789url = &#x27;http://c.biancheng.net/java/&#x27;#获取从索引5开始，直到末尾的子串print(url[7: ])#获取从索引-21开始，直到末尾的子串print(url[-21: ])#从开头截取字符串，直到索引22为止print(url[: 22])#每隔3个字符取出一个字符print(url[:: 3]) 运行结果： 1234c.biancheng.net/java/c.biancheng.net/java/http://c.biancheng.nethp/bne.ta/ Python len()函数详解 Python中，要想知道一个字符串有多少个字符（获取字符串长度），或者一字符串占用多少个字节，我们可以使用len()方法。 1len（string） 123&gt;&gt;&gt; a=&#x27;http://c.biancheng.net&#x27;&gt;&gt;&gt; len(a)22 在实际开发中，除了常常获取字符串的长度外，有时候我们还需要获取字符串的字节数。在Python中，不同的字符所占的字节数不同，数字、英文字母、小数点、下划线以及空格各占一个字节，而一个汉字可能占2~4个字节，具体占多少个，取决于采用的编码方式。例如，汉字在GBK/GB2312编码中占用2个字节，而在UTF-8编码中一般占用3个字节。 我们可以通过使用encode()方法，将字符串进行编码后再获取它的字节数。例如，采用UTF-8编码方式，计算”人生苦短，我用Python“的字节数，可以执行如下代码： 123&gt;&gt;&gt; str1 = &quot;人生苦短，我用Python&quot;&gt;&gt;&gt; len(str1.encode())27 因为汉字加中文标点符号共7个，占21个字节，而英文字母和英文的标点符号占6个字节，一共占用27个字节。同理，如果要获取采用GBK编码的字符串的长度，可以执行如下代码： 123&gt;&gt;&gt; str1 = &quot;人生苦短，我用Python&quot;&gt;&gt;&gt; len(str1.encode(&#x27;gbk&#x27;))20 Python split()方法切割字符串 Python中，除了提供了一些内置函数获取字符串的相关信息外（例如len()),字符串类型本身也提供了一些方法供我们使用，这些方法都是字符串类型特有的。 split()方法可以实现将一个字符串按照指定的分隔符切分成多个子串，这些子串会被保存到列表中（不包括分隔符），作为方法的返回值。 1str.split(sep,maxsplit) 此方法中各部分参数的含义分别是： str：表示要进行分割的字符串； sep：用于指定分隔符，可以包含多个字符。此参数默认为 None，表示所有空字符，包括空格、换行符“ ”、制表符“\\t”等。 maxsplit：可选参数，用于指定分割的次数，最后列表中子串的个数最多为 maxsplit+1。如果不指定或者指定为 -1，则表示分割次数没有限制。 在split()方法中，如果不指定sep参数，那么也不能指定maxsplit参数。 要注意，当未指定sep参数时，split(）方法默认采用空字符进行分割，但是当字符串中有连续的空格或其他空字符时，都会被视为一个分割符归字符串进行分割 1234&gt;&gt;&gt; str = &quot;C语言中文网 &gt;&gt;&gt; c.biancheng.net&quot; #包含 3 个连续的空格&gt;&gt;&gt; list6 = str.split()&gt;&gt;&gt; list6[&#x27;C语言中文网&#x27;, &#x27;&gt;&gt;&gt;&#x27;, &#x27;c.biancheng.net&#x27;] Python join()方法合并字符串 join()方法就是split()方法的逆方法，用来将列表（或者元组）中包含的多个字符串连接成一个字符串。 使用join()方法合并字符串时，他会将列表（或者元组）中多个字符串采用固定的分隔符连接在一起。例如，字符串&quot;c.biancheng.net&quot;就可以看做是通过分隔符“.”将[‘c’,‘biancheng’,‘net’] 列表合并为一个字符串的结果。 1newstr = str.join(iterable) 此方法中各参数的含义如下： newstr：表示合并后生成的新字符串； str：用于指定合并时的分隔符； iterable：做合并操作的源字符串数据，允许以列表、元组等形式提供。 12345&gt;&gt;&gt; dir = &#x27;&#x27;,&#x27;usr&#x27;,&#x27;bin&#x27;,&#x27;env&#x27;&gt;&gt;&gt; type(dir)&lt;class &#x27;tuple&#x27;&gt;&gt;&gt;&gt; &#x27;/&#x27;.join(dir)&#x27;/usr/bin/env&#x27; Python count()方法统计字符串出现的次数 count()方法用于检索指定字符串在另一字符串中出现的次数，如果检索的字符串不存在，则返回0，否则返回出现的次数。 1str.count(sub[,start[,end]]) 此方法中，各参数的具体含义如下： str：表示原字符串； sub：表示要检索的字符串； start：指定检索的起始位置，也就是从什么位置开始检测。如果不指定，默认从头开始检索； end：指定检索的终止位置，如果不指定，则表示一直检索到结尾。 12345&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.count(&#x27;.&#x27;,2,-3)1&gt;&gt;&gt; str.count(&#x27;.&#x27;,2,-4)0 要注意搜索范围是[start,end)即末尾是开区间。 Python find()方法检测字符串中是否包含某子串 find()方法用于检索字符串中是否包含目标字符串，如果包含，则返回第一次出现该字符串的索引，反之则返回-1。 1str.find(sub[,start[,end]]) 此格式中各参数的含义如下： str：表示原字符串； sub：表示要检索的目标字符串； start：表示开始检索的起始位置。如果不指定，则默认从头开始检索； end：表示结束检索的结束位置。如果不指定，则默认一直检索到结尾。 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.find(&#x27;.&#x27;,2,-4)-1 同时Python还提供了rfind()方法，他可以从字符串右边开始检索，因此返回的是最靠近右侧的首次出现的字符串 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.rfind(&#x27;.&#x27;)11 Python index()方法检测字符串中是否包含某子串 和find()方法类似，index()方法也可以用来检索是否包含指定的字符串，不同之处在于，当指定的字符串不存在时，idnex()方法会抛出异常。 1str.index(sub[,start[,end]]) 此格式中各参数的含义分别是： str：表示原字符串； sub：表示要检索的子字符串； start：表示检索开始的起始位置，如果不指定，默认从头开始检索； end：表示检索的结束位置，如果不指定，默认一直检索到结尾。 123456789&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.index(&#x27;.&#x27;)1&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.index(&#x27;z&#x27;)Traceback (most recent call last): File &quot;&lt;pyshell#49&gt;&quot;, line 1, in &lt;module&gt; str.index(&#x27;z&#x27;)ValueError: substring not found 类似的，Python也提供了rindex()方法，从右边开始检索： 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.rindex(&#x27;.&#x27;)11 Python字符串对齐方法 Python str还提供了3种可以用来进行文本对齐的方法，分别是ljust()、rjust()和center()方法。 Python ljust()方法 ljust()方法的功能是向指定字符串的右侧填充指定字符，从而达到左对齐文本的目的。 1S.ljust(width[, fillchar]) 其中各个参数的含义如下： S：表示要进行填充的字符串； width：表示包括 S 本身长度在内，字符串要占的总长度； fillchar：作为可选参数，用来指定填充字符串时所用的字符，默认情况使用空格。 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.ljust(35,&#x27;-&#x27;))print(addr.ljust(35,&#x27;-&#x27;)) 运行结果： 12http://c.biancheng.net/python/-----http://c.biancheng.net------------- Python rjust()方法 rjust()和ljust()方法类似，唯一的不同之处在于，rjust()方法是向字符串的左侧填充指定字符串，从而达到右对齐文本的目的。 1S.rjust(width[, fillchar]) 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.rjust(35,&#x27;-&#x27;))print(addr.rjust(35,&#x27;-&#x27;)) 运行结果： 12-----http://c.biancheng.net/python/-------------http://c.biancheng.net Python center()方法 1S.center(width[, fillchar]) 1234S = &#x27;http://c.biancheng.net/python/&#x27;addr = &#x27;http://c.biancheng.net&#x27;print(S.center(35,&#x27;-&#x27;))print(addr.center(35,&#x27;-&#x27;)) 运行结果： 12---http://c.biancheng.net/python/---------http://c.biancheng.net------ Python startswith()和endswith()方法 startswith()方法 startswith()方法用来检索字符串是否以指定字符串开头，如果是返回True,反之返回False。 1str.startswith(sub[,start[,end]]) 此格式中各个参数的具体含义如下： str：表示原字符串； sub：要检索的子串； start：指定检索开始的起始位置索引，如果不指定，则默认从头开始检索； end：指定检索的结束位置索引，如果不指定，则默认一直检索在结束。 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.startswith(&quot;b&quot;,2)True endswith()方法 endswith() 方法用于检索字符串是否以指定字符串结尾，如果是则返回 True；反之则返回 False。该方法的语法格式如下： 1str.endswith(sub[,start[,end]]) 123&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.endswith(&quot;net&quot;)True Python字符串大小写转换 Python title()方法 titile()方法用于将字符串中的每一个单词的首字母转为大写，其他字母全部转为小写，转换完成后，此方法会返回转换得到的字符串。如果字符串中没有需要被转换的字符，那么字符串将会被原封不动的返回 1str.title() 123456&gt;&gt;&gt; str = &quot;c.biancheng.net&quot;&gt;&gt;&gt; str.title()&#x27;C.Biancheng.Net&#x27;&gt;&gt;&gt; str = &quot;I LIKE C&quot;&gt;&gt;&gt; str.title()&#x27;I Like C&#x27; Python lower()方法 用于将字符串中的所有大写字母转换为小写字母，转换完成以后，该方法会返回新得到的字符串。如果字符串中原本就都是小写字母，那么这个方法返回原字符串。 1str.lower() 123&gt;&gt;&gt; str = &quot;I LIKE C&quot;&gt;&gt;&gt; str.lower()&#x27;i like c&#x27; Python upper()方法 upper()方法和lower()方法功能相反，他用来将字符串中的所有小写字母转换为大写字母。 1str.upper() 123&gt;&gt;&gt; str = &quot;i like C&quot;&gt;&gt;&gt; str.upper()&#x27;I LIKE C&#x27; { % note color:yellow 要注意，以上三个方法都仅限于将转换后的新字符串返回，而不会修改原字符串。 %} Python去除字符串中空格 用户输入数据时，很有可能无疑中输入了多余的空格，或者在一些场景中，字符串前后不允许出现空格或者特殊字符，此时就需要去除字符串中的空格或者特殊字符了。 这里的特殊字符，指的是制表符\\t，回车符\\r,换行符 等。 在Python中，字符串变量提供了3种方法来删除字符串中多于的空格或者特殊字符，他们分别是： strip()：删除字符串前后（左右两侧）的空格或特殊字符。 lstrip()：删除字符串前面（左边）的空格或特殊字符。 rstrip()：删除字符串后面（右边）的空格或特殊字符。 我们要注意Python中字符串类型是不可变的，因此这三个方法仅仅是返回字符串前面或后面空白被删除以后的副本，并不会改变原字符串本身。 Python strip()方法 1str.strip([chars]) 其中，str 表示原字符串，[chars] 用来指定要删除的字符，可以同时指定多个，如果不手动指定，则默认会删除空格以及制表符、回车符、换行符等特殊字符。 1234567&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.strip()&#x27;c.biancheng.net&#x27;&gt;&gt;&gt; str.strip(&quot; ,\\r&quot;)&#x27;c.biancheng.net \\t &#x27;&gt;&gt;&gt; str&#x27; c.biancheng.net \\t \\r&#x27; Python lstrip()方法 123&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.lstrip()&#x27;c.biancheng.net \\t \\r&#x27; Python rstrip()方法 123&gt;&gt;&gt; str = &quot; c.biancheng.net \\t \\r&quot;&gt;&gt;&gt; str.rstrip()&#x27; c.biancheng.net&#x27; Python format()格式化输出方法 之前我们学习了使用%操作符来对各种类型的数据进行格式化输出，这是早期Python提供的方法。自从Python2.6版本之后，字符串类型提供了format()方法对字符串进行格式化。 1str.format(args) 此方法中，str 用于指定字符串的显示样式；args 用于指定要进行格式转换的项，如果有多项，之间有逗号进行分割。 学习 format() 方法的难点，在于搞清楚 str 显示样式的书写格式。在创建显示样式模板时，需要使用&#123;&#125;和：来指定占位符，其完整的语法格式为： 1&#123; [index][ : [ [fill] align] [sign] [#] [width] [.precision] [type] ] &#125; 注意，格式中用 [] 括起来的参数都是可选参数，即可以使用，也可以不使用。各个参数的含义如下： index：指定：后边设置的格式要作用到 args 中第几个数据，数据的索引值从 0 开始。如果省略此选项，则会根据 args 中数据的先后顺序自动分配。 fill：指定空白处填充的字符。注意，当填充字符为逗号(,)且作用于整数或浮点数时，该整数（或浮点数）会以逗号分隔的形式输出，例如（1000000会输出 1,000,000）。 align：指定数据的对齐方式，具体的对齐方式如下表所示 align参数 含义 &lt; 数据左对齐。 &gt; 数据右对齐。 = 数据右对齐，同时将符号放置在填充内容的最左侧，该选项只对数字类型有效。 ^ 数据居中，此选项需和 width 参数一起使用。 sign：指定有五符号数，此参数的值以及对应的含义如下表所示 sign参数 含义 + 正数前加正号，负数前加负号。 - 正数前不加正号，负数前加负号。 空格 正数前加空格，负数前加负号。 # 对于二进制数、八进制数和十六进制数，使用此参数，各进制数前会分别显示 0b、0o、0x前缀；反之则不显示前缀。 width：指定输出数据时所占的宽度。 .precision：指定保留的小数位数。 type：指定输出数据的具体类型，如下表所示 type类型值 含义 s 对字符串类型格式化。 d 十进制整数。 c 将十进制整数自动转换成对应的 Unicode 字符。 e 或者 E 转换成科学计数法后，再格式化输出。 g 或 G 自动在 e 和 f（或 E 和 F）中切换。 b 将十进制数自动转换成二进制表示，再格式化输出。 o 将十进制数自动转换成八进制表示，再格式化输出。 x 或者 X 将十进制数自动转换成十六进制表示，再格式化输出。 f 或者 F 转换为浮点数（默认小数点后保留 6 位），再格式化输出。 % 显示百分比（默认显示小数点后 6 位）。 12345678#以货币形式显示print(&quot;货币形式：&#123;:,d&#125;&quot;.format(1000000))#科学计数法表示print(&quot;科学计数法：&#123;:E&#125;&quot;.format(1200.12))#以十六进制表示print(&quot;100的十六进制：&#123;:#x&#125;&quot;.format(100))#输出百分比形式print(&quot;0.01的百分比表示：&#123;:.0%&#125;&quot;.format(0.01)) 运行结果： 1234货币形式：1,000,000科学计数法：1.200120E+03100的十六进制：0x640.01的百分比表示：1% Python字符串编码转换 我们知道，最早的字符串编码是ASCII编码，它仅仅对10个数字、26个大小写英文字母以及一些特殊字符进行了编码。ASCII码最多只能表示256个字符，每一个字符只需要占用一个字节。但是伴随着信息技术的发展，各国的文字都需要进行编码，于是相继出现了GBK,GB2312,UTF-8编码等。其中GBK和GB2312是我国制定的中文编码标准，规定英文字符占用1个字节，中文字符占2个字节。而UTF-8是国际通过的编码格式，它包含了全世界所有国家需要用到的字符，其规定是英文字符占1个字节，中文字符占3个字节。 Python3.x默认采用UTF-8编码格式，有效的解决了中文乱码的问题。 我们之前学习过在Python中有两种字符串类型，分别是str和bytes类型，其中str用来表示Unicode字符，bytes用来表示二进制数据。str类型和bytes类型之间就需要使用encode()和decode()方法进行转换。 Python encode()方法 encode()方法为字符串类型str提供的方法，用于将str转换为bytes类型，这个过程也称为编码。 1str.encode([encoding=&quot;utf-8&quot;][,errors=&quot;strict&quot;]) 注意，格式中用 [] 括起来的参数为可选参数，也就是说，在使用此方法时，可以使用 [] 中的参数，也可以不使用。 参数 含义 str 表示要进行转换的字符串。 encoding = “utf-8” 指定进行编码时采用的字符编码，该选项默认采用 utf-8 编码。例如，如果想使用简体中文，可以设置 gb2312。 当方法中只使用这一个参数时，可以省略前边的“encoding=”，直接写编码格式，例如 str.encode(“UTF-8”)。 errors = “strict” 指定错误处理方式，其可选择值可以是：strict：遇到非法字符就抛出异常。ignore：忽略非法字符。replace：用“？”替换非法字符。xmlcharrefreplace：使用 xml 的字符引用。该参数的默认值为 strict。 注意，使用 encode() 方法对原字符串进行编码，不会直接修改原字符串，如果想修改原字符串，需要重新赋值。 123456&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; str.encode()b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x91&#x27;&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; str.encode(&#x27;GBK&#x27;)b&#x27;C\\xd3\\xef\\xd1\\xd4\\xd6\\xd0\\xce\\xc4\\xcd\\xf8&#x27; Python decode()方法 和encode()方法相反，decode()方法用于将bytes类型的二进制数据转换为str类型，这个过程又称为阶解码。 1bytes.decode([encoding=&quot;utf-8&quot;][,errors=&quot;strict&quot;]) 参数 含义 bytes 表示要进行转换的二进制数据。 encoding=“utf-8” 指定解码时采用的字符编码，默认采用 utf-8 格式。当方法中只使用这一个参数时，可以省略“encoding=”，直接写编码方式即可。 注意，对 bytes 类型数据解码，要选择和当初编码时一样的格式。 errors = “strict” 指定错误处理方式，其可选择值可以是：strict：遇到非法字符就抛出异常。ignore：忽略非法字符。replace：用“？”替换非法字符。xmlcharrefreplace：使用 xml 的字符引用。该参数的默认值为 strict。 1234&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; bytes=str.encode()&gt;&gt;&gt; bytes.decode()&#x27;C语言中文网&#x27; 注意，如果编码时采用的不是默认的 UTF-8 编码，则解码时要选择和编码时一样的格式，否则会抛出异常，例如： 123456789&gt;&gt;&gt; str = &quot;C语言中文网&quot;&gt;&gt;&gt; bytes = str.encode(&quot;GBK&quot;)&gt;&gt;&gt; bytes.decode() #默认使用 UTF-8 编码，会抛出以下异常Traceback (most recent call last): File &quot;&lt;pyshell#10&gt;&quot;, line 1, in &lt;module&gt; bytes.decode()UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xd3 in position 1: invalid continuation byte&gt;&gt;&gt; bytes.decode(&quot;GBK&quot;)&#x27;C语言中文网&#x27; Python dir()和help()帮助函数 前面我们仅仅是学习了Python字符串中提供的常用的方法，但是这远远不是他的全部方法。我们还可以通过dir()或者help()方法查看更多方法。 Python dir()函数用来列出某个类或者某个模块中的全部内容，包括变量、方法、函数和类等。他的用法： 1dir(obj) obj 表示要查看的对象。obj 可以不写，此时 dir() 会列出当前范围内的变量、方法和定义的类型。 Python help() 函数用来查看某个函数或者模块的帮助文档，它的用法为： 1help(obj) obj表示要查看的对象，obj可以不写，此时help()会进入帮助子程序。 假设现在我们要使用dir()查看str类型支持的所有方法： 12&gt;&gt;&gt; dir(str)[&#x27;__add__&#x27;, &#x27;__class__&#x27;, &#x27;__contains__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dir__&#x27;, &#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;, &#x27;__getattribute__&#x27;, &#x27;__getitem__&#x27;, &#x27;__getnewargs__&#x27;, &#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__init_subclass__&#x27;, &#x27;__iter__&#x27;, &#x27;__le__&#x27;, &#x27;__len__&#x27;, &#x27;__lt__&#x27;, &#x27;__mod__&#x27;, &#x27;__mul__&#x27;, &#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__rmod__&#x27;, &#x27;__rmul__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;, &#x27;capitalize&#x27;, &#x27;casefold&#x27;, &#x27;center&#x27;, &#x27;count&#x27;, &#x27;encode&#x27;, &#x27;endswith&#x27;, &#x27;expandtabs&#x27;, &#x27;find&#x27;, &#x27;format&#x27;, &#x27;format_map&#x27;, &#x27;index&#x27;, &#x27;isalnum&#x27;, &#x27;isalpha&#x27;, &#x27;isascii&#x27;, &#x27;isdecimal&#x27;, &#x27;isdigit&#x27;, &#x27;isidentifier&#x27;, &#x27;islower&#x27;, &#x27;isnumeric&#x27;, &#x27;isprintable&#x27;, &#x27;isspace&#x27;, &#x27;istitle&#x27;, &#x27;isupper&#x27;, &#x27;join&#x27;, &#x27;ljust&#x27;, &#x27;lower&#x27;, &#x27;lstrip&#x27;, &#x27;maketrans&#x27;, &#x27;partition&#x27;, &#x27;replace&#x27;, &#x27;rfind&#x27;, &#x27;rindex&#x27;, &#x27;rjust&#x27;, &#x27;rpartition&#x27;, &#x27;rsplit&#x27;, &#x27;rstrip&#x27;, &#x27;split&#x27;, &#x27;splitlines&#x27;, &#x27;startswith&#x27;, &#x27;strip&#x27;, &#x27;swapcase&#x27;, &#x27;title&#x27;, &#x27;translate&#x27;, &#x27;upper&#x27;, &#x27;zfill&#x27;] 我们已经找到了它支持的所有方法，接下来我们可以通过help()方法去详细了解每一个方法的具体功能。如下所示我们使用help()方法查看str中lower()方法的用法： 12345&gt;&gt;&gt; help(str.lower)Help on method_descriptor:lower(self, /) Return a copy of the string converted to lowercase. 注意，使用help() 查看某个函数的用法时，函数名后边不能带括号，例如将上面的命令写作help(str.lower())就是错误的。"},{"title":"什么是计算机图形学","path":"/wiki/GAMES191笔记/什么是图形学/index.html","content":"fff ggg"},{"title":"变量类型和运算符","path":"/wiki/Python学习笔记/变量类型和运算符/index.html","content":"Python整数类型(int)详解 数值范围 对于弱类型语言python，整数的范围是无限大，他不会区分byte,int,long等等，只要是整数统一使用int来表示，当使用的数值超过计算机自身的计算能力时，python就会自动转用高精度进行计算（大数计算） 1234567891011121314#将 78 赋值给变量 nn = 78print(n)print( type(n) )#给x赋值一个很大的整数x = 8888888888888888888888print(x)print( type(x) )#给y赋值一个很小的整数y = -7777777777777777777777print(y)print( type(y) ) 以上的所有数字最终的type打印出来的类型都是int，即python不会发生数值溢出，具有非常强大的整数处理能力，但是要注意python2.x是会区分int、long的类型的。 整数的不同进制 十进制形式：0~9组成，开头不能是0 二进制形式：书写时以0b或者0B作为开头，同时数字只能由0和1组成，比如0B101对应的就是十进制的5 八进制形式：首先是0o或者0O开头，数字范围为0~7,同时要注意在Python2.x中八进制数字还可以以0开头表示 十六进制形式：以0x或者0X开头，后面数字0~9，同时还可以使用字母A-F或者a-f表示 1234567891011121314151617#十六进制hex1 = 0x45hex2 = 0x4Afprint(&quot;hex1Value: &quot;, hex1)print(&quot;hex2Value: &quot;, hex2)#二进制bin1 = 0b101print(&#x27;bin1Value: &#x27;, bin1)bin2 = 0B110print(&#x27;bin2Value: &#x27;, bin2)#八进制oct1 = 0o26print(&#x27;oct1Value: &#x27;, oct1)oct2 = 0O41print(&#x27;oct2Value: &#x27;, oct2) 运行结果： 123456hex1Value: 69hex2Value: 1199bin1Value: 5bin2Value: 6oct1Value: 22oct2Value: 33 同时Python中为了提高数字的可读性，允许对数字使用_进行分割，比如348000000可以表示为348_000_000，一般是隔三个数字进行一次划分。 Python小数/浮点数(float)类型详解 Python浮点数就是float类型，没有double双精度类型，他有如下两种写法 十进制形式 这个就是我们平常总是使用的形式，比如34.6、34.60等等，书写时必须包含一个小数点从而和整数进行区分 指数形式 Python中指数形式的写法就和科学计数法类似，形式为: 1aEn或者aen a是尾数部分，是一个十进制数（可以是整数或者小数），n是指数部分，必须是一个十进制整数，E或者e是固定的字符，用于分割尾数部分和指数部分，整个表达式计算公式为 a×10na×10^n a×10n 例如以下形式： 2.1E5 = 2.1×105，其中 2.1 是尾数，5 是指数。 3.7E-2 = 3.7×10-2，其中 3.7 是尾数，-2 是指数。 0.5E7 = 0.5×107，其中 0.5 是尾数，7 是指数。 要注意只要写成了指数形式就一定是小数，即使此时他的值看起来像一个整数，比如14E3等价于14000，但是实际上此时14E3也是小数而非整数 Python复数类型(complex)类型详解 在Python中还内置了复数类型，直接书写即可，复数由实部和虚部两部分组成，因此在python中写法如下： 1a+bj a表示实部，b表示虚部 12345678910c1 = 12 + 0.2jprint(&quot;c1Value: &quot;, c1)print(&quot;c1Type&quot;, type(c1))c2 = 6 - 1.2jprint(&quot;c2Value: &quot;, c2)#对复数进行简单计算print(&quot;c1+c2: &quot;, c1+c2)print(&quot;c1*c2: &quot;, c1*c2) 运行结果： 12345c1Value: (12+0.2j)c1Type &lt;class &#x27;complex&#x27;&gt;c2Value: (6-1.2j)c1+c2: (18-1j)c1*c2: (72.24-13.2j) Python字符串(string)详解 首先我们要知道在Python中字符串可以看成是若干个字符组成的列表，因此他支持len()统计长度，使用索引进行获取指定位置字符等方法。Python中字符串必须使用双引号&quot;&quot;或者单引号''包裹。 处理字符串中的引号 对于本身就包含双引号&quot;或者单引号'的字符串，此时我们需要对其进行处理，我们这里以I'm a great coder为例，此时我们需要使用如下两种方法正确表示这个字符串： 对引号进行转义 如果此时我们就要使用单引号对这个字符串进行包裹，那么我们需要对字符串内部的单引号进行转义，使用符号\\对其进行转义即可 12str1 = &#x27;I\\&#x27;m a great coder!&#x27;str2 = &quot;引文双引号是\\&quot;，中文双引号是“&quot; 使用不同的引号包围字符串 也可以此时外部使用不同的双引号包裹即可： 12str1 = &quot;I&#x27;m a great coder!&quot; #使用双引号包围含有单引号的字符串str2 = &#x27;引文双引号是&quot;，中文双引号是“&#x27; #使用单引号包围含有双引号的字符串 但是假设此时这个字符串内部同时包含有单引号和双引号，那么没有办法只能使用\\对特殊的符号进行转义了 字符串的换行 我们只需要在需要换行处末尾添加一个反斜杠\\既可以换行继续书写字符串如下，同时也可以对过长的表达式进行换行： 1234567#长字符串进行换行书写s2 = &#x27;It took me six months to write this Python tutorial. \\ Please give me more support. \\ I will keep it updated.&#x27;#长表达式进行换行书写num = 20 + 3 / 4 + \\ 2 * 3 长字符串 我们之前也了解过在Python有两种书写代码注释的方法： 12345678#单行注释&quot;&quot;&quot;多行注释&quot;&quot;&quot;&#x27;&#x27;&#x27;多行注释&#x27;&#x27;&#x27; 但是实际上三个单引号或者三个双引号自身就是长字符串，也就是说三个单引号或者三个双引号包围的字符串会默认支持换行书写，同时在其内部在放置单引号或者双引号也是不会出现解析错误的，因此无需对其进行转义，当这个长字符串没有赋值给任何一个变量时，那么这个长字符串就是一个不会对代码程序本身起到任何影响的事物，因此他可以用来书写注释，那么换句话说也就是它本身实际上是可以被当成字符串赋值给一个变量进行存储的如下： 123456longstr = &#x27;&#x27;&#x27; It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.&#x27;&#x27;&#x27;print(longstr) 运行结果： 12345#注意这里是有一个空行的It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.#这里也会有一个空行 但是我们会发现对于长字符串，他会自动存储换行、空格、缩进等内容，因此对于上面的代码我们如果想去掉空行需要写为： 1234longstr = &#x27;&#x27;&#x27;It took me 6 months to write this Python tutorial. Please give me a to &#x27;thumb&#x27; to keep it updated. The Python tutorial is available at http://c.biancheng.net/python/.&#x27;&#x27;&#x27;print(longstr) Python原始字符串 由于反斜杠\\本身具有转义的意义，那么假如我们希望写一些包含反斜杠的字符串（最常见的即使文件路径）时就需要特别注意需要对反斜杠进行转义从而取消其自身本身的转义功能，那么写起来就会非常麻烦如下： 假设此时我们要写一个Windows路径D:\\Program Files\\Python 3.8\\python.exe,那么为了避免反斜杠转义对路径的影响，我们需要对路径中的每一个反斜杠进行转义因此应该写为:D:\\\\Program Files\\\\Python 3.8\\\\python.exe。 但是这样写太麻烦了，因此Python支持原始字符串，即默认字符串中的每一个反斜杠\\都是会原封不动的保留(即使此时他发挥转义的作用），所有内容都保持原汁原味的样子，写法只需要在开头加上r即可： 123str1 = r&#x27;原始字符串内容&#x27;str2 = r&quot;&quot;&quot;原始字符串内容&quot;&quot;&quot;rstr = r&#x27;D:\\Program Files\\Python 3.8\\python.exe&#x27; 一定要注意原始字符串中的反斜杠还是会起到转义的作用，但是不同的是此时反斜杠也会被保留显示出来 假设此时我们对单引号包裹的原始字符串I'm a great coder进行转义，很明显需要在'前加上反斜杠，但是这个反斜杠也会保留显示如下： 12str1 = r&#x27;I\\&#x27;m a great coder!&#x27;print(str1) 运行结果： 1I\\&#x27;m a great coder! 正是由于斜杆转义这个特性，我们一定要注意字符串的结尾处不能是反斜杠，否则字符串结尾处的引号将会被转义，导致字符串不能正常结束。 思考：D:\\Program Files\\Python 3.8\\怎么表示？ 那么此时上面的这种以反斜杠结尾的路径我们该怎么样表示呢？有两种方法： 方法一：直接使用\\\\进行结尾即可 很简单我们对结尾的\\进行转义即可，如下所示： 1print(&#x27;D:\\\\Program Files\\\\Python 3.8\\\\&#x27;) 方法二：拼接字符串 但是上面的写法中我们需要对每一个反斜杠都进行一次转义太麻烦了，为了方便我们肯定是会用到原始字符串来写的，但是此时如果结尾是\\\\就会保留显示出两个反斜杠，但是又不能只写一个反斜杠，此时我们就可以使用字符串拼接的方法： 123str1 = r&#x27;D:\\Program Files\\Python 3.8&#x27; &#x27;\\\\&#x27;str1 = r&#x27;D:\\Program Files\\Python 3.8&#x27; + &#x27;\\\\&#x27;print(str1) 前半部分使用原始字符串书写，结尾的反斜杠再使用字符串双反斜杠书写，这样即可简便的完成需求，同时我们注意到了python会自动将相邻的字符串进行拼接，即中间的+写不写都可以。 Python bytes Python中bytes用来表示一个字节串，他和字符串很类似，但是又有区别： 字符串是由若干个字符组成的，以字符为单位进行操作，但是字节串是由若干个字节组成的，以字节为单位进行操作 字节串和字符串除了操作的数据单元不同之外，它们支持的所有方法基本相同 字节串和字符串都是不可变序列，不能随意增加和删除数据，一般的操作都仅仅是生成一个新的字节串或者字符串，并不会修改其自身 bytes的最大特点就是他只负责以字节序列的形式（二进制形式）存储数据，这些数据到底表示什么完全由程序的解析方式决定，如果采用合适的字符编码方式（字符集），字节串可以恢复成字符串，反之亦然，字符串也可以转换成字节串。 说白了，bytes 只是简单地记录内存中的原始数据，至于如何使用这些数据，bytes 并不在意，你想怎么使用就怎么使用，bytes 并不约束你的行为。 字符串和 bytes 存在着千丝万缕的联系，我们可以通过字符串来创建 bytes 对象，或者说将字符串转换成 bytes 对象。有以下三种方法可以达到这个目的： 如果字符串的内容都是 ASCII 字符，那么直接在字符串前面添加b前缀就可以转换成 bytes。 bytes 是一个类，调用它的构造方法，也就是 bytes()，可以将字符串按照指定的字符集转换成 bytes；如果不指定字符集，那么默认采用 UTF-8。 字符串本身有一个 encode() 方法，该方法专门用来将字符串按照指定的字符集转换成对应的字节串；如果不指定字符集，那么默认采用 UTF-8。 123456789101112131415161718#通过构造函数创建空 bytesb1 = bytes()#通过空字符串创建空 bytesb2 = b&#x27;&#x27;#通过b前缀将字符串转换成 bytesb3 = b&#x27;http://c.biancheng.net/python/&#x27;print(&quot;b3: &quot;, b3)print(b3[3])print(b3[7:22])#为 bytes() 方法指定字符集b4 = bytes(&#x27;C语言中文网8岁了&#x27;, encoding=&#x27;UTF-8&#x27;)print(&quot;b4: &quot;, b4)#通过 encode() 方法将字符串转换成 bytesb5 = &quot;C语言中文网8岁了&quot;.encode(&#x27;UTF-8&#x27;)print(&quot;b5: &quot;, b5) 运行结果： 12345b3: b&#x27;http://c.biancheng.net/python/&#x27;112b&#x27;c.biancheng.net&#x27;b4: b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x918\\xe5\\xb2\\x81\\xe4\\xba\\x86&#x27;b5: b&#x27;C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x918\\xe5\\xb2\\x81\\xe4\\xba\\x86&#x27; 我们仔细观察b3的三个输出结果，可以发现字节串和字符串的区别，对于字符串获取的是返还的字符，**但是对于字节串，获取的是指定数据的ASCII，这个特性可以帮助我们获取任意一个字符的ASCII。**假设此时我们需要知道B的ASCII，我们不需要查询ASCII表，只需要在Python终端中输入print(b'B'[0])即可获知： 12&gt;&gt;&gt; print(b&#x27;B&#x27;[0])66 Python布尔(bool)类型详解 Python中使用True和False来表示真假，同时True相当于整数值1，False相当于整数值0，因此下面运算是可以的： 1234&gt;&gt;&gt; False+11&gt;&gt;&gt; True+12 Python input()函数 input()是Python的内置函数，用来从控制天获取用户输入的内容。Input()函数总是以字符串的形式来处理用户输入的内容，所以用户输入的内容可以包含任意字符串。 1str=input(tipmsg) str表示一个字符串类型的变量，input会将读取到的字符串放入str中 tipmsg表示提示信息，他会显示在控制台上，告诉用户应该输入什么样的内容，如果不写tipmsg那么就不会有任何的提示信息 123456789a = input(&quot;Enter a number: &quot;)b = input(&quot;Enter another number: &quot;)print(&quot;aType: &quot;, type(a))print(&quot;bType: &quot;, type(b))result = a + bprint(&quot;resultValue: &quot;, result)print(&quot;resultType: &quot;, type(result)) 运行结果： 123456Enter a number: 100↙Enter another number: 45↙aType: &lt;class &#x27;str&#x27;&gt;bType: &lt;class &#x27;str&#x27;&gt;resultValue: 10045resultType: &lt;class &#x27;str&#x27;&gt; ↙表示按下回车键，按下回车键后 input() 读取就结束了。但是我们发现上面的代码我们是想计算输入的a和b的和，但是由于输入的内容会被当做字符串类型，因此最终变成了字符串的拼接，为了解决这个问题，我们首先需要将a和b输入内容转成整数类型，此时我们会使用如下一些类似的强转类型函数： int(string) 将字符串转换成 int 类型； float(string) 将字符串转换成 float 类型； bool(string) 将字符串转换成 bool 类型。 Python print()函数高级用法 之前我们使用print()函数都只是输出显示单个内容变量，但是实际上print()函数完全可以同时输出多个变量，而且他具有更复杂丰富的功能。 1print (value,...,sep=&#x27;&#x27;,end=&#x27; &#x27;,file=sys.stdout,flush=False) value参数可以接收任意多个变量的值，不同的变量之间使用,进行分割，因此print()可以输出多个值： 1234user_name ＝ &#x27;Charlie&#x27;user_age = 8#同时输出多个变量和字符串print(&quot;读者名：&quot;,user_name,&quot;年龄：&quot;,user_age) 运行结果： 1读者名： Charlie 年龄： 8 从上面的输出结果我们不难看出print()输出多个变量时，会默认使用空格进行分隔，如果希望手动设定分隔符，需要修改sep参数： 12#同时输出多个变量和字符串，指定分隔符print(&quot;读者名：&quot; ,user_name,&quot;年龄：&quot;,user_age,sep=&#x27;|&#x27;) 运行结果： 1读者名：|Charlie|年龄：|8 同时我们还发现print()默认输出结束会进行换行，这是因为print()的end参数的默认值是 因此他总是会在输出结果后面加上一个换行符，如果我们要手动设定，只需要修改end参数即可： 1234#设置end 参数，指定输出之后不再换行print(40,&#x27;\\t&#x27;,end＝&quot;&quot;)print(5O,&#x27;\\t&#x27;,end＝&quot;&quot;)print(60,&#x27;\\t&#x27;,end＝&quot;&quot;) 运行结果： 140 50 60 同时file指定了输入的地方，默认是sys.stdout即控制台因此会将变量的内容打印在控制台上，我们也可以修改它为指定文件，这样内容将会打印到文件中： 1234f = open(&quot;demo.txt&quot;,&quot;w&quot;)#打开文件以便写入print(&#x27;沧海月明珠有泪&#x27;,file=f)print(&#x27;蓝回日暖玉生烟&#x27;,file=f)f.close() 上面的代码中，open()函数用于打开demo.txt文件，同时权限为w写入权限，此时即使没有这个文件也会自动创建，然后写入两句话再关闭这个文件输入流，这样我们就将这句诗输出到了demo.txt文件中了 print()的flush参数用于控制输出缓存，改参数一般设置为False，这样可以获得更好的性能。 Python格式化输出字符串 转换说明符 和C类似，Python也可以对要输出的变量的内容进行格式化，在print()中使用%开头的转换说明符对各种类型的数据进行格式化输出，具体参考下表：、 转换说明符 解释 %d,%i 转换为带符号的十进制整数 %o 转换为带符号的八进制整数 %x,%X 转换为带符号的十六进制正式 %e 转换为科学计数法表示的浮点数（e小写） %E 转换为科学计数法表示的浮点数（E大写） %f,%F 转换为十进制浮点数 %g 智能选择使用%f或者%e格式 %G 智能选择使用%F或者%E格式 %c 格式化字符及其ASCII码 %r 使用repr()函数将表达式转换为字符串 %s 使用str()函数将表达式转换为字符串 要注意转换说明符只是一个占位符，他会被后面表达式（变量，常量，数字，字符串，加减乘除等各种形式）的值代替。 123name=&quot;小明&quot;age = 8print(&quot;%s已经%d岁了！&quot; % (name,age)) 运行结果： 1小明已经8岁了！ 指定最小输出宽度 有时候我们需要指定格式化的输出内容占用的最少宽度即最小输出宽度（至少占用多少个字符的位置）： %10d 表示输出的整数宽度至少为 10； %20s 表示输出的字符串宽度至少为 20。 123n = 1234567print(&quot;n(10):%10d.&quot; % n)print(&quot;n(5):%5d.&quot; % n) 运行结果： 12n(10): 1234567.n(5):1234567. 可以看出对于整数和字符串，当数据的实际宽度小于指定宽度时，会在左侧以空格填充补齐，当数据的实际宽度大于指定宽度时，会按照数据的实际宽度输出，因此他只会限制最小宽度，当数据的实际宽度够宽时指定宽度就没有任何意义了。 指定对齐方式 也就是说默认情况下，print()的数据对齐方式是右对齐的，当数据宽度不够宽时，数据总是靠右侧，左侧不足的地方用空格进行填充，但是我们有时候需要指定的对齐方式，此时我们就可以使用如下标志进行指定： 标志 说明 - 指定左对齐 + 表示输出的数字要带着符号，正式带+，负数带- 0 表示宽度不足时补充0，而不是补充空格 几点说明： 对于整数，指定左对齐时，在右边补 0 是没有效果的，因为这样会改变整数的值。 对于小数，以上三个标志可以同时存在。 对于字符串，只能使用-标志，因为符号对于字符串没有意义，而补 0 会改变字符串的值。 12345678910111213n = 123456# %09d 表示最小宽度为9，左边补0print(&quot;n(09):%09d&quot; % n)# %+9d 表示最小宽度为9，带上符号print(&quot;n(+9):%+9d&quot; % n)f = 140.5# %-+010f 表示最小宽度为10，左对齐，带上符号print(&quot;f(-+0):%-+010f&quot; % f)s = &quot;Hello&quot;# %-10s 表示最小宽度为10，左对齐print(&quot;s(-10):%-10s.&quot; % s) 运行结果： 1234n(09):000123456n(+9): +123456f(-+0):+140.500000s(-10):Hello . 指定小数精度 对于小数（浮点数），print()还允许指定小数点的数字位数，也即指定小数的输出精度。精度值需要放在最小宽度以后，中间用.隔开，也可以不写最小宽度，只写精度，具体格式如下： 12%m.nf%.nf m表示最小宽度，n表示输出精度，.是必须存在的。 1234567f = 3.141592653# 最小宽度为8，小数点后保留3位print(&quot;%8.3f&quot; % f)# 最小宽度为8，小数点后保留3位，左边补0print(&quot;%08.3f&quot; % f)# 最小宽度为8，小数点后保留3位，左边补0，带符号print(&quot;%+08.3f&quot; % f) 运行结果： 123 3.1420003.142+003.142 Python转义字符 ASCII编码为每一个字符都分配了唯一的编号，称为编码值。在Python中，一个ASCII字符除了可以使用它的实体（也就是真正的字符）表示，还可以使用它的编码表示值。这种使用编码值来间接的表示字符的方式称为转义字符。 转义字符以\\0或者\\x开头，当转义字符以\\0开头表示后面跟的是八进制形式的编码值，以\\x开头表示后面跟十六进制形式的编码值，Python中转义字符只能使用八进制或者十六进制。 ASCII编码共收录了128个字符，而\\0和\\x后面最多只能跟两位数字，所以八进制形式\\0并不能表示所有ASCII字符，只有十六进制\\x可以表示所有ASCII字符。 字符 1、2、3、x、y、z 对应的 ASCII 码的八进制形式分别是 61、62、63、170、171、172，十六进制形式分别是 31、32、33、78、79、7A。下面的例子演示了转义字符的用法： 1234str1 = &quot;Oct: \\061\\062\\063&quot;str2 = &quot;Hex: \\x31\\x32\\x33\\x78\\x79\\x7A&quot;print(str1)print(str2) 运行结果： 12Oct: 123Hex: 123xyz 要注意使用八进制的转义字符是不能表示xyz的，因为他们的编码值都转换成八进制以后有三位。 对于ASCII编码，0~31（十进制）范围内的字符是控制字符，他们都是看不见的，不能在显示器上显示，甚至无法从键盘输入，只能使用转义字符的形式来表示，不过，直接使用ASCII编码记忆不方便，也不容易理解，因此针对常用的控制字符，我们有简写方式如下： 转义字符 说明 换行符，将光标位置移到下一行开头 \\r 回车符，将光标位置移到本行开头 \\t 水平制表符，也即Tab键，一般相当于四个空格 \\ 在字符串行尾的续行符，即一行未完，转到下一行继续写。 \\b 退格（Backspace），将光标位置移到前一列。 \\\\ 反斜线 \\’ 单引号 \\\\&quot; 双引号 虽然转义字符书写形式上由多个字符组成，但是Python将他们看成是一个整体，表示一个字符。 1234567#使用\\t排版str1 = &#x27;网站\\t\\t域名\\t\\t\\t年龄\\t\\t价值&#x27;str2 = &#x27;C语言中文网\\tc.biancheng.net\\t\\t8\\t\\t500W&#x27;str3 = &#x27;百度\\t\\twww.baidu.com\\t\\t20\\t\\t500000W&#x27;print(str1)print(str2)print(str3) 运行结果： 123网站 域名 年龄 价值C语言中文网 c.biancheng.net 8 500W百度 www.baidu.com 20 500000W Python数据类型转换 假设我们现在要输入一句话是“您的身高+身高值”，此时身高值是小数类型，那么如下写法是错误的： 123456&gt;&gt;&gt; height = 70.0&gt;&gt;&gt; print(&quot;您的身高&quot;+height)Traceback (most recent call last): File &quot;&lt;pyshell#1&gt;&quot;, line 1, in &lt;module&gt; print(&quot;您的身高&quot;+height)TypeError: must be str, not float 解释器提示我们字符串和浮点数类型变量不能直接相连，需要将浮点数类型变量height转换为字符串类型才可以。此时我们就需要使用类型转换函数了如下所示： 函 数 作 用 int(x) 将 x 转换成整数类型 float(x) 将 x 转换成浮点数类型 complex(real，[,imag]) 创建一个复数 str(x) 将 x 转换为字符串 repr(x) 将 x 转换为表达式字符串 eval(str) 计算在字符串中的有效 Python 表达式，并返回一个对象 chr(x) 将整数 x 转换为一个字符 ord(x) 将一个字符 x 转换为它对应的整数值 hex(x) 将一个整数 x 转换为一个十六进制字符串 oct(x) 将一个整数 x 转换为一个八进制的字符串 思考：除了使用类型转换还能怎样输出？ 其实很简单，使用我们之前提到的格式化输出即可，如下所示： 1234567&gt;&gt;&gt; height=185.0&gt;&gt;&gt; print(&#x27;你的身高是%g&#x27; % height)你的身高是185&gt;&gt;&gt; print(&#x27;你的身高是%f&#x27; % height)你的身高是185.000000&gt;&gt;&gt; print(&#x27;你的身高是%.1f&#x27; % height)你的身高是185.0 Python算术运算符 这里就简单介绍了，因为无论是运算符号还是运算优先级都是差不多的，但是我们要注意在python中指数不是^表示，这个是按位异或的意思，我们需要使用**来表示指数，同时/就是除法并且不是整除而是直接输出具体的值，//才是整除。如下所示： 123456789101112&gt;&gt;&gt; 2**38&gt;&gt;&gt; 4**01&gt;&gt;&gt; 2/30.6666666666666666&gt;&gt;&gt; 2//30&gt;&gt;&gt; 3/31.0&gt;&gt;&gt; 3//31 一定要注意python中/输出的一定是浮点数，如果要输出整数必须使用//。 Python比较运算符 这里我们主要区分理解一下==和is的区别： 比较运算符 说明 == 等于，如果==两边的值相等，则返回 True，否则返回 False。 is 判断两个变量所引用的对象是否相同，如果相同则返回 True，否则返回 False。 实际上很好区分，==就是单纯比较数值是否相同，而is就是比较引用是否相同，即存储地址是否相同。因此一下代码如下输出： 123456import time #引入time模块t1 = time.gmtime() # gmtime()用来获取当前时间t2 = time.gmtime()print(t1 == t2) #输出Trueprint(t1 is t2) #输出False 运行结果： 12TrueFalse 由于time模块的gettime()方法用来获取当前的系统时间，精确到秒级，因为程序运行非常快，所以t1和t2得到的时间是一样的。==用来判断t1和t2的是否相等，因此返还True。而is是判断两者是否为一个对象，但是gettime()每次都是返还一个新对象，因此两者的存储地址并不相同，因此is判断返还False。 Python逻辑运算符 逻辑运算符 含义 基本格式 说明 and 逻辑与运算，等价于数学中的“且” a and b 当 a 和 b 两个表达式都为真时，a and b 的结果才为真，否则为假。 or 逻辑或运算，等价于数学中的“或” a or b 当 a 和 b 两个表达式都为假时，a or b 的结果才是假，否则为真。 not 逻辑非运算，等价于数学中的“非” not a 如果 a 为真，那么 not a 的结果为假；如果 a 为假，那么 not a 的结果为真。相当于对 a 取反。 123456age = int(input(&quot;请输入年龄：&quot;))height = int(input(&quot;请输入身高：&quot;))if age&gt;=18 and age&lt;=30 and height &gt;=170 and height &lt;= 185 : print(&quot;恭喜，你符合报考飞行员的条件&quot;)else: print(&quot;抱歉，你不符合报考飞行员的条件&quot;) 一种运行结果： 123请输入年龄：23↙请输入身高：178↙恭喜，你符合报考飞行员的条件 但是我们要注意逻辑表达式最终返还的结果并不一定是布尔类型，即不一定是True或者False。他可以是任意类型。 1234print(100 and 200)print(45 and 0)print(&quot;&quot; or &quot;http://c.biancheng.net/python/&quot;)print(18.5 or &quot;http://c.biancheng.net/python/&quot;) 运行结果： 12342000http://c.biancheng.net/python/18.5 那么为什么上面的输出结果不是布尔类型呢，这就要求我们要去理解逻辑运算的本质原理。 逻辑运算符的本质 在Python中，and和or并不一定会计算右边表达式的值，有时候仅仅计算左边的值就能得到最终的结果。同时and和or运算会将其中一个表达式的值作为最终结果，而不一定是True或者False。 对于and运算，两边的都为真时，最终结果才为真，但是只要其中有一个值为假，那么最终结果就是假，所以Python按照下面的规则执行and运算： 如果左边表达式的值为假，那么就不用计算右边表达式的值了，因为不管右边表达式的值是什么，都不会影响最终结果，最终结果都是假，此时 and 会把左边表达式的值作为最终结果。 如果左边表达式的值为真，那么最终值是不能确定的，and 会继续计算右边表达式的值，并将右边表达式的值作为最终结果。 对于 or 运算符，情况是类似的，两边的值都为假时最终结果才为假，只要其中有一个值为真，那么最终结果就是真，所以 Python 按照下面的规则执行 or 运算： 如果左边表达式的值为真，那么就不用计算右边表达式的值了，因为不管右边表达式的值是什么，都不会影响最终结果，最终结果都是真，此时 or 会把左边表达式的值作为最终结果。 如果左边表达式的值为假，那么最终值是不能确定的，or 会继续计算右边表达式的值，并将右边表达式的值作为最终结果。 了解了上面的原理以后我们就可以很容易理解下面的代码的输出结果了： 123456789url = &quot;http://c.biancheng.net/cplus/&quot;print(&quot;----False and xxx-----&quot;)print( False and print(url) )print(&quot;----True and xxx-----&quot;)print( True and print(url) )print(&quot;----False or xxx-----&quot;)print( False or print(url) )print(&quot;----True or xxx-----&quot;)print( True or print(url) ) 运行结果: 12345678910----False and xxx-----False----True and xxx-----http://c.biancheng.net/cplus/None----False or xxx-----http://c.biancheng.net/cplus/None----True or xxx-----True Python三元运算符 我们在C中和Java中都可以使用一种非常简便的比较赋值操作即三元比较符，他们的格式为： 1234567a=(exp?trueVal:falseVal)//等价于if(exp==true)&#123; a=trueVal&#125;else&#123; a=falseVal&#125; 那么python中有没有三元比较符呢？是有的，但是形式略有区别，他直接使用if和else来表示如下： 123456max = a if a&gt;b else b#等价于if(a&gt;b): max=aelse: max=b 也就是说形式为： 1a=trueVal if exp else falseVal 更复杂的嵌套如下： 123a = int( input(&quot;Input a: &quot;) )b = int( input(&quot;Input b: &quot;) )print(&quot;a大于b&quot;) if a&gt;b else ( print(&quot;a小于b&quot;) if a&lt;b else print(&quot;a等于b&quot;) ) 运行结果： 123Input a: 45↙Input b: 100↙a小于b 两个变量值得大小关系有三种，很明显我们需要嵌套使用三元比较复杂，此时由于嵌套后逻辑关系较为难以理解我们最好使用()包裹表达式以便提高代码可读性"},{"title":"流程控制","path":"/wiki/Python学习笔记/流程控制/index.html","content":"Python if else条件语句详解 123456789101112131415height = float(input(&quot;输入身高（米）：&quot;))weight = float(input(&quot;输入体重（千克）：&quot;))bmi = weight / (height * height) #计算BMI指数if bmi&lt;18.5: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;体重过轻&quot;)elif bmi&gt;=18.5 and bmi&lt;24.9: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;正常范围，注意保持&quot;)elif bmi&gt;=24.9 and bmi&lt;29.9: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;体重过重&quot;)else: print(&quot;BMI指数为：&quot;+str(bmi)) print(&quot;肥胖&quot;) 运行结果： 1234输入身高（米）：1.7↙输入体重（千克）：70↙BMI指数为：24.221453287197235正常范围，注意保持 要注意Python的判断条件语句后面要加上冒号:，同时他是通过缩进来识别代码块的，不支持大括号包裹，具有相同缩进量的若干行代码属于同一个代码块，因此我们要注意Python中的代码缩进量。 要注意Python中的elseif可以使用更简洁的elif来代替书写。 如何判断表达式是否成立 在Python中if和elif后面的“表达式”的形式是很自由的，只要表达式有一个结果，不管这个结果是什么类型，Python都能判断他是“真”还是“假”。布尔类型有两个值分别是True和False，Python会把True当做真，False当做假。但是对于数字，Python会把0和0.0当做假，其他值都当做真。而对于对象或者序列，当他们为空或者None时，Python会把他们当做假，其他情况当做真，比如下面的表达式都是不成立(假)的： 12345&quot;&quot; #空字符串[ ] #空列表( ) #空元组&#123; &#125; #空字典None #空值 123456789101112131415161718192021222324252627282930313233b = Falseif b: print(&#x27;b是True&#x27;)else: print(&#x27;b是False&#x27;)n = 0if n: print(&#x27;n不是零值&#x27;)else: print(&#x27;n是零值&#x27;)s = &quot;&quot;if s: print(&#x27;s不是空字符串&#x27;)else: print(&#x27;s是空字符串&#x27;)l = []if l: print(&#x27;l不是空列表&#x27;)else: print(&#x27;l是空列表&#x27;)d = &#123;&#125;if d: print(&#x27;d不是空字典&#x27;)else: print(&#x27;d是空字典&#x27;) #不规定时默认函数返还Nonedef func(): print(&quot;函数被调用&quot;)if func(): print(&#x27;func()返回值不是空&#x27;)else: print(&#x27;func()返回值为空&#x27;) 运行结果： 1234567b是Falsen是零值s是空字符串l是空列表d是空字典函数被调用func()返回值为空 对于没有return语句的函数，返回值即为空，也即None Python pass语句及其作用 在实际开发中，有时候我们先搭建起程序的整体逻辑框架，但是暂时不去实现某些细节，而是在这些地方加一些注释，方便以后添加代码，如下所示： 1234567891011age = int( input(&quot;请输入你的年龄：&quot;) )if age &lt; 12 : print(&quot;婴幼儿&quot;)elif age &gt;= 12 and age &lt; 18: print(&quot;青少年&quot;)elif age &gt;= 18 and age &lt; 30: print(&quot;成年人&quot;)elif age &gt;= 30 and age &lt; 50: #TODO: 成年人else: print(&quot;老年人&quot;) 当年龄大于等于30并且小于50时，我们没有使用print()语句，而是使用了一个注释，希望以后再处理成年人的情况，当Python执行到这个elif分支时，会跳过注释，什么都不执行。但是Python系统了一个更加专业的做法，就是空语句pass,pass是Pytohn中的关键字，用来让解释器跳过此处，什么都不做。 就像上面的情况，有时候程序需要占用一个位置，后者放一条语句，但是又不希望这条语句做任何事情，此时就可以通过pass语句来实现，使用pass语句比使用注释更加优雅。 1234567891011age = int( input(&quot;请输入你的年龄：&quot;) )if age &lt; 12 : print(&quot;婴幼儿&quot;)elif age &gt;= 12 and age &lt; 18: print(&quot;青少年&quot;)elif age &gt;= 18 and age &lt; 30: print(&quot;成年人&quot;)elif age &gt;= 30 and age &lt; 50: passelse: print(&quot;老年人&quot;) 运行结果： 1请输入你的年龄：40↙ 从运行结果可以看出，程序虽然执行到第10行代码，但是并没有进行什么操作、 Python assert断言函数及其用法 assert语句又称为断言语句，可以看成是功能缩小版的if语句，他用来判断某个表达式的值，如果值为真，则程序可以继续往下执行，反之如果值为假，那么Python解释器就会报AssertionError错误，程序退出执行。 12345mathmark = int(input())#断言数学考试分数是否位于正常范围内assert 0 &lt;= mathmark &lt;= 100#只有当 mathmark 位于 [0,100]范围内，程序才会继续执行print(&quot;数学考试分数为：&quot;,mathmark) 如果输入的分数为90那么程序可以正常执行： 1290数学考试分数为： 90 但是如果输入的值为159此时表达式为假，程序就会报错： 12345159Traceback (most recent call last): File &quot;C:\\Users\\mengma\\Desktop\\file.py&quot;, line 3, in &lt;module&gt; assert 0 &lt;= mathmark &lt;= 100AssertionError 你可能会疑惑，命名assert会令程序崩溃，为什么还要使用它呢？这是因为，预期让程序在晚些时候崩溃，不如再错误条件出现时，就直接让程序崩溃，这样有利于我们对程序排错，提高程序的健壮性。 因此assert语句通常用于检查用户的输入是否符合规定，还经常用作程序初期测试和调试过程中的辅助工具。 Python while循环语句 12345my_char=&quot;http://c.biancheng.net/python/&quot;i = 0;while i&lt;len(my_char): print(my_char[i],end=&quot;&quot;) i = i + 1 运行结果： 1http://c.biancheng.net/python/ 只需要保证while在有限次循环以后能够退出就行，同时循环体内部的代码缩进要相同。 Python for循环及用法详解 1234for 迭代变量 in 字符串|列表|元组|字典|集合： 代码块for 索引值,元素 in 枚举: 代码块 12345my_dic = &#123;&#x27;python教程&#x27;:&quot;http://c.biancheng.net/python/&quot;,\\ &#x27;shell教程&#x27;:&quot;http://c.biancheng.net/shell/&quot;,\\ &#x27;java教程&#x27;:&quot;http://c.biancheng.net/java/&quot;&#125;for ele in my_dic: print(&#x27;ele =&#x27;, ele) 运行结果： 123ele = python教程ele = shell教程ele = java教程 要注意对于字典的遍历，默认取出来的是键，因此如果想要获取相应的值还需要使用get()方法。 Python循环结构else用法 在Pytohn中，无论是while循环还是for循环，其实都可以紧跟一个else代码块，他们的作用是当循环条件为False跳出循环时，程序会最先执行else代码块中的代码。 1234567add = &quot;http://c.biancheng.net/python/&quot;i = 0while i &lt; len(add): print(add[i],end=&quot;&quot;) i = i + 1#原本位于 else 代码块中的代码print(&quot; 执行 else 代码块&quot;) 运行结果: 12http://c.biancheng.net/python/执行 else 代码块 12345add = &quot;http://c.biancheng.net/python/&quot;for i in add: print(i,end=&quot;&quot;)else: print(&quot; 执行 else 代码块&quot;) 运行结果： 12http://c.biancheng.net/python/执行 else 代码块 我们发现一个问题，就是上面的代码完全不可不添加else也可以实现相同的效果，那也就是说else语句没有用处吗？并不是的，else代码块经常和break结合使用实现一些特殊用处。 Python嵌套循环实现冒泡排序 冒泡排序是数据结构中的经典算法，他的时间复杂度为O(n^2)，就是两个循环的简单嵌套，因此接下来我们尝试使用Python来实现这个冒泡排序。 冒泡排序算法的实现思想遵循以下几步： 比较相邻的元素，如果第一个比第二个大，就交换它们两个。 从最开始的第一对到结尾的最后一对，对每一对相邻元素做步骤 1 所描述的比较工作，并将最大的元素放在后面。这样，当从最开始的第一对到结尾的最后一对都执行完后，整个序列中的最后一个元素便是最大的数。 将循环缩短，除去最后一个数（因为最后一个已经是最大的了），再重复步骤 2 的操作，得到倒数第二大的数。 持续做步骤 3 的操作，每次将循环缩短一位，并得到本次循环中的最大数。直到循环个数缩短为 1，即没有任何一对数字需要比较，此时便得到了一个从小到大排序的序列。 例如，使用 for 循环实现用冒泡排序算法对 [5,8,4,1] 进行排序： 1234567data = [5,8,4,1]#实现冒泡排序for i in range(len(data)-1): for j in range(len(data)-i-1): if(data[j]&gt;data[j+1]): data[j],data[j+1] = data[j+1],data[j]print(&quot;排序后：&quot;,data) 运行结果： 1排序后： [1, 4, 5, 8] 可以看到，实现冒泡排序使用了 2 层循环，其中外层循环负责冒泡排序进行的次数，而内层循环负责将列表中相邻的两个元素进行比较，并调整顺序，即将较小的放在前面，较大的放在后面。 Python break用法详解 在while和for循环中，只要循环条件满足，程序就会一直执行循环体，不停地转圈。但是在某些场景下，我们可能希望程序在循环结束前就能强制退出循环，此时我们就需要使用Python提供的两种强制离开的办法了： 使用 continue 语句，可以跳过执行本次循环体中剩余的代码，转而执行下一次的循环。 只用 break 语句，可以完全终止当前循环。 在上一节我们学习到for可以配备一个else语句，那么在这种情况下，如果使用break语句跳出循环，就不会执行else包含的代码，如下所示： 123456789add = &quot;http://c.biancheng.net/python/,http://c.biancheng.net/shell/&quot;for i in add: if i == &#x27;,&#x27; : #终止循环 break print(i,end=&quot;&quot;)else: print(&quot;执行 else 语句中的代码&quot;)print(&quot; 执行循环体外的代码&quot;) 从输出结果可以看出，使用 break 跳出当前循环体之后，该循环后的 else 代码块也不会被执行。但是，如果将 else 代码块中的代码直接放在循环体的后面，则该部分代码将会被执行。 Python推导式初始化序列 列表推导式 12[表达式 for item in 可迭代对象][表达式 for item in 可迭代对象 if 条件判断] 之前我们实际上已经简单的学习了使用推导式进行序列的初始化，比如： 12y = [x for x in range(1, 5)]print(y) 运行结果： 1[1, 2, 3, 4] 进一步，我们可以在for后面添加一个if条件语句进行元素的筛选，比如： 12y = [x for x in range(1, 50) if x % 5 == 0]print(y) 运行结果： 1[5, 10, 15, 20, 25, 30, 35, 40, 45] 如山所示，我们使用if条件句和for循环推导式初始化了一个50以内所有5的倍数组成的列表。 我们甚至可以使用多个for初始化一个元素为元组的列表如下所示： 12y = [(row, col) for row in range(1, 7) if row % 2 != 0 for col in range(1, 7) if col % 2 == 0]print(y) 运行结果： 1[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)] 字典推导式 1&#123;key表达式: value表达式 for item in 可迭代对象&#125; 比如我们统计一个字符串中各字符出现的次数： 123text = &#x27;you could not see my tears cause I am in the water&#x27;char_count = &#123;c: text.count(c) for c in text&#125;print(char_count) 运行结果： 1&#123;&#x27;y&#x27;: 2, &#x27;o&#x27;: 3, &#x27;u&#x27;: 3, &#x27; &#x27;: 11, &#x27;c&#x27;: 2, &#x27;l&#x27;: 1, &#x27;d&#x27;: 1, &#x27;n&#x27;: 2, &#x27;t&#x27;: 4, &#x27;s&#x27;: 3, &#x27;e&#x27;: 6, &#x27;m&#x27;: 2, &#x27;a&#x27;: 4, &#x27;r&#x27;: 2, &#x27;I&#x27;: 1, &#x27;i&#x27;: 1, &#x27;h&#x27;: 1, &#x27;w&#x27;: 1&#125; 集合推导式 12&#123;表达式 for item in 可迭代对象&#125;&#123;表达式 for item in 可迭代对象 if 条件判断&#125; 12y = &#123;x for x in range(1, 50) if x % 5 == 0&#125;print(y) 运行结果： 1&#123;35, 5, 40, 10, 45, 15, 20, 25, 30&#125; 生成器推导式（生成元组） 12(表达式 for item in 可迭代对象)(表达式 for item in 可迭代对象 if 条件判断) 这样会返还一个生成器对象，一个生成器只能使用一次。 12y = (x for x in range(1, 50) if x % 5 == 0)print(y) 1&lt;generator object &lt;genexpr&gt; at 0x0000025228C64518&gt; 接下来我们遍历这个y 123456789101112131415&gt;&gt;&gt; y = (x for x in range(1, 50) if x % 5 == 0)&gt;&gt;&gt; for i in y: print(i)...51015202530354045&gt;&gt;&gt; for i in y: print(i)...&gt;&gt;&gt; 我们发现第二次遍历时y的元素不见了。因此一定要注意这种表达式初始化的生成器对象（元组）只能使用一次。 Python zip函数 zip()函数时Python内置函数之一，他可以将多个序列(列表、元组、字典、集合、字符串以及range()区间构成的列表)“压缩”成一个zip对象，所谓压缩，就是将这些列表中对应位置的元素重新组合，生成一个新的元组。 1zip(iterable, ...) 其中 iterable,… 表示多个列表、元组、字典、集合、字符串，甚至还可以为 range() 区间。 123456789my_list = [11,12,13]my_tuple = (21,22,23)print([x for x in zip(my_list,my_tuple)])my_dic = &#123;31:2,32:4,33:5&#125;my_set = &#123;41,42,43,44&#125;print([x for x in zip(my_dic)])my_pychar = &quot;python&quot;my_shechar = &quot;shell&quot;print([x for x in zip(my_pychar,my_shechar)]) 运行结果： 123[(11, 21), (12, 22), (13, 23)][(31,), (32,), (33,)][(&#x27;p&#x27;, &#x27;s&#x27;), (&#x27;y&#x27;, &#x27;h&#x27;), (&#x27;t&#x27;, &#x27;e&#x27;), (&#x27;h&#x27;, &#x27;l&#x27;), (&#x27;o&#x27;, &#x27;l&#x27;)] 注意在使用zip()函数“压缩”多个序列时，他会分别读取各序列中第1个元素，第2个元素、…、第n个元素，各自组成一个新的元组。特别注意，当多个序列中元素个数不一致时，会以最短的序列为准进行压缩。 另外，对于 zip() 函数返回的 zip 对象，既可以像上面程序那样，通过遍历提取其存储的元组，也可以向下面程序这样，通过调用 list() 函数将 zip() 对象强制转换成列表： 123my_list = [11,12,13]my_tuple = (21,22,23)print(list(zip(my_list,my_tuple))) 运行结果： 1[(11, 21), (12, 22), (13, 23)] Python reversed()函数及用法 reversed()函数时Python内置函数之一，其功能是对于给定的序列（包括列表、元组、字符串以及range(n)区间)，该函数可以返回一个逆序序列的迭代器（注意是一个新的迭代器类型，没有len())方法，如果必要需要使用list()，tuple()等函数进行转换)用于遍历该逆序序列。 1reversed(seq) 其中，seq 可以是列表，元素，字符串以及 range() 生成的区间列表。 12345678#将列表进行逆序print([x for x in reversed([1,2,3,4,5])])#将元组进行逆序print([x for x in reversed((1,2,3,4,5))])#将字符串进行逆序print([x for x in reversed(&quot;abcdefg&quot;)])#将 range() 生成的区间列表进行逆序print([x for x in reversed(range(10))]) 运行结果： 1234[5, 4, 3, 2, 1][5, 4, 3, 2, 1][&#x27;g&#x27;, &#x27;f&#x27;, &#x27;e&#x27;, &#x27;d&#x27;, &#x27;c&#x27;, &#x27;b&#x27;, &#x27;a&#x27;][9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 同样的我们也可以使用list()函数将reversed()函数逆序返还的迭代器直接转换成列表进行打印： 12#将列表进行逆序print(list(reversed([1,2,3,4,5]))) 运行结果： 1[5, 4, 3, 2, 1] 再次强调，使用 reversed() 函数进行逆序操作，并不会修改原来序列中元素的顺序，例如： 1234a = [1,2,3,4,5]#将列表进行逆序print(list(reversed(a)))print(&quot;a=&quot;,a) 运行结果： 12[5, 4, 3, 2, 1]a= [1, 2, 3, 4, 5]"},{"title":"什么是操作系统","path":"/wiki/操作系统笔记/什么是操作系统/index.html","content":"操作系统的概念功能和目标 操作系统的结构分布 OS系统就是连接用户和应用程序与硬件之间的中间载体，他来实现两层结构间的数据交换，因此一个程序运行一定要在操作系统上才可以运行。 操作系统的定义 操作系统（Operating System,OS)是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境。它是计算机系统中最基本的系统软件。 从上面的定义我们可以看出操作系统的几个根本功能： 操作系统是系统资源的管理者，任务是分配资源 为上层应用提供易用的服务和环境 是最接近硬件的一层软件（因此还是由算法编程实现的） 任务管理器中，左侧是对应的用户程序，而右侧就是硬件的信息。 思考：内存的作用？ 执行一个程序前需要先将该程序（包裹执行代码，数据块）等放入内存中才可以在CPU上面执行。 以打开QQ和朋友聊天为例： 在各个文件夹中找到QQ安装的位置 第一步是找到程序的存放位置，当然一般上左面的快捷方式直接映射到了执行程序的存放位置 双击打开QQ.exe 将程序的执行代码和数据等放入内存中，做好准备后等待CPU执行此程序 QQ程序开始运行 执行程序开始在CPU上被执行 开始和朋友视频聊天 需要将摄像头设备分配给QQ进程来使用 在上面得到一系列过程中存入内存，分配进程等工作就是OS系统的任务。 操作系统的功能–为上层提供方便易用的服务 向上层提供方便易用的服务 将各个硬件进行封装为多个功能接口并分配给进程程序使用。如下图： 美丽就好像一个接口他需要多个硬件提供支持，而操作系统就是提供接口的服务者，之所以软件层和硬件层不能直接运行而需要OS系统提供媒介的主要原因就是因为语言障碍，软件层是高级语言如“服务A”，而硬件层并不能理解，因此需要OS系统进行指令翻译为提供“美丽”接口同时传达给硬件层能够理解的二进制指令。 GUI：图形用户接口 封装思想：操作系统把一些丑陋的硬件功能封装为简单易用的服务，使用户能够更加方便的使用计算机，用户无需关心底层硬件的原理，只需要对操作系统发出命令即可。 类似于前后台，用户和程序就像前台，只关注于页面设计和数据呈现，而具体的数据提供与数据分析就是由硬件系统这一&quot;后台&quot;来完成，而他们之间的联系者就是OS，提供对应的接口。 很多现代的操作系统都提供了GUI，即图形化用户接口，用户可以使用形象的图形界面进行操作，而不再需要记忆复杂的命令，参数。例如下图： 因此像古老的计算机就是拥有的没有GUI的操作系统，无论是打开文件或者开关机都是需要输入相对应的指令的，而现在的计算机和手机等设备就是拥有GUI的现代操作系统，例如菜单栏，管理文档的文档区等都属于GUI，类似的应用程序也有有无GUI的区分，像vim等就是没有GUI的编辑器，他们需要手动输入指令来打开文件，退出文件等行动，而VSCODE就是拥有GUI的应用程序。 联机命令接口 联机命令接口是交互式命令接口。如win系统计算机必备的cmd窗口就是一个没有GUI的命令窗口。特点就是用户说一句系统就做一步，打开方式： win+R 输入cmd,回车，打开命令解释器 尝试使用time指令，ipconfig指令 类似像git命令窗口也是这种特点的接口，用户输入一条指令，就执行一步，然后在等待用户输入指令在执行。 脱机命令接口 脱机命令接口是批处理命令接口，例如win系统自带的文档搜索功能，他是在用户输入一条指令后进行多步处理即用户说一堆指令，系统跟着做一堆指令，这是与交互式命令接口的根本区别。 程序接口 可以再程序中进行系统调用来使用程序接口。普通用户不能直接使用程序借口，只能通过程序代码间接使用。例如程序猿编写程序时调用的C语言库就是一种程序接口的调用过程。 这种系统调用（或者叫做广义指令）类似于函数调用，使用用程序请求操作系统服务的唯一方式。例如C语言中的输出指令printf函数就是调用的C库函数中的一个原函数，相对应的就会在底层调用操作系统提供的显式相关的&quot;系统调用&quot;,而一般平时情况用户是无法通过输入指令来通过操作系统调用这个接口的。 总结： 所有的有关软硬层直接的信息传输和功能调度都是一定要经过OS处理的，对于命令接口和程序接口了解即可。 操作系统的目标–作为最接近硬件得层次 简而言之，操作系统就是实现对硬件机器的扩展，只有一个裸机安装上了操作系统才能够提供方便用户的服务功能，从而大幅提高了机器的便捷性和功能使用性。我们通常把覆盖了软件的机器称为扩充机器或者虚拟机。 如果将一台设备比喻成一个汽车，那么硬件就像是发动机（只会转），轮胎（只会滚），在原始的硬件机器上覆盖一层系统才能够让发动机有目的性得带着轮子转，即操作系统是连接各个硬件的关键者，他使得各个独立工作的硬件之间产生了协调配合，互相合作的联系从而才能够使用简单的硬件设备之间的合作来实现复杂的功能。 总结 操作系统的四个特征 特征1–并发性 并发是指两个或多个事件在同一时间间隔内发生。这些事件宏观上看是同时发生的，但是实际上微观上看是交替发生的。即cpu频繁的不断切换为两个多个进程服务，因为进程并不是一直不间断的连续需要cpu时刻在旁边提供服务，而是在完成某个阶段的任务后向cpu发起一个服务需求，然后cpu在提供计算服务。这就类似于餐厅内的顾客和服务员，应用程序就像顾客，cpu就像服务员（因为这里讨论的是单核，所以就是一名服务员），服务员需要同时为这几桌的的顾客提供上菜等服务，所以整体上看可以同时为多个顾客提供服务，而微观上服务员一次只能为一个顾客提供服务，所以叫做同一时间间隔内发生。 思考：并行性与并发性的区别？ 并行性就是指两个或多个事件在同一时间内发生，这个才是真正的微观上的同时发生，类似于每一个顾客都有一名服务员，他们之间如果同时需要服务时，则不需要等待或者频繁切换服务员走动，可以真正做到一人配一个实时服务的情况。因此也不难推测到，并行性一般对应是多核CPU，才可以做到同时执行多个程序，实现并行执行。但是注意并行性可不是操作系统的四大特征之一。 思考：并法与并行是互斥事件吗（即操作系统不能同时兼具）？ 并不是，首先毋庸置疑，单核CPU的操作系统肯定就是只有并发性了，毕竟就一个可以提供服务的cpu，但是对于多核的计算机，一般是同时兼具并发性和并行性，原因很好理解，对一个n核cpu处理器，当需要同时服务n+k(k&gt;0)个事件时，也需要并发执行，当然同时也是具有并行性的毕竟一次可以同步执行n个事件。 特征2–共享性 共享是指资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。 所以资源共享所说的也是宏观上的同时“共享”，在微观上来看，有可能是交替的对资源进行访问的（分时共享）。 互斥共享 例如QQ和微信同时使用视频聊天，但是同一段时间内摄像头只能分配给其中的一个进程使用。 同时共享 QQ发送文件A，同时微信发送文件B，两边都在同时读取发送硬盘里的文件资源，从读取数据来看他们宏观上在同时共享硬盘资源，但是微观上来看，两个进程还是交替着访问硬盘的。 思考：互斥共享和同时共享的本质区别？ 首先需要声明，无论是这两种共享方式的哪一种本质上都不是真正的并行性共享，即都是分时共享，互斥共享指的仅仅是物理设备位置上的共享，时间上是根本不共享的，即这一时间段内就是只能有一个程序使用。而同时共享在物理设备位置上的共享基础上，在时间间隔内还有类似于并发性的特点，即这一段时间间隔内切换着同时为两个进程资源服务。至于真正做到的并行性共享即同一时间内两个进程或多个进程同时同地对于一个资源进行操作是尽量避免的，互斥锁也正是由这个应运而生的，因为会造成重大的Bug，应该尽量避免此类共享的发生。 思考：并发和共享的关系？ 并发性是指计算机系统中同时存在着多个运行着的程序。而并发性是指计算机系统中的资源科供内存中多个并发执行的进程同时使用。 对于上面QQ和微信同时发送文件A和B的例子来看，并发性体现在两个进程在同一个时间间隔内共同执行，共享性体现在在同一段时间间隔内两个并发执行的程序同时共享的访问硬盘资源。 特质3–虚拟性 虚拟是指把一个物理上的实体变为若干个逻辑上的对应物，物理实体是实际存在的，而逻辑对应物是用户感受到的，但是并不是真实存在的。 举个例子，例如一个程序需要在第7个地址空间存储一个数据，然后再在第50000个地址空间存储一个数据，那么中间没有进行存储的8-49999地址空间不可能真正的留白空出，而是操作系统进行了虚拟化，比如物理地址上的1对应着虚拟地址7，物理地址上的3对应50000，这样就可以有效提高空间的利用率同时压缩了真实物理空间的大小。在实际生活中我们时常发现一个大型主机游戏需要4-20GB的运行内存，而我们的电脑一般只有4-8G的内存，理论上如果按照物理地址1:1对应映射存储的话，根本就不可能将程序放入到内存中（这里先不讨论内外存动态存储，就默认必须直接一次性全部放入才可执行），更别提运行程序了，这时候虚拟的特征就解决了这个问题。再比如，一个程序放入到内存后会分配给cpu执行，但是单核cpu的计算机在频繁切换执行时却可以给用户造成一种同时运行对个程序的感觉（当然实际上是并发运行的），这也能体现虚拟性，这种方法就体现了“分时复用”的一个特点。 思考：虚拟性和并发性的特点？ 虚拟就是一种用逻辑上的映射来加快物理上的执行效率，从而产生了一种同时执行的错觉。所以虚拟是建立在并发的基础之上的，如果每次就运行一个程序，那么也就没必要实现虚拟了。 特征4–异步性 异步是指，在多道程序环境下，允许多个程序并发执行，但是由于资源有限（即使是用来虚拟，实际上空间也是远远不够的），进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是异步性。 思考：异步性和并发性的关系？ 因为异步也是在多程序同时进行才能体现出来的特征，所以如果失去了并发性，即系统只能串行的运行各个程序，那么每个程序的执行就会一贯到底，也就没有异步性了，所以只有系统拥有并发性，才有可能导致异步性。 总结 我们通过上面的四大特征的定义以及思考对比，发现虚拟和异步都是建立在异步的基础上才会有可能体现出来的，而共享和并发则是相互体现，互为存在的条件，因此并发和共享才是一个操作系统的最基本额两个特征。 操作系统的发展与分类 这部分了解即可，主要是关注和理解各类不同的操作系统主要想解决的问题是什么，以及各自的优缺点。 手工操作阶段 最早的阶段，基本上等同于没有操作系统的阶段，就是人机交互，用户需要和硬件之间进行交互操作导致消耗大量时间，效率极低。即使机器的运行效率很快，但是运行时间的上限非常受人机交互操作的限制。 批阶段处理阶段 单道批处理系统 引入脱机输入、输出技术，（用外围机和磁道完成），并且由监督员负责控制作业的输入和输出），即输入和输出时不再是人机交互，而是引入一些类似磁带等外部接入设备加快输入与输出速度，如下图： 这样没有了超慢和慢两个环节，速度大幅提升： 但是缺点为内存中仅能有一道程序执行，运行结束后才可以调入下一个程序，即没有并发性，cpu利用率太低，空闲时间长。 多道批处理系统 既然读入的程序太少，那就多读，每次都输入多个程序存入内存中并发执行可以进一步加快速度： 多个程序并发进行，共享计算机的资源，资源利用率大幅提升，cpu和其他资源能够长时间保持“忙碌”状态，系统的吞吐量提升： 可以看到这种多条线有交集的就是并发性图的特点，现在流水线加工也一般是这种并发执行。 但是多道批处理系统仍然有缺点，即用户相应时间过长，从输入数据开始后用户就一直得等到输出完成，中间没有人机交互功能，即一旦将作业提交给机器就只能等待机器执行完，这期间用户无权在控制访问自己的作业，这种情况导致程序无法在机器执行时被用户调试或者用户在运行过程中添加其他的参数或选项（当然这种问题手工操作和单道批处理系统也是拥有此缺陷的，但是但是速度都上不来，就更没有考虑此问题，现在速度提上来以后又发现了新的缺陷）。当然多道批系统还是象征着操作系统开始出现，毕竟操作系统主要是为了提供人机随时交互的便捷服务，提升运行速度并不是其根本任务，当然也是重要任务之一。 分时操作系统 计算机以时间片为单位轮流的为各个用户/服务，各个用户可以通过终端（终端概念在此时出现）与计算机进行交互。 优点：用户请求可以及时响应了，及用户可以实时对作业进行暂停，加入新参数或者中途终止任务等，并且这种并发性执行也允许了多个用户同时使用一台计算机进行任务调度，并且用户对计算机的操作相互独立，感受不到其他用户的存在，即各个用户之间操作相互独立，互不打扰。 缺点：不能优先处理一些紧急任务，操作系统是对各个用户/作业绝对公平的，循环的为每一个作业服务一个时间片，不区分任务的紧急性。 实时操作系统 其实就是在分时操作系统的基础上解决了缺点，可以能够优先相应一些紧急任务，某些紧急任务不需要时间片排队，而是优先一直执行完。在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在严格的时限内处理完事件（可以认为根据不同的事件的时限对每一个事件增加了优先级），这种操作系统主要特点为及时性和可靠性。 当然也有特例，例如软实时系统允许偶尔超时。 其他几种操作系统 网络操作系统 伴随着网络的产生应运而生的，能把网络中各个计算机有机集合，实现数据传送等，这种操作系统一般应用于后台大型服务器，主要是实现网络中各种资源的共享（如文件共享）和各台计算机之间的通信。 分布式操作系统 主要特点就是分布性和并发性，系统中的各台计算机地位相同，任何工作够可以分布在这些计算机上，由他们并行、协作完成。 个人计算机操作系统 个人使用，win XP,MacOS等，以上介绍的几种通常都是用于大型服务器的。 总结"},{"title":"什么是线程","path":"/wiki/操作系统笔记/什么是线程/index.html","content":"线程的概念和特点 线程的概念 考虑一个问题，如下图 很明显这是三个进程并发进行。那么在实际上的并发运行中操作系统会频繁的切换进程以达到同时以某种未知的速度进行（异步性的体现）。那么上节我们知道每次切换进程都要进行PCB更新来记录离开时的运行环境，毋庸置疑，这需要很大的时间开销。 并且从上图我们也可以看出进程是调度（即任务分配）和资源分配的基本单位，那么有没有一种而更好的模型可以减少时间开销的同时还能够保证功能的实现？ 这时我们就引入了一个新的概念–线程，其实线程和进程很相似，如下图： 线程的优点 对比之前的模型，我们发现三个进程合并在了一个进程里，此时合并成为了一个QQ进程，而此时进程依然是资源分配的基本单位，他是分配资源的最下单位，但是此时三个合并的进程更名为线程，此时他们不再是资源分配的基本单位，三者共同共享QQ进程这一进程的共享资源，但是线程仍然是cpu调度的基本单位。此时进程成为了资源分配的基本单位，线程是调度的基本单位，这样，当切换线程时就没有必要频繁更新PCB的环境信息了也就减少了切换的时间开销。 对比两种模型，线程的引入只是减小了线程间并发的时间开销，而当时切换不同进程下的线程时，在时间开销并未得到优化，开销还是很大。当然此时，从属于不通进程的线程间的通信仍然必须请求操作系统的系统服务，而统一进程下的线程间可以直接在共享资源空间下进行读写的操作，所以此时同一个进程下的线程间通信不在需要操作系统的服务。 思考：引入线程的概念后进程发生了哪些变化？ 引入线程前，进程同时是cpu调度和资源分配的基本单位，而当引入线程后，进程只是资源分配的基本单位，而线程成为了cpu调度的基本单位。所以可以理解为线程是一个寄存在进程下的小进程，小进程之间拥有直接通信，切换不用更新PCB，共用共享资源的特殊点而已。但是由于线程不是资源分配的单位，所以线程基本上不拥有独属于自己的资源空间，大部分都是共用的一个进程下的共享空间。当然在多cpu的环境下，各个线程也可以分配到不同的cpu上并行地执行且时间开销还很小。但是这里我们只讨论单核，所以线程之间也只会并发执行。 引入了线程的概念后，进程不仅仅是只能串行的执行某一个任务了，从宏观视角来看，此时cpu上的进程可以并发进行，同时某一个进程内的线程也在并发进行，所以并发性显著提高，此时进程只作为除cpu之外的系统资源的分配单元（如打印机，内存地址空间等都是分配给进程的），而线程则成为了处理机的分配单元。 线程的实现方式 用户级线程 用户级线程（User-Level Thread,ULT),用户级线程由应用程序通过线程库实现。所有的线程管理工作都由应用程序负责（包括线程切换），用户级线程中，线程切换在目态即可完成，无需操作系统的干预。在用户看来是有多个线程，但是在操作系统的视角来看，操作系统并意识不到线程存在（用户级线程对用户不透明，对操作系统透明），即用户级线程只是从用户的视角能够看到线程。 在早期的操作系统（如早期的UNIX），只支持进程，不支持线程。当时的“线程”是由线程库实现。以操作系统视角来看，根本就没有线程，而是就是三个进程。即在操作系统看来： 还是三个进程。。如果我们从代码的角度来看，线程其实就是一段代码逻辑，上述三段代码逻辑上可以看做是三个“线程”，而while循环就是“线程库”，线程库完成了对线程的管理工作（如调度，当然while循环就是通过If-else判断管理线程的）。 123456789int main()&#123;int i=0; while(true)&#123; if(i==0)&#123;//处理视频聊天的代码&#125; if(i==1)&#123;//处理文字聊天的代码&#125; if(i==2)&#123;//处理文件传输的代码&#125; i=(i+1)%3; &#125;&#125; 很多变成语言提供了强大的线程库，可以实现线程的创建，销毁和调度等功能。因为用户级线程是由应用程序通过线程库实现的，所有的线程管理工作都是由应用程序负责（包括线程切换），所以在用户级线程中，线程切换在目态即可完成，无需操作系统的干预，当然进程切换还是得有操作系统完成的，不同进程下的线程间信息交流也需要操作系统的服务。由于用户级线程是只是在用户视角下有体现线程，但是在操作系统看来还是几个进程并发进行，所以一旦一个用户级线程被阻塞，整个进程就都被阻塞了，即其他的几个线程也会阻塞，并发度并不高。此时的多个线程不可在多核处理机上并行运行，因为只有在操作系统中的线程才可以在多核cpu上并行运行，而现在虽然有多个线程，但是在系统看来并没有意识到线程。 内核级线程 内核级线程（Kernel-Level Thread,KLT)又称“内核支持的线程”，内核级线程中用户所看到的线程都和操作系统中某一个线程对应（注意不一定是一一对应），所以此时的线程管理工作是由操作系统内核完成，线程调度、切换工作也都是由内核负责，所以也就不需要线程库了，因此内核级线程的切换需要在管态下才能完成。可以简单地理解为此时从操作系统的视角看内核可以看到线程。大多数的现代操作系统都实现了内核级线程，如windos,linux。 以上这些都属于内核级线程，一定要特别注意内核级线程和用户级线程的本质区别就是内核有没有内核级线程的概念，至于所说的多线程模型（下面会将）都是针对内核级线程而讨论的。并且一定要注意，因为操作系统只能看得到内核级线程，所以只有内核级线程才是处理机分配的单位。 操作系统为每一个内核级线程都建立了TCP（Thread Control Block,线程控制块，线程是Thread,进程是Process，所以进程控制块叫做PCB)来对内核级线程进行管理。优点是此时当一个线程在被阻塞后别的线程可以继续并发执行。且因为此时操作系统可以看到线程，所以此时的多线程可以在多核处理机上并行执行。缺点是一个用户进程会有许多的内核级线程，又因为此时的线程是由操作系统内核完成，所以需要频繁的变态，因为管理成本高，开销大。并且对比思考，PCB有不同的组织方式，那么TCB应该也有不同的组织方式。 思考：用户级线程和内核级线程的根本区别？ 就是在操作系统内核看来能否意识到线程的存在即有无内核级线程的概念。 多线程模型 首先我们需要注意的是，当说到多线程模型时，操作系统首先是一定有了线程的概念，即此时肯定是可以意识到线程的存在的，所以用户级线程就没有多线程模型的以下几个分类的概念，即用户级线程不属于下面的任意一种。在支持内核级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分为以下几类。 一对一模型 一个用户级线程就对应与一个内核级线程，每个用户进程有与用户级线程同数量的内核级线程，优点是当一个线程被阻塞后，别的线程还可以继续执行，并发能力强，且此时多线程可在多核处理机上并行执行。缺点是一个用户进程就会占用多个内核级线程，线程切换由内核完成成本高。 多对一模型 优点是用户级线程的切换在目态下切换即可，线程管理的系统开销小，效率高，但是当一个用户级线程阻塞时，整个进程都会被阻塞，并发度不高。多个线程不可以在多核处理器上并行运行。（和用户级线程很想，但不是用户级线程的模型，因为此时系统能够意识到线程即内核级线程的存在）。 多对多模型 n个用户线程映射到m个(m&lt;=n)内核级线程，每个用户进程对应着m个内核线程。克服了多对一模型的并发度不高的缺点的同时又克服了一对一模型中开销太大的缺点，所以性能较为稳定不极端。还记得前面强调的内核级线程才是cpu调度的基本单位吗，所以此时这个用户进程虽然有3个用户级线程，但是一次性只能个有两个内核级线程获得cpu的调度。 因此我们可以理解为用户级线程是“代码逻辑”的载体，而内核级进程是“运行机会&quot;的载体，内核级线程才是处理机分配的单位，例如：多核cpu环境下，上面这个进程最多被分配到两个和并行执行。一段”代码逻辑“只有获得了“运行机会”才能被cpu执行。内核级线程可以运行任意一个有映射关系的用户级线程的代码，所以只有两个内核级线程中逻辑都被阻塞时，这个进程在会被阻塞。 总结"},{"title":"信号量与经典同步问题(1)","path":"/wiki/操作系统笔记/信号量与经典同步问题(1)/index.html","content":"信号量机制 在信号量机制中一个信号量代表一种资源，信号量的值就是这种资源剩余的值，如果信号量的值小于0，说明此时有进程在等待这种资源。P(s)代表申请一个资源s,如果资源不够就阻塞等待，V(s)代表释放一个资源s,如果有进程在等待该资源，则唤醒一个进程。 信号量机制实现进程互斥 首先我们先看一下信号量的结构体 12345//数值型信号量的定义typedef struct &#123; int value;//剩余资源数 struct process *L;//等待队列&#125;semaphore 一般我们如果要借用信号量机制实现进程间的互斥，那么首先毫无疑问需要将并发进程间的关键活动划定为临界区，如各进程对临界资源打印机的访问的代码就应该划分到临界区。然后我们这里初始化一个新的信号量mutex（代表一种新的资源）初始化为1，则进入区P(mutex)就是申请资源，退出区的V(mutex)就是释放资源。所以我们对于不同的临界资源都需要设置各自对应的互斥信号量进行判断。并且P,V操作必须成对出现，缺少P就不能保证临界资源的互斥访问，而缺少V就会导致资源永不释放，等待的进程一直永不被唤醒造成饥饿现象。这样当mutex设置为1时每次都保证了只会有一个进程访问临界资源并且做到了进程互斥的四大原则（“空闲让进”，“忙则等待”，“有限等待”，“让权等待”）。如下： 这样P1,P2之间就通过mutex1和P,V操作实现了并发进行间的互斥，而P3,P4之间通过mutex2和P,V操作也实现了并发进行间的互斥。代码如下： 12345678910111213141516171819202122232425262728semaphore mutex2=1;//初始化信号量semaphore mutex1=2;//初始化信号量P1()&#123; ... P(mutex1)//使用临界资源前需要加锁 critical section;//临界区 V(mutex1);&#125;P2()&#123; ... P(mutex1)//使用临界资源前需要加锁 critical section;//临界区 V(mutex1);&#125;P3()&#123; ... P(mutex2)//使用临界资源前需要加锁 critical section;//临界区 V(mutex2);&#125;P4()&#123; ... P(mutex2)//使用临界资源前需要加锁 critical section;//临界区 V(mutex2);&#125; 实际上上面这种方法也就是PV互斥锁实现进程互斥，这种方法无疑是最优解他做到了四个原则。 信号量实现进程同步 我们前面学到了进程同步它是一种直接限制关系，即一般发生在某个进程P2必须等待进程P1发生以后才可以发生，这种存在先后关系的并发运行就存在进程同步问题。那么这种让本来异步并发的进程互相配合，有序推进就需要信号量机制加以约数实现。 实现方法如下： 分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作（或两句代码） 设置同步信号量S，初始化为0 在“前操作”之后执行V(s) 在“后操作”之前执行P(s) 从上面的操作中我们也可以看出P,V操作一定还是成对出现的但是出现顺序可以发生改变，对于进程互斥是P前V后并且每个进程同时拥有P,V操作，而对于进程同步一般是V前P后，且每个进程只拥有P或者V。 代码如下： 我们还是要先声明信号量但是此时一定要注意是初始化为0： 1semaphore s=0 这样我们可以理解为信号量s代表“某种资源”，刚开始是没有的，而P2需要这种资源才能继续执行，所以他需要等待P1执行完P操作后s++，此时P2才可以继续执行，这种P,V操作就完美实现了进程间的同步。 即如果先执行到了进程1的V(s)操作，那么s++,之后当执行到进程2的P(s)操作时，由于s=1满足条件表示有可用资源，会执行s–，s的值会变回0同时p2进程不会执行block原语而是继续向后执行代码4。 如果先执行到了进程2的P(s)操作，由于s=0,s–后s=-1，此时表示没有可用资源，前面也提到过了当信号量&lt;0表示有进程等待，所以此时进程2执行block原语主动请求阻塞等待。之后当执行到P1的V(s)后s++,使s变回0同时前面也提到过当执行V操作对信号量++的同时还会检查等待队列是够有阻塞进程，如果有就会执行wakeup原语唤醒等待进程，这样P2进程就可以继续执行了。 信号量机制实现前驱关系 进程P1有句代码S1,P2有句代码S2，P3有句代码S3,…，P6有句代码S6，这些代码需要按照如下图的先后顺序执行，其实仔细看对于每一对前驱关系都对应一个信号量一组P,V操作所以前驱关系的子问题就是进程同步。因此对于前驱关系(具有多组进程同步关系的问题)需要为每一对前驱关系都设置一个同步信号量，在“前操作”之后设置相对应的V操作(由于信号量不同，V操作并不相同)同时对于“后操作”之前对应的同步信号量也需要执行P操作(由于信号量的不同，P操作也不相同)。 各进程之间的代码如下： 我们可以画出树状结构来更好的看出前驱关系如下： 总结 生产者-消费者问题 我们首先看一下问题描述 问题描述 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品都会放入缓冲区，而消费者进程每次从缓冲区都取出一个产品使用(这里的&quot;产品&quot;就是一种数据)。所以生产者和消费者共享一个初始为空，大小为n的缓冲区，只有缓冲区没满时生产者才能把产品放入缓冲区，否则就要阻塞等待。只有缓冲区不空时消费者才能从产品中取出产品，否则必须阻塞等待。并且缓冲区是临界资源，需要各进程互斥的访问。 问题分析 我们对于这种问题很容易就能想到刚刚介绍的PV操作实现同步互斥关系。一般对于PV操作解决问题就是分析出题目中的各个进程之间的关系，然后画图确定P,V操作的大致顺序，同时设置信号量(一般都是数值型)进程互斥设置为1就行，而对于同步信号量的处置要根据对应资源的初始值设置。对于生产/消费者问题我们分析一下题目要求： 缓冲区没空的时候消费者可以消费(同步关系) 缓冲区没满的是够生产者才可以生产(同步关系) 进程之前（即生产者-消费者，消费者-消费者）之间都需要互斥访问临界资源缓冲区(互斥关系) 所以我们需要设置三个信号量如下： 1234semaphore mutex=1;//互斥信号量，实现对缓冲区的互斥访问semaphore empty=n;//同步信号量，表示空闲缓冲区的数量，当&lt;=0表示缓冲区满semaphore full=0;//同步信号量，表示产品的数量即非空缓冲区的数量当&lt;=N时表示缓冲区没满 那么我们可以用如下代码实现： 首先无论是哪个进程进入临界资源都要新进行mutex互斥锁判断，然后对于生产者和消费者之间的同步关系分别具有一个P,V同步锁的一部分。一定要记住P操作每次都–，V操作每次都++同时V操作每次还会进行唤醒等待进程的操作。所以一定要理解并不是每次产品者都把缓冲区用产品填满以后才唤醒消费者，而是当生产出了产品就可以唤醒等待的消费者了同时也并不是消费者每次都用空了缓冲区才唤醒生产者，而是只要缓冲区没满就会唤醒生产者，即边生产边消费的现象出现，但是最终边生产边消费的现象会趋于一个稳态： 生产的速度和吃的速度整体看来相当，那么缓冲区既不空也不满整体上看来生产者和消费者都有并发互斥访问临界资源 生产的速度整体上比消费的速度快，最终缓冲区满了以后生产者沉睡并且直至缓冲区再次没满的情况出现前一直沉睡直至消费者消费了产品后再次唤醒生产者 生产的速度整体上慢于消费的速度，那么缓冲区空了以后消费者全部沉睡等待，当生产者再次生产出产品时就会再次唤醒消费者 思考：相邻的P操作能够更改顺序？ 即如下图： 临界区访问互斥锁的P操作和同步信号量检验的P操作进行了交换，此时是先检验能否进入临界资源在检验能否生产或者消费的情况。 我们假设此时缓冲区已经满了，即empty=0,full=n。此时生产者又生产了一个产品按照① 使mutex变为0，然后在执行②，由于此时已经没有空闲缓冲区了，所以生产者被阻塞沉睡，由于生产者阻塞，因此切换回消费者进程，消费者进程执行③，由于mutex=0即生产者还没有释放对临界资源的&quot;锁&quot;，所以生产者就一直沉睡等待与此用时生产者也在沉睡等待消费者消费产品造成了&quot;死锁&quot;现象的出现。 同样的假设缓冲区现在没有产品，即empty=n,full=0。那么此时消费者进入临界区想取出一个产品，此时mutex=0，发现没有产品可以取出了，所以阻塞沉睡切换到生产者进程生产者生产了产品想放入临街资源缓冲区中，但是此时mutex=0消费者还没有释放&quot;锁&quot;所以生产者只能也沉睡等待消费者出来在放入产品，而此时消费者也在等待生产者放入产品也造成了&quot;死锁&quot;现象。 所以我们可以总结出来无论是哪个进程实现互斥的P操作必须放在实现同步的P操作之后。 思考：上图右边的问题：能否把使用产品放到PV操作之前 即如下图： 12345678910consumer()&#123;\twhile(1)&#123; //使用产品 P(mutex); P(full); //从缓冲区取产品 V(mutex); V(empty); &#125;&#125; 想也不要想这种情况会造成一个很离谱的情况就是此时如果缓冲区已但是消费者却可以不经过检验继续先使用产品，但是此时缓冲区已经没产品了他消费的产品从哪里来呢？ 思考：相邻的V操作能够更改顺序？ 事实证明，V操作之间是可以更改顺序的，此时不会造成&quot;死锁&quot;现象仍可以正常执行。 多生产者-多消费者问题 问题描述 桌子上有一只盘子，每次只能向其中放一个水果，爸爸专向盘子中放苹果，妈妈专向盘子放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果，只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果，仅当盘子中有自己需要的水果，儿子或者女儿才可以从盘子中取水果。 问题分析 我们发现有如下几个关系： 盘子需要互斥访问(互斥关系) 只有盘子中为苹果时女儿才取(同步关系) 只有盘子中为橘子时儿子才取(同步关系) 只有盘子为空时爸爸或者妈妈才可以放水果(同步关系) 所以我们第一想法就是设置4个信号量如下： 1234semaphore mutex=1;//实现盘子互斥访问的信号量semaphore apple=0;//盘子中有几个苹果&lt;=0为无苹果semaphore orange=0;//盘子中有几个橘子&lt;=0为无橘子semaphore plate=1;//盘子中还可以放几个水果&lt;=0表示不可以放水果 那么4个进程之间的代码实现如下： 很明显确实实现了题目要求。 思考：可不可以不要互斥信号量？ 即plate互斥信号量删除不用能否满足要求，如下： 我们发现也没有太大的问题，因为此时apple,orange,plate三个信号量永远只有一个会是1也就说明每次都只会有一个进程是非阻塞状态，所以也就只有他可以访问临界区完全不可能出现多个进程用时访问临界资源的情况，所以完全不需要互斥信号量mutex。所以这种方法更好，但是注意仅适用于plate=1的情况，如果一次性可以放入2个或多个水果，即缓冲区容量&gt;1的情况就必须使用mutex互斥信号量了。 思考：为什么缓冲区容量&gt;1时必须使用互斥信号量mutex? 因为此时假设缓冲区容量为2，即盘子可以放2个水果，那么此时假设父亲P(plate)可以访问盘子(此时plate初始值为2，一次P操作plate–=1)，母亲此时也进行P(plate)也可以访问盘子(因为此时plate&gt;0还可以通过检验)此时就出现了两个进程同时访问缓冲区的情况，有可能导致两个进程写入的缓冲区数据相互覆盖。因此当缓冲区大于1的情况时就必须专门设置一个互斥信号量mutex来实现互斥访问了。 总结 对于无论是生产者-消费者问题还是多生产者-多消费者问题最好都加上mutex锁以避免特殊情况出现。"},{"title":"什么是进程","path":"/wiki/操作系统笔记/什么是进程/index.html","content":"进程的概念，组成，特征和组织方式 进程的概念 程序是静态的，就是存放在某个磁盘里的可执行文件，是一系列指令的集合。而进程是动态的，是程序的一次执行过程，所以同一个程序会对应多个进程。 如上图，QQ是一个程序，而图中的三个框分别对应着QQ程序三次执行过程，因此各为一个进程。仔细回想，你会注意到并发性所描述的是进程在同一个时间间隔内同时进行。 进程的组成 那么操作系统该如何区分每一个进程呢，毕竟有些进程在我们看来是一模一样的根本不好区分，操作系统则是根据PID来区分不同的进程。当一个进程被创建时，操作系统就会为这个进程分配一个唯一的且不重复的“身份证号”–PID。 而操作系统要记录PID和进程所属用户ID（UID)，这个是进程最基本的描述信息，可以使操作系统区分各个进程。例如上图中的3个QQ登录进程实际上在操作系统看来并不相同，他们每个进程各对应着一个独一无二的PID号码。 并且操作系统还要记录为进程分配了那些资源（如：分配了多少内存，正在使用那些I/O设备和正在使用哪些文件），这样以便实现操作系统对于共享资源的管理和分配。 同时还要记录进程的运行情况（如：CPU使用情况，磁盘使用情况，网络流量使用情况等）以方便实现操作系统对进程的控制和协调调度。 而这些信息均被存放在一个数据结构–PCB中（Process Control Block)中，即进程控制块，操作系统需要对各个并发运行的进程进行管理，但凡是管理时所需要的的信息，都会被放在PCB中，因此PCB不仅仅是记录PID号码而已，而是进程的信息以及所运行的环境都要记录，这样放切换不同的进程时操作系统可以保证其在合适的运行环境下进行适当的工作。并且要注意每一个进程都对应一个自己的PCB存储着自己的信息，当进程结束时操作系统会回首PCB，因此可以说PCB是存储进程完整信息的最小单位。 同时进程还拥有程序段和数据段，分别用来存储程序的代码和运行过程中的各种数据。而PCB虽然也属于进程的一部分，但是他并不是提供给进程自身使用的，而只是一个个人身份信息卡，用来提供给操作系统使用，只有程序段和数据段才是进程自己使用的。 思考：程序是怎么运行的？ 先看下图： 这个是一个高级语言翻译到指令然后由cpu执行的过程，那么高级语言-&gt;指令-&gt;cpu执行所对应的一个程序具体的运行过程是怎样的呢？如下图： 高级语言所编写的可执行文件.exe存放于硬盘上存储，当双击打开程序的一个进程时，首先会把程序放入内存，并且操作系统会创建一个PCB分配给这个进程，此时进程所组成的三部分PCB，程序段和数据段都被存放在了内存中，并且程序段中是二进制指令，这样cpu在执行指令时会取出相对应的指令，并将执行所产生的的数据存放在数据段，在进程运行时cpu和内存会频繁的进行信息交换。 我们在这里定义一个新名词叫做进程实体或者进程映像，就是程序段，数据段，PCB三部分的组合，那么引入进程实体后，我们可以更加准确的定义进程：进程并不是一个可见的物质实体，而是一个进程实体的运行过程即是一种连续性的状态组成的，是系统进行资源分配和调度的独立单位，所以准确来说我们之前所称呼的进程实际上是进程实体，因此对于每一个进程，他们的PCB，数据段各不相同会时刻发生着变化，而程序段就是指令集合，一般同一个程序所产生的进程程序段代码会相同。又因为PCB是记录进程的信息，所以PCB中的某些信息（如占用内存的状况等环境信息，当然PID除外）肯定也是时刻发生变化的并且PCB是进程存在的唯一标志。 进程的特征 程序是静态的而进程是动态的，因此进程拥有以下几个特征： 动态性：进程是程序的一次执行过程，是动态产生，变化和消亡的，这也是进程最基本的特征。 并发性：内存中有多个进程实体，各进程可以并发地执行。 独立性：进程是能够独立运行、独立获得资源、独立接受调度的基本单位。 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制”来解决异步问题。 结构性：每个进程都会配置一个PCB，结构上看，进程由程序段、数据段、PCB组成。 进程的组织方式 在一个系统中，一般会有数十至数百乃至数千个PCB，为了能够对他们有效的管理，需要适当的方式将PCB组织起来存储管理。进程的组成讨论的是一个进程内部的组成结构信息，而进程的组织讨论的是多个进程之间的组织方式。这里我们讨论两种方式。 链接方式 链接方式是按照进程的状态将PCB分为多个队列，操作系统持有各个队列的指针方便管理进程。如下： 这种方法优点很明显，各个PCB形成一个队列并且PCB指针执行下一个PCB，由指针统一指向调配，切换时更改指针指向后一个PCB即可，切换简便，但是缺点时当有对个PCB块时采用这种队列，当中途需要删除或者提高某个PCB优先级时则需要对两边的指针进行更新比较复杂。 索引方式 根据进程状态的不同，建立几张索引表用来记录PCB地址，操作系统指向各个索引表的指针。如下： 这种方法优点是建立索引表存储，更改指针执行即可切换进程，并且创建删除只需对索引表项进行操作，非常简便，但是缺点是当PCB很多时，索引表就会长可能需要建立多级索引表，同时索引表也许占用额外的空间。 进程的状态与转换 进程的状态 这是个非常重要的概念，他根据不同的进程所处信息环境将进程分为以下几个状态： 创建态 进程正在被创建时，他的状态就是创建态，这个阶段操作系统会为进程分配资源并初始化PCB。因此可能会有多个程序处于就绪态都带等待cpu的情况出现。 就绪态 当进程创建完成后并不是立刻就上cpu执行，当创建完成后便进入了就绪态，此时已经具备了运行条件，但是如果此时cpu没有空闲，则该就绪态进程则需要等待暂时不运行随时准备进入cpu执行，当然运气好的话，也可能刚创建完就上cpu。 运行态 当cpu空闲时，并且内存中有处于就绪态的进程，操作系统就会选择一个就绪态进程（这个会涉及到多种不同的算法，后面介绍）让其上处理机pu执行，此时这个进程就是处于运行态。 阻塞态 当然进程不可能会提前将所有图中的准备都一次性做好，他在运行时可能中途会请求等待另一个事件的发生后才能继续执行，或者发现某个所需的共享资源已被占用，则需等待其他进程的相应，此时操作系统会让这个进程下cpu，并让他进入阻塞态等待（毕竟cpu不只是服务这一个进程，可没时间一直等），此时操作系统就会启动另一个就绪态的进程运行。所以阻塞态不可能直接变为运行态，一定要先恢复到就绪态（毕竟要先准备好切回该进程的工作环境等工作）。并且可以看出在阻塞态之前进程一定是处于运行态。 终止态 一个进程已经执行完成或者中途被用户关掉时就会执行exit系统调用，此时会请求系统终止该程序，然后程序就会进入终止态，操作系统让该进程下cpu，并回收内存空间等资源，最后还要回首该进程的PCB，当终止进程的工作完成之后，这个进程就彻底消失了，如果是连接形式组织方式，那么这个PCB就会删除，指针指向它所指向的下一个PCB，而如果是所以方式，则PCB删除的同时，索引表的项也会删掉。注意就绪态/阻塞态/运行态的进程都可能立刻转换为终止态。 进程状态的转换 这个模型非常重要，需要牢记。 从上图可见运行态和就绪态之间是双向可以切换的，而当是外界因素例如时间片或者其他进程抢占导致的下cpu实惠直接回到就绪态，只有是通过系统调用的方式申请请求时才会切换到阻塞态，即是进程一种的自愿让出cpu的主动行为，所以可以理解为此时自愿下cpu,所以会将工作环境，工作的状态等记录下后下cpu,当可以继续执行的时候则首先需要在配置回所需的工作环境并做好之前的工作状态到达就绪态才能继续执行，而当是被动的不情愿下cpu时则会随时准备抢回cpu的使用权所以会直接切换到就绪态。当然要注意阻塞态切换到就绪态是被动地行为因为这不是进程想继续回到就绪态准备执行就可以随时自主切回就绪态的，而是需要等到某个事件发生后才能回到就绪态，由于时间无法预测所以只能被动等待。而运行态到终止态一般是调用了exit函数（不一定是正常执行完成，当遇到重大的bug如数组越界等导致进程无法继续运行也会触发），一旦转换为终止态，则只能重新创建进程了。 在进程PCB中，会有一个state变量来记录当下进程的状态，1代表创建态，2代表就绪态，3代表运行态…为了对同一个状态下的各个进程进行统一的管理，操作系统会将各个进程的PCB以链接形式或者索引形式统一存储管理。 进程控制 进程控制就是对系统中的进程实施有效的管理，它具有创建新进程，撤销已有进程，实现进程状态转换等功能，其中最重要的就是实现进程的状态转换。 进程控制的实现 实现进程的控制肯定会也是需要程序来实现的，而这个程序就是内核中的原语部分（重点：原语是一个程序），原语是一种特殊的程序，他的执行具有原子性，即这段程序的运行必须是一气呵成无中断的。 思考：原语为什么不能有中断？ 因为如果不能一气呵成，那么就有可能导致操作系统在某些关键数据结构信息处不统一，从而影响操作系统进行个别的管理工作。如果可以中断，就会出现重大的bug，如： 这是一个以连接形式组织的PCB队列，此时假设系统要执行将PCB2（此时他在队列头部，该轮到他了）所对应的进程2等待的进程已经发生了，则此时需要从阻塞态转换到就绪态，即放到就绪队列中，此时原语程序需要进行以下两个步骤： 将PCB的state变量设为1（假设1表示就绪态，2表示阻塞态） 将PCB2从阻塞队列放到就绪队列 那么如果原语可以被打断的话，此时刚刚执行完第一个步骤后收到了中断信号停止执行原语程序，就会出现state=1但是却在阻塞队列的bug。所以原语必须具有一气呵成的特点。 思考：如何实现原语的“原子性”？ 我们可以使用“关中断指令”和“开中断指令”两个特权指令实现原子性。 我们首先知道cpu在每执行完一个指令后都会例行检查是否有中断信号需要处理，如果有，就会暂停运行当前的这段程序，转而执行相应的中断处理程序。如下： 那么显然在执行原语时我们需要cpu不在根据中断信号而停止运行原语程序，因此就有了关中断指令和开中断指令两个特权指令（此时其他的指令如指令1，2和a,b还是非特权指令），那么可以这样实现：当cpu执行了关中断指令后，就不在例行检查中断信号，知道执行到开中断指令之后在恢复检查。这样关中断和开中断之间的这些指令序列（指令a,b)就是不可被中断的了，当然在这期间cpu还是会受到中断信号，但是此时不检查，就可视为忽略了，知道开中断以后在执行中断信息。如下图： 显然关开中断指令必须是特权指令，否则用户可以修改就会造成原语程序被打断的情况出现。 进程控制相关的原语 首先我们看有关进程创建的原语： 有关进程终止的原语： 这里面将该进程拥有的所有资源归还给父进程或操作系统要特别注意。撤销原语是指由就绪态/阻塞态/运行态切换到终止态再到释放时所执行的原语程序。 有关进程的阻塞和唤醒的原语 有关进程的切换的原语： 我们可以看出大部分原语都会有许多步骤，并且引起原语的事件也各不相同。 程序是如何运行的 学完进程转换后，我们在更加详细的讨论一下程序在运行时切换进程在切回进程的具体步骤。首先我们需要了解一个新的概念–寄存器，就是用来存储信息的，这里寄存器可以分为许多类（机组原理有讲），如下图： 我们可以看出PC和IR的作用分别是存储下一条指令和现在正在执行的指令的特殊功能寄存器，并且回忆PSW寄存器是用来记录当前cpu处于管态还是目态的，通用寄存器就是用来存储中间的某些计算数据结果的，所以PC和IR肯定是经常与内存中进程处的程序段进行交流的，而通用寄存器就是与数据段进行频繁的信息交换。 当执行完指令1后PC和IR会立刻更新，并且如果需要通用寄存器会存储信息。那么鸡舍现在进程A执行到了指令3以后需要开始执行另一个就绪进程B，则此时进程A需要切换到阻塞态，因为通用寄存器和PC,IR都是共享资源，那么进程A的信息肯定就不能在占用了，那么之后执行完进程B切换回进程A时如何能够恢复到之前的运行环境呢？如下图： 上图是执行进程B到指令x，此时需要切换回进程A的运行环境并开始执行进程A。这时我们就需要PCB来保存之前进程A运行态时的环境信息（一些必要的寄存器信息），这样在切换回进程A（当然这之前进程A肯定是要先到达就绪态）后可以保证其正常运行。如下图： 因此PCB会存储一些进程必要的环境信息，所以我之前说道PCB会随时发生小部分变化。但是要注意到这个信息是提供给操作系统，然后操作系统进行恢复cpu到之前进程A的运行环境的任务。所以PCB存储的环境信息也是提供给操作系统的，进程自身不使用。 进程通信 顾名思义，进程之间也是需要信息交换的，进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间。但是进程之间的信息交换又是必须实现的，所以为了进程之间的通信安全，操作系统提供了一些方法。 共享存储 即有一个共享空间可以来实现两个进程之间的信息交换，但是需要满足两个进程对共享空间的访问必须是互斥的（互斥访问通过操作系统提供的工具实现）。操作系统只负责提供共享空间和同步互斥工作，具体的信息编写和读入是由进程之间完成的。 思考：为什么共享空间的访问要互斥？ 访问互斥即意味着每次只能有一个进程进入共享空间进行读写，原因很简单，如果可以有多个进程同时进入共享空间进行信息的编写，那么就会出现冲突，即两个进程可能同时对某一个变量更改，这种冲突应该避免。 思考：共享空间的实现方式 共享存储有基于数据结构的共享和基于存储区的共享两种方式来实现，两种不同的共享空间会对共享速度产生影响。 基于数据结构的共享：比如共享空间里只能放入一个长度为10的数组，这种共享方式速度慢并且限制多，是一种低级的通信方式。 基于存储区的共享：在内存中划出一块共享存储区，数据的形式，存放位置都由进程控制，而不是操作系统，相比之下，这种共享方式速度更快是一种高级的通信方式。 消息传递 进程间的数据交换格式与共享一个空间不同，而是“信书传递”，数据交换以格式化的消息为单位，进程通过操作系统的“发送消息/传递消息”两个原语（不可打断）进行数据交换。一般一个消息由两部分组成： 而消息传递又有两种方式，一种是直接通信方式，类似于邮递员链接，消息直接挂到接受进程的消息缓冲队列上，另一种是先发送到中间实体类似于信箱，然后另一个进程从中间实体收取，因此也称为“信箱通信方式”。如下图： 上半部分是直接通信，下半部分是简介通信方式，无好坏之分。 管道通信 如下图： 管道实际上是一个用于连接读写进程的一个共享文件，又名pipe文件，其实就是在内存中开辟一个大小固定的缓冲区。那么他和共享空间又有什么本质区别呢？ 管道采用的是半双工通信，某一个时间段内只能实现单向的传输，即一个时间段只能我传给你或者你传给我，当然方向可以任选只是一个时间段只能一个方向，如果需要双向同时通信，则只能在设置一个管道即两个管道才能同时双向通信。因此管道在一个时间段内永远只有一端是可以写数据的口，另一端是读数据的口，且不能同时打开。 各进程要互斥的访问管道（即读写不同时）。 数据以字符流的形式写入管道，当管道满时，写进程的write()系统调用就会被阻塞即使没有写完，等待读进程将数据取走。当读进程将数据全部取走后，管道变空后，此时读进程的read()系统调用会被阻塞，此时才能继续write()。 如果没写满，就不允许读，如果没读空，就不允许写。 数据一旦被读出，就从管道被抛弃，这就意味着读进程最多只有一个，否则可能会有读错误数据的情况，但是写进程可以有多个。 小测试：项目实战 如果你对管道通信了解透彻了，尝试完成以下这个大作业吧😬：作业大礼包"},{"title":"内存管理概念","path":"/wiki/操作系统笔记/内存管理概念/index.html","content":"内存基础 内存的定义和作用 其实我们在前面学习进程时已经经常提到了内存的部分知识，我们知道一个进程在上cpu之前需要现在内存中处于就绪态，上cpu后进程实体的PCB,数据段，代码段大部分都处于内存中方便随时和cpu进行信息交换。所以内存可存放数据，程序执行前需要先放到内存中才能被cpu处理----所以cpu的功能是缓和cpu与硬盘之间的速度矛盾。 思考：内存如何区分多个程序的数据存储地？ 我们知道在多道程序环境下，系统中会有多个程序并发执行，也就是说会有多个程序的数据需要同时放在内存中，那么如何区分每一个数据段是属于哪个程序的呢？实际上内存会分为许多部分，有一个一个小房间，每一个小房间就是一个“存储单元”，内存地址从0开始，每个地址对应一个存储单元。 如果计算机“按字节编址”，则每个存储单元为1字节（1Byte)，即1B，即8个二进制位。 如果字长为16位的计算机“按字编址”，则每个存储单元为1个字，每个字的大小为16个二进制位，所以一个字=两个字节。 补充：常用的数量单位与换算 1KB(1K)=210Byte1KB(1K)=2^{10}Byte 1KB(1K)=210Byte 1MB(1M)=220Byte1MB(1M)=2^{20}Byte 1MB(1M)=220Byte 1GB(1G)=230Byte1GB(1G)=2^{30}Byte 1GB(1G)=230Byte 所以我们知道换算进制为2^10也就是1024Btye,所以1K实际上已经非常大了。 思考：4GB内存是什么意思？ 一台手机/电脑的内存为4GB，是什么意思。我们按照上面的公式计算，4GB=4*2^30Byte,如果内存是按照字节编址的，那么也就是会有2^2*2^30=2^32个房间，又因为是从0开始编号，所以房间编号为0~2^32-1。所以需要2^32个地址一一标识这些房间，所以需要32个二进制位来表示。 指令的工作原理 我们思考现在要对x=x+1指令语句进行执行，具体过程如下图： 首先高级指令x=x+1翻译成处理机可以看懂的二进制指令串（可能一个高级指令会对应多条二进制指令），然后cpu执行这个二进制指令串。 我们从上面可以看到cpu根据二进制指令找到010011111处的数据进行取出到寄存器中，然后+1操作，在返还该值到地址处，这样就完成了一个读写操作将x+1。可见，我们写的代码要翻译成CPU能识别的指令，这些指令会告诉CPU应该去内存中的那个地址读/写数据，这个数据应该做什么样的处理。在这个例子中，我们默认这个进程的相关内容从地址#0开始连续存放，指令中的地址参数直接给出了变量x的实际存放地址（物理地址）。 思考：如果进程不是从地址#0开始存放的会影响正常执行吗？ 比如如下面这个案例，我们现在将79处的存储单元写入10然后再将79处的数据读入到寄存器3中，如果进程是从#0开始存放数据的，那么确实可以正常执行： 从上面的图中我们也可以看出程序经过编译，链接后生成的指令中指明的是逻辑地址即相对地址，即相对于进程其实地址而言的地址，如上图中实际上指令中的地址为79处并不是指的物理地址79处，而是相对于进程起始处79处的地址，只不过是刚好此时进程是从地址为#0开始存储的，所以逻辑地址处的79就是映射的物理地址的79处。所以可以正常运行。（为了简化理解，本次我们都默认操作系统为进程分配的是一片连续的内存空间）。 但是实际上情况不可能总是如此的理想。如下图： 我们如果默认逻辑地址就是物理地址的话，此时上面的过程就会出现重大错误。因为此时指令0和1值的还是逻辑地址处的79，但是此时这个进程并不是放到内存中的#0地址开始毕竟内存中会存入许多进程（并发性导致许多进城会在内存中存储随时准备就绪上cpu)，所以此时指令0和1处的所说的的逻辑地址79处实际上是相对于此时起始地址#100开始后面的79个存储单元即绝对地址179处的数据，但是如果我们仅仅是按照逻辑地址==绝对地址执行的话，那么此时就会映射到其他进程的数据段（物理地址79处）这明显是不对的，所以我们在装入模块（可执行文件）进入内存时（这是高级调度/作业调度）需要对地址进行转换以达到在执行指令时读/写数据的地址正确，此时我们需要某些策略来使得指令中的逻辑地址转换为正确的物理地址。 思考：如何将指令中的逻辑地址转换为物理地址？ 策略1：绝对装入 策略2：可重定位装入（静态重定位） 策略3：动态运行时装入（动态重定位） 模块装入的三种方式 绝对装入 在编译时，如果知道程序将放到内存中的那个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存。比如上面那道题我们在装入模块到内存之前知道将要在内存地址为100的地方开始存放。 那么此时在对文件进行编译，链接后指令中不在使用逻辑地址，而是直接转换为物理地址如上图，此时在将装入模块（可执行文件）放入内存中，当处理机执行到指令0和指令1时就会到正确的存储单元（物理地址为179）读/写数据。如下图： 虽然没有什么大问题，但是绝对装入只适用于单道程序环境。程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。通常情况下都是编译或汇编时在转换为绝对地址。 思考：为什么只使用于单道程序环境？ 很简单，因为在装入模块进入内存后指令一直是不变的物理地址，但是我们知道在多道程序环境中进程是并发异步执行的，不可能一直存储于内存的一个固定地方，但是一旦装入模块变换了存储地址那么初始地址就也改变了，那么此时很显然此时装入模块中的地址就又出现指向错误了，而且如果绝对装入只能适用于单道环境程序，显然也不满足进程并发执行和内存建立的初衷，所以这种方法缺陷较大，有待改进。 可重定位装入（静态重定位） 静态重定位（可重定位装入），顾名思义肯定是能够弥补上面绝对装入的缺陷，具体做法是编译，链接后的装入模块的地址还是从0开始的，但是指令中使用的地址，数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块放入内存的适当位置。装入时进行重定位，将逻辑地址变换为物理地址（地址变换是在装入时一次完成）。 我们从上图可以看到，他是在装入时对于逻辑地址进行了+100的处理，这样当再次进入内存分配到内存的其他地方时也可以随时更新为正确的地址，不像绝对装入那样直接改变为绝对地址当再次进入内存就有可能出现错误。 思考：还有没有什么可以改进的地方？ 我们对比一下绝对装入和静态可重定位装入两者的区别。 装入策略 地址变化 异同点 绝对装入 编译后逻辑地址-&gt;绝对地址装入内存 有效解决了逻辑地址-&gt;绝对地址的问题，使得可以映射到正确的物理地址上，但是编译后直到运行完销毁前起始存放地址不许更改 静态重定位装入 编译后仍是逻辑地址，装入内存时逻辑地址-&gt;绝对地址 在编译后还是逻辑地址，只有在放入内存前进行+起始地址操作转换为正确的绝对地址，当出内存再次进内存时如果更改了起始存放地址可动态转换为正确的物理地址 但是我们发现静态重定位的特点是一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，作业就不能装入该内存并且最大缺陷是作业一旦进入内存后，在运行期间就不能在移动，也不能再申请内存空间。所以我们好需要解决在内存运行期间移动的问题。 动态运行时装入（动态重定位） 动态重定位：编译，链接的装入模块的地址还是从0开始的，装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方法需要一个重定位寄存器的支持。 装入时： 执行时： 我们看出动态重定位满足所有要求是最好的策略。动态重定位在满足程序在内存中移动的同时，还可以将程序分配到不连续的存储区，所以他区别于静态重定位不需要一次性申请所有连续的地址空间并且每次都只需要取出部分代码执行，如果需要映射地址则通过重定位寄存器可以随时指向正确的存储单元（都不需要连续存储了），简直是太棒了。并且由于是重定位寄存器更改映射地址所以可以向用户提供一个比存储空间大得多的地址空间（虚拟性）。 思考：总结三种策略的异同点？ 我们从以下几个角度区分这三个策略： 装入模块起始地址：绝对装入策略装入模块中的起始地址未必是0，但是静态重定位和动态重定位一定是0 逻辑地址-&gt;物理地址转换时期：绝对装入策略中是在编译，链接后即将逻辑地址转换为物理地址，静态重定位是在装入内存时，而动态重定位是在执行时借助重定位寄存器转换。总的来说，只有动态重定位是在内存中还保存逻辑地址。 借助外界手段：只有动态重定位需要一个辅助的重定位寄存器，静态重定位不需要。 装入的地址要求：绝对装入和静态重定位都需要一次性申请一片连续的容量够大的地址空间，而动态重定位可以离散装入。 思考：链接编译到底是什么？ 我们知道在一个程序从写到运行一次需要经过以下几个过程： 编译就是将用户源代码编译成若干个目标模块（编译就是把高级语言翻译为机器语言），而链接程序将编译后形成的一组目标模块，以及所需要的的库函数链接在一起，形成一个完整的装入模块，装入是由装入程序将装入模块装入内存运行。所以链接很重要，他是形成一个模块的关键步骤，这里面有3中链接方式。 链接的三种方式 静态链接 静态链接就是在程序运行之前先将各目标模块及它们所需要的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。如下图： 没啥大问题，但是这样就必须一次性申请一片连续的存储地址貌似难以实现因为内存中会造成许多内存碎片。而且准备工作时间很长，没有链接成一个完整的模块之前不能进入内存执行。 装入时动态链接 将各目标模块装入内存时，边装入边链接的一种链接方式，如下图： 这样即使还没有完成全部链接，但是前面的部分模块已经可以进入内存，准备工作时间明显缩短。 运行时动态链接 在程序执行中需要该目标模块时，才对他进行链接。如下图： 不但占用内存空间小，准备时间短，而且便于修改和更新，便于实现对目标模块的共享。 思考：怎么就便于实现目标模块的共享了？ 我们思考有两个程序现在都有一个调用打印机I/O设备的代码段，那么对于运行时动态链接的好处是不需要写两份了，谁需要谁就链接这部分模块，加大了模块的可重复利用率，这也是组件化思想的体现。 总结 基本上全是重点和易错点 内存管理 回顾前面所讲的知识，我们主要着重于对装入模块装入内存前和装入内存时的问题如正确的地址转换，链接方式等，那么接下里来我们在讨论一下对于内存中运行时对于各进程的管理。 内存空间的分配与回收 操作系统作为系统资源的管理者，当然也需要对内存进行管理，要管些什么？首先对于内存空间的分配和回收的任务必不可少。如下： 这些问题都会涉及到许多后续问题所以有不同的算法策略，后面我们将详细讲到。 内存空间的扩展 我们前面也讲过操作系统的虚拟性，实际上就是用过逻辑地址和物理地址的映射以及内外存切换装入等方式实现的，从而能够在有限大小的内存空间中虚拟出远大于物理空间大小的内存空间。所以操作系统需要提供某种技术从逻辑上对内存空间进行扩展。 地址转换 为了使变成更方便，程序猿写程序时应该只需要关注指令、数据的逻辑地址，而逻辑地址到物理地址的转换（这个过程称为地址重定位就是之前讲的三种装入策略）应该由操作系统负责，这样就保证了程序猿写程序时不需要关注物理内存的实际情况。类似的还有刚学写管程概念，也是为了更加方便于程序猿只集中于程序的编写而提出的。所以对于三种装入方式，我们可以看出只有动态重定位是现代操作系统才拥有的，毕竟其他两种方式还需要程序猿关注地址转换为体以防止出错。 内存保护 同时操作系统还需要提供内存保护功能，保证各进程在各自存储空间内运行，互不干扰。这里有两种策略： 策略1: 在cpu上设置一对上、下限寄存器，存放进程的上，下限地址。进程的指令要访问某个地址时，cpu检查是否越界。 所以可以看出上、下限寄存器存储的是物理地址。 策略2 采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界的检查，重定位寄存器中存放的是进程的起始物理地址，界地址存放的是进程的最大逻辑地址。 所以管理判断是否越界的是界地址寄存器，并且策略2是根据逻辑地址进行越界检查的，而策略1是根据物理地址进行越界检查的。 总结 覆盖与交换 这里我们讲的覆盖与交换技术不用想肯定是内存空间扩充的技术来实现操作系统的虚拟性，扩大内存空间大小。 覆盖技术 在早期的计算机内存很小，也没有操作系统所以无虚拟性的概念，即就是逻辑地址==物理地址的情况，那么比如IBM推出的第一台PC机最大只支持1MB大小的内存，那么就真的只是1MB了，所以会经常出现内存大小不够的情况出现（比如一个文件为20MB，那么放都放不进去更谈何运行）。所以后来提出了覆盖技术来解决程序大小超过物理内存总和的问题。 覆盖技术的思想是将程序分为多个段（多个模块）。常用的段常驻内存，不常用的段在需要时再调入内存（很容易想到）。所以内存中相应的有一个“固定区”和多个“覆盖区”。需要常驻内存的段放在“固定区”，调入后就不再调出（除非运行结束），不常用的段放在“覆盖区”，需要用到时调入内存，用不到时调出内存。如下： main函数部分在固定区，而BCDEF在覆盖区，这种覆盖技术确实解决了问题，但是必须由程序猿声明覆盖结构，操作系统完成自动覆盖。所以缺点是对用户不透明，增加了用户编程负担。覆盖技术只用于早期的操作系统，现在已经成为历史。并且我们发现还有一个小细节操作系统还可以做到让不能同时被访问的程序段共享同一个覆盖区，这样也做到了一定的减少占用内存空间的作用。 交换技术 交换技术（对换技术）的设计思路是当内存空间紧张时，系统将内存中某些进程暂时换出内存，把外存中某些亿具备运行条件的进程换入内存（进程在内存与磁盘间动态调度，这也是绝对装入方式易出错的地方）。 这里面的进程挂起和就绪运行的状态切换涉及的是中级调度（内存调度），就是决定将那个处于挂起状态的进程重新调入内存。 所以暂时被换出到外存等待的进程为挂起状态（suspend),挂起态又可细分为就绪挂起和阻塞挂起两种状态，这就不得不再提一下状态经典三角切换模型。 思考：交换技术应该将挂起的进程放在外存（磁盘）的什么位置？ 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式（空间碎片少）。 对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换出速度，因此通常对换区采用连续分配方式（学过文件管理章节后即可理解）。总之，对换区的I/O速度比文件去更快。 思考：什么时候应该交换？ 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页（后面会讲）就说明内存紧张，此时就可以换出一些进程，如果缺页率明显下降了，那么就可以暂停换出了。 思考：换出时应该换出那些进程？ 可优先换出阻塞进程（毕竟在哪都是等😉），可优先换出优先级低的进程，为了防止优先级低的进程在被调入内存后很快又被换出，有的系统会考虑进程在内存的驻留时间来决定换出哪个进程。但是一定要注意PCB是一定不会被换出的，他是常驻内存的。 总结 一定要注意覆盖技术和交换技术的区别在于角度不同，覆盖技术着眼于一个程序或进程，而交换技术是着眼于全局多个进程之间的关系，所以覆盖技术与交换技术互相配合最大限度的对内存空间进行扩展。"},{"title":"同步与互斥","path":"/wiki/操作系统笔记/同步与互斥/index.html","content":"进程同步与进程互斥 进程同步 首先我们在前面已经知道进程具有异步性的特点，异步性是指各进程并发地以各自独立的，不可预知的速度向前推进。而在某些需求上，仅仅实现异步性是不可以的。例如：进程通信中的管道通信，读进程和写进程是并发执行的，由于并发性必然导致异步性，因此“写数据”和“读数据”两个操作虽然根据并发和异步的特点会在一个时间间隔内交叉运行，但是归根结底，“读数据”时必须在“写数据”后面的，所以这里仅仅有异步性是不能满足这个需求的实现的，因为并发异步执行的先后顺序是不确定的。 所以这里我们引入了“进程同步”的概念，它是指为了完成某个任务（如上面的管道通信）而建立的两个或多个进程，这些进程因为需要在某些位置上协调他们的工作次序而产生的限制关系。进程间的直接限制关系主要就是来源于他们之间的相互合作。 进程互斥 进程的“并发”需要“共享”的支持（前面讲过并发和共享相互存在，是操作系统进程的两大基础特性）。那么各个并发执行的进程不可避免的需要共享一些资源（比如内存，又比如打印机、摄像头等I/O设备），所以这里根据同一时间段内能否允许多个进程同时使用这个共享资源将共享细分为两类。 同时共享方式 即系统中的某些共享资源，允许一个时间段内由多个进程“同时”对其进行访问。 互斥共享方式 即系统中的某些共享资源，虽然可以提供给多个进程使用，但是一个时间段内只允许一个进程访问该资源。 我们把一个时间段内只允许一个进程使用的资源称为临界资源（前面也讲过访问临界资源的代码段称为临界区）。许多物理设备（比如摄像头，打印机）都属于临界资源，此外还有许多变量，数据，内存缓冲区等都属于临界资源。对临界资源的访问，必须互斥的进行。互斥，亦称为间接制约关系。 进程互斥是指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源以后，另一个进程才能去访问临界资源。所以互斥共享实际上就要求进程互斥关系。 对临界资源的互斥访问，可以在逻辑上分为如下四个部分： 临界区是进程访问临界资源的代码段，进入区和退出区是负责实现互斥的代码段（后面所讲的互斥锁PV操作代码段就是这两个区内完成），临界区也称为“临界段”。 思考：如果一个进程暂时不能进入临界区，那么该进程一直占用着处理机吗？该进程要是一直进不去临界区怎么办？ 为了实现对临界资源的互斥访问，同时还要保证系统的整体性能，需要遵循以下原则： 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。 忙则等待：当已有进程进入临界区，其他试图进入临界区的进程必须等待。 有限等待：对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饿死）。 让权等待：当进程不能进入临界区，应立即释放处理机，防止进程忙等待。 思考：有限等待和让权等待不矛盾吗？ 可能你会认为一方面保证进程会在优先时间内等待到进入临界区，一方面又说当不能进入临界区就释放处理机，那进程到底等不等？实际上有限等待的意思是保证进程在一段时间后必定会被操作系统提示可以进入临界区，而让权等待的意思是该进程在等待时就不要在这用cpu了，先阻塞或者挂起等待，在有限等待以后在唤醒该进程上cpu然后范文临界资源，所以不矛盾。 总结 进程互斥的软件实现方式 很明显进程互斥有研究的内容，毕竟具体怎样实现互斥的方法有多种，我们一一了解。 思考：进程互斥需要解决的根本问题？ 首先我们先思考一个问题，现在有两个进程A和B并发地运行，如下图： 那么当A上处理机运行使用打印机时，我们知道根据调度算法，一般一个进程会在执行一个时间片（一般现在的操作系统都是MFQSA调度）后，可能并没有执行完，但是也需要下cpu让另一个进程开始执行，此时进程B上cpu后也开始运行使用打印机，这样结果就是A,B的内容混在了一起（这也解释了前面介绍系统调用必要性的例子中打印内容会混合在一起的原因），那么该怎样才能解决这个问题呢？ 单标志法 算法思想：两个进程（注意只适用于两个对象的情况）在访问临界区后会把使用临界区的权限转交给另一个进程，也就是说每个进程进入临界区的权限只能被另一个进程赋予）。代码如下： 首先我们定义一个全局变量turn=0,turn表示当前允许进入临界区的进程号，因为就两个进程，所以0表示允许进程0访问临界资源，1表示允许进程1访问临界资源。 1int turn = 0; 然后进程0的代码如下，这里我们要自己完善进入区和退出区，因为两个进程要互斥访问，所以1能否进入临界区取决于进程0有没有访问完，所以进程0访问完只需通知一下进程1现在可以进入即可，相对应的就是在退出区让turn=1，这样就可以允许进程1在进程0访问完以后进入临界区了。 P0： 12345//如果此时是对方进入回合即turn值为1则一直执行空语句等待while(turn!=0)&#123;&#125;; ----1//进入区critical section； ----2//临界区turn =1; ----3//退出区remainder section ----4//剩余区 相对应的P1访问完临界区后也要告诉P0现在可以访问临界区了，所以turn=0; P1: 12345//如果此时是对方进入回合即turn值为0则一直执行空语句等待while(turn!=1)&#123;&#125;; ----5//进入区critical section； ----6//临界区turn =0; ----7//退出区remainder section ----8//剩余区 这样turn的初始值为0，所以一开始只允许进程0进入临界区，若P1先上的cpu执行到了访问临界区代码，则会一直卡在代码段5，即进入区禁止进入，此时就一直到P1的时间片用完，调度切换到P0上处理机运行，代码1就不会卡在P0，所以P0可以正常访问临界区，此时如果在P0还在访问临界区阶段时间片到了，此时turn还没有更新到1，所以即使切换到P1此时P1还是在等待，直至P0访问完临界资源并更新了turn值以后P1才能进入临界区。 因此，这种算法可以在软件层次上实现“同一时刻最多只允许一个进程访问临界区”。但是貌似有一些小问题，比如只能按照P0-&gt;P1-&gt;P0-&gt;P1…这样的顺序轮流访问，这种必须“轮流访问”的问题是，如果此时允许进入临界区的进程是P0，而P0一直不访问临界区或者根本就不想访问临界区，那么此时虽然临界区是空闲的，但是也不允许P1访问，因此单标志法违背了“空闲让进”原则。并且这种方法对于多个进程的情况会比较复杂。 注意：上方代码的while后面带分号什么意思？ 一定要仔细观察代码，发现是对于P0，当turn!=0时在一直循环while的空语句表示等待，所以P0也可以写成： 1234while(turn!=0); ----1//进入区critical section； ----2//临界区turn =1; ----3//退出区remainder section ----4//剩余区 这个;很致命，一定要透彻理解第一行whlie语句的意义，他是判断是否需要等待，所以这里的判断条件为turn!=0则表示此时如果不是0的回合，那么0代码就一直在while后面的{};语句中执行空语句等待，这里因为{}里面是空语句所以可以省略大括号，P1同上原因。后面也都是这样表示。 双标志先检查法 算法思想：设置一个布尔型数组flag[],数组中各个元素用来标记各进程想进入临界区的意愿，比如&quot;flag[0]=true&quot;表示0号进程P0现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身的对应标志位flag[i]设置为true，之后开始访问临界区。 我们这里还是以进程P0和进程P1为例。首先初始化flag为两位，且一开始都默认为不想访问临界资源。 1bool flag[2]=&#123;false,false&#125;; 然后P0和P1每次访问前都先检查对方是否进入临界区，如果对方不想（即flag=false)那么就将自身的标志位设置为true,这样在自己访问临界资源期间，对方是不能进入的，当访问结束后再将自身的标志位设置为false。 P0： 123456//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[1]); ----1 // 进入区flag[0]=true; ----2//将自身标志位更新为true 进入区critical section ---3//访问临界资源 临界区flag[0]=false ----4//访问完毕，将自身标志位在更新为false 退出区remainder section //剩余区 P1: 123456//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[0]); ----5 //进入区flag[1]=true; ----6//将自身标志位更新为true 进入区critical section ---7//访问临界资源 临界区flag[1]=false ----8//访问完毕，将自身标志位在更新为false 退出区remainder section //剩余区 这个看似完美，实际上比上一个单标志法还不靠谱，他存在一个重大的bug，就是如果按照1-&gt;5-&gt;2-&gt;6-&gt;3-&gt;7的顺序执行，即假设现在flag数组所有位置都为false,即此时临界资源空闲，然后P0执行完允许进入后进入区判断以后突然时间片用完了，那么此时P0该下cpu了并且PCB记录此时状态是被允许进入空闲资源的，然后此时调度切换到P1执行了进入区代码，此时他发现P0的标志位仍然是false呢，所以他也进入，但是就那么巧，此时P1也用完时间片了下cpu前PCB记录此时被允许进入临界资源的状态，然后又切回了P0开始执行临界区，结果此时又用完时间片了此时P0还在临界资源，里面的P0临街资源还没被释放，P1又进来了，此时也可以对临界资源进行读写，完蛋，打印的内容又混在了一起。所以此时违背了“忙则等待”的原则。 思考：能不能优化一下代码避免这种bug? 可以，我们仔细观察，发现出现这种问题主要是因为进入区的“检查”和“上锁”两个操作不是一气呵成的所以会有可能在“检查完”和“上锁前”出现进程切换。所以我们可以更改一下操作顺序，管那么干嘛，先上上锁不让别人进来然后再检查，即更改成如下 双标志后检查法 首先初始化肯定是不变的 1bool flag[2]=&#123;false,false&#125;; 但是此时是先上锁在检查 P0： 123456flag[0]=true; ----1//先上锁 进入区//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[1]); ----2 // 进入区critical section; ----3//临界区flag[0]=fasle; ----4//访问完后解锁 退出区remainder section; P1: 123456flag[1]=true; ----5//先上锁 进入区//如果此时对方想进入即布尔值为true则一直执行空语句等待while(flag[0]);----6//进入区critical section; ----7//临界区flag[1]=fasle; ----8//访问完后解锁 退出区remainder section; 好像更改完确实不会在发生“忙则不等待”的问题了，但是此时貌似又出问题了，按照1-&gt;5-&gt;2-&gt;6的顺序即进程0想访问临界资源然后上锁了但是在检查前时间片用完了，切换到进程1他也先上锁然后发现0貌似已经上锁了所以就一直停在了代码6直至时间片用完，此时又切换回了进程0，由于进程1并没有检查完发现不能进以后解锁的操作，所以此时进程0也会发现进程1貌似也已经上锁了，所以进程0也一直卡在检查区代码2最终时间片用完，就这样即使空闲资源空闲，但是双方都发现对方上锁了就都一直不进入（其实就是产生了对方正在访问的误会），产生了饥饿现象。所以双标志后检查法不能应用。 思考：难道不能进一步优化双标志位法避免bug? 你可能会想到之所以双方都不进入是因为在检查到对方上锁后自己不能进入后没有解锁的操作，所以可能认为在2和6下方各加上一个若发现对方在就自己解锁的操作。但是你会发现无论这个功能根本实现不了，无论这个解锁操作放在哪里都不太合适仍然会触发更多的bug，所以就不要在尝试优化双标志法了，直接放弃思考一个更好的方法。 Peterson算法 算法思想：结合双标志法和单标志法的思想特点，如果双方都想争着进入临界区，那么就尝试互相退让，作一个有礼貌的进程。 其实实现也很简单就是有添加一个新的参量turn表示优先让哪个进程进入临界区，这样就实现了进程之间的谦让，代码如下： 还是先初始化 12bool flag[2]=&#123;false,false&#125;;//初始化时默认此时双方都不想访问临界资源turn=0;//初始化时默认进程1谦让进程0 P0: 1234567flag[0]=true; ----1//表达自己想进去的意愿上锁 进入区turn=1; -----2//优先让1进程进，即自己谦让有礼貌 进入区//如果此时1也想进入即对方上锁了且自己谦让，那么就循环空语句等待while(flag[1]&amp;&amp;turn==1);----3 //进入区critical section; ----4//临界区flag[0]=false; ----5//访问完了，解锁 退出区remainder section; //剩余区 P1： 1234567flag[1]=true; ----6//表达自己想进去的意愿上锁 进入区turn=0; -----7//优先让0进程进，即自己谦让有礼貌 进入区//如果此时0也想进入即对方上锁了且自己谦让，那么就循环空语句等待while(flag[0]&amp;&amp;turn==0);----3 //进入区critical section; ----4//临界区flag[1]=false; ----5//访问完了，解锁 退出区remainder section; //剩余区 此时进程们都很有礼貌了，每次自己想进去时都会谦让，这是我们在走一次1-&gt;2-&gt;3-&gt;6-&gt;7-&gt;8我们会发现确实做到了“忙则等待”和“空闲让进”并且没有在出现重大致命bug了，但是此种方法也不是太好，首先turn值限制了当涉及到多各进程之间时也很复杂，turn就会变得不那么简单，其次他和前面两种方法一样也没有做到“让权等待”即等待是下处理机，而是一直在循环执行while的空语句所以一直在占用cpu，所以peterson算法虽然比前面的方法好但是也不够好。 总结 进程互斥的硬件实现方法 中断屏蔽方法 利用“开/关中断指令”实现（和原语的实现思想相同，即在某个进程开始访问临界区到结束访问临界区为止都不允许中断，也就不会发生进程切换了因为时钟管理也只是在时间片结束后向cpu发送中断信号但是cpu可以忽视即决定权在cpu手中，这样也就不可能发生两个同时访问临界区的情况了） 优点很明显，简单高效确实实现了进程互斥的所有原则，但是缺点是不适用于多处理机，只适用于操作系统内核进程，不适用于用户进程（因为开/关中断指令都是特权指令，只能运行在内核态，这组指令如果用户可以随意使用会很危险，所以覆盖范围太小） TestAndSet指令 简称TS指令，也有地方成为TestAndSetLock指令，或者TSL指令，TSL是用硬件实现的，执行的过程不允许被中断只能一气呵成（很像原语），这里我们用C语言描述一下逻辑（但是一定要注意是硬件实现的，不是软件实现）。 1234567891011121314//布尔共享变量lock表示当前临界区是否被加锁//true 表示已加锁，false 表示未加锁bool TestAndSet(bool *lock)&#123; bool old; old=*lock;//old用来存放lock原来的值 *lock=true;//无论之前是否已经加锁，现在都将lock设置为true; return old;&#125;//以下是使用TSL指令实现互斥的算法逻辑while(TestAndSet(&amp;lock));//上锁并检查 进入区critical section;//临界区lock=false;//访问完解锁 退出区remainder section;//剩余区代码 实际上TSL就是通过硬件手段强制检查和上锁必须一气呵成执行（主要是因为TSL指令必须一气呵成，而TSL就一次完成上锁和检查），此时如果刚开始lock是false,则TSL返回的old值不满足while循环条件，直接跳过等待循环，进入临界区，如果刚开始lock是true,则执行TSL后old返回的值为true，此时满足while循环条件，会一直循环等待，直至当前访问临界区的进程在退出区进行“解锁”后该进程再访问临界资源。相比软件实现方法，TSL指令把“上锁”和“检查”操作用硬件的方式绑定为一气呵成的原子操作，但是注意他不是真的原语，只是具有原语的特性。 优点是实现简单就可以避免bug，这种无需软件实现方法那样严格检查是否会有逻辑漏洞，适用于多处理机环境，缺点是不满足“让权等待”，一旦无法进入临界区进程就会一直执行循环空语句占用cpu。 Swap指令 有的地方也叫作Exchange指令，或简称XCHG指令，Swap指令也是使用硬件实现的，执行的过程中不允许被打断，只能一气呵成，以下是用C语言描述的逻辑（但是一定要注意是硬件实现的，不是软件实现）。 1234567891011121314151617//Swap指令的作用是交换两个变量的值Swap(bool *a, bool *b)&#123; bool temp; temp=*a; *a=*b; *b=temp&#125;//以下是用Swap指令实现进程互斥的算法逻辑//lock 表示当前临界区是否被加锁bool old=true;while(old==true)&#123; Swap(&amp;lock,&amp;old);&#125;critical section;lock=false;remainder section; 看着有点晕😫，正常。我们来屡一下思路，首先我们有一个地方需要注意，此时的while后面不再是空语句了，而是Swap语句，这也就说明加入while判断条件返回为true即old为true,那么就会一直执行Swap(&amp;lock,&amp;old)交换lock和old值然后在判断，所以知道这一点后我们先假设lock=true的情况，那么此时说明有其他进程正在访问临界资源呢，然后bool设置为true后满足while条件进入循环语句内此时lock和old都是true，所以交换后还会满足while判断条件，所以又交换因此当当前正在访问临界资源的进程没有访问完，lock和old就会一直为true，所以等待的进程就是一直在不断的swap，直到那个进程访问完将lock更改为false,此时在经过1~2次的swap就会出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)此时这个进程就不在等待了出循环开始访问临界资源。而当lock一开始为false即临界资源空闲的情况，那么进入while循环一次后就会出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)的情况所以此时该进程就不需要等待就可以进入了。所以这个指令实现的方法很神奇，他唯一可以进入临界资源的情况就是出现lock=true(实际上lock的true是和old换来的）,old=false(实际上old的false是和lock换过来的)，当没有出现这个情况时等待的进程也不是一直循环空语句，而是一直在swap(虽然此时lock和old都为true😂),即使初始时临界资源空闲也要执行一次swap，所以无论何种情况，swap至少执行一次。并且转来转去实际上Swap和TSL实现的逻辑思路一模一样。 优点也是实现简单就可以避免bug，这种无需软件实现方法那样严格检查是否会有逻辑漏洞，适用于多处理机环境，缺点是不满足“让权等待”，一旦无法进入临界区进程就会一直循环执行Swap语句占用cpu。 总结"},{"title":"处理机调度","path":"/wiki/操作系统笔记/处理机调度/index.html","content":"处理机调度 基本概念 我们前面说过处理机cpu空闲时会在就绪态进程中挑选一个上cpu执行，这就是调度。当有一堆任务要处理，但由于资源有限，这些事情没有办法同时处理，这就需要某种规则来决定处理这些任务的顺序，这就是“调度”索要研究的问题。在多道程序系统中，进程的数量往往是多于处理机的个数的，这样不可能同时并行地处理各个进程。处理机调度，就是从就绪队列中按照一定的算法选择一个进程并将处理机分配给他使用，以实现进程的并发执行。 调度的三个层次 高级调度（作业调度） 由于内存的空间有限，有时无法将用户提交的所有作业全部放入内存中，因此就需要某种规则来决定将作业调入内存的顺序。高级调度（也叫做作业调度）就是按一定的原则从外存（硬盘等）上处于后备队列的作业中挑选一个（或多个）作业，给他们分配内存等必要资源，一旦进入内存就说明次进程被创建并处于了就绪态，所以需要操作系统创建并分配给其一个PCB，以使他们获得了竞争处理机的权利。 所以高级调度是外存（也叫辅存）与内存之间的调度。每个作业只调入一次，作业调入时会建立相应的PCB，作业调出时才撤销PCB，这也就说明当一个进程处于阻塞态下cpu后仍会存储在内存中随时准备上cpu，而只有当是终止态时才会从内存中取出然后作业调出。高级调度主要是指调入的问题，因为只有调入的时机需要操作系统确定，但调出的时机必然是作业运行结束才掉出。 中级调度（内存调度） 引入了虚拟存储技术后我们知道每次并不是将进程全部的数据放入内存，而是将常用的放入，而可将暂时不能运行的进程调至外存等待，等他重新具备了运行条件且内存又稍有空闲时，再重新调入内存，这么做的目的就是为了提高内存利用率和系统的吞吐量。暂时调到外存等待的进程状态为挂起状态（不是阻塞态），值得注意的是，PCB并不会一起调到外存，而是会常驻在内存中。PCB会记录进程数据在外存中存放的位置，进程状态等信息，操作系统通过内存中的PCB来保持对各个进程的监控和管理，被挂起的进程PCB会被放到挂起队列中。 中级调度（内存调度）就是要决定哪个处于挂起状态的进程重新调入内存，一个进程可能会被多次调出，调入内存，因此中级调度发生的频率要比高级调度更高。 思考：挂起状态在状态转换模型中的位置以及他和阻塞态的区别？ 暂时调到外存等待的进程状态为挂起状态，挂起态又可以进一步分为就绪挂起和阻塞挂起两种状态。所以加上后5状态模型-&gt;7状态模型 低级调度（进程调度） 低级调度（进程调度）其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给他（这个会涉及到很多种调度算法，后面会详细讲解）。进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度，进程调度的频率很高，一般几十毫秒一次。 思考：三种调度的联系与对比 调度名称 要做什么 发生地点 发生频率 对进程状态的影响 高级调度(作业调度) 按照某种规则，从后备队列中选择合适的作业将其调入内存，并为其创建进程 外存-&gt;内存（面向作业） 最低 无-&gt;创建态-&gt;就绪态 中级调度（内存调度） 按照某种规则，从挂起队列中选择合适的进程将其数据调回内存 外存-&gt;内存（面向进程） 中等 挂起态-&gt;就绪态（阻塞挂起-&gt;阻塞态） 低级调度（进程调度） 按照某种规则，从就绪队列中选择一个进程为其分配处理机 内存-&gt;cpu 最高 就绪态-&gt;运行态 总结 进程调度 这里我们详细展开对低级调度或者叫进程调度的详细研究。 进程调度的时机 进程调度就是按照某种算法从就绪队列中选择一个进程为其分配处理机。一般进程调度会发生在以下两种情况，当然，在某些系统中只允许进程主动放弃处理机（即只有上半部分功能），当然也有的系统除了可以进程主动放弃处理机以外，当有更紧急的任务需要处理时，也会强行剥夺该进程的处理机使用权给更加紧急重要的进程使用（被动放弃）。 一般是发生在运行态转换为其他状态，cpu空闲时发生。但是在以下的情况下一般进程调度很难发生 一定要注意第二点，是进程在操作系统内核程序临界区而不是进程自身处于临界区。当进程处于自身临界区时是可以进行处理机调度的。 思考：什么是临界区？什么是临界资源？ 临界资源是一个时间段内只允许一个进程使用的资源，各进程需要互斥地访问临界资源。而临界区就是访问临界资源的那段代码。所以内核程序临界区就是一般用来访问某种内核数据结构的代码，比如访问进程的就绪队列（由个就绪进程的PCB组成）。 之所以此时一般不发生进程调度，是因为如果内核程序还没退出临界区（即临界资源还没解锁） 就进行进程调度，但是进程调度相关的程序也需要访问就绪队列， 但此时就绪队列被锁住了，因此又无法顺利进行进程调度，同时，内核程序临界区访问的临界资源如果不尽快释放的话，极有可能影响到操作系统内核的其他管理工作。因此在访问内核程序临界区期间不能进行调度与切换。但是当在进程处于临界区时是可以进行处理机调度的，例如：在打印机打印完成之前，进程一直处于临界区内，临界资源不会解锁。但打印机又是慢速设备，此时如果一直不允许进程调度的话就会导致CPU一直空闲内核程序临界区访问的临界资源如果不尽快释放的话，极有可能影响到操作系统内核的其他管理工作。因此在访问内核程序临界区期间不能进行调度与切换而普通临界区访问的临界资源不会直接影响操作系统内核的管理工作。因此在访问普通临界区时是可以进行调度和切换的。 进程调度的方式 非剥夺调度方式 又称为非抢占方式，即只允许进程主动放弃处理机（一般是通过系统调用陷入函数发送请求中断该进程），这种方式，在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，知道该进程结束或者主动要求进入阻塞态。这种方式明显不合理，但是实现简单，系统开销小但是无法及时处理紧急任务，一般适用于早期的批处理系统。 剥夺调度方式 又称为抢占方式，当一个进程正在处理机上执行时，如果有一个更重要或者更加紧迫的进程需要使用处理机，则操作系统会立即暂停正在执行的进程，将处理机分配给更加紧迫重要的进程。这种方式优先处理更紧急的进程，也可以实现让各进程按时间片流转执行的功能（通过时钟中断）。适用于分时操作系统，实时操作系统。 进程的切换与过程 思考：狭义的进程调度和进程切换的区别？ 狭义的进程调度就是指从一个就绪队列中选出一个要运行的已就绪的进程（这个进程可以是刚刚被暂停执行的进程或者也可以是另一个进程，而后一种情况就需要进程切换）即仅仅是选择，进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。 广义的进程调度包括选选择一个进程和进程切换两个步骤，进程的切换过程主要完成了： 对原来运行进程各种数据的保存 对新的进程各种数据的恢复（如操作系统根据PCB对程序计数器，程序状态字寄存器PSW，各种段寄存器等处理机现场信息） 所以进程切换是有代价的，因此如果过于频繁的进行进程调度，切换必然会导致整个系统的效率降低，使得系统花费大量时间在进程切换上，而真正用于执行进程的时间减少。 总结 调度算法的评价指标 cpu利用率 因为早期的cpu造价昂贵（说实话现在对于学生来说也得吃好几天土。。），因此人们希望cpu尽可能的多工作，所以就引出了cpu利用率–用来描述cpu忙碌的时间占总时间的比例。 利用率=忙碌的时间/总时间利用率=忙碌的时间/总时间 利用率=忙碌的时间/总时间 一般设备的利用率指的都是cpu利用率，如：某计算机只支持单道程序（单核），某个作业刚开始需要在CPU上运行5秒， 再用打印机打印输出5秒，之后再执行5秒，才能结束。在此过程中， CPU利用率、打印机利用率分别是多少？ 很简单的计算：cpu利用率=5+5/5+5+5=66.6%，同理打印机利用率=33.3%。通常会考察多道程序并发执行的情况，可以使用“甘特图”来辅助计算。 思考：什么是甘特图？ 就是横道图、条状图。其通过条状图来显示项目、进度和其他时间相关的系统进展的内在关系随着时间进展的情况。类似于下图： 系统吞吐量 对于计算机来说，希望能够尽可能用少的时间处理完尽可能多的作业，这就是系统吞吐量–单位时间内完成的作业的数量。 系统吞吐量=总共完成了多少道作业/总共花了多少时间系统吞吐量=总共完成了多少道作业/总共花了多少时间 系统吞吐量=总共完成了多少道作业/总共花了多少时间 例如：某计算机系统处理完10道作业，共花费100秒，则系统吞吐量为？ 10/100=0.1道/秒。 周转时间 对于计算机的用户来说，他最关心的就是自己的作业从提交（注意不是开始运行）到完成花费的时间。周转时间就是指从作业被提交给系统开始（一般是双击应用程序开始）到作业完成为止的这段时间间隔。一般周转时间由四部分组成：作业在外存后备队列上等待作业调度（高级调度）的时间、进程在就绪队列上等待进程调度（低级调度）的时间，进程在cpu上运行的时间、进程等待I/O操作完成（一半是阻塞态或者挂起态）的时间。后三个在一个作业的整个执行过程中，可能发生多次。 （作业）周转时间=作业完成时间−作业提交时间（作业）周转时间=作业完成时间-作业提交时间 （作业）周转时间=作业完成时间−作业提交时间 上面的周转时间是指对于用户来说更加关心自己的单个作业的周转时间，而对于整个操作系统来说，更关系的是系统自身的整体表现即周转时间的平均值。 平均周转时间=各作业周转时间之和/作业数量平均周转时间=各作业周转时间之和/作业数量 平均周转时间=各作业周转时间之和/作业数量 带权周转时间 因为有的作业运行时间长，有的作业运行时间短，因此在周转时间相同的情况下，运行时间不同的作业给用户的感受也是不一样的。可能有的作业虽然运行时间长会导致平均周转时间更大，但是其对用户产生的满意度更高，所以不能操作系统不能仅仅用平均周转时间来衡量，如果只追求平均周转时间短，那岂不是每次都会尽量做运行时间短的任务，但是可能运行时间更长的大型主机游戏对用户的满意度提升更高也就更主要。所以这里引出一个新的概念–带权周转时间。 带权周转时间=作业周转时间/作业实际运行的时间带权周转时间=作业周转时间/作业实际运行的时间 带权周转时间=作业周转时间/作业实际运行的时间 因为一作业周转时间还包括等待时间，所以带权周转时间必然&gt;=1，但是等待时间肯定是越小越好，所以操作系统需要尽量使带权周转时间和周转时间都是越小越好。 平均带权周转时间 当然肯定也会再引进一个平均带权周转时间的概念 平均带权周转时间=各作业的带权周转时间之和/作业数平均带权周转时间=各作业的带权周转时间之和/作业数 平均带权周转时间=各作业的带权周转时间之和/作业数 思考：周转时间和带权周转时间的关系？ 对于周转时间相同的两个作业，实际运行时间更长的作业在相同时间内被服务的时间肯定更多，相应的带权周转时间就更小，用户满意度更高。对于实际运行时间相同的两个作业，周转时间更短的带权周转时间更小，等待时间更短，用户满意度越高。 等待时间 计算机的用户希望自己的作业尽可能少的等待处理机，等待时间就是指进程（或作业）处于等待处理机状态时间（即处于就绪态）之和，等待的时间越长，带权周转时间越大，用户满意度越低。 对于进程来说，等待时间就是指进程建立后等待被服务的时间，在等待/O完成的期间其实进程也是在被服务的，所以不计入等待时间。对于作业来说，不仅要考虑建立进程后的等待时间，还要加上作业在外存后备队列中等待高级调度的时间。 一个作业总共需要被cpu服务多久，被I/O设备服务多久一般是确定不变的，因此调度算法其实只会影响进程/作业的等待时间，当然，和前面的指标类似，也有“平均等待时间”来评价整体性能的。 响应时间 对于计算机用户来说，会希望自己的提交的请求（比如通过键盘输入一个调试指令）尽早地开始被系统服务、回应，响应时间就是指从用户提交到首次产生相应的时间。"},{"title":"基本页式存储管理","path":"/wiki/操作系统笔记/基本页式存储管理/index.html","content":"基本地址变换机构 本节还是讲解基本页式存储管理，在上一节中我们学习了页式存储的地址变换方法，这里我们来理解基本地址变换机构（用于实现逻辑地址到物理地址转换的一组硬件机构）的原理和流程。 页表寄存器 基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。通常我们要设置一个页表寄存器（PTR）存放页表在内存中的起始地址F和页表长度M。这样我们才可以找到页表，进程未执行时，页表的起始地址和页表长度放在进程控制块PCB中，当进程被调度室，操作系统内核会把他们放到页表寄存器。 地址变换过程 我们现在已图示的方法演示，注意这里页面大小是2的整数幂，设页面大小为L，逻辑地址A到物理地址E的变换过程如下： 其实前面都讲过了，这里只是演示一下借助页表寄存器具体的转换流程。理解后不需要死记硬背。这里我们来练习一下：假设页面大小为1KB，页号2对应的内存块号b=8，将逻辑地址A=2500转换为物理地址E。相当于告诉了我们以下有效信息： 系统按字节寻址 页内偏移量占地址的10位 页号2对应页框8 那么我们首先计算页号=2500/1024=2,页内偏移为2500%1024=452。所以物理地址实际上就已经出来了是8*1024+452=8644。 所以在分页存储管理的系统中，只要确定了每个页面的大小，逻辑地址结构就可以啦，因此，页式管理中地址是一维的。即只要给出一个逻辑地址系统就可以自动地算出页号、页内偏移量两个部分，并不需要显示的告诉系统这个逻辑地址中，页内偏移量占多少位。 页表项大小的深究 我们知道页表项所占字节大小是根据最大页号所占的位数确定的并且每个页表项的长度是相同的，页号是“隐含”的。前面我们讲过一个例题：物理内存为4GB，页面大小4KB，我们最终算出来页表项至少要占3个字节也就是24bit。但是实际上一般我们是让页表项占4个字节，即即使我们一直页表项为20bit，3字节就已经可以表示了我们还是宁愿在让他多占一个字节为4字节。 思考：为什么要这样做，有什么意义？ 我们知道页表项会按顺序连续地存放在内存中。那么如果页表在内存中的存放起始地址为X，那么M号页对应的页表项是存放在内存地址为X+3*M的。但是如果此时一个页面大小为4KB，那么每个页框都可以存放4096/3=1365个页表项（因为页表存在内存中，那么显然页表也是按页式存储的，所以页表项也是存在页框中的，只不过这几个页框会相邻这样就实现了连续存储了），但是这个页框还会剩余4096%3=1B页内碎片。这其实内部碎片大小是可以忽略的，但是此时就会导致X+3*M公式不适用了，即整体看来页表项不再是连续存储的了，而是每1365个页表项就间隔1B这可很难受。如下： 所以此时我们发现如果每个页表项按4B存储，那么一个页框就可以放4096/4=1024个页表项，并且刚刚好没有内部页内碎片，这样整体看来页表项就还是连续存储的也就说明此时公式X+3*M是可以适用的，所以明显4B更好，即使这样一个页框所存储的页表项就少了但是不差这一点空间。但是我们要注意不是每次都是4个字节都是刚刚好，根据页框大小的不同我们要动态更新但是原则上就是每次都要使得页面恰好可以装得下整数个页表项。 总结 具有快表的地址变换机构 实际上就是一种在基本地址变换机构的改进版本使得查询速率更快了。 什么是快表（TLB） 快表，又称联想寄存器（TLB,translation lookaside buffer)，是一种访问速度比内存快很多的高速缓存（注意TLB不是内存），用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表（前面说过页表存放在内存中）称为慢表。 地址变换过程（引入快表） 一般访问快表TLB只需要1微秒，而访问内存需要100微秒。现在我们同样以图示演示一下用快表寻找（0,0）（0,4）（0,8）这几个逻辑地址。 我们发现和之前的过程不相同的是在得到页号后不是立刻取内存慢表中查找对应的内存块号，而是先在TLB寻找有没有最近刚刚查找过此页表项，如果有那么就可以直接命中知道内存块号了，这样就加速了查找速度，但是前提是TLB中得有即最近查找过这个表，如果没有那么还是需要去慢表中查找。 思考：两种查找方法的本质区别？ 速度不同那是肯定地了，还有就是访问内存单元的次数也是不同的，对于直接TLB命中的，只需要一次内存单元访问即得到物理地址后访问内存中的存储数据的单元，而如果没有在TLB中命中，那么还需要额外在进行一次在内存中的慢表中查询页表项得到物理块号，所以需要两次内存的访问，当然如果这次未命中，那么查询完此次页表项后会将这个页表项的副本加入到TLB中以便下一次再查找这个页表项时可以命中快速查询。 思考：可以提速多少？ 我们知道由于查询快表的速度比查询页表的速度快很多，所以只要尽可能多的快命中，就可以节省很多时间。由局部性原理（即CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中）一般来说快表的命中率可以达到90%以上。我们以一道例题来计算： 某系统使用基本分页存储管理，并采用了具有快表的基本地址变换机构，访问一次快表耗时1微秒，访问一次内存耗时100微秒。如果快表的命中率为90%，那么访问一个逻辑地址的平均耗时时间为多少？ （1+100）*0.9+（1+100+100）*0.1=111微秒 对于上面的计算可不要轻视，一定要理解透彻，前面是快表命中，需要一次查询快表的时间1微秒+一次内存访问时间（查询数据）100微秒，而对于未命中时也是查询了一次快表1微秒+两次内存访问时间200微秒（一次慢表查询，一次数据访问）。 思考：能否进一步提速？ 可以，对于某些系统来说支持快表和慢表同时查找即两个搜索同时进行，谁先找到就用谁，这样快表找到的时间还是101微秒，但是慢表查询就是200微秒了（因为不查找快表了）这样计算一个逻辑地址平均查找时间为110.9微秒。而如果不采用快表，那么查找一个逻辑地址所用的平均时间为200微秒。显然引入快表以后，访问一个逻辑地址的速度快了一倍。 这里对于两种查询快表的方式进行对比： 思考：如果把所有页表全部放在TLB那么岂不是更快？ 显然不可能，TLB造价高昂，肯定是容量有限不能容下所有页表，所以这种想法目前为止还不可能实现，但是这样就会出现一个问题，当TLB满了以后再添加新的页表项副本时就需要先淘汰一些页表项，这就涉及到了淘汰谁的问题，这里也大有讲究有许多置换算法后面细讲。 局部性原理 时间局部性原理：如果执行了程序的某条指令，那么不久后这条指令很有可能会再次执行，如果某个数据被访问过，那么不久之后这个数据很有可能会再次被访问。（因为程序中存在大量的循环） 空间局部性原理：一旦程序访问了某个存储单元，在不久之后其附近的存储单元也很有可能再次被访问。（因为许多数据在内存中都是连续存放的） 所以对于上节介绍的无快表的基地址变换机构中，每次访问一个逻辑地址，都需要查询内存中的页表。由于局部性原理，可能很多次查到的都是同一个页表项。 总结： 这里我们在学习了机组原理后知道有一个和TLB非常类似的机构叫做Cache实际上两者是由区别的：TLB中只有页表项的副本，而普通Cache中可能会有其他各种数据的副本。但是解决问题的思路是类似的，实战请参考：缓存Cache实验 两级页表 单级页表存在的问题 我们以一个例题为例：某计算即系统按字节寻址，支持32位的逻辑地址，采用分页存储管理，页面大小为4KB，页表项长度为4B。 那么4KB=2^12B，因此页内地址要用12位表示，所以剩余的20位表示页号。因此，该系统中用户进程最多有2^20页。相应的，一个进程的页表，最多会有2^20=1M=1,048,576个页表项，所以一个页表最大需要2^20*4B=2^22B=4M，共需要2^22/2^12=2^10个页框存储该页表。即需要专门给进程分配1024个连续的页框来存放它的页表。 注意：页表的存储方式！ 这里我还是想再谈一谈页表的存储方式，虽然我们知道按照分页存储，数据是可以离散存放的，但是对于页表这一特殊的数据结构在分页内存中存放时还是要连续放的，所以这就要求页框必须是连续的，并且为了地址好查询即X+4*M还尽量要求页框能够放入整数个页表项。 思考：上面的单级页表存储有什么问题？ 页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框 没有必要让整个页表常驻内存，因为局部性原理进程可能一般在一个时间段内只会访问几个特定的相邻的页面。 所以我们想把页表再分页并离散存储，然后在建立一张页表记录各个部分的存放位置，称为页目录表，或称外层页表，或称顶层页表。这就是两级页表甚至多级页表的由来。 两级页表的原理、地址结构 我们先来看一下单机页表时怎么存储的，此时将页表分为了1024个部分即1024个连续页框，每个页框里有1024个页表项如下： 现在我们将这1024个部分也离散存放然后建立一张表格来记录各部分所存储的位置。如下： 此时一级页号（页目录号）有1024项记录的是1024个部分所存储的页框号，然后二级页号对应的是某个页表中的页号（即页号），最后12位还是页内偏移量。例如此时 此时我们发现实际上空间并没有变大，还是只能存储2^20页，但是此时可以不用连续存储了并且最终的计算还是满足X+4*M的公式。但是此时内存里的分布就比较复杂了，原先是某一连续区间里存放的全是页表（里面放的是页表项），然后另外的地方存储着数据单元，但是现在3号存放的是页表（里面对应的是页表项）但是2号页框里面存储的就是数据了，所以数据存储和页表存储夹杂在一起了。并且分成二级发现无论是哪个页表都是最大为1023的数不会再出现1048575这么大的数了就是因为两级导致的拆分。相当于原先的0~1048575的一张大表变成了1024个小页表了每个页表时0~1023并且每个小页表有了编号为0#~1023#。 现在还没有解决页表常驻的问题，所以我们还需要在页目录中添加一栏状态标志位表示此时i#页表是否在内存中如下： 只有在需要访问i#页表时才放入到内存中（虚拟存储技术），当然页目录肯定是得一直在内存中的。如果想访问的页面不在内存中，就是缺页中断了（内中断/异常：自发指令触发，在cpu中发出中断信号）然后将目标页面从外村调入内存（此时不能说是中级调度，因为不是挂起进程进入调入内存而是缺的页表调入）。 思考：之前为什么说当缺页率高时说明内存紧张了？ 毕竟内存有限，如果内存很小时那么每次调入缺的页表同时还需要调出某些页表腾地方，那么老缺页中断就说明没有足够的地方存放被访问页的地方了。 使用多级页表是有没有什么变化？ 我们知道在单级页表时每一个页表项的地址就是起始地址+页号*页表大小，但是当使用多级页表时只有同一张页表中的页表项还使用（因为一张页表内还是连续存储的）但是此时页表间的页表项就不再适用了，因为此时各个页目录表是离散存储的了。 思考：什么时候使用多级页表？ 若分为两级页表后，页表依然很长，那么我们就可以采用更多级页表，一般来说各级页表的大小不能超过一个页面，毕竟页目录最好就放入一个页框中最合适。例如：某系统按字节编址，采用40位逻辑地址，页面大小为4KB，页表项大小为4B，假设采用纯页式存储，则需要几级页表？页内偏移量多少位？ 页面大小=4KB=2^12B，按字节编址所以页内偏移量就是12位。 那么页号所占位数=40-12=28。又因为页面大小为4KB=2^12B,页表项为2^2B，那么每个页面可以放2^10个页表项。因此各级页表最多包含2^10个页表项，需要10位二进制才能映射到2^10个页表项，因此每一级的页表对应页号为10位（可以少但是不要多于10要不就会出现一张表放不下两张表多于的情况，少的话后面就空着呗）。所以需要三级页表，逻辑地址结构如下： 思考：如果就要用两级页表会怎么样？ 按理论你要是非得用也不是不可以，但是此时就会出现一级页号18位即有2^18个二级页表，那么页目录一张放不下，需要1.8个这就很不优雅。所以不推荐。而如果是8,10,10这样分布就很好，一级页号对应有多少个二级页目录一共有2^8个二级页目录，然后二级页号每一个都是一张二级页目录，页目录中的每一项映射着一个三级页表，三级页号表项映射着页号所对应的物理块号。这样一共是有2^28个物理块存储着数据。 思考：为什么不是10,10,8分布？ 这样很不优雅，意味着有2^20个表都是填不满的，虽然对于查找没什么影响，但是页内碎片多，而8,8,10就只有一级页目录有页内碎片。既节省空间还优雅。 思考：两级页表和三级页表查询步骤（没有快表）？ 两级页表： 第一次访存：访问内存中的页目录表 第二次访存：访问内存中的二级页表 第三次访存：访问目标内存单元 三级页表： 第一次访存：访问内存中的一级页目录表 第二次访存：访问内存中的二级页目录表 第三次访存：访问内存中的三级页表 第四次访存：访问目标内存单元 总结 超级重点，必须会计算！"},{"title":"操作系统的运行环境","path":"/wiki/操作系统笔记/操作系统的运行环境/index.html","content":"操作系统的运行机制 预备知识 在学习之前，我们先来回忆一下程序是如何运行的。首先指令是指处理器cpu可以识别、执行的最基本命令。在生活中，很多人习惯将Linux,Windows,MacOS的小黑窗中的命令也称为“指令”，实际上这些是“交互式命令接口”，与本节的“指令”不同，本节中的“指令”是指硬件层机器所能识别的二进制指令（即01串）。 一条高级指令如C,JAVA等都会首先通过编译器翻译为机器能够读懂的二进制指令然后才能被硬件机器识别和执行。高级语言逻辑复杂更符合人类思维，而二进制指令则更对机器的执行友善，简单地01交并补就可以实现高级语言。但是相对应的指令长度和数量也就更多，所以一条高级语言的代码可能会翻译出许多条对应的机器指令（举个例子，实际上通过二进制指令和操作系统的代码实现输出函数printf就已经对于机器来说是一个非常复杂高级的指令了，如果你做过nemu的话会深有体悟）。而cpu就是一条一条的执行二进制指令，当然执行的速度非常快。 内核程序和应用程序 这两个程序有本质上的区别，对于应用程序我们再熟悉不过，普通程序猿写的程序大多都是应用程序，其大部分都是应用于软件层，最终运行在操作系统上。而例如微软、苹果、华为等一些顶级大牛会负责实现操作系统，如果你还记得上节的内容，应该知道操作系统本质上也是一个软件，只是他是连接软件层和硬件层的中间层。这些很多内核程序组成的“操作系统内核”，又叫做内核（kernel)，内核是操作系统最重要的核心部分，也是最接近硬件的部分，可以说，一个操作系统只要有了内核基本上就够了例如Docke仅需要Linux内核，操作系统的内核是实现核心功能的部分，未必拥有操作系统的全部功能，录入图形化接口GUI就不在内核中实现。 特权指令和非特权指令 应用程序使用的都是“非特权指令”，例如加法指令，减法指令等，而操作系统内核作为管理者，就有权有时让cpu执行特权指令，如：内存清零指令，这些指令影响重大，一般会直接影响到操作系统，硬件上的工作，只能由“管理者”–操作系统内核使用。归根对比，应用程序使用的非特权指令权利很小，无权或者不能对操作系统和硬件层产生直接影响，并且一定是需要经过操作系统才能间接使用接口来和硬件层产生关联，而特权指令就是直接更改操作系统代码或者硬件层调度配合工作的代码，不可能暴露给外界以防产生恶意程序入侵破坏设备。在设计cpu时会划分特权指令和非特权指令，因此cpu可以执行一条指令前判断出指令的类型。 内核态和用户态 cpu有两种状态：内核态和用户态。处于内核态时，说明此时正在运行的是内核程序，此时cpu可以执行特权指令（注意是可以，也就是说此时还可以继续执行非特权指令）。而当处于用户态时，说明此时运行的是应用程序，此时只能执行非特权指令。这里用到了一个特殊地寄存器来存储程序状态–程序状态字寄存器（PSW），其中有个二进制位，1表示“内核态”，0表示“用户态”，这样cpu就可以随时判断出此时处于什么状态下。 当然这里有许多别名： 内核态=核心态=管态（即管理状态） 用户态=目态（即只能观看状态） 那么你一定会好奇仅仅用一个PSW就来判断cpu处于什么状态是否过于草率，那么只要更改这个位，岂不是可以按照人为意愿随意更改状态，更可怕的是如果有黑客此时病毒植入，更改了cpu状态然后执行了格式化等指令将系统破坏掉会造成很大的安全隐患，所以这里会有异常中断来避免这种情况，所以PSW不能随意更改，只能由特权指令更改。 这里有一个故事来描述这种情况的应急措施：首先，设备刚刚开机后首先会使cpu处于管态，此时操作系统内核程序先上cpu运行（原因是应用程序需要在操作系统上运行，所以操作系统需要先做准备工作提供接口环境），开机完成后，用户启动某个应用程序，待操作系统内核在合适的时候（准备工作完成）主动（此时处于管态，运行特权指令更改PSW是可以的）让出cpu,让该程序上cpu放入内存后上cpu执行，此时应用程序运行在目态，只能执行非特权指令，当此时有黑客在应用程序中植入一条特权指令（更改PSW）时，企图破坏系统，cpu此时在目态发现要执行的是特权指令（更改PSW）时发现自己是用户态时就会触发异常中断，此时操作系统发现中断信号会立刻夺回cpu的控制权以防有非法指令破坏系统，然后对引发中断的事件进行处理，处理完后在cpu使用权交给应用程序并且此时再次切回目态，这样就保护了系统不会受到入侵破坏了。 思考：内核态和用户态怎样切换 内核态-&gt;用户态：刚刚上面已经讲过了，当cpu处于内核态时可以执行一条特权指令修改PSW的标志位来实现主动切换到目态，这个动作意味着操作系统主动让出cpu的使用权。 用户态-&gt;内核态：任何情况下都不可能通过指令切换回管态，因为PSW只能通过特权指令更改判断位，而此时目态下cpu无权执行特权指令，但是可以通过中断信号引发，硬件自动完成变态过程，触发中断信号意味着操作系统将强行夺取cpu的使用权，因此除了非法使用特权指令以外，还会有许多事件触发中断信号，从而由目态切换到管态，但有一个共性是，但凡需要操作系统介入的地方，都会触发中断信号。 总结 操作系统内核 说了那么多，那么操作系统内核到底是什么，其实内核就是计算机上配置的底层软件，是操作系统最基本，最核心的部分，实现操作系统内核功能的那些程序就是内核程序。如下图： 那么哪些是不属于内核的操作系统的功能呢？例如记事本、任务管理器等设备自带的传说中免费的赠品软件APP，即使没有这些软件，我们仍然可以使用计算机。当然，这些非内核的功能用来推销也是不错哦😹：放松时刻 当然不同厂商对于内核的定义也不同，这里又对内核进行了细分：大内核和微内核。 操作系统的结构和企业的管理问题很相似，内核就是企业的管理层，负责一些重要的核心工作，只有管理层才能执行特权指令，普通员工就只能执行非特权指令。管态和目态之间的切换就相当于普通员工和管理层之间的工作交换。 大内核：企业初创时体量不大，人人都有官，人人皆高层，所以管理层的人会负责大部分的事情，有点事效率高，缺点就是组织结构混乱，难以维护。 微内核：随着企业的体量增大，管理层只负责最核心的一些工作，有点事结构清晰，方便维护，缺点是效率低。 中断和异常 中断的作用 cpu上会运行两种程序，一种是操作系统内核程序（是整个操作系统的管理者），另一种就是应用程序。前面已经基本上知道了中断实际上就是会使cpu由用户态变为内核态，使操作系统重新夺回对cpu的控制权。 在合适的情况操作系统内核会把cpu的使用权主动让给应用程序，而中断就是让操作系统内核夺回cpu使用权的唯一途径。如果没有中断机制，那么一旦cpu开始运行某个应用程序，cpu就会一直运行这个应用程序，那么又何来的并发性呢，所以当切换cpu上的应用程序时就是需要中断信息，使操作系统重新掌权，将cpu使用权让给其他的应用程序，所以中断保证了并发性。 中断的类型 所以中断切换状态是很常见的一种方法，那么根据不同触发的触发中断的情况我们可以分为两类–内中断和外中断。 内中断 内中断与当前执行的指令有关，一般来自cpu的内部，比如发现cpu执行了特殊的特权指令造成的异常或者除0出现计算异常等都是执行的指令自身引发的，这种就成为内中断。当然也不一定指令是出现错误才触发中断，比如应用程序想请求操作系统内核的服务时，此时会执行一个特殊的指令–陷入指令（在Nemu实验中也有，为trap()），此时该指令就会引发一个内部中断信号，也是内中断的一种，这种陷入指令虽然会触发中断，但是此动作意味着应用程序主动的将cpu控制权还给操作系统内核，系统调用就是通过陷入指令完成的。 外中断 外中断与当前的执行无关，不是当前指令引起的中断信号，所以自然不是来自于cpu内部，而是通过内核中某些算法（这些算法来实现任务间合理调度）引起的中断信号。比如内核中的时钟中断，它是由时钟部件发来的中断信号或者是IO设备发起的任务完成的中断信号。 例如时钟算法是用来分配调度任务之间的占用cpu的时间的，我们从上图可以看出时钟计时每50ms会发一个中断信号给cpu,而cpu每次执行完一条指令后都会例行检查是否有外中断信号。当检测到外中断信号时，就会由目态切换到管态。所以回忆之前的知识，可以猜出单批道操作系统的并发性实现即每隔一个时间片切换任务就是通过时钟算法外中断信号引起的。 中断分类的总结 经过上面两个的对比，我们可以看出外中断更符合我们广义上所说的中断，而内中断更多的像是故障，异常终止或者主动陷入，所以大多数的教材和讲义上中断都是特指的外中断，内中断一般称为异常。 中断机制的基本原理 那么对于不同的中断信号，如何知道该进行什么相应操作呢？这时cpu检测到中断信号后，会根据中断信号的类型去查询“中断向量表”，以此来找到相应的中断处理程序在内存中的存放位置。 总结 系统调用 什么是系统调用 我们在前面已经学到了操作系统作为用户和计算机硬件之间的接口，需要向上提供一些简单易用的服务，主要包括命令接口和程序接口。其中程序接口就是由系统调用组成的。例如C库函数中的system()就是一种库函数方法，需要通过程序接口实现。 一般系统调用是操作系统提供给程序猿等编程开发人员使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以通过系统调用来获得操作系统内核的服务。 思考：系统调用和库函数的区别？ 通过上图我们可以看出应用程序一般是直接通过系统调用来请求内核服务的，当然也有一部分是调用库函数时，库函数中需要系统调用来请求内核服务。但是并不是所有的库函数都需要系统调用的，比如“取绝对值”的函数sqrt()只是一个数学操作函数，虽然需要引入cmath库，但是是不需要系统调用的。而“创建一个新文件”局就涉及到了系统调用的库函数。所以一般来说，普通用户是不会手动触发系统调用的，只有编程人员调用库函数和应用程序可能会触发系统调用。 系统调用的必要性 那么为什么要有系统调用呢，即为什么程序需要每次都向内核发送服务请求呢而不是直接自己执行呢？这就涉及到了操作系统的自身的功能–协调分配任务，管理资源。比如两个人的电脑连接着一个打印机，第一个人按下了打印按钮，此时打印机开始打印第一个文件，但是在打印至一半时，第二个人也按下了打印按钮，开始带引他的文件。如果没有系统调用申请内核服务的话，那么两个进程就会互相随意地并发的共享计算机资源，最终造成两个文件混杂在一起的情况。而使用系统调用，触发陷阱发送中断信号请求内核对共享资源的统一的管理，操作系统就会向上提供“系统调用”服务，内核会对这几个进程进行协调处理，使其互相不干扰的并发进行，即在某个进程该工作占用cpu和打印机共享资源时工作，非这个进程阶段就进制此进程占用共享资源，这样就会使得最终的结果互补混杂了。所以系统调用对于共享资源的管理和任务之间的协调调度起着至关重要的作用。 系统调用的分类 应用程序通过系统调用来请求系统的服务，而系统中的各种共享资源都又操作系统内核统一掌管，因此凡是与共享资源有关的操作（如存储分配，I/O操作，文件管理）等，都必须通过系统调用的方式向操作系统内核发出服务请求等待响应，然后又操作系统内核代为完成（所以是在管态进行的分配服务），这样就保证了系统的稳定性与安全性，防止了用户的非法操作。 系统调用的过程 因为系统调用是应用程序主动然爱过出cpu的使用权，使用陷入指令触发的中断信号，所以系统调用一定是内中断。 我们可以看到系统调用时并不是立刻就进行陷入指令，而是首先在目态进行一系列准备工作，比如记录中断地址（毕竟最终操作系统服务完以后还要回到这个地址继续执行），还有传参指令即将系统调用需要的参数存放到制定的寄存器以便操作系统使用，最终才调用陷入指令（此时已经做好了移交cpu的准备工作），然后操作系统掌握cpu使用权（管态）进行服务，完成后最终再返回到中断位置继续执行后面的指令。 总结 操作系统的体系结构 我们通过上图可以看出一个操作系统内核部分和非内核部分可以组装，比如Ubuntu等就是建立在linux基础上再加以非内核功能组装住的操作系统。并且我们也已经知道内核是操作系统最基本，最核心的部分，实现操作系统内核功能的那些程序就是内核程序。并且内核分为了四个部分： 因为其对软硬件的操作程度不同，有区分成了大内核和微内核，我们前面是以企业模型分析了两种内核类别的效率和优缺点。这里我们再以变态次数分析一下，首先我们需要知道应用程序想要请求操作系统的服务时，这个服务会涉及到进程管理，存储管理，设备管理即对硬件操作不是很大的那层（橘色层）。然后在涉及到最接近硬件层的时钟管理，中断处理和原语部分。按照大内核和微内核的定义： 我们可以看出他们两种类型的内核布置造成了不同的变态次数。 对于大内核其认为两层均是内核功能部分，所以这两层都处于管态执行，这样四个功能之间的切换就不会在涉及到变态过程了，唯一造成变态的位置就是应用程序和大内核之间的切换，所以只有2次变态。而对于微内核，其任务进程管理，存储管理和设备管理（橘色层）不属于内核部分，所以此部分还是需要在用户态执行，这样虽然应用程序和橘色层之间不再需要变态了，但是由于这三个操作都是会涉及到时钟管理，中断处理和原语部分，所以每一个都需要经历两次变态，最后总体来看会造成6次变态。而变态的过程是有成本的，要消耗不少的时间，频繁的变态会降低系统的性能，所以这也是大内核效率更高的原因之一。 生活中的系统分类 典型的大内核/宏内核/单内核操作系统：Linux,UNIX 典型的微内核操作系统：Windows NT 总结"},{"title":"文件共享与保护","path":"/wiki/操作系统笔记/文件共享与保护/index.html","content":"文件共享 操作系统为用户提供文件共享功能，可以让许多个用户共享的使用同一个文件。所以也意味着系统中只有一份文件数据，并且只要某个用户修改了该文件的数据，那么其他用户也可以看到文件数据的变化。如果是多个用户都“复制”了同一个文件，那么系统就会由好几份文件数据，其中一个用户修改了自己的那份文件数据此时并不会其他用户的文件数据造成影响。 基于索引节点的共享方式（硬链接） 我们知道，索引节点是一种文件目录瘦身策略，由于检索文件只需要文件名，所以其他的信息都存放到了索引节点中，这样目录项就只包括文件名和索引节点指针了，如下图： 索引节点中设置了一个链接技术变量count，用于表示链接到本索引节点的用户目录项。如果count=2,说明此时有两个用户目录项都链接到了该索引节点上也就意味着这两个用户共享这个文件。如果某个用户决定删除该文件，那么只需要把用户目录中与该文件对应的目录项删除即可，且索引节点的count值减1。只要count&gt;0，就说明此时还有别的用户要使用这个文件，那么就不能把文件数据删除，否则就会导致目录项中索引节点指针悬空（NULL）。当count==0时就说明没有用户使用这个文件那么就可以删除了，操作系统会负责删除这个文件。 基于符号链的共享方式（软链接） 当User3访问ccc时，操作系统会判断文件ccc属于Link类型文件，那么就会根据其中记录的路径层层查找目录最终找到User1的目录表中的aaa表项，于是就找到了文件1的索引节点。 思考：这种链接方式的一种特点？ 我们发现这种方式的链接会有如下情况发生：当User1的aaa目录项被删除了而此时User3的目录项ccc还没有删除时，那么即使ccc可以指向Link文件2，但是由于User1的aaa不存在了所以不能找到文件1了，所以此时ccc会出现无法找到文件的情况，即User3ccc访问文件是基于User1在存在文件aaa存在的前提下才能实现的。 总结 文件保护 这里我们介绍几种文件保护的具体做法。 口令保护 主要是用于保护文件，设置特殊口令，只有正确才可以访问。所以此时用户访求文件时必须提供正确的口令，口令一般会存放在文件对应的FCB活索引节点中，用户访问文件前需要输入口令，然后操作系统将口令和FCB中的口令做对比，如果正确则允许用户访问文件（那么FCB中的口令肯定是不允许普通用户随意获得的）。这种方式优点是保存口令的空间开销不多，验证口令的时间开销也很小，但是缺点是正确的口令存放在系统内部不够安全。 加密保护 使用某个密码对文件进行加密，在访问时需要提供正确的密码才可以进行正确的解密。那么密码肯定是有多种的，我们以一个最简单的加密算法–异或加密为例。假设用于加密/解密的密码为01001，那么： 上面这种方法确实做到了加密的作用，并且优点是保密性强，不需要在系统中存放正确的密码，缺点是编码/译码（加密/解密）需要花费一定的时间。 访问控制 为每个文件的FCB（或者索引节点）中增加一个访问控制表（Access-Control List,ACL),该表记录各个用户可以对文件执行那些操作。 精简的访问列表就是：以组为单位，标记各组用户可以对文件执行那些操作。如下表： 当某用户想要访问文件时，系统会检查该用户所属的分组是否有相应的访问权限。所以一般重要的OS内核文件肯定是不允许用户访问的即使是操作者。 总结 磁盘的结构 磁盘、磁道、扇区 磁盘的表面由一些磁性物质组成，可以用来存储二进制数据，所以磁盘不能被刮坏。这里我们讲解一下一个磁盘的具体结构术语。 上图就是一个磁盘，他会被等大分为许多扇形，每一个扇形就是一个磁盘块（前面讲过磁盘块存储的数据大小相同），这里的一圈就是磁道，越靠近内侧数据的密度就越大。 磁盘读/写数据方法 我们知道磁盘在被访问时会一直转动，所以就会一直切换不同的扇区即磁盘块，而右边的磁头就是从磁盘上滑过，但是他只会从里到外滑动，不会旋转转动，这样他想在某个扇区（磁盘块）进行数据的读写只需要等到磁盘转到指定扇区即可，即磁头主要是负责切换磁道。 盘面、柱面 为了高效，一般一个盘片的两面均可以存放数据，所以会有许多盘面。所以每一个盘面均对应着一个滑过的磁头，但是磁头是连在一起的所以共进退。这也就意味着一次只能有一个磁头到达他想要到达的位置对应着的就是（柱面号，盘面号，扇区号），柱面号就是规定了磁头将要访问的磁道，而盘面号规定的是此时是哪一个磁头访问这个柱面磁道的数据，扇区号就是访问盘面的哪一个扇面，其他的磁头如果没有到达所要访问的位置也只能等待。 思考：为什么磁头要设计成这样？ 当然我也想过每个磁头可以不用共进退，各自访问他们想要去的位置这样岂不是更加读写高效，但是貌似实现起来也更复杂，并且我们也知道磁盘一转很快的，实际上磁头读写的速度非常快，上面这种已经可以高效实现磁盘的读写操作了。 磁盘的物理地址 其实我们上面已经介绍过来，可以用(柱面号，盘面号，扇区号)来定位任意一个磁盘块，在文件的物理结构中，我们经常提到文件数据存放在外存中的几号块，这个块号就是对应着一个具体的物理地址所以可以转换成（柱面号，盘面号，扇区号）的地址形式。 可根据该地址读取一个块： 根据柱面号移动磁臂，让磁头指向指定柱面（柱面号的作用） 激活指定盘面对应的磁头（盘面号的作用） 磁盘旋转的过程中，当指定的扇区划过时，磁头进行数据的读写，如果一次没有完成可以再等磁盘转过时进行直至完成数据的读/写（扇区号的作用） 磁盘的分类 此时图二的下方也是有许多磁头的只是没画出来，实际上这两种各有利弊，第一个磁臂需要频繁移动来切换磁道，而第二个磁头太多。 总结"},{"title":"文件系统基础与目录","path":"/wiki/操作系统笔记/文件系统基础与目录/index.html","content":"初识文件管理 那么我们现在要了解一席文件内部的数据的组织方式与文件之间的组织方式。并且思考从下往上看OS是提供哪些服务方便用户、应用程序使用文件，而从上往下看文件数据又要怎么存放到外存（磁盘）的问题。 文件属性（文件构成） 文件名：由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。 标识符：一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用来区分各文件的一种内部名称（同样的，操作系统为各个进程是通过PID来识别的）。 类型：文件的类型 位置：文件存放的路径（让用户使用），在外存中地址（操作系统使用，对用户不可见） 大小：文件的大小 创建时间，上次修改时间，文件所有者信息等 保护信息：对文件进行保护的访问控制信息 文件内部的组织方式 无结构文件：如文件文件，就是一些由二进制或者字符流组成，又称“流式文件” 有结构文件：如数据库表，由一组相似的记录组成，又称&quot;记录式文件&quot;，这里要注意记录是一组相关数据项的集合，而数据项才是文件系统中最基本的数据单位。 文件之间的组织组织方式 实际上就是通过目录来实现分层，这里的层最好不要太少（这样会造成目录下文件密度过大），同时也不要太多，否则分层太多，搜索查找文件时间开销大。 思考：文件夹是有结构文件吗？ 当然是，用过电脑的都知道文件夹可以以文件项排列各文件的详细信息，很明显每一个文件此时都是一个记录，而每一个文件的具体文件名，大小，创建时间等就是文件夹这一个记录式文件的数据项。 OS向上提供的服务 创建文件：可以“创建文件”，点击新建后，图形化交互进程在背后使用“create系统调用” 删除文件：可以“删除文件”，点击删除操作之后，图形化交互进程通过操作系统提供的“删除文件”功能，即delete系统调用，将文件数据从外存中删除 读文件：将文件数据从外存中读入内存，这样才能让CPU处理，使用的是read系统调用 写文件：将更改过的数据写回外存，使用的是write系统调用 打开文件：读/写之前需要打开文件 关闭文件：读/写文件结束之后需要关闭文件 基本上更多复杂的功能都是通过上面的基本功能组合实现的。 文件如何存放至外存 我们发现其实这个就是分页存储的思想，所以外存中与内存一样也是分成一个一个存储单元然后将文件切割离散存储，当然如果文件特别小，那么一个存储单元就可以放下整个文件，所以明显外存中也会有内部碎片。 思考：这里我们思考是不是外存中也会有连续存储的方式？ 肯定是有的，这里也有固定分区分配的存储思想和分页存储思想两种方式存储文件。 操作系统需要完成的其他文件管理的操作 文件共享：使多个用户共享一个文件 文件保护：保证不同的用户对文件有不同的操作权限 总结 大部分都是概念性知识点，记住即可 文件的逻辑结构 类似于数据结构的“逻辑结构”和“物理结构”，如线性表就是一种逻辑结构，在用户看来，线性表就是一组有先后顺序的元素序列。而线性表这种逻辑结构可以通过许多种物理结构实现，不如顺序表和链表均可以，顺序表是元素在逻辑和物理上都是连续相邻的，而链表是物理上不相邻但是逻辑上相邻的数据结构。所以顺序表的线性表可以随机访问，而链表形式的线性表就不可以了。所以算法的具体实现与逻辑结构和物理结构都有关（文件也是一样，文件操作的具体实现和文件的逻辑结构，物理结构有关) 无结构文件 首先无结构文件前面也提到过了就是“流式文件”是一组二进制或者字符流，所以没有明显的结构，也就不用讨论“逻辑结构”的问题。 有结构文件 前言：记录的分类 记录式文件，每条记录都是由若干个数据项组成的集合。一般来说，每一条记录的一个数据项都是一个关键字（可以作文识别不同记录的ID）。 根据各条记录的长度我们可以将记录分为定长记录和可变长记录： 定长记录：一般每条记录的长度是必须等长的，每一个数据项所在位置也都是相同不变的。 可变长记录：数据项的长度不一定相同因此记录的长度也是各不相同的，甚至某一个数据项没有是可以删掉的即下图中如果无特长可以直接删掉。 顺序文件 文件中的记录一个一个的地顺序排列（逻辑上），记录可以是定长或者变长的。各个记录在物理上可以是顺序存储或者链式存储。 根据记录之间的顺序是否与关键字有关我们分成： 思考：加入现在知道文件的起始位置，那种文件可以快速找到第i个记录的位置？那种文件又可以找到某个关键字对应的记录的位置？ 首先链式存储肯定是不可能实现随机随机存放的，所以每次都需要从头开始查找这样很难快速找到第i个文件的位置。所以快速查找只能在顺序存储中，又由于可变长记录长度不相同不能使用X+i*M的连续查找公式所以也不能和实现快速查找，所以只有定长记录的顺序存储才可以实现，同时只有采用顺序结构即存储的顺序和关键字有关的才可以找到关键字对应的记录的位置。 很明显从上图我们就可以看出可变长记录不能随机存取的原因了，由于长度不同，连续查找公式是不能使用的。定长记录的顺序文件，如果采用物理上的顺序存储那么就可以实现随机存取。如果还能保证记录的顺序结构那么就可以关键字快速检索了。一般上，考试题中的“顺序文件”指的是逻辑结构和物理结构上都是顺序存储的文件。所以顺序文件一般如果不说都是默认定长记录所以可以随机存放，但是缺点是增加/删除一个记录就很复杂，需要整体记录前移或者后移，但是如果是串结构那么就相对简单。 索引文件 对于很多场景都需要快速查找都第i个记录的位置，但是又是可变长记录文件，那么这时就需要索引文件的逻辑结构形式，即建立一张索引表，每个索引表都有唯一的索引号，长度m(毕竟是可变长的需要记录)以及一个指针ptr指向文件再外存中存放的地址，所以索引文件在结构上还顺序的，但是物理结构上是可以离散存储的，当然如果你非得在物理结构上也顺序存储也可以。 其实感觉就是分页存储的思想，只不过那个是讨论内存存放时提出的方法，现在这种思想应用在了文件管理上，实际上思想类似。索引表本身是定长记录的顺序文件（这里指的是物理结构上也顺序存储，否则不能实现随机存取），因此可以快速找到第i个文件的索引项。并且可以在索引表中以关键字作为索引号内容，若按照关键字顺序排列，那么还可以实现按照关键字折半查找。这是我们在尝试删除/增加一个记录时就是对索引表进行修改。因为索引表有很快的检索速度，所以主要用于对信息处理的及时性要求很高的场合。并且，可以用不同的数据项建立很多个索引表，如：学生信息表可以用关键字“学号”“姓名”都各建立一张索引表。这样就可以根据不同的关键字检索文件了。 索引顺序文件 我们思考一个问题，每个记录都会对应一个索引表项，因此索引表可能会非常巨大。比如：文件的每个记录平均只占8B，而每个索引表项占32个文件，那么索引表都要比文件本身还要大4倍，这样就降低了空间利用率。所以提出了索引顺序文件。 我们可以看出索引顺序文件的索引项不需要按关键字顺序排列，这样就极大方便新表项的插入，同时在上图中我们发现学生记录按照学生的姓名开头字母进行分组，每一个分组就是一个顺序文件，分组内的记录不需要按关键字排序。索引顺序文件就是索引文件和顺序文件思想的结合。索引顺序文件同样会为每个文件建立一个索引表，但是不是每一个记录对应一个索引表项，而是每一组数据对应一个索引表项。然后每一组文件中顺序存储，这样就大大瘦身了。 思考：三种文件的区别？ 顺序文件就是顺序存放，那么查找时如果是不定长就只能逐一查找并且顺序存放不好增删所以出现索引文件每一个记录对应索引表一定长个表项，索引表是物理顺序存放那么查找时就可以很快找到并且增删只需要修改索引表项，但是空间会很大毕竟索引表项和文件各占用很大的空间，所以索引顺序文件是将整个文件组按某些标准分成许多组然后为每个组建立一个索引表这样就实现了瘦身。 思考：用这种索引顺序策略能否解决不定长记录的顺序文件检索速度慢的问题？ 我们假设现在有一个10000个记录的顺序文件（不定长记录的物理结构顺序存储的顺序文件），那么如果根据关键字检索文件，只能从头开始顺序查找，平均需要查找5000个记录。 如果是索引文件，虽然表项定长，但是索引文件只是在已知起始地址查找第i个文件时加快了速度，现在是要查找某个关键字的搜索，那么也只能从头开始顺序查找，所以最终也是5000次平均查找。 如果使用的是索引顺序文件结构，可以把10000个记录分成100组每组100个记录，那么先顺序查找索引表找到分组（共100个分组，所以平均需要查找50次）然后找到分组后再在分组中顺序查找记录也是平均需要50次，那么最终只需要100次。很明显确实相较于顺序文件和索引文件有了检索速度的提升。 思考：但是如果现在是10^6的记录怎么办？ 我们发现如果是10^6个记录，那么此时索引顺序文件的查找次数还是很大，所以此时多建几层次级索引表就好了（毕竟每建一层索引表理论上会减少查找没有必要的多组文件），所以此时就是多级索引顺序文件如下： 此时对于一个10^6记录的文件(注意还是可变长记录文件），可以先为该文件建立一张低级索引表，每100个记录为一组，所以总共会有10000个表项，即10000个定长的表项，然后再把这10000个定长记录再次分组为每组100个再为其建立顶级索引表，那么顶级索引表就有100个定长表项。 这里有个公式：N个记录的文件建立K级索引，则最优的分组是每组N^(1/K+1)个记录。这样检索一个记录的平均查找次数是 (N1/K+1/2)∗(K+1)(N^{1/K+1}/2)*(K+1) (N1/K+1/2)∗(K+1) 次，例如上面我们分成了2级，那么每组就是(10^6)^1/3=100个记录，并且平均查找次数就是（100/2)*(2+1)=150次。 总结 文件目录 文件控制块 思考当我们双击照片这个文件夹后OS是如何找到文件夹下的文件和显示到我们屏幕上的呢？ 实际上此时是借助文件控制块实现的，我们双击“照片”后，操作系统会在这个目录表中找到关键字“照片”对应的目录项（也就是记录，毕竟记录就是存得许多不同的数据项也就是关键字），然后从外存中将“照片”目录的信息读入内存，于是“照片”目录中的内容就可以显示出来了。所以我们所说的目录实际上就是一个索引表。 那么目录文件中每一条记录实际上就是一个文件控制(FCB),FCB实现了文件名和文件之间的映射，使得用户(用户程序)可以实现“按名存取”。FCB的有序集合就成为“文件目录”，一个FCB就是一个文件目录项。FCB中包含了一个文件的基本信息，存取控制信息使用信息等。当然最重要的就是文件名和文件存放的物理位置。 那么通过文件控制块FCB我们可以实现哪些功能呢？ 搜索：当用户使用一个文件时，系统根据文件名搜索目录，找到该文件对应的目录项。 创建文件：当创建一个文件时，需要在所属的目录中增加一个记录项。 删除文件：当删除一个文件时，需要在目录中删除相应的目录项。 显示目录：用户可以请求显示目录的内容，如显示该目录中的所有文件及相应的属性。 修改目录：某些文件属性保存在目录中，因为这些属性变化时需要修改相应的目录项（如：文件重命名等）。 目录结构 单机目录结构 早期的操作系统不支持多级目录，所以整个系统只建立一张目录表，每个文件占据一个目录项，单机目录实现“按名存取”，不允许有任何文件重名。在创建一个文件时，需要先检查目录中有没有重名文件，只有确定不重名后才能建立文件，并将新文件对应的目录项插入到目录表中。 很显然，不适合多用户(这里的用户值得是多程序,应用软件)操作系统。想一想也知道现在的应用程序肯定都有许多重名文件例如：data,dist.source,js等 两级目录结构 早期的多用户操作系统采用两级目录结构，分为主目录(MFD,Master File Directory)和用户文件目录(UFD,User File Directory)。 此时就允许有重名文件了只要不在一个FCB下，但是此时还是不够灵活，毕竟用户文件夹可能也需要有自己的目录，所以就有了多级目录结构。 多级目录结构 又称树形目录结构，灵活高效，解决了上面两种目录结构的缺陷。 此时因为有许多可能重名的文件但是他们所在的位置是不同的，所以要访问某个文件时要用文件路径标识文件，文件路径是一个字符串。各级目录之间用&quot;/&quot;隔开，从根目录出发的就是绝对路径，从当前位置或者当前位置的父目录出发就是相对路径。例如：./就是相对路径表示从现在的位置出发，…/是从当前位置的父文件开始出发明显也是相对路径，但是…/或者/就是根目录出发就是绝对路径了。 思考：为什么要用相对路径？ 考虑一个问题现在我们要对某个文件夹下的许多文件进行操作，那么如果使用绝对路径，那么每一次都要输入很长的根目录路径明显低效，而如果此时使用相对路径./就很方便简洁。同时不仅仅是为了输入简便，如果我们使用绝对路径，那每一次都需要从根目录开始逐一从外存读入对应的目录表，然后在找到该文件夹下的文件，而是用相对路径就可以直接一次性将这个文件夹读入内存然后访问文件。可以见到，在引入“当前目录”和“相对路径”以后，磁盘的I/O次数减少了，这样就提升了访问文件的效率。所以相对路径是常用的文件路径方式，当然对于某些特殊的情况是必须使用绝对路径的。 所以树形目录结构不仅可以很方便的对文件进行分类，层次结构清晰，而且也能够更加有效的进行文件的管理和保护。但是树形结构不便于实现文件的共享，所以提出了“无环图目录结构”。 无环图目录结构 可以用不同的文件名指向一个文件，甚至可以指向同一个目录（共享一个目录下的所有内容）。需要为每一个共享节点设置一个共享计数器，用于记录此时有多少个地方在共享该节点。用户提出删除节点的请求时，只是删除该用户FCB、并且使共享计数器减1，并不会直接删除共享节点。直至共享计数器为0时，才删除节点。 我们发现共享文件不是赋值文件。在共享文件中，由于各用户指向的都是同一个文件，因此只要其中一个用户修改了文件数据，其他所有用户都可以看到文件数据的变化。 FCB的改进 我们之前进行的瘦身策略，实际上是对目录项进行分组然后多级索引表的存储，但是对于同一个目录下的目录项最好是对应一个目录表，那么该怎样实现瘦身呢？我们可以对FCB进行修改，毕竟查找时只是按照“文件名”进行查找，只有文件名匹配才能读出文件的信息，所以可以考虑让目录表瘦身吗，如下： 瘦身前： 瘦身后： 思考：好处是什么？ 假设一个FCB是64B，磁盘块大小为1KB=2^10B，那么每个盘块只能存放16个FCB，如果一个文件目录中共有640个目录项，那么需要占640/16=40个盘块。因此按照某文件名检索目录平均需要查找320个目录项，平均需要启动磁盘20次（每次磁盘I/O读入一块）。但是如果瘦身后即使用索引节点机制那么文件名占14B，索引节点指针占2B，一个FCB只占用16B，那么一个盘就可以放64个目录项，那么按文件名目录平均只需要读入320/64=5个磁盘块。显然这就大大提升了文件检索速度。 只有找到文件名对应的目录项才会将索引节点放到内存中，索引节点中记录了文件的各种信息，包括在文件再外存中的位置，根据“存放位置”即可找到文件。存放在外存中的索引节点就叫做“磁盘索引节点”而当索引节点放入到内存后就称为“内存索引节点”。相比之下内存索引节点需要增加一些信息，比如：文件是否被修改，此时有几个进程正在访问该文件等。 总结"},{"title":"段页式管理与虚拟内存概念","path":"/wiki/操作系统笔记/段页式管理与虚拟内存概念/index.html","content":"基本分段存储管理 分段 实际上类似于分页管理中的“分页”思想。我们先看一下分段的定义。 地址空间：按照程序自身的逻辑关系将程序划分为若干个段，每个段都有一个段名（在低级语言中，程序猿使用段名来编程），每段从0开始编制。而分段的内存分配规则就是：以段为单位进行分配，每个段在内存占据连续空间，但各个段可以离散存储不相邻，所以大小也是可以不相等的（不像分页必须规定固定大小的页帧）。 思考：为什么要引进分段的概念？ 我们熟悉的数据段，代码段都是分段的概念，那么分段和分页的区别是什么呢，又为什么要引入分段的概念呢？我们思考分页的存储方式，他是直接将进程按照固定大小切成许多小部分存到了不同的页。但是这里会涉及到一个尴尬的问题，就是大部分页要不存的全是代码，要不存的全是数据，但是总是会有那么几个页且在了数据和代码的交界处，这样这个页就会同时存储着数据和代码的混合体，这种页对于系统管理当然是没有问题的，但是对于编程人员来说就会可读性很差，不友好，导致用户编程不方便。按照人类的正常思维，最好将程序的不同的种类分段，这一段全存储数据，这一段全存储数据等等这样就会对人类可读友好。所以引进了段的概念。即分页是按照物理大小划分，分段是按照逻辑功能模块划分。 那么分段系统中同样有逻辑地址此时的逻辑地址是由段号（段名）和段内地址（段内偏移量）组成，如下： 段号决定每个进程最多可以分为几个段，而段内偏移量决定了每个段的最大长度是多少。如上图这样的32位划分，那么如果系统是按照字节编址，那么段号16位，因此程序最多可以分为2^16=64K个段，段内地址为16位，因此每个段最大长度为2^16=64KB。 同样的和分页查找地址类似，段中的某一个地址也是根据段号+段内偏移量找到具体的位置，如下： 那么 段号一般是用[]包裹，然后根据逻辑地址和段号就可以求得段内偏移量同样也需要段表查找到段的物理起始地址然后就可以找到真正的物理地址进行相应的读/写操作了(实际上和分页存储的查找方式是一样的)。 段表 问题：程序会被分为许多个段，各段离散地装入内存中，为了保证程序能正常运行，就必须从物理内存中找到各个逻辑段的存放位置。因此同样需要建立一张段映射表简称“段表”。 不同的是此时段表没有块号而是改为基址，并且有新添加了一栏段长，这是因为分段存储中段的大小长度不固定而导致的。所以物理块的起始地址也就不能使用X+4*M这种来计算了。 这里有几个要注意的点： 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称“基址”）和段的长度 各个段表项的长度是相同的。例如：某系统按照字节寻址，采用分段存储管理，逻辑地址结构为（段号16位，段内地址16位），因此使用16位即可表示最大段长。物理内存大小为4GB（可以用32位表示整个物理内存）。因此可以让每个段表项占16+32=48位，即6B。由于段表项长度相同，因此段号是可以隐含的，不占存储空间。若段表其实地址为,。则K号段对应的段表项存放的地址为M+K*6。 思考：分段存储和大小不等的固定分区分配的区别？ 我们知道在讲解分页时我们对比了分页和固定大小的固定分区分配两者的区别。这里我们同样来区分以下分段和大小不等的固定分区分配的区别。大小不等的固定分区分配是将内存块分成大小不等的一个个小空间，每个空间存放一个作业/进程，各个空间之间的进程/作业互不干扰。但是分段存储是将进程首先分成许多个大小长度不固定的块然后离散存储到物理块的不同位置处。这就是区别。 思考：此时我们是不是也需要考虑页表项凑成刚好被放入整数个时的字节大小问题？ 答案是不用的，我们思考以下问什么，对于分页存储每一个存储单元是固定大小的，所以需要连续存储时就是选取相邻连续的页帧凑成的，只有刚好恰好装满整数个时才能实现页表项之间的连续。但是现在段存储长度是可以改变的，所以就是页表项有多少，段的大小就是多少不需要再去凑了，毕竟段表肯定也是以段的方式存储到物理内存的（此时我们不讨论段页式存储，就仅仅是纯页式存储或纯段式存储） 思考：有没有可能有多级段表？ 应该是没有的，毕竟之所以有多级页表是因为页完全不需要连续，可以在离散的基础上再次离散，但是段就是按照逻辑模块进行划分的最小单元了，在离散逻辑模块就不连续了。所以应该是没有多级段表的。 地址变换 同样的我们也讨论以下如何实现逻辑地址到物理地址的转换。此时就没有什么“相除取页号，取余得偏移量”的步骤了，段式存储最大的特点就是在指令中直接就指出了段号和逻辑地址，那么直接就可以求得段内偏移然后查表就可以了。即少了求段号的一步（段号一般用[]包裹）。 同样的此时在二进制串中的转换方法是不变的，还是后K位表示偏移量，剩下的位数表示段号，然后根据段号查表找到基址，那么物理地址就是基址+段内偏移量。多简单，都不用像页式存储那样还得得到块号自己算物理起始地址，此时段式存储直接就可以根据表得到基址。 具体的变换演示如图： 我们一定要注意此时还多了一个步骤就是步骤4需要进行检查段内偏移量是否越界了。这个可千万不要忘记。所以也是需要进行两次访存一次是查表，一次是访问数据。 分段、分页管理的对比 我们从以下几个角度探讨： 角度1：划分单位 页是信息的物理单位，分页的主要目的是为了实现离散存储，提高内存的利用率（内部碎片很少）。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。 段是信息的逻辑单位，分段的主要目的是更好的满足用户需求，一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显示的给段名。 角度2：单位大小 页的大小固定由系统决定 段的长度不固定，决定于用户编写的程序 角度3：地址空间 分页的用户进程地址空间是一维的，程序猿只需要给出一个记忆符即可表示一个地址 分段的用户进程地址空间是二维的，程序猿在标识一个地址时，既要给出段名，也要给出段内地址。 角度4：信息的共享与保护 分段比分页更容易实现信息的共享和保护。不能被修改的代码成为纯代码或可重入代码（不属于临界资源），这样的代码是可以共享的。可修改的代码是不能共享的（比如，有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致） 思考：如何使得某个段是临界资源可以被共享？ 很简单，就是使表项的基址指向同一个段即可： 而页不是按照逻辑模块划分的，这就很难实现共享。因为假设一个函数模块被放在了两个页A,B，那么如果想让这个函数模块被共享，那么就需要A,B页都是可以允许共享的，但是如果此时A只有一半存的是函数模块，另一半存的是不允许共享的资源，那么显然现在A就很难实现共享，那么这个函数模块就也不能被共享了，这种冲突就造成了分页很难实现共享，同时风险也就更大。 角度5：访存流程 对于分页存储（单级页表）：第一次访存–查内存中的页表，第二次访存–访问目标内存单元。总共两次访存。 对于分段存储：第一次访存–查内存中的段表，第二次访存–访问目标内存单元。总共两次访存。 并且分页和分段都可以引入快表机构，这样近期访问过得表项再次被访问时就只需要访存一次了。 总结 段页式管理方式 前面我们一直都是讲解的纯分页式管理或者纯段式管理，那么能不能同时集合两者的优点，这就出现了段页式管理方式。 分页、分段的优缺点 存储方式 优点 缺点 分页管理 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 不方便按照逻辑模块实现信息的共享和保护 分段管理 很方便按照逻辑模块实现信息的共享和保护 如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生很大的外部碎片（当然可以使用“紧凑”技术来解决，但是时间开销大） 分段+分页=段页式管理 我们前面说过页可以再分页，但是段不能再分段，但是我们可以用分段后在分页的方式存储，这样逻辑模块功能划分的优点保存的同时也可以将较大的段离散存储。所以首先要知道段页式存储一定是先分段再分页并且是对相同的段分页。如下： 段页式管理的逻辑地址结构 那块此时逻辑地址的结构也是变化的，我们此时会将逻辑地址变为如下： 此时就没有段内偏移量了，“分段”对用户是可见的，程序猿编程时需要显式地给出段号、段内地址。而将各段“分页”对用户是不可见的，系统会根据内地址自动划分页号和页内偏移量来具体存储段的位置。因此段页式管理的地址结构也是二维的。 段号的位数决定了每个进程可以最多被分成几个段，页号位数决定了每个段可以最多被分成几个页，而页内偏移量决定了页面大小和内存块大小（当然如果是多级页表存储，页号还可以分成许多多级页号更复杂）。 例如上图中的结构如果系统是按字节寻址的，那段号占16位因此该系统中，每个进程最多有2^16=64个段，而页号占4位，因此每个段最多被分为2^4=16页，页内偏移量是12位，因此每个页面/内存块大小为2^12=4096=4KB。 段表、页表 显然此时段表和页表也是有变化的，如下图： 此时每个段对应一个段表项，每个段表项由段号，页表长度（实际上就是段长度），页表存放块号（可以算出页表其实地址）组成。每个段表项长度相同，段号是隐含的。所以段表变化很大，页表基本上不变。每个页表对应一个页表项，每个页表项由页号和页面存放的内存块号组成。每个页表项长度相同，页号是隐含的。当然对于页表为了连续存储公式计算方便，最好还是一个页帧可以放入整数个页表项。 地址变换 注意此时一般来说就需要三次访存了，一次查段表，二次查页表，三次访存目标内存单元。当然如果加入了快表，那就只需要一次访存就是访存目标内存单元。 总结 虚拟内存的基本概念 这部分主要谈论内存管理中内存空间的扩充部分。我们之前已经讲过覆盖和交换技术了，那么这次来讲一讲虚拟存储技术（在中级调度中有过应用）。 传统存储管理方式的特征与缺点 所以我们之前讲的都是属于传统存储管理的部分。缺点是长期占用内存，所以可以使用虚拟存储技术解决。在传统的存储管理方式中有以下特点： 一次性：作业必须一次性全部装入内存才能开始运行。这会造成两个问题：一是作业很大时不能全部装入内存导致大作业无法运行，二是当大作业要求运行时，由于内存无法容纳所有作业，因此只能有少量作业能运行，导致多道程序并发度降低。 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分就可以正常运行了，这就导致内存中会驻留大量的，暂时用不到的数据，浪费了宝贵的内存资源。 而以上的缺点我们都可以使用虚拟存储技术来解决。 局部性原理 我们之前已经讲过局部性原理了，实际上虚拟存储技术就应用了局部性原理的思想，已知的应用有快表机构就是将常访问的页表项副本放到更快速访问的TLB中，这种高速缓冲技术的思想就是利用了局部性原理，将近期频繁访问到的数据放到更高速的存储器中，暂时用不到的就放在更低速的存储器中。 虚拟内存的定义和特征 基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。（覆盖技术的思想） 如果内存空间不够，由操作系统将内存中暂时用不到的信息换出到外存。（交换技术的思想） 在操作系统的管理下，在用户看来似乎有一个比实大的多的内存，这就是虚拟内存。（操作系统虚拟性的体现） 思考：覆盖技术，交换技术，虚拟存储技术的区别？ 我们可以发现实际上虚拟内存的出现就是虚拟存储技术的具体应用，而且思想貌似就是覆盖交换技术，实际上他们的思路就是一样的，只是作用的单位不同。覆盖技术和交换技术都是对于进程来说的，而虚拟内存是对内存中的数据信息块进行管理。 易混淆知识点： 虚拟内存的最大容量是由计算机的地址结构（CPU寻址范围）确定的 虚拟内存的实际容量=min(内存和外存容量之和，CPU寻址范围) 例如：某计算机地址结构为32位，按字节编址，内存大小为512MB，外存大小为2GB。 那么虚拟内存的最大容量就是2^32B=4GB（虚拟出来的），但是虚拟内存的实际容量就是min(2^32B,512MB+2GB)=2GB+512MB 思考：虚拟内存的特征？ 虚拟内存凭借虚拟存储技术有以下三个特点： 多次性：无需在作业运行时一次性全部装入内存，而是允许分成多次调入内存 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量远大于实际容量。 虚拟内存技术的应用条件 虚拟内存技术允许一个作业多次调入内存，如果是采用的连续分配方式很明显不方便，所以虚拟内存的实现方式需要建立在离散分配的内存管理方式基础上。 但是区别于传统的离散分配存储管理，虚拟内存不是一次性装入全部，所以才会像之前所说的出现缺页中断等现象，此时就需要请求调入内存了，所以在虚拟内存技术中很明显会频繁的发生&quot;请求&quot;所以在虚拟内存技术下的存储方式叫做 所以主要区别就是在程序执行过程中，当所访问的信息不在内存时，有操作系统负责将所需要的信息从外存调入到内存中，然后继续执行程序。若内存空间不够了，就由操作系统将内存中暂时不需要的信息换出到外存。所以操作系统需提供请求页面功能和页面置换功能，当然后面会讲解页面置换算法决定具体该将那个信息暂时调出内存。 总结"},{"title":"文件存储与基本操作","path":"/wiki/操作系统笔记/文件存储与基本操作/index.html","content":"文件的物理结构 文件块，磁盘块 外存中的文件存储方式我们前面提到过实际上和内存中的分页存储类似，磁盘中的存储单元也会被分为一个个“块/磁盘块/物理块”，甚至在许多操作系统中，磁盘块的大小和内存块，页面的大小是相同的。 所以I/O操作的时间开销较大，一般要避免I/O操作（例如内存中页面调度优先淘汰干净页面以避免写回）或者降低I/O的操作次数例如上面讲到的PCB索引节点机制。因为在外存中也是分成一个个外存块，所以文件的逻辑地址也是逻辑块号+块内地址拼接的形式。用户给出的是逻辑地址而操作系统转换为物理地址进行映射。 连续分配 连续分配要求每个文件在磁盘上占有一组连续的块。如下图： 并且对应的文件目录中也需要记录起始块号，占据的块的长度： 并且由于逻辑地址-&gt;物理地址的方法相似，所以当用户给出逻辑块号后，只需要操作系统根据目录项FCB找到对应的物理块号=起始块号+逻辑块号即可，然后在检验合法后在拼接上块内地址即可完成，因此连续分配支持顺序访问和直接访问（随机访问）。 思考：连续分配存储的好处？ 当读取一个磁盘块时，需要移动磁头。那么访问的磁盘块距离越远，移动磁头所需要的的时间也就越长。所以连续分配时块号相邻，那么文件再顺序读/写时速度最快。 思考：连续分配的缺点是什么？ 我们考虑一种情况，比如下图： A此时是占用了连续的3个黄色的磁盘块，但是现在A要进行拓展，需要在增加一个磁盘块并且由于要连续存储，因此此时A放不下了，又因为后面的连续块都已经被橙色所占用，所以A只能全部迁移到绿色区域。这无疑会造成很大的开销。所以物理上采用连续分配的文件不方便拓展。 并且还会造成如上图的情况，这是连续分配存储的共性问题，大量的外部碎片会降低空间的利用率，当然那我们同样可以使用紧凑技术来处理碎片，但是很明显会有大量的开销。 链接分配 隐式链接 为了解决上面的外部碎片问题，我们采用链接分配磁盘块，这里先给出隐式链接的方法，还是如上图，我们此时把文件离散存储并记录起始块号和结束块号（中间块号不记录），每一个中间块都有一个尾指针指向下一个存储文件信息的磁盘块并且对用户开放，这样就不要紧凑技术仍然可以充分利用外部碎片了。如下图： 并且貌似文件拓展也就不是什么难事了所以不会有外部碎片，但是此时却产生了另一个缺点。 思考：这种链接方法的缺陷？ 我们发现此时实际上并不是连续存储了，那么就产生了非连续存储的一个常见问题，就是假设现在用户要访问逻辑块号i，那么操作系统找到对应的FCB然后从起始块开始一个一个查找直至找到所需块号，这样假设要读入逻辑块号i，那么需要i+1次磁盘I/O。这种采用隐式链接的方法，只支持顺序访问，不支持随机访问，查找效率低。另外，指向下一个盘块的指针也需要移动很长距离的磁头，时间开销较大。 显式链接 为了解决上面所遇到的问题，可以把用于链接文件各物理块的指针显式的存放在一个表中，即文件分配表（FAT,File Allocation Table)。同样目录中只需要记录起始块号即可，会另有FAT用来存储这些指针如下： 此时我们为每一个磁盘设置一张FAT，开机时，将FAT放入内存并常驻内存。因为此时按物理块号递增排列，所以物理块号可以隐含不需要占用额外的空间。 此时我们在观察目录表和FAT可以轻松得知文件aaa的磁盘块有2-&gt;5-&gt;0-&gt;1，bbb的文件一次存放在4-&gt;23-&gt;3中。此时如果我们得到了逻辑块号i，那么找到其实块号，如果i&gt;0,则查询内存中的文件分配表FAT，往后查找第i个物理块号即可。所以此时逻辑块号转换成物理块号不需要再进行读磁盘操作。 所以采用显式链接方式的文件，支持顺序访问，也支持随机访问（想访问i号逻辑块时，并不需要依次访问之前的0~i-1号逻辑块），由于块号的转换也不需要访问磁盘，所以相比于隐式链接来说，显式链接访问速度更快。并且显式链接也不会产生外部碎片，可以很方便的进行文件的拓展。 索引分配 这就是分页存储思想在外存中的应用，索引分配允许文件离散的分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表记录了文件的各个逻辑块对应的物理块（索引表的功能类似于内存管理中的页表–建立逻辑页面到物理页之间的映射关系）。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。 假设某个新创建的文件aaa的数据依次存放在磁盘块2-&gt;5-&gt;13-&gt;9,7号磁盘块作为aaa的索引块，即7号块存放aaa的索引表存放aaa文件的逻辑块号与物理块号的映射关系。所以我们注意到与FAT不同，索引分配中，索引表是一个文件对应一张。 同样我们也涉及到索引表项的字节大小的问题，我们假设磁盘总容量为1TB=2^40B，磁盘块大小为1KB，那么总共有2^30个磁盘块，所以索引表项即可以用4B来表示磁盘块号（同样我们也争取凑成2的整数次幂），因此索引表的逻辑块号也是可以隐含的。 所以，索引分配中逻辑块-&gt;物理块的转换就是通过查表得知，并且索引分配也是可以支持随机访问的，稳健拓展同样容易实现（只需要给文件分配一个空闲块，并增加一个索引表项即可）但是索引表需要占用一定的空间。 思考：一个磁盘块装不下文件的整张索引表时，此时如何解决？ 假设如果每个磁盘块1KB，一个索引表项4B，那么一个磁盘块只能存放256个索引项，但是如果一个文件的大小超过了256块，那么很明显此时一个磁盘块装不下文件的整张索引表，该怎么办。我们有以下几种解决策略： 链接方案 如果索引表太大，一个索引块放不下，那么可以将多个索引块链接起来存放。如下： 看似问题有效解决了，但是考虑一种情况：假设磁盘块大小为1KB，一个索引表项占4B，则一个磁盘块只能存放256个索引项。如果一个文件大小为256*256KB=64MB，那么这个文件一共需要256*256块,也就是256个索引块来存储，那么如果真的是按照链接形式存放，如果想要访问最后一个索引块就需要先将前面的255个全部访问一遍，这样顺序查找时间开销太大。 多层索引 建立多层索引（类似于多级页表），是第一层索引块指向第二层索引块，还可根据需要再建立第三层，第四层索引块。 如果采用这种二层索引，那么该文件的最大程度可以到达64MB，并且还可以根据逻辑块号算出应该查找索引表中的哪个表项。例如现在要查找1026号逻辑块： 1026/256=4,1026%256=2。所以先将第一层索引表调入内存，查询4号表项，然后在对应的二级索引表调入内存，再查询二级索引表的2号表项即可知道1026号逻辑块存放的磁盘块号了。这样访问数据块，需要3从I/O操作，那块采用K级索引结构，且顶级索引表未调入内存（一定要注意，一般顶级索引表常驻内存），那么访问一个数据块只需要K+1次读磁盘操作。同理如果是三层索引，那么文件最大长度就是256*256*256KB=16GB,并且查找到一个物理块需要4次磁盘读操作。 混合索引 多种索引分配方式的结合。例如：一个文件的顶级索引表中，既包含了直接地址索引（直接指向数据块），又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表）。 这样需要经常被访问的就放在直接地址索引，对于不经常使用的放在多级地址索引，高效同时长度拓展的也很大。非常合理，同时我们也可以进行文件的大小估计。例如上图中的最大文件长度就是65800KB，其实计算和多级索引类似。 三种索引分配的总结 索引策略 策略规则 缺点 链接方案 一个索引块装不下可以多个索引块链接存放 I/O次数过多，查找效率极低 多层索引 建立多级索引表，类似于多级页表 即便是小文件也需要K+1次读磁盘 混合索引 多种索引方式的结合，既有直接地址索引也有多级间接索引 对于小文件访问次数少，查找高效 ❗超级重点：一定要回根据多层索引和混合索引的结构（各级索引表必须放在一个磁盘块中）计算文件的最大长度，公式是： 个数∗索引块的大小个数*索引块的大小 个数∗索引块的大小 要回分析所需要的读磁盘次数，并且一定要注意题目条件–顶级索引块是否已经掉入内存。 总结 分配方式 怎样实现 目录项内容 优点 缺点 顺序分配 为文件分配的块必须是连续的磁盘块 起始块号、文件长度 顺序存取速度快，支持随机访问 会产生碎片，不利于文件拓展 链接分配（隐式链接） 除文件的最后一个盘块之外，每个盘块中都存有指向下一个盘块的指针 起始块号，结束块号 可解决碎片问题，外存利用率高，文件拓展实现方便 只能顺序访问，不能随机访问 链接分配（显式链接） 建立一张文件分配表FAT显式记录盘块的先后关系（开机后FAT常驻内存） 起始块号 除了拥有隐式链接的优点之外，还可以通过查询内存中的FAT实现随机访问 FAT需要占用一定的存储空间 索引分配 为文件数据块建立索引表，索引表存储在索引块中，如果文件太大，可采用链接方案，多层索引或者混合索引策略 链接方案记录第一个索引块的块号，多层/混合索引记录的是顶级索引块的块号 支持随机访问，易于实现文件的拓展 索引表需占用一定的存储空间，访问数据块前需要先读入索引块。如果采用的是链接方案，查找索引块时可能需要很多次读磁盘操作 混淆点：什么是支持随机访问？ 假设现在这个文件的逻辑结构是“顺序文件”，并且是定长记录，每个记录的长度是16B，那么i号记录的逻辑地址是多少？（从0开始编号） 每块大小为1KB，定长记录时16B，所以一各磁盘块可以存放64个记录，则： “文件的某种逻辑结构支持随机存取/随机访问”是指：采用这种逻辑结构的文件，可以根据记录号直接算出该记录对应的逻辑地址（逻辑块号，块内地址）。 文件存储空间管理 存储空间的划分与初始化 安装windows操作系统的时候必须经历的步骤–为磁盘分区（C盘，D盘等）。 存储空间管理–空闲表法 空闲表法主要适用于连续分配方式，这里是用一张空闲盘块表进行对空闲物理块的记录，如下： 如何分配磁盘块：其实和内存管理的动态分区分配很相似，为一个文件分配连续的存储空间，同样可以采用首次适应，最佳适应，最坏适应等算法来决定为文件配到那个区。 所以毋庸置疑回收磁盘块时肯定是情况也类似有以下几种情况： 回收区的前后都没有相邻空闲区 回收区的前后都是空闲区 回收区前面是空闲区 回收区后面是空闲区 所以我们也需要注意合并的问题。 存储空间管理–空闲表链法 空闲盘块链 操作系统保存着链头，链尾指针。分配时如果要申请K个盘块，那从链头开始依次摘下K个盘块分配，并修改空闲链的链头指针。回收时回收的盘块挂到链尾，并修改空闲链的链尾指针。这种方法适用于离散分配的物理结构，为文件分配多个盘块时可能要重复多次操作。 空闲盘区链 操作系统保存着链头，链尾指针。 分配时若某文件申请K个盘块，则可以采用首次适应，最佳适应等算法，从链头开始检索，按照算法规则找到一个大小符合要求的空闲盘区， 分配给文件。若没有合适的连续空闲块，也可以 将不同盘区的盘块同时分配给一个文件，注意分配后可能要修改相应的链指针、盘区大小等数据。 回收时若回收区和某个空闲盘区相邻，则需要将回收区合并到空闲盘区中。若回收区没有和 任何空闲区相邻，将回收区作为单独的一个空闲盘区挂到链尾。 这种方法离散分配和连续分配都适用，为一个文件分配多个盘块时效率更高。 存储空间管理–位示图法 其实就类似于矩阵存储，但是又不是完全一样，如下图： 这是磁盘的情况，那么我们可以列出一种特殊的矩阵形式，如下： 他是由字号和位号来表示的，因为这个矩阵时16列，所以一个字号就是代表几个16，而位号就是几个1，优点类似于满16进1的表示意味。 位示图：每个二进制位对应一个盘块，在本例中，“0”代表空闲，“1”代表盘块已分配。位示图一般用连续的“字”来表示，如本例题中一个字的字长是16，字中的每一位对应一个盘块。因此可以用（字号，位号）对应一个盘块号。当然有的题目中也描述为（行号，列号）。但是总之就是要自己会推算出每个盘块的空闲状态。这里主要要注意开头的号码是0还是1千万要注意一个字是多少位。 (字号,位号)=(i,j)的二进制位对应的盘块号b=n∗i+j(字号,位号)=(i,j)的二进制位对应的盘块号b=n*i+j (字号,位号)=(i,j)的二进制位对应的盘块号b=n∗i+j 所以如下图我们可以推出： 同理我们也可以一直盘块号反推出字号和位号 b号盘对应的字号i=b/nb号盘对应的字号i=b/n b号盘对应的字号i=b/n b号盘块对应的位号j=b%nb号盘块对应的位号j=b\\%n b号盘块对应的位号j=b%n 所以我们可以反推出： 所以分配时：若分配需要K个块， ①顺序扫描位示图，找到K个相邻或不相邻 的“0” ②根据字号、位号算出对应的盘块号，将相应盘块分配给文件 ③将相应位设置为“1” 回收时： ①根据回收的盘块号计算出对应的字号、位号 ②将相应二进 制位设为“0” 存储空间管理–成组链接法 空闲表法和空闲链表法都不适用于大型文件系统，因为空闲表或者空闲链表会过大。所以UNIX系统采用了成组链接法对磁盘空闲块进行管理。 文件卷的目录区中专门有一个磁盘块为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。 超级块记录的是下一组的空闲块数，然后底下表示的就是空闲块号，并且这些空闲块不是连续的，而是离散存储使用指针相连的，这里只是为了方便表示。所以现在上图中的情况是表示超级块表示下一组有100个空闲块分别是201~300号同时发现300号，即此时300号是空的，但是同时300号有表示下一组有100个空闲块分别是301~400号，同时400号表示下一组7801~7900是空闲块，但是当遇到-1表示这个是空闲块的末尾了即使空闲块此时显示一个正整数但是此时也表示没有空闲块了。 思考：如何分配空闲块？ 我们现在假设需要给一个空闲块分配，那么首先检查第一个分组的块数是否满足。发现1&lt;100所以第一组就可以满足，然后分配第一组中的一个空闲块并修改数据即可。所以加入一个后变成： 此时第一个超级块变成了99，同时201~300号中有一个变成了非空闲块。一定要注意即使此时300上面显示下一组的空闲块数说明他是一个空闲块但是他仍然自身还是一个空闲块。 现在我们假设要分配100个空闲块，那么显然此时第一组刚好放下，所以201~300全部填满都变成了非空闲块，但是此时300底下也有一组空闲块为301~400所以此时不能放在300底下了赋值到超级块底下如下： 所以超级块第一个位置是400，直接指向400开头的组，所以此时超级块底下为400，7801~7900。 思考：如何回收非空闲块？ 因为每组就只能100（一般是规定好的最大值），那么此时下图中： 超级块此时是99表示下一组有99个空闲块，还可以回收一个，所以回收的如果刚好1个那么就放到第一组的末尾。但是如果此时要回收100个，那么就会超了，所以要新建一组来存放空闲块，并且组头用来标记下一组的空闲块数，如下图： 那么此时组成的100个空闲块的一组就组成一个新组并且300中的400指向之前的400开头的组，那么此时超级块就表示第一个组只有1个空闲块了。 对于成组链接法不要求掌握，确实不太好描述和理解。主要是知道超级块是一切的起点然后同时记录着下一组的空闲块数就好。我讲的不太好，可以参考这篇博客大佬博客 总结 文件的基本操作 这里我们学习基本功能的具体实现方法，了解即可 创建文件 需要调用Create系统调用，主要需要提供以下几个参数： 文件所需要的外存空间大小（如：一个盘块，即1KB）。 文件存放的路径(“D:/Demo”) 文件名（这个地方默认为&quot;新建文本文档.txt&quot;) 操作系统在进行Create系统调用时，主要进行了两件事： 在外存中找到文件所需的空间（结合上小节学习的空闲链表法，位示图等） 根据文件存放的路径的信息找到该目录对应的目录文件（此处就是D:/Demo目录)，在目录中创建该文件对应的目录项。目录项中包含了文件名、文件在外存中的存放位置信息。 删除文件 进行Delete系统调用，需要以下几个参数： 文件存放路径（D:/Demo ） 文件名（test.txt） 操作系统在处理Delete系统调用时，主要做了几件事： 根据文件存放路径找到对应的目录文件，从目录中找到文件名对应的目录项 根据该目录项记录的文件在外存中的存放位置。文件信息大小等回收文件占用的磁盘块。（同样的，回收时也需要根据空闲链表，空闲表，位示图等策略回收） 从目录表中删除文件对应的目录项 打开文件 在很多操作系统中，在对文件进行操作之前，需要用户使用Open系统调用打开文件，需要提供以下几个参数： 文件存放路径（D:/Demo） 文件名（test.txt) 要对文件的操作类型（如：r只读，rw读写等） 操作系统需要处理Open系统调用时，主要做一下几件事： 根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项，并检查该用户是否有指定的操作权限。 将目录项复制到内存中的“打开文件表”中，并将对应表目的编号返还给用户，之后用户再使用打开文件表的编号来指明要操作的文件。 思考：一共有多少个打开文件表？ 每个进程会对应着自己的一个打开文件表，同时系统也还拥有一张系统的打开文件表： 关闭文件 与打开文件相反，操作也类似。 一定不要忘记最后一步的系统打开文件表项的操作。 读文件 进程使用read系统调用完成读操作，需要指明是哪个文件（在支持“打开文件”的操作系统中，只需要指明文件在打开文件表中的索引值就行了），还需要指明要读入的数据大小、读入的数据的存放位置。 操作系统在处理read系统调用时，会从读指针指向的外存中，将用户指定大小的数据读入到内存的指定存放位置。 写文件 进程使用write系统调用完成写操作，需要指明是哪个文件（在支持“打开文件”操作系统中，只需要提供文件在打开文件表中的索引号即可），还需要指明要写出多少数据，写回外存的数据的存放位置。 操作系统在处理write系统调用时，会从用户指定的内存区域，将指定大小的数据写回写指针指向的外存。 思考：读写操作的细节？ 读操作是数据进入内存，写操作是写回外存，并且读/写指针都是指向的外存，一定要注意。 总结 实际上当遇到文件重名时，系统会请求用户端能否使用(1)(2)后缀表示或者用户端更改文件名。"},{"title":"早期分配管理方式","path":"/wiki/操作系统笔记/早期分配管理方式/index.html","content":"连续分配管理方式 这里我们讲一讲内存空间的分配方式，分为连续分配管理方式和非连续分配管理方式，我们首先学习连续分配管理方式。 连续分配顾名思义就是为用户进程分配的必须是一个连续的内存空间，这里有三种连续分配方式如下： 单一连续分配 在单一连续分配方式中，内存被分为系统区和用户区。系统区通常位于内存的低地址部分，用于存放操作系统相关数据，而用户区存放用户进程相关数据。内存只有一道用户程序，用户程序独占整个用户区空间。 这种方式优点是实现简单，没有外部碎片，可以采用覆盖技术扩充内存，不一定需要采取内存保护（例如早期的PC操作系统MS-DOS）。但是缺点是只能用于单用户，单任务的操作系统中（这显然不适合并发进程），并且有内部碎片，存储器利用率极低。 思考：什么是内、外部碎片，有什么区别？ 我们先给出定义： 外部碎片是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。外部碎片是处于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或者其他原因，使得系统无法满足当前申请。多道可变连续分配只有外部碎片。 内部碎片就是已被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间。内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程不能使用这个存储块。而在进程占有这块存储块时，系统无法利用它。知道进程释放他，或进程结束，系统才有可能利用这个存储块。 所以内外碎片本质区别就是是否已经属于某个被分配的进程。并且外部碎片在操作系统的调整下可以消除，而内部碎片操作系统无权调配管理，只能等待被分配进程结束。 这里我们举一个例子来形象介绍，假设现在有1,2,3,4,5,6六个仓库，当1,2,3,4,5已填满后，4清仓了，那么此时空仓库有4,6，此时来了一批货物大小为2个仓库刚好满足4,6容量之和，但是货物要去连续存储，此时4,6无法使用并且4,6不属于任何一个货物所以4,6形成的就是外部碎片。而现在假设六个仓库都是空的，并且要求货物最小分配空间为间，所以一个仓库只能装一种货物，那么现在有一批2.5间容量的货物装载1-3号仓库，那么3号仓库只装了半间，但是此时再有别的货物也不能装入3号仓库并且此时3号仓库属于第一批货物，并且管理员也不能调整再使用3号仓库了，那么3号仓库剩余的空部分就是内部碎片。–大佬博客 按照上面的介绍我们知道了单一连续分配不会产生外部碎片的原因了，并且这种分配管理方式不用想也知道肯定会产生很大的内部碎片，所以不合理。 固定分区分配 20世纪60年代支持多道程序的系统出现后，为了能在内存中装入多道程序并且这些程序之前互不干扰，于是将整个用户控件划分为若干个固定大小的分区，在每个分区中只装入一道作业，这样就形成了最早的。最简单的一种可运行多道程序的内存管理方式，但是显然这种固定大小分区的分配方式很不合理，于是又出现了分区大小不等的分配方式。 分区大小相等：缺乏灵活性，但是很适用于一台计算机控制多个相同对象的场合（比如：钢铁厂有n个相同的炼钢炉，就可以把内存分为n个大小相等的区域存放n个炼钢炉控制程序） 分区大小不等：增加了灵活性，可以满足不同大小的进程需求，根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区，适量中等区，少量大分区）。 思考：那我们如何知道某个分区i的具体大小是多少？ 所以我们需要建立一个数据结构–分区说明表来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小，起始地址，状态（是否已分配）。如下： 当用户程序要装入内存时，由操作系统内核程序根据用户程序的大小检索检索表，从中找到一个满足大小的，未分配的分区，将之分配给该程序，然后修改状态为“已分配”。 这种固定分区分配优点是实现简单，无外部碎片（因为可以调整消除）缺点是当用户程序太大时，可能所有的分区都不能满足需求，此时就不得不采取覆盖技术来解决但是这又会降低性能，并且这种方法肯定是会产生内部碎片的，内存利用率低（无论是大小固定还是大小不等的分区分配方式）。 动态分区分配 动态分区分配又称为可变分区分配，这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的，（比如：假设某计算机的内存大小为64MB，系统区8MB，用户区56MB…） 很明显这种方法肯定是没有内部碎片的，解决了固定分区分配的缺陷。 思考：系统需要用什么样的数据结构记录内存的使用情况？ 其实和固定分区分配中分区不等大小的方法一样，也是建立表或者链来记录呗，如下： 当然名字还是得换一换的，实际上思路是异曲同工的。一定要注意此时只需要记录空闲连续分配区间的大小和起始地址就可以了。。 思考：当很多个空闲分区都能满足需求时选择哪个分区进行分配？ 如在上图中的空闲区域情况时，又来了一个进程5（之所以没有进程1,2,3可能是挂起或者运行完成释放了）大小为4MB，此时所有分区都满足，那么如何分配呢？ 这里我们有以下几种情况（后面会细讲）： 用最大的分区进行分配 用最小的分区进行分配（比较符合正常思维） 用地址最低的部分进行分配 把一个新作业装入内存时，须按照一定的动态分区分配算法，从空闲分区表（或空闲分区链）中选出一个分区分配给该作业。由于分配算法对系统性能会有很大的影响，因此人们研究后发明了几种动态分区分配算法（后面讲）。 思考：如何进行分区的分配和回收？ 空闲分区分配 首先看分配，这个简单，如果分配后某个分区刚刚好被占据了那么这个表项直接删除就好了。如下图： 5号进程放在了3号空闲分区刚好占满，那么删除3号表项即可。 如果空闲分区分配一定空间后没有被占满，那么就要更新分区大小和起始地址了，如下图： 5号进程放在了1号分区并且从1号分区的头部开始放，那么1号分区并未占满，此时就要更新1号分区，起始地址+4变为12同时大小-4变为16。 分区回收 分区的回收涉及的问题较多，这里我们逐一讨论 情况1：回收区的后面有一个相邻的空闲分区 例如下图： 此时要回收进程4了，那么很明显回收区后面相邻连着空闲分区1，那么此时只需要将后面的空闲分区更新起始地址-4同时分区大小+4就好。这个是两个相邻的空闲分区的合并。 情况2：回收区的前面有一个相邻的空闲分区 例如下图： 进程3完成后回收，此时回收区与前面的2号空闲分区所以合并更新2号分区的分区大小+18=28即可，起始地址此时是不需要变得。 情况3：回收区的前、后各有一个相邻的空闲分区 如下图： 此时比较复杂，需要将回收区和后相邻分配去全部加入到前相邻分配区，此时如上面的进程4被回收，那么回收区+后相邻空闲区的总大小为14都加到前相邻空闲分配区1中，所以此时1号空闲分配区大小为34，同时起始地址还是不变，然后还要将后相邻空闲分区删除表项，即2号分区变为了原先的3号分区。 情况4：回收区的前、后都没有相邻的空闲分区 如下图： 我们可以看到此时如果进程2回收，那么新的回收区就成为了一个新的最靠近低地址的空闲分区，所以加入一个新表项这里是1号分区大小为进程大小14，同时起始地址是28。 我们可以看出动态分区不会有内部碎片，但是会有外部碎片。如果内存中空闲空间的总和本来可以满足某进程的需求，但由于进程需要的是一部分连续的内存空间，因此这些“碎片”不能满足进程的需求，可以通过紧凑（拼凑，Compaction)技术来解决外部碎片。紧凑技术就是操作系统不时地对进程进行移动和整理来达到将几个外部碎片凑成一片连续的分区这需要动态重定位寄存器的支持。 总结 动态分区分配算法 接着前面的思考问题，我们来思考一下对于具有许多个空闲分区都可以容下进程数据时我们应该使用哪种策略选取分区。 首次适应算法 顾名思义，该算法的思想就是每次都从低地址开始查找，找到第一个能满足大小的空闲分区。实现方法就是空闲分区以地址递增的次序排列，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小满足要求的第一个空闲分区。如下图： 那么很明显5号进程会放在1号空闲分区，6号进程会放到2号分区。这种算法没有什么问题，但是缺陷是可能前面有一个非常大的空闲分区可以放入很多很小的进程数据，但是后面有刚刚好可以放进该进程的大小的空闲分区，这样大的空闲分区会优先被使用，最终造成许多小的空闲分区，再来大的进程就放不下了。同时会导致许多小的空闲分区在低地址处排列，每次分配查找还要再经过这些分区，增加了查找的开销。 最佳适应算法 算法思想是由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因为为了保证当大进程到来时也能有连续的大片空间，可以尽可能多地留下大片的空闲区，所以优先使用更小的空闲区，这样就弥补了首次适应算法的缺点。实现方法是空闲分区按容量递增次序链接，每次分配内存时顺序查找空闲分区链（或空闲分区表）找到大小能满足要求的第一个空闲分区也就是最小的可以容纳该进程的空闲分区（符合人类思维，尽可能不浪费的多放） 加入现在有一个进程6那么显然要放到2号分区这样2号分区就只剩下1MB了就要同时更新到表或链的最前面。我们发现这种方法的缺陷是每次都选更小的分区放最后只会导致很多外部碎片。 最坏适应算法 又称最大适应算法，就是为了解决最佳适应算法的问题而产生的，为了避免留下太多的外部碎片，优先使用最大的连续空闲区，这样分配后剩下的空闲区就不会太小，更方便使用。实现也很简单就是按照容量递减次序排列，每次分配也是顺序查找找到大小能满足要求的第一个空闲分区。 其实我们发现对于首次适应算法如果恰巧大的分区在前面，小的分区在后面，那么实际上就和最适应算法你一样了，所以最坏适应算法的缺陷就是大分区快速被消耗，再来大进程放不下了。 邻近适应算法 弥补首次适应算法的查找开销大的缺陷，这个算法思想是每次都从上次查找结束的位置开始向两侧检索就能解决上述问题，哪侧先找到大小合适的就放下该进程，所以是双向链表。 首次适应算法每次都要从头查找，每次都必须需要先检索低地址的小分区。但是这种规则决定了当低地址有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会有可能把高地址部分的大分区空闲出来，所以首次适应算法有可能会出现最坏适应算法的缺点即外部碎片多但同时也可能出现最佳适应算法的优点即合理利用空间。 而邻近适应算法的规则可能导致无论低地址，高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大小分区更可能被使用，划分为许多小分区，最后导致无大分区可用，所以综合四种算法来看，首次适应算法的效果反而更好。 思考：四种分配算法的异同？ 算法 算法思想 分区排列顺序 优点 缺点 首次适应 从头到尾找合适的分区 空闲分区以地址递增次序排列 综合性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排列 可能会出现低地址处许多非常小的空闲分区加大查找开销 最佳使用 优先使用更小的分区以保留更大的分区 空闲分区以容量递增次序排列 会有更多的大分区被保留下来，更能满足大进程的需求 会产生很多太小的、难以利用的碎片导致查找算法开销大，回收分区后可能需要对空闲分区队列重新排序 最坏适应 优先使用更大的分区，以防止产生太小的不可用的碎片 空闲分区以容量递减次序排列 可以减少难以利用的小碎片（外部碎片） 大分区容易被用完，不利于大进程，算法开销大（最后也会造成许多小分区导致查找开销大） 邻近适应 由首次适应算法演变而来，每次从上次查找结束为止开始查找 空闲分区以地址递增次序排列（可排列成循环链表） 不用每次都从低地址的小分区开始检索，算法开销小 会使高地址的大分区也被用完 基本分页存储管理的基本概念 我们先看一个图： 我们可以看出此节我们就开始讲解非连续分配管理方式了，这里只是一种一个小部分而已。非连续分配就是为用户进程分配的可以是一些分散的内存空间。 地址空间 我们先回忆一下什么是地址空间，我们知道地址分为两种逻辑地址（相对地址）和物理地址（绝对地址）两者有一定的映射关系。 但是我们发现这种存储只能连续存储，这很不方便，所以引出了分页存储的概念。 分页存储 我们将内存空间分为一个个大小相等的分区（比如每个分区为4KB），那么每个内存分区就是一个“页框”（页框=页帧=物理块=物理页面）。每个页框都有一个编号，即“页框号“（页框号=页帧号=内存块号=物理块号=物理页号），页框从0开始编号。 将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分称为一个“页”或“页面”。每个页面也有一个编号，即“页号”，页号也是从0开始。 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，可以放到不相邻的各个页框中。 注意进程的最后一个页面可能没有一个页框那么大，也就是说分页存储有可能产生内部碎片，因此页框不能设置的太大，否则可能产生过大的内部碎片造成浪费。 思考：固定分区分配（分区大小相等）和分页存储的区别？ 我们第一想法一定是这个和分区大小相等的固定分区分配好像，实际上思路就是差不多的，只不过是前者是一个小空间里放一个作业，所以作业/进程还是连续分配的，并且分区大小无论是多大都有可能会放不下更大的进程并且内部碎片会很大，而现在分页存储类似于将作业分块离散存储在许多的小分区中，所以作业/进程本身是不连续的且相应的无论作业/进程多大理论上都可以放下（只不过是会分成许多页面存储在许多页框中)并且内部碎片在一定的页框大小时是很小可控的。 思考：那么我们怎么知道每个页面存放在了内存的那个页框中呢？ 所以我们同样需要建表来说明–页表 页表 每个进程都会被分为许多页面存放在许多同样数量的页框中，所以每个进程都要有一张的页表，所以页面一般存放在PCB中，所以页表会一直在内存中（毕竟PCB是一直在内存中）直至该进程销毁。 所以一个进程对应一个页表，进程的每个页面对应一个页表项，每个页表项由“页号”和“块号”组成。页表记录着进程页面和实际存放的页框之间的映射关系。每个页表项的长度是相同的。 思考：每个页表项多大？占几个字节？ 首先我们要走出误区，表项的个数只是和页面页框数量一样，但是大小不同，页框大小和页表表项没有直接关系，我们先看一下两者的区别。页框是存储数据的单位，而页表表项是存储页框号和页面号的单位。所以页框大小是人为划分的，但是一旦内存大小和页框大小确定了，那么页表表项也就确定了。比如下题： 假设某个系统物理内存大小为4GB，页面大小是4KB，则每个页表项至少应该为多少字节？ 首先内存大小为4GB也就是2^32字节，页面大小实际上等于页框大小，所以页面页框的大小都是4KB=2^12字节，所以一共可以有2^32/2^12=2^20个页框(页面当然也就是2^20个），编号为0~2^20-1，所以一共会有2^20个页表项并且编号至少需要20bit来表示，又因为一个字节为8bit,多以至少需要3个字节来表示。所以一个页表项为3B，一个页框或页面为4KB。 并且页表项肯定是连续的，假设页表中的页表项从地址为X的地方开始连续存放，那么第i号页表项的地址就是X+3*i,同时第i个页面的存储地址就是第i号页表项中所对应的块号。并且我们发现页号是隐含的，所以页号不占用存储空间，一个页表项所占空间就是块号所占的空间，页号就好像数组的键值一样是隐含不占用空间的。 并且还要注意，块号记录的不是页框的起始地址，而只是页框号，又因为0号页框号的起始地址就是0，所以j号内存块的起始地址就是j*内存块大小。 思考：如何实现地址的转换？ 我们回忆一下在连续存储时，操作系统有三种策略实现地址转换（绝对装入，静态重定位，动态重定位)。现在是分页离散存储，我们如何找到逻辑地址所对应的物理地址呢？我们知道虽然各个页面是离散存放的，但是页面内部是连续存放的。 所以如果想要访问逻辑地址A需要以下步骤： 确定逻辑地址A对应的“页号”P 找到P号页面在内存中的起始地址（需要查页表找到内存块号j,起始地址就是j*内存块大小) 确定逻辑地址A的“页内偏移量”W 逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W 逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W 思考：如何确定逻辑地址对应的页号和页内偏移量？ 我们以一道例题来讲解：假设在某个计算机系统中，页面大小时50B，某进程逻辑地址空间大小为200B，则逻辑地址110对应的页号、页内偏移量是多少？ 页号=逻辑地址/页面长度（取除法的整数部分） 页内偏移量=逻辑地址%页面长度（取除法的余数部分） 所以上面的题页面号=110/50=2，页内偏移量=110%50=10，所以逻辑地址可以拆分为页号和页内偏移量来表示。接下来我们去页表中寻找页号2所对应的块号j,那么物理地址就是j*50+10。这里我们是用十进制表示的，但是我们知道对于计算机来说，他的操作都是二进制串进行操作，现在我们还是按照这个思路来看一下二进制的表示： 在计算机内部，地址用二进制表示，如果页面大小刚好是2的整数幂，则计算机硬件可以很快就把逻辑地址拆分成页号和页内偏移量，这样自然转换到物理地址也就更快了。如果是2的整数幂，那么假设每个页面的大小为2^K字节，那么用二进制表示逻辑地址时，逻辑地址01串的末尾K为就是页内偏移量，其余部分就是页号。如下： 我们可以看出页面大小为2^12B，所以末尾12位就是黑色部分就是页内偏移量，同时红色的20位就是页号了。 这样我们可以就轻松的对逻辑地址进行拆分转换成物理地址了。又因为内存块的大小=页面大小，且块的起始地址就是页内偏移量为0的地址，所以各个块的地址可以表示为： 同样对于物理地址，假设现在我们通过查询页表得到1号页面存放在了9（1001）号内存块，那么 我们发现前面红色部分就是9的二进制串即内存块号 思考：二进制串中物理地址和逻辑地址的异同点？ 我们仔细观察发现逻辑地址和物理地址的表示公式都是如下（前提：页面大小是2的整数幂）： 逻辑地址=页面号+页内偏移量逻辑地址=页面号+页内偏移量 逻辑地址=页面号+页内偏移量 物理地址=页框号+页内偏移量物理地址=页框号+页内偏移量 物理地址=页框号+页内偏移量 所以假设现在页面大小为4KB=2^12B=4096B。那么4097的页号就是1，页内偏移量为1，所以逻辑地址二进制串为 并且通过查表得知1号页面存放在9号页框，那么物理地址就是 总结：页面大小刚好是2的整数幂的好处就是 逻辑地址的拆分更加迅速–如果每个页面大小为2^KB，用二进制表示逻辑地址，则末尾K为就是页内偏移量，其余部分就是页号。因此，如果让每个页面的大小为2的整数幂，计算机硬件就可以很方便地得出一个逻辑地址对应的页号和页内偏移量，而无需进行除法操作，从而提升了运行速度。 物理地址的计算更加迅速–根据逻辑地址得到的页号，查询页表找到对应存放的页框号，将二进制表示的内存块号和页内偏移量拼接起来，就可以得到最终的物理地址。 逻辑地址结构 实际上通过上面的例题我们已经掌握了逻辑地址的结构和应用，这里再给出严格定义，分页存储管理的逻辑地址结构如下图： 地址结构包括两个部分：前一部分为页号P，后一部分为页内偏移量W。在上图所示的例子中，地址为32位，其中0~11号为“页内偏移量”，或称“页内地址”，12~31位为“页号”。 如果有K位表示“页内偏移量”，则说明该系统中一个页面的大小是2^K个内存单元。如果有M位表示“页号”，则说明在该系统中，一个进程最多允许有2^M个页面。所以页面大小&lt;–&gt;页内偏移量位数。 思考：页面大小一般设为什么数比较好？ 当然就是2的整数幂啦，因为这样地址转换快，这也是现代操作系统大多的做法。当然考研的题中有些奇葩题（为了考而考）会出现页面大小不是2的整数幂的情况，那就只能按照最原始的公式计算了页号=逻辑地址/页面长度（取除法的整数部分），页内偏移量=逻辑地址%页面长度（取除法的余数部分）。 思考：从上面的结构中我们能否看出一些页号和页内偏移量的规律？ 我们可以易知页号简介反映了页框的数量，页内偏移量简介反应了一个页框的大小。那么当一个页框很大时，页内偏移量也就大，K值也就大，那么所占的地址位数也就多，那么相应的页号所占位数32-K也就越小代表着此时页号就下了，也就说明页框数量变少了，其实这很正常，毕竟空间就那么大，一个存储单元变大了，相应的存储单元数量自然就少了。 总结"},{"title":"经典同步问题(2)","path":"/wiki/操作系统笔记/经典同步问题(2)/index.html","content":"吸烟者问题 问题描述 假设有一个系统有三个抽烟者进程和一个供应者进程，每个抽烟者不停地卷烟并抽掉他，但是要卷烟起并抽掉一只烟需要有三种材料：烟草，纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限的提供这三种材料但是每一次供应者只在桌子上放两种材料，而拥有剩余那种材料的抽烟者才能卷一根并抽掉他，并给供应者一个信号告诉完成了，此时供应者就会将另外两种材料放在桌子上一直重复使得三个抽烟者进程可以轮流的抽烟。 问题分析 我们分析一下题意不难发现这是一个生产者对应多个消费者的问题，并且特殊地是这个生产者可以生产多种产品，如上图： 生产者可以生产三种产品分别是： 纸+胶水 烟草+胶水 烟草+纸 而消费者各自有不同的产品需求分别对应消费生产者的三种产品同时这样看来实际上还是缓冲区只能容下一个产品，并且一次性只能有一个进程访问缓冲区，所以事件关系如下： 桌子上有组合1的产品-&gt;第一个抽烟者取走东西抽烟(同步关系) 桌子上有组合2的产品-&gt;第二个抽烟者取走东西抽烟(同步关系) 桌子上有组合3的产品-&gt;第三个抽烟者取走东西抽烟(同步关系) 抽烟者发出完成信号-&gt;供应者将下一种产品组合放到桌子上(同步关系) 各进程互斥访问临界资源–桌子(互斥关系) 思考：需要设置，互斥信号量吗？ 前面我们提到过对于一个临界资源并且每次都只有一个同步信号量为1的情况可以不设置互斥信号量，此问题也可以不设置互斥信号量。 代码如下： 首先声明信号量其次声明索引值i用来判断供应者该提供那种产品了 12345semaphore offer1=0;//桌子上组合1的数量semaphore offer2=0;//桌子上组合2的数量semaphore offer3=0;//桌子上组合3的数量semaphore finish=0;//抽烟是否完成int i=0;//用于实现&quot;三个抽烟者轮流抽烟&quot; 供应者代码： 123456789101112131415161718provider()&#123; while(1)&#123; if(i==0)&#123; //将组合1的产品放到桌子上 V(offer1); &#125; else if(i==1)&#123; //将组合2的产品放到桌子上 V(offer2); &#125; else if(i==2)&#123; //将组合3的产品放到桌子上 V(offer3); &#125; i=(i+1)%3; P(finish); &#125;&#125; 抽烟者代码： 思考：为什么这次供应者的P操作放到了后面？ 因为初始化时finishi为0，而桌子上一开始是没有组合产品的，所以供应者现需要进行一次产品放置，所以此时P操作放在了最后面实际上就等于放在了下一次循环的开头，如果初始化时finish为1那么P操作就应该放在最前面。并且对于这种可以生产多个产品的供应者一定注意V操作对应着不同事件下。 读者-写者问题 问题描述 有读者和写者两组并发进程，共享一个文件，当两个或两个以上的读进程用时访问共享数据时不会产生副作用，但若某个写进程和其他进程(读进程或者写进程)同时访问共享数据时则可能导致数据不一致的错误，因此要求： 允许多个读者进程同时对文件进行读操作 只允许一个写者往文件中写信息 任一一个写者在完成写操作之前不允许其他的读者或者写者工作 写者操作执行写操作之前需要保证已有的读者和写着进程全部已经退出共享文件 注意：这里和生产-消费者最大的不同是共享数据不会被取走所以共享资源不会减少甚至清空，因此多个读者可以同时访问共享数据。 问题分析 首先我们知道无论是写进程-写进程之间还是写进程-读进程之间都是互斥访问共享文件的。而读进程-读进程之间是不互斥的。所以我们首先肯定是需要设置一个互斥变量rw用来保证写-写，写-读之前互斥，同时为了记录此时正在有几个读进程执行我们设置一个参量count用来记录读进程个数，这样我们知道只有count==0时此时写进程才可以进行写操作，当count&gt;0时说明还有读操作进行，每次新加入一个读进程count就++，每次退出一个读进程count–，只有count==0时说明此时没有读进程才能进行写操作。所以我们的代码如下： 首先声明一个互斥信号量和一个记录参量： 12semaphore rw=1;//实现对共享文件的互斥访问int count=0;//记录当前有几个进程在访问文件 那么写进程代码： 1234567writer()&#123; while(1)&#123; P(rw);//写之前“加锁” write....//进入共享区域进行写操作 V(rw);//退出共享区域并“解锁” &#125;&#125; 一个读进程 12345678910111213reader()&#123; while(1)&#123; if(count==0)&#123;//如果是第一个读进程那么需要进行判断&quot;上锁&quot; P(rw);//&quot;上锁&quot; &#125; count++;//读进程个数加一 read....//进入共享区域进行读操作 count--;//读完，退出读进程个数减一 if(count==0)&#123;//如果是最后一个读进程那么退出前解锁 V(rw);//&quot;解锁&quot; &#125; &#125;&#125; 思考：为什么对于读进程只有count==0时进行PV操作？ 我们思考，rw实际上是一个用来使得写-写和写-读之间互斥的信号量，所以对于每一个写进程都需要进行P,V操作保证每次共享区域都只有自己一个写进程。而对于读者进程来说，如果他是第一个要进入共享区域的进程，那么他唯一需要做的就是保证此时共享区域里面没有写进程即可，即使里面已经有读进程了没关系因为他们之间不是互斥的。所以对于count!=的读进程来说他不需要进行P操作检验就可以直接进入共享区域因为此时说明共享区域里面有读进程且没有写进程，同理对于退出也是，只有自己是最后一个读进程退出时才需要解锁否则其他读进程直接退出即可。 思考：上面的代码有没有什么问题？ 我们想一下，如果此时已经有一个读进程进入共享文件区域了，那么毫无疑问rw=0已经上锁了，此时如果又来了一个读进程我们知道由于count!=0他是不用经过P操作检查就可以直接进入共享区域的，但是我们现在就想对这个后来的读进程进行P操作检查，那么肯定他是通不过的，所以对于第一个if语句的作用除了要做到让第一个读进程上锁同时还要做到避免让其他后来的读进程被P操作检查因为一旦检查他们都是不可能进入的，但是现在上面的if语句操作代码有bug做不到第二个作用。原因如下：我们考虑现在有两个读进程在并发执行此时count==0，好巧不巧第一个读进程刚刚通过if(count==0)的检验还没来得及进行P上锁时间片用完了切换到了第二个读进程他也恰巧刚刚通过if(count==0)的检验也要进行P操作，此时说明这两个读进程都要进行P操作检查此时第二个进程的时间片也用完了有切换到了第一个进程第一个进程此时rw=1可以进入他通过了P操作检查并将rw设置为了0，此时他又用完时间片了切换到进程2PCB状态信息记录着他也要经过P检查，但是此时rw=0!完了第二个度进程是进不去的他过不了P进程的检查所以就一直阻塞到本轮所有的读进程结束才能进入。此时很明显是有问题的，if语句没有做到后来的读进程不用P操作检查。同理对于第二个if操作也会有问题，仔细想想就知道会造成最后一个进程还没有离开共享资源区，倒数第二个离开的进程就已经解锁了，这也很致命，所以我们需要对两个If语句进行优化。 思考：如何优化两个if语句？ 分析易知此时会发生这种bug是因为此时的if判断语句和后面的操作语句不想P,V操作可以做到检查和操作一气呵成的原子性特点，所以我们需要借助P,V做到if语句判断和操作一气呵成，因此我们可以再设置一个互斥信号量来实现各读进程对count的访问是互斥的。所以优化后的代码如下： 我们需要再声明一个互斥信号量： 1semaphore mutex=1;//用于保证对count变量的互斥访问 读进程的代码： 1234567891011121314151617reader()&#123;\twhile(1)&#123; P(mutex);//对count访问上锁 if(count==0)&#123;//如果是第一个读进程那么需要进行判断&quot;上锁&quot; P(rw);//&quot;上锁&quot; &#125; count++;//访问的进程加一 V(mutex);//对count访问解锁 read... P(mutex);//对count访问上锁 count--;//对count访问解锁 if(count==0)&#123;//如果是最后一个读进程退出那么退出前需要解锁 V(rw);//“解锁” &#125; V(mutex);//对count访问解锁 &#125;&#125; 思考：上面的代码还有什么问题？ 我们再仔细想一想，貌似这种代码还是有一个缺陷，我们想每次中途都可以来新的读进程并且如果已知读进程个数不是0那么rw就一直不解锁，也就意味着只要有读进程正在读并且此时又来了新的读进程，那么写进程就得已知阻塞等到所有的读进程全部读完并且没有再来新的读进程，此时rw解锁后写进程才能继续写，这很容易就造成写进程饥饿（即已知有新的读进程源源不断的断断续续的来）。所以上面这种算法是读进程优先的，所以我们需要优化一下代码，即不允许读进程一直插队，当写进程正在等待前面的读进程时新来的读进程只能排在正在的写进程后面等待下一轮的读进程。所以事先代码如下，可能有点不太好理解： 首先还是需要声明信号量，此时还要在上面的基础上在新添加一个信号量w用于实现“写优先”如下： 这样上面加粗部分的就是新家的互斥信号锁，我们来分析以下为什么加上了这个信号量就避免了写进程饥饿。假设现在来了一个读进程R1，他将w上锁然后进行count++和rw上锁等功能，然后在解锁w,此时来了一个写进程W1，他可以通过w的P检验并上锁，此时他还不能通过rw的P操作，因为R1还没有解锁，此时W1在阻塞等待，此时又来了一个读进程R2如果按照上面原先的读者优先算法读进程可以立即进入共享区域执行读操作，但是此时他因为不能通过w的P操作（因为此时W1没有解w锁）所以R2也只能阻塞等待，当R1读完退出临界资源后将rw解锁此时W1可以进行写操作了，此时R2正在阻塞等待W1完成，只有当写进程完成并解锁w后R2才可以开始访问共享文件。我们发现从原来的R1-W1-&gt;R1-R2-W1变成了R1-W1-&gt;R1-W1-R2即读进程不能随意插队了也就是读写进程公平等待了避免了写进程饥饿的风险。 总结一下我们发现实际上上面这种算法并不是&quot;写优先&quot;算法，他只是做到了保证读进程和写进程公平排队而已。所以有的教材也把这种算法叫做&quot;读写公平法&quot;。 总结：各个信号量的作用？ 我们一定要理解上面的代码衍生过程这样才可以深刻记忆各个信号量之间的作用。 rw-保证写写，写读的互斥访问 metux-保证读进程互斥访问count w-保证读写公平排队 十分注意count不是信号量他只是一个记录读进程数量的参量。 哲学家进餐问题 问题描述 一张圆桌上面坐着5名哲学家，每两个哲学家之间的桌子上摆着一个筷子，桌子的中间是一碗米饭，哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人，只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根拿起）。如果筷子已经在他人手上时，则需要等待。解饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。 问题分析 从上面的描述中我们可以知道其实筷子就好像临界资源，每次都只允许一位哲学家进程访问，所以毋庸置疑这是互斥关系。5位哲学家与左右相邻对其中间的筷子是互斥访问的，但是这个不同于之前的生产者-消费者问题或者多生产者-多消费者问题亦或是吸烟者问题，此时一个进程需要同时访问两个临界资源。如何避免临界资源分配不当造成的死锁现象是哲学家问题的关键所在。 这里我们先设置互斥信号量，定义互斥信号量数组chopsticks[5]={1,1,1,1,1}（互斥信号量初始化为1）用于实现对5个筷子的互斥访问。并对哲学家按照0~4编号，同时哲学家i左边的筷子编号为i，右边的筷子编号为(i+1)%5。 思考：同时先左后右可取吗？ 即每一个哲学家都是先尝试拿左边的筷子然后在尝试拿到右边的筷子，如果拿不到就放下筷子。此时代码如下： 123456789101112semaphore chopsticks[5]=&#123;1,1,1,1,1&#125;;pi()&#123; while(1)&#123; P(chopsticks[i])//拿左 P(chopsticks[(i+1)%5])//拿右 eat... V(chopsticks[i])//放左 V(chopsticks[(i+1)%5])//放右 think... &#125;&#125; 很明显这种方法不妥当，会造成死锁最终谁也吃不上饭。因为当所有人都拿起左边的筷子时所有哲学家都不可能能拿到右边的筷子，所以所有哲学家最终都放下筷子重新再按照此方法尝试下去，最终谁也吃不上饭。这种循环等待右边的人放下筷子(阻塞)就是造成&quot;死锁&quot;的原因。 思考：加上某些条件可以避免死锁吗？ 可以我们尝试每次都只限制至多4名哲学家同时吃饭，这样就会由5双筷子4个人分，至少保证了有一名哲学家可以吃饭，不会在造成死锁现象。但是貌似效率太低，究其原因是虽然某些哲学家不能吃上饭但是还是会拿起一根筷子占为己有进行尝试。即某些进程明明已经不可能访问到临界资源了却还是占用了一部分临界资源。我们最好能够避免不能立刻执行的进程占用临界资源。 思考：加上某些条件可以避免进程占用不必要的临界资源？ 我们可以要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家正相反。这样可以保证当相邻的奇偶数号哲学家都想吃饭时，只会有一个哲学家获得第一个筷子，而另一名哲学家连第一个临街资源都没有获得就阻塞了，这样就避免了占有一支后再等待另一支的情况了。 思考：还有没有其他方法？ 归根结底上面的方法都是在还没能确保能获得全部临界资源时就拿起了部分临界资源然后再尝试获取另一部分临界资源，这样就可能会造成大家都拿到了一部分临界资源然后等待。所以我们可以规定只有进程一次性可以获得全部临界资源才执行即仅当一个哲学家左右两支筷子都可以使用时才允许他抓起来。这种方法貌似最合适代码如下： 123456789101112131415semaphore chopsticks[5]=&#123;1,1,1,1,1&#125;;semaphore mutex=1;//互斥的拿筷子pi()&#123; while(1)&#123; P(mutex); P(chopsticks[i])//拿左 P(chopsticks[(i+1)%5])//拿右 V(mutex); eat... V(chopsticks[i])//放左 V(chopsticks[(i+1)%5])//放右 think... &#125;&#125; 我们对比之前的发现只是在取筷子时加上了互斥锁，这样各个哲学家拿筷子这件事必须是互斥进行的，这样就保证了即使一个哲学家在拿筷子时如果拿到一半被阻塞了，也不会有别的哲学家会继续尝试拿筷子，这样的话，当前正在吃饭的哲学家放下筷子后，被阻塞的哲学家就可以获得等待的筷子了。我们发现这种方法虽然可以避免死锁，但是貌似和上面的思路不太一样，实际上他并没有真正的实现满足有两个筷子的哲学家尝试吃饭，而是保证了每次都只允许一名哲学家尝试拿筷子，如果他能一次性拿齐两双就吃饭如果拿不齐就阻塞等待，并且在他等待期间其他哲学家也禁止尝试拿筷子，必须等到这个阻塞的哲学家能够拿齐筷子吃饭后其他哲学家才可以尝试。这样的方法可以至少保证有一个哲学家能够进餐同时最好情况还可以有两名哲学家同时进餐。 思考：上面的方法有没有什么瑕疵？ 我们发现上面这种方法并不能保证只有两边的筷子都可用湿才允许哲学家拿起筷子。例如： 此时1号哲学家已经尝试拿齐了右边筷子(2号筷子)，但是由于0号此时在吃饭所以1号筷子不能拿齐，所以此时1号哲学家不拿起筷子进入阻塞等待，而此时虽然2号哲学家可以同时拿齐2,3号筷子，但是由于mutex此时在1号筷子处为1，其他哲学家此时都不能拿筷子，所以2号哲学家此时虽然可以同时拿齐两双筷子但是却没有资格去尝试拿，而1号哲学家虽然不能用时拿齐两双筷子但是他却可以等待0号进程吃完然后拿齐1,2号筷子吃饭。 思考：三种方法哪种更好? 对于上面所说的三种方法： 每次最多允许4名哲学家拿筷子 奇偶号哲学家反方向拿筷子 互斥锁保证每次一个哲学家拿筷子(两个筷子都能拿才有资格拿筷子) 实际上没有好坏之分，都是最好情况为同时2名哲学家进餐，对于多个进程访问临界资源并且一个进程需要同时访问两个临界资源的变式题参考哲学家问题。 各种问题总结 问题类型 生产者-消费者问题：一个临界资源，两个进程互斥访问，互斥+同步关系 多生产者-多消费者问题：一个临界资源，多个进程互斥访问，互斥+同步关系 吸烟者问题：一个临界资源，一个生产者-多个消费者问题，互斥+同步关系 读者-写者问题:一个临界资源，部分进程互斥访问，互斥+同步关系同时有优先级问题 哲学家进餐问题：多个临界资源，进程需要两个临界资源，纯互斥关系"},{"title":"磁盘","path":"/wiki/操作系统笔记/磁盘/index.html","content":"磁盘调度算法 显然对于一个磁盘数据的读/写序列（中途可能会更新）使用不同的调度算法会产生不同的效率，这里我们也探讨一下几种不同算法的性能，那么指标肯定就是时间了所以我们先介绍几个指标概念然后介绍调度算法。 一次磁盘读/写操作需要的时间 寻道时间Ts 寻道时间Ts：又称为寻找时间，在读/写操作之前，将磁头移动到指定磁道所花费的时间。 启动磁头臂是需要时间的。假设耗时为s。 移动磁头也是需要时间的，假设磁头均匀移动，每跨越一个磁道耗时为m，总共需要跨越n条磁道，则： Ts=s+m∗nT_s=s+m*n Ts​=s+m∗n 现在的硬盘移动一个磁道大约需要0.2ms,磁臂启动时间约为2ms。 延迟时间Tn 延迟时间Tn:通过旋转磁盘，使磁头定位到目标扇区所需要的时间。设磁盘转速为r(单位:转/s，转/min)，那么平均所要的延迟时间为 Tn=(1/2)∗(1/r)=1/2rT_n=(1/2)*(1/r)=1/2r Tn​=(1/2)∗(1/r)=1/2r 1/r就是转一圈所需要的时间，找到目标扇区平均需要转半圈，因此再乘1/2，硬盘的典型转速为5400转/min，或者7200转/min。 传输时间Tt 传输时间Tt:从磁盘读出或向磁盘写入数据所经历的时间，假设磁盘转速为r，此次读/写的字节数为b，每个磁道上的字节数为N，则： Tt=(1/r)∗(b/N)=b/rNT_t=(1/r)*(b/N)=b/rN Tt​=(1/r)∗(b/N)=b/rN 每个磁道可存N字节的数据，因此b字节的数据需要b/N个磁道才能存储，而读/写一个磁道所需要的时间刚好又是一圈所需要的时间1/r。 总的平均时间Ta Ta=Ts+Tn+Tt=s+m*n+1/2r+b/rN 延迟时间Tn和传输时间Tt都与磁盘的转速有关，且为线性关系，而转速是硬件的固有属性，因此操作系统无法优化延迟时间和传输时间。 先来先服务算法（FCFS) 根据进程请求访问磁盘的先后顺序进行调度。例如：假设磁头的初始位置为100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道，那么按照FCFS的规则，按照请求的顺序，磁头需要一次移动到55、58、39、18、90、160、150、38、184号磁道。 磁头一共移动了45+3+19+21+72+70+10+112+146=498个磁道。响应一个请求平均需要移动489/9=55.3个磁道。（平均寻找长度）。 优点：公平，如果请求访问的磁道比较集中的话，算法还可以。 缺点：如果有大量进程竞争使用磁盘，请求访问的磁道很分散，那么FCFS在性能上很差，寻到时间长。 最短寻找时间优先（SSTF） SSTF算法优先处理的是离当前磁头最近的磁道，可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短。其实就是贪心思想，贪心解未必是最优解。 例如：假设磁头的初始位置为100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道： 磁头总共移动了(100-18)+(184-18)=248个磁道，响应一个请求平均移动248/9=27.5个磁道（平均寻道长度） 优点：性能好，平均寻道时间短 缺点：可能产生饥饿现象 扫描算法（SCAN） SSTF产生饥饿的原因是磁头有可能会在一个小区域内来回的移动，为了防止这个问题，可以规定，只有磁头移动到最外侧的磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。这就是扫描算法（SCAN）的思想。由于磁头移动方式很像电梯，因此也叫电梯算法。 假设某磁道为0~200号，磁头的初始位置是100号，此时磁头正在往磁道号增大的方向移动，那么此时有多个进程的请求访问：55、58、39、18、90、160、150、38、184号磁道。 一定要注意必须移动到磁道最边缘处才可以更改移动方向即使没有请求访问最边缘磁道也要经过。 磁头总共移动了（200-100）+（200-18）=282个磁道，响应一个请求平均需要282/9=31.3个磁道（平均寻道长度）。 优点：性能好，平均寻道时间短，不会产生饥饿现象 缺点：①只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求之后就不需要再往右移动磁头了。②SCAN算法对于各个位置磁道的响应频率不均匀（如：假设此时磁头正在向右移动，且刚处理过90号磁道，那么下次处理90号磁道的请求就需要等磁头移动很长一段距离，而相应了184号磁道的请求之后，很快又可以再次相应184号磁道的请求了） LOOK调度算法 扫描算法（SCAN）：只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求之后就不需要再往右移动磁头了。LOOK算法就是为了解决这个问题，如果在磁头移动方向上没有别的请求，就可以立即改变磁头移动方向。（边移动边观察，因此叫LOOK） 假设某磁道的磁盘为0~200号，磁头的初始位置为100号磁道，且此时磁头正在往磁道号增大的方向移动，有多个进程先后陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 那么响应一个请求平均寻道长度为250/9=27.5磁道 优点：比起SCAN算法来，不需要每次都移动到最外侧或最内侧时才改变磁头方向，使寻道时间进一步缩短。 缺点：只解决了SCAN算法的缺点1，响应频率还是不均匀。 循环扫描算法（C-SCAN） SCAN算法对于各个位置磁道的响应频率不平均，而C-SCAN就是解决了这个问题。规定只有磁头向右移动或者向左移动时才可以处理磁道访问请求，而返回时直接快速移动到起始端中间返回过程不做任何请求任务。 假设某磁盘的磁道为0~200号，磁头的初始位置为100号磁道，且此时磁头正在向磁道号增大的方向移动，那么有多个进程陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 优点：比起SCAN算法，对于各个位置的响应频率很平均 缺点：只解决了SCAN算法的缺点2，但是还是只有到达最边缘的磁道才可以返回到起始端。 C-LOOK调度算法 C-SCAN算法的主要缺点是只有到达最边缘的磁道才可以返回到起始端，但是我们也可以模仿LOOK算法边移动边观察，当后面没有更大的请求磁道号时就不用再移动到最边缘了，直接返回到起始端节省开销。 假设某磁盘的磁道为0~200号，磁头的初始位置为100号磁道，且此时磁头正在向磁道号增大的方向移动，那么有多个进程陆续的请求访问55、58、39、18、90、160、150、38、184号磁道。 优点：比起C-SCAN算法来，不需要每次移动到最外侧或者最内侧才改变刺头方向，同时响应频率也很均匀。 缺点：也不算是缺点，就是没必要，因为边移动边观察看似节省开销了实际上实现起来开销也不必C-SCAN小多少。 总结 减少延迟时间的方法 我们知道延迟时间就是磁头等待到目标扇区的时间，那么磁盘扇区的不同排列方式也会对延迟时间造成影响。 如果排列如下： 那么假设现在要连续读取橙色区域的2,3,4区域，那么磁头读取一块的内容（也就是一个扇区的内容后）需要一小段的处理时间，而此时盘片还在不停地旋转。因此如果2,3号扇区相邻着排列，则读完2号扇区后无法连续不断的读入3号扇区。必须等待盘片继续旋转，3号扇区再次滑过磁头，才可以完成扇区读入。所以我们可以得到如下结论：磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，那么读入几个连续的逻辑扇区，可能需要很长的延迟时间。 减少延迟的方法：交替编号 很明显，此时采用交替编号后，逻辑相邻的磁盘块物理结构上并不是相邻的，这样可以使读取连续的逻辑扇区所需要的延迟时间更小。 磁盘结构的设计 我们思考一个问题，为什么在设计磁盘的物理地址时使用的表示方法为（柱面号，盘面号，扇区号）而不是（盘面号，柱面号，扇区号）？这里的原因如下： 假设现在某个磁盘有8个柱面即8个磁道（且最内侧磁道编号为0），4个盘面，8个扇区。那么可以用3个二进制位表示柱面，2个二进制位表示盘面，3个二进制位表示扇区。 那么如果物理地址是（盘面号，柱面号，扇区号）来表示，那么如果现在需要连续读入物理地址（00,000,000）~（00,001,111）的扇区。那么（00,000，000）~（00,000,111）转两圈即可读完，之后在读取物理地址相邻的区域即（00,001,000）~（00,001,111）的时候需要启动磁头臂，将磁头移动到下一个磁道。 而如果是物理地址结构为（柱面号，盘面号，扇区号），且需要连续读入物理地址为（000,00,000）~（000,01,111）的扇区时，由于都在柱面为000的位置，所以不需要移动磁臂，只是在读入(000,01,000)~(000,01,111)时需要激活1号盘面的磁头即可。所以如果是（盘面，柱面，扇区）这种物理地址结构读入连续的物理地址时也需要不断的移动磁头，但是如果是（柱面，盘面，扇区）时就只需要激活不同盘面的磁头即可，无需移动磁臂，这样可以减少磁头移动消耗的时间。 减少延迟的方法：错位命名 如果按照上面这样命名，即不同盘面的相对位置处编号相同，那么假设要连续读入物理地址为(000,00,000)~(000,01,111)时当读取完磁盘块（000,00,111）之后需要短暂的时间处理，而盘面又在不停地旋转，那么当（000,01,000）第一次滑过1号盘面的磁头下方时，并不能读取数据，只能再等扇区再次滑过磁头。所以我们可以错位命名如下： 即此时的两个盘面相对位置处的编号都有错位。那么就可以做到当读取完磁盘块（000,00,111）之后，还有一段时间处理，当（000,01,000）第一次滑过1号盘面的磁头下方时，就可以直接读取数据了，从而减少了延迟时间。 思考：交替编号和错位命名的区别？ 首先交替编号和错位命名是两种策略，他们相互配合减少了磁盘读/写的时间开销。交替编号是针对某一个盘面的编号来说的，使得每一个盘面的编号的交替的。而错位命名是针对的不同盘面之间编号的，使得每一个盘面编号相同的扇区在不同的相对位置，使得切换盘面有一定的时间缓冲可以立刻读取下一个相邻的物理地址。 总结 磁盘的管理 磁盘初始化 分为如下几个步骤： 进行低级格式化（物理格式化），将磁盘的各个磁道划分为扇区。一个扇区通常可分为头、数据区域（如512B大小）、尾三个部分组成。管理扇区包括各种数据结构一般存放在头、尾两个部分，包括扇区校验码（如奇偶校验码，CRC循环冗长验证码等，校验码用于校验扇区中的数据是否发生错误） 将磁盘分区，每个分区由若干柱面组成（即分为C,D,E盘等） 我们可以看出越靠近里面的盘数据密度也就越大。 进行逻辑格式化，创建文件系统。包括创建文件系统的根目录，初始化存储空间管理所用的数据结构（如位示图法、空闲分区表等） 引导块 计算机在开机时需要进行一系列初始化工作，这些初始化工作通过执行初始化程序（自举程序）完成的。 初始化程序可以放在ROM中（只读存储器）中，ROM中的数据在出厂时就写入了，并且以后就不可以修改了（ROM一般是出厂时就集成在主板上）。 思考：自举程序放在ROM中存在什么问题？ 我们发现当需要更新自举程序时就会很不方便，因为ROM中的数据结构无法更改。所以我们需要解决此问题。 我们可以考虑不将自举程序放入ROM，而是在ROM中存放很小的“自举装入程序”，开机时计算机先运行“自举装入程序”，通过执行该程序就可以找到引导块，并将完整的“自举程序”读入内存，完成初始化。而完整的自举程序放在了磁盘的启动块（即引导块/启动分区）上，启动块位于磁盘的固定位置。拥有启动分区的磁盘称为启动磁盘或系统磁盘（一般我们的计算机中都是C盘）。 坏块的管理 对于简单的磁盘，可以在逻辑格式化时（建立文件系统时）对整个磁盘进行坏块检查，标明那些是坏扇区比如在FAT表上标明（在这种方式中，坏块对操作系统不透明）。对于复杂的磁盘，磁盘控制器（磁盘设备内部的一个硬件部位）会维持一个坏块链表。在磁盘出厂前进行低级格式化（物理格式化）时就将坏块链进行初始化。当然也可以保留一些备用扇区用于替换坏块。这种方案称为扇区备用，且这种处理方式中，坏块对操作系统透明。我们这里介绍几种策略： RAID0 RAID0又称为Stripe或者Striping,他代表着所有RAID级别中最高性能的存储性能。RAID0的原理就是把连续的数据分散到多个磁盘上存取，这样当系统有数据请求时就可以多个磁盘并行的执行，每一个磁盘运行属于它自己的那部分数据请求。这种并行操作请求的方法显著提高了存储性能。并且磁盘的读/写操作也会提高，假设RAID0将某一个请求分成了三个部分，那么每个磁盘只运行自己的那部分任务，那么理论上运行速度会提升为原来的3倍，但是由于总线带宽等影响，会低于理论值，但是也明显提升了速度。 虽然优点显著：读写，存储性能极高，但是缺点是不提供数据冗余，一旦用户数据损坏，损坏的数据将不能再恢复。所以RAID0中只要有一个硬盘损坏，整个RAID0设备都不能使用，所以可维护性极差。 磁盘空间使用率：100%，故成本最低。 读性能：N*单块磁盘的读性能 写性能：N*单块磁盘的写性能 冗余：无，任何一块磁盘损坏都将导致数据不可用 RAID1 其实就是镜像备份了，这样就实现了数据冗余，在成对的独立磁盘上产生互相备份的数据。当原始数据繁忙时，可以镜像拷贝读取数据，所以读取性能提高了。并且由于每一个盘都有镜像备份，所以磁盘阵列中单位成本很高。但是也提供了数据的安全性和可用性，当一个磁盘损坏失效，系统可以快速切换到备份的镜像磁盘上读写，不会立刻停止工作。当然两个都损坏了也是无法工作的，但概率太小。所以RAID1中总是有一个保持完整数据的备份盘，可靠性更好。 细节：读写数据的区别？ 一定要注意RAID1中读只能在一个磁盘上进行，即要不在DRIVE1BlockX读，要不在DRIVE2BlockX读,只是在DRIVE1BlockX忙碌时暂时无法提供读数据的时候，DRIVE2BlockX可以替DRIVE1BlockX提供读，但是总体上看只能一个盘提供，所以读的时候是不能并行执行的。而写磁盘的时候可以并行的对两个磁盘进行写，毕竟他们的数据应该是一样的（备份盘和原盘数据必须一致），但是虽然是并行写操作，但是因为要比较硬盘中的数据，所以写数据性能还是比单块磁盘慢。 磁盘空间使用率：50%，故成本最高。 读性能：只能在一个磁盘上读取，取决于磁盘中较快的那块盘 写性能：两块磁盘都要写入，虽然是并行写入，但因为要比对，故性能单块磁盘慢 冗余：只要系统中任何一对镜像盘中有一块磁盘可以使用，甚至可以在一半数量的硬盘出现问题时系统都可以正常运行 RAID10 其实可以看出特点，就是RAID1和RAID0的组合，对于整体来看组合是RAID0而局部看来每一个不分都是RAID1这样的好处是，整体上的读写性能很好，并且也不容易损坏因为每一个部分都有备份盘即使损坏了也可以立刻用备份盘替换。 磁盘空间利用率：50% 读性能：N/2*单块硬盘的读性能 写性能：N/2*单块硬盘的写性能 冗余：只要一对镜像盘中有一块磁盘可以使用就没问题 思考：为什么不是RAID01组合？ 即整体看来是RAID1，而局部看来每个部分都是RAID0我们发现整体看性能写很慢，读还可以，但是只要有2个局部损坏任意一个分盘都是整体都不能在使用了，性能一般且成本昂贵不易于维护😅。所以这个组合不适用。 RAID5 RAID 5是RAID 0和RAID 1的折中方案。RAID 5具有和RAID0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID5的磁盘空间利用率要比RAID 1高，存储成本相对较低，是目前运用较多的一种解决方案。当然我们发现每一组类型的盘都有一个备份盘随时准备顶替损坏的磁盘工作，并且备份盘每一个都分布在不同的disk上，而相应的有备份盘的disk就么有哪一种类的工作原盘。这样既便于维护整体性能也还不错，当有一个盘损坏时也可以继续工作，当然仅限于坏掉一个，当再坏掉一个或者备份盘先坏掉此时又有盘坏掉时也是会停止工作的。 磁盘空间利用率：(N-1)/N，即只浪费一块磁盘用于奇偶校验 读性能：(n-1)*单块磁盘的读性能，接近RAID0的读性能。 写性能：比单块磁盘的写性能要差 冗余：只允许一块磁盘损坏 以上内容来自大佬博客 总结"},{"title":"管程与死锁","path":"/wiki/操作系统笔记/管程与死锁/index.html","content":"管程 这部分仅是了解内容，当做拓展就好 为什么引入管程 在提出信号量后我们确实可以借用信号量+PV操作实现进程互斥关系但是我们发现这对编程人员极其不友好，编写程序困难，易出错。如下图： 我们知道这种P操作顺序错误会造成死锁，但是在编程中我们确实需要时刻注意P,V操作的顺序，这非常困难，所以能不能设计一个机制，让程序猿写程序时不需要关心复杂的PV操作，让写代码更轻松呢？可以，1973年，Brinch Hanson首次在程序设计语言（Pascal)中引入了&quot;管程&quot;的概念–一种高级同步机制，自此我们不需要在关心复杂P,V操作了，而是由编译器负责实现各进程的互斥进入管程操作。 管程的定义和基本特征 管程实际上就是一种特殊地软件模块，由这些部分组成： 局部于管程的共享数据结构说明 对该数据结构进行操作的一组过程(实际上就是函数) 对局部于管程的共享数据设置初始值的语句 管程有一个名字 管程的基本特征： 局部于管程的数据只能被局部于管程的过程(就是函数)所访问 一个进程只有通过调用管程内的过程(实际上就是函数)才能进入管程访问共享数据 每次仅允许一个进程在管程内执行某个内部过程(就是函数) 所以我们知道管程有自己的内部局部变量和函数以及一个管程名字，管程一次性只允许一个进程执行管程内函数并且管程内的数据只能被局部于管程的函数访问这样就实现了进程之间的互斥，即管程的函数封装了具体的操作，并且凭借每次只有一个进程能够调用管程函数来修改管程内的数据(实际就是信号量)。这样我们就不需要经常关注PV操作了。 如下是一个应用： 用管程解决生产者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//定义管程数据结构为ProducerConsumermonitor ProducerConsumer //管程内数据实际上就是信号量 //解决同步问题 condition full,empty;\tint count=0;//缓冲区内产品数\t//第一个管程内部函数\t//把产品放入到缓冲区\tvoid insert(Item item)&#123; if(count==N)//缓冲区已满 wait(full)//阻塞等待 count++;//否则产品数加一 insert_item(item);//缓冲区放进一个产品 if(count==1) //此时缓冲区不空了唤醒wait(empty) signal(empty) &#125;\t//第二个管程内函数\t//从缓冲区取产品\tItem remove()&#123; //缓冲区是空的 if(count==0) wait(empty)//阻塞等待 count--;//否则产品数减一 if(count==N-1) //此时缓冲区不满了唤醒wait(full) signal(full); return remove_item();//取出产品 &#125;end monitor;//结束管程定义//生产者进程producer()&#123; while(1)&#123; item=生产一个产品; //调用管程函数进行放入产品操作 ProducerConsumer.insert(item); &#125;&#125;//消费者进程consumer()&#123; while(1)&#123; //调用管程函数进行取出产品操作 ProducerConsumer.remove(); //消费产品item &#125;&#125; 我们发现管程只是保证每次都只有一个进程进行操作的互斥关系，具体的同步关系还是需要我们在管程内自己实现代码逻辑，并且这种封装管程内函数然后暴露给其他进程调用来操作内部数据的方式就是典型的“封装”思想。 引入管程的目的无非就是要更方便的实现进程互斥和同步。所以原理如下： 需要在管程中定义共享数据(如生产者-消费者问题中的缓冲区) 需要在管程中定义用于访问这些共享数据的&quot;入口&quot;–其实就是一些封装函数(如生产者-消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品) 只有通过这些特定的&quot;入口&quot;才能访问共享数据 管程中有很多&quot;入口&quot;，但是每次只能开放一个&quot;入口&quot;，并且只能让一个进程或线程进入(如生产者-消费者问题中，各进程需要互斥的访问共享缓冲区，管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。注意：这种互斥特性是由编译器负责实现的，程序猿不用关心，但是互斥关系还是需要程序猿自己实现) 可在管程中设置条件变量(实际上就是信号量)+等待/唤醒操作以解决同步问题，可以让一个进程或者线程在条件变量上等待(此时，该进程应先释放管程的使用权，也就是让出&quot;入口&quot;)，可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。 程序猿可以用某种特殊的语法定义一个管程（比如：monitor ProducerConsumer…end monitor)之后其他程序猿就可以使用这个管程提供的特定&quot;入口&quot;很方便的使用实现进程同步/互斥了。 JAVA中类似于管程的机制 JAVA中，如果使用synchronized来描述一个函数，那么这个函数同一时间段内只能被一个线程调用。 如下： 12345678static class monitor&#123; private Item buffer[]=new Item[N]; private int count=0; public synchronized void insert(Item item)&#123; .... &#125;&#125; 如上每次都只允许一个线程进入insert函数，如果多个线程同时调用insert函数则后来者需要排队等待。 总结 死锁 什么是死锁 其实我们在前面已经不止一次提到“死锁”的概念了，例如刚刚讲到的哲学家问题中同时都先拿左筷子再拿右筷子就会导致死锁现象出现。这里每个人都占有一个资源同时又在等待另一个人手里的资源的情况就是“死锁”这里我们给出严格的定义：在并发环境下，各种进程因争夺资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是&quot;死锁&quot;。发生死锁后若无外力干涉，这些进程都将无法向前推进。 思考：死锁，饥饿，死循环有什么区别？ 死锁：各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。比如：SPF算法中，若有源源不断的短进程到来，则长进程一直得不到处理机，从而发生长进程“饥饿”。 死循环：某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序猿故意设计的（比如while(1)）。 共同点 区别 死锁 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 死锁一定是“循环等待对方手里的资源”而导致的，因此如果有死锁现象，那么至少有两个或两个以上的进程同时发生死锁。另外，发生死锁的进程一定处于阻塞态。 饥饿 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 可能只有一个进程发生饥饿，发生饥饿的进程既可能是阻塞态（如长期得不到需要的I/O设备），也可能是就绪态（长期得不到处理机）。 死循环 都是进程无法顺利向前推进的现象（故意设计的死循环除外） 可能只有一个进程发生死循环，死循环的进程可以上处理机运行（可以是运行态），只不过无法像期待的那样顺利推进，思索和饥饿问题是由于操作系统分配资源的策略不合理导致的，而死循环是由代码逻辑的错误导致的。死锁和饥饿是管理者（操作系统）的问题，死循环是被管理者的问题。 死锁产生的必要条件 产生死锁必须同时满足以下四个条件，只要其中任意一个条件不成立，死锁就不会发生。 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家问题的筷子，打印机等I/O设备）。像内存，扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）。 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源的请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。 所以我们完全可以参照哲学家问题的死锁情况推出这四个条件，并且还可以知道发生死锁时一定是有循环等待，但是发生循环等待时未必死锁（循环等待是死锁的必要不充分条件）。当然如果同类资源数大于1，则即使有循环等待，也未必发生死锁，但如果系统中每类资源都只有一个，那循环等待就是死锁的充要条件了。 什么时候发生死锁 对系统资源的竞争，各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源(cpu)的竞争是不会引起死锁的。 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如：并发执行的进程P1，P2分别申请占有了资源R1,R2，之后进程P1有紧接着申请资源R2，而进程P2又申请资源R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁。 信号量的使用不当也会造成死锁，如生产者-消费者问题中实现互斥的P操作在实现同步操作P之前，就有可能会发生死锁。（我们可以把互斥信号量和同步信号量也看做是一种抽象的系统资源） 总之对不可剥夺的资源的不合理分配就可能会导致死锁。 死锁的处理策略 预防死锁。破坏死锁产生的四个必要条件中的一个或多个 避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁（银行家算法） 死锁的检测和接触、允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后才去某种措施解除死锁。 前面的两种方法都是不允许死锁发生，最后一种是允许死锁发生。 总结 死锁的处理策略 那么接下来我们就逐一讲解一下死锁处理的三条策略。 预防死锁 破坏互斥条件 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁 如果我们把只能互斥使用的资源改造为允许共享使用，那么系统就不会再进入死锁状态了，比如：SPOOLing技术。操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备，比如用SPOOLing技术将打印机改造成共享设备。 这个策略的缺点是并不是所有的资源都可以改造成共享使用的设备，并且为了系统的安全，很多地方还必须保护这种互斥性，因此很多时候无法破坏互斥条件。 破坏不剥夺条件 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 我们可以采用以下两种方案破坏不剥夺条件 方案1：当某个进程请求新的资源得不到满足时，他必须立即释放保持所有的资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。 方案2：当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用） 这种策略的缺点是： 实现起来复杂无论是方案1还是方案2 释放已获得的资源可能会造成前一阶段的工作的失效，因此这种方法一般适用于易保存和恢复状态的资源，如cpu。（有PCB记录信息的好处） 反复地申请和释放资源会增加系统开销，降低系统吞吐量。 如果采用方案1，意味着只要暂时得不到某个资源，之前获得的那些资源都要放弃，以后再重新申请，如果一直放生这样的情况，就会导致进程饥饿。 破坏请求和保持条件 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 可以采用静态分配方法，即进程在运行前一次申请完他所需要的全部资源，在它的资源未满足之前，不让他投入运行，一旦投入运行，这个资源就一直归他所有，该进程就不会再请求别的任何资源了。 该策略实现起来简单，但也有明显的缺点：有些资源可能只需要很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，资源利用率低，另外该策略也会导致某些进程饥饿。 破坏循环等待条件 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。 我们可以采用顺序资源分配法，首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完。 思考：什么原理破坏了循环等待条件？ 一个进程只有已经占有小编号的资源时，才有资格申请更大编号的资源，按照此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而就破坏了循环等待链也就不会再出现循环等待的现象了。 我们假设现在有10个资源，编号1~10。 该策略的缺点： 不方便增加新的设备，因为可能需要重新分配所有的编号 进程实际使用资源的顺序可能和编号递增顺序不一致，可能会导致资源浪费 必须按照规定次序申请资源，用户编程麻烦 总结 避免死锁 避免死锁就是利用银行家算法避免系统处于不安全状态，那么首先我们先了解一下一个定义 安全序列，不安全序列，安全状态，不安全状态 我们以一个投资的例子来分析介绍，假设你是一位成功的银行家，手里拥有100亿资金，有三个企业借贷，分别是B,A,T三个公司： B表示最多会借70亿 A表示最多会借40亿 T表示最多会借50亿 然而有个不成文规定，如果你借给企业的钱总数达不到企业提出的最大要求那么值钱借给企业的钱就都拿不回来了。刚开始B,A,T三个企业分别借了20,10,30亿，如下： 此时我们手里还剩下40亿，此时A又提出要借款20亿，那么我们能否借给A呢？ 思考：如果借给A会有三家公司的钱都要不回来的风险吗？ 我们思考，此时借给A20亿，如下: 那么此时我们手中还剩下20亿，此时如果按照T-&gt;B-&gt;A或者A-&gt;T-&gt;B的顺序追债是可以把之前借的钱都要回来的，所以此时没有三家公司的钱都要不回来的风险，所以此时是安全的，我们可以借给A20亿。 思考：能否举出一个三家公司的钱都要不回来的情况吗？ 很简单，假设此时我们手上还有40亿，此时B也要借钱借30亿，那么此时如果我们借出去，如下图： 那么此时我们手中还剩下10亿，我们发现此时就不安全了，因为三家公司的钱我们都要不回来了。所以此时就是不安全的，我们不能再借给B30亿了。 根据上面的例子我们知道所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成，只要能找出一个安全序列，系统就是安全的，当然安全序列可能有多个。 如果分配了资源之后，系统找不出任何一个安全序列，系统就进入了不安全状态，这也就意味着之后可能所有进程都无法顺利的执行下去了，当然如果有进程提前归还了一些资源（比如A先归还了10亿，那么手里有20亿按照T-&gt;B-&gt;A），那么系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。 如果系统处于安全状态，就一定不会发生死锁。如果系统进入了不安全状态也未必就一定发生死锁，只是有死锁的风险，但是如果死锁了那么一定是在不安全状态下发生的。因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求，这也是“银行家算法”的核心思想。 银行家算法 银行家算法是荷兰学者Dijkstra为银行设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。后来这种算法被用在操作系统中用于避免死锁。 核心思想和刚刚的借贷案例相同就是在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态，如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。 思考：对于多种资源的情况，如何实现银行家算法？ 我们思考在BAT借贷的例子中只有一种类型的资源–钱，但是在实际的计算机系统中会有多种多样的资源，应该怎么把算法拓展为多种资源的情况呢？这里我们可以把单维的数字拓展为多维的向量，比如：系统中有5个进程P0~P4，3中资源R0~R2，初始数量为(10,5,7)，则某一时刻的情况可用下表方式表示： 对于上面的例子我们分析一下能否安全。首先第一次分配后剩余的资源数如下表： 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P1 (3,2,2) (2,0,0) (1,2,2) P2 (9,0,2) (3,0,2) (6,0,0) P3 (2,2,2) (2,1,1) (0,1,1) P4 (4,3,3) (0,0,2) (4,3,1) 此时我们还剩下（3,3,2）的资源在手里，那么此时系统是否处于安全状态？ 我们先检查（3,3,2）此时可以满足那些进程的需求，很明显现在满足P1,P3： 假设我们先把P1收回，此时应该是按照下面的公式更新已有资源 if(已有的资源&gt;最多还会需求)then{已有资源=已有资源+已分配资源}if(已有的资源&gt;最多还会需求)\\\\ then\\{ 已有资源=已有资源+已分配资源 \\} if(已有的资源&gt;最多还会需求)then{已有资源=已有资源+已分配资源} 所以我们收回P1后，已有资源更新为(3,3,2)+(2,0,0)=(5,3,2),剩余的进程资源表变为 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P2 (9,0,2) (3,0,2) (6,0,0) P3 (2,2,2) (2,1,1) (0,1,1) P4 (4,3,3) (0,0,2) (4,3,1) 此时满足收回条件的有P3,P1，我们假设先收回P3，那么现有资源为(5,3,2)+(2,1,1)=(7,4,3)，表更新为 进程 最大需求 已分配 最多还会需求 P0 (7,5,3) (0,1,0) (7,4,3) P2 (9,0,2) (3,0,2) (6,0,0) P4 (4,3,3) (0,0,2) (4,3,1) 此时全部进程都满足收回条件了，那肯定是先收回那个都可以了，所以只要是P1-&gt;P3开头的序列就一定是安全序列，所以操作系统处于安全状态，当然也不是只有P1-&gt;P3开头的是安全序列，同理P3-&gt;P1同样是安全序列，总之只要找到一条安全序列就是安全状态所以此时不会发生死锁。 以此类推，共5次循环检查即可将5个进程都加入安全序列，最终得到一个安全序列。这种算法成为安全性算法，可以很方便的使用代码实现以上流程，每一轮都从编号较小的进程开始检查。这里主要是要牢记已有资源的更新公式！ 思考:银行家算法的定义？ 假设系统有n个进程，m中资源，每个进程在运行前先声明对各种资源的最大需求数，则可以用一个n*m的矩阵（可以用二维数组实现）表示所有进程对各种资源的最大需求数。不妨称为最大需求矩阵Max,Max[i,j]=K表示进程Pi最多需要K个资源Rj,同理，系统可以使用一个n*m的分配矩阵Allocation表示对所有进程的资源分配情况，Max-Allocation=Need矩阵，表示各进程最多还需要多少各类资源。另外还要用一个长度为m的一维数组Available表示当前系统还有多少可用资源。某进程Pi向系统申请资源，可用一个长度为m的一维数组Requesti表示本次申请的各种资源量。 可用银行家算法预判本次分配是否会导致系统进入不安全状态： 如果 Requesti[j]&lt;=Need[i,j](0&lt;=j&lt;=m)Request_i[j]&lt;=Need[i,j](0&lt;=j&lt;=m) Requesti​[j]&lt;=Need[i,j](0&lt;=j&lt;=m) 便转向2，否则认为出错 如果 Requesti[j]&lt;=Available[j](0&lt;=j&lt;=m)Request_i[j]&lt;=Available[j](0&lt;=j&lt;=m) Requesti​[j]&lt;=Available[j](0&lt;=j&lt;=m) 便转向3，否则表示尚无足够资源，Pi必须等待 系统试探着把资源分配给Pi,并修改相应的数据（并非真的分配，修改数值只是为了做预判）： Available=Available−RequestiAvailable=Available-Request_i Available=Available−Requesti​ Allocation[i,j]=Allocation[i,j]+Requesti[j]Allocation[i,j]=Allocation[i,j]+Request_i[j] Allocation[i,j]=Allocation[i,j]+Requesti​[j] Need[i,j]=Need[i,j]−Requesti[j]Need[i,j]=Need[i,j]-Request_i[j] Need[i,j]=Need[i,j]−Requesti​[j] 操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式分配，否则，恢复相应数据，让进程阻塞等待。 总结 死锁的检测和解除 死锁的检测和解除一大特点就是他允许死锁的发生然后检测到死锁后用一些方法解除死锁。所以首先我们需要能够检测出死锁。 死锁的检测 为了能够对系统是否已发生了死锁进行检测，必须： 用某种数据结构来保存资源的请求和分配信息 提供一种算法，利用上述信息来检测系统是否已进入死锁状态 我们一般可以用资源分配图来保存资源的请求和分配信息，有以下两点两边的定义： 如果系统中剩余的可用资源数足够满足进程的需求，那么这个进程暂时是不用阻塞的，可以顺利执行，如果这个进程执行结束了把资源归还给系统，就可能使某些正在等待资源的进程被激活，并顺利的执行下去。相应的，这些被激活的进程执行完了之后又会归还一些资源，这样可能又会激活另外一些阻塞的进程。 按照上面的过程叙述，我们知道对于资源分配图，每一个边对应一个圆的资源节点，如果最终能够消除所有边（优先消除绿边然后再消除蓝边），就称这个图是可完全简化的，此时一定没有发生死锁（相当于能找到一个安全序列）。如果最终不能消除所有变，那么此时就是发生了死锁，最终还连着的边的那些进程就是处于死锁状态的进程。 检测算法： 在资源分配图中，找出既不阻塞又不是孤点的进程Pi(即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如上图中R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配边，使之成为孤立的节点。在上图中P1是满足这一条件的进程节点，于是P1的所有边消去。 进程Pi所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程，在下图中，P2就满足这样的条件，根据1的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的。 死锁的解除 一旦检测出死锁的发生，就应该立即解除死锁，注意并不是系统中的所有进程都是死锁状态，而是用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程。解除死锁的方法有： 资源剥夺法：挂起（暂时放到外存）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程，但是应防止被挂起的进程长时间得不到资源而饥饿。 撤销进程法：也叫终止进程法，顾名思义，强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大，因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑还得从头再来。 进程回退法：让一个或多个死锁进程回退到足以避免死锁的地步，这就要求系统要记录进程的历时信息，设置还原点。 总结"},{"title":"虚拟内存管理","path":"/wiki/操作系统笔记/虚拟内存管理/index.html","content":"请求式分页管理方式 前面我们介绍了虚拟内存，并且介绍了请求式管理的由来，那么接下来就详细介绍一下请求式分页管理方式。请求分页存储管理与基本分页存储管理的主要区别是在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息调入内存（这里操作系统要提供请求调页功能把缺失页面从外存调入内存）后继续执行程序。如果内存空间不足，由操作系统负责将内存中暂时用不到的信息换出到外存。（操作系统要提供页面置换的功能，将暂时用不到的页面换出外存).这里会涉及到页面机制，缺页中断机构和地址变换机构，我们在下面一一进行介绍。 页表机构 与基本分页管理相比，请求分页管理中，为了实现“请求调页”，操作系统需要知道每个页面是够已经掉入内存，如果还没有调入内存，那么也需要知道该页面在外存中存放的位置。并且当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面（页面置换算法），有的页面没有被修改过，就不用再浪费时间写回外存。有的页面修改过，需要将外存中的旧数据覆盖，因此操作系统需要记录各个页面是否被修改的信息。如下： 从上图我们可以看出请求分页存储管理的页表中存储了所有的页表，即使没有放入到内存中页记录在一个页表项。例如x现在就没有在内存中。 缺页中断机构 假设现在某进程要使访问的逻辑地址为（页号，页内偏移量）=（0，1024），那么经过查表发现此时0号页不在页表中，所以产生一个缺页中断，然后然后由操作系统对缺页中断进行处理。首先是将缺页的进程阻塞，然后放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。如果内存中还有空闲块，那么就为进程分配一个空闲块，将所缺页面装入该快，并修改页表中相应的页表项。 如上图就是将0号页表项内存块号修改为a并且状态为1，并且还要将x号块内的页面装入内存中去： 思考：如果内存块此时是满的怎么办？ 那么就会调用页面置换算法将一些符合调出条件的页面写回外存，所以只有内存满的时候才会触发调换算法（其实很容易理解，写回外存肯定是有时间开销的，所以只有满的时候迫不得已了才会增加时间开销为新来的页腾地儿），类似的实际上TLB等快表也有这个调出暂时长时间不命中的页表项的算法。并且如果内存满了，调出某个页面时，如果这个页面在内存期间被修改过，那么需要将其写回外存覆盖旧数据，否则未修改过的页面就不用了写回外存了，直接淘汰掉就好。毕竟外存块x处还存有旧数据的页，所以我们也可以看出调入是从外存快复制一份页面进入内存块，调出的意思是从内存淘汰的意思，当修改过的时候，这个被淘汰的页面还肩负着通知外存块更新数据的使命所以还需要写回外存（当然肯定是有额外的时间开销的），当没有被修改过（不意味着没被使用，可能在内存期间一直在在被读也发挥作用了）那么就直接扔出内存即可。 思考：缺页中断属于内中断的哪一类？ 我们知道缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断。一条指令在执行期间，可能会产生多次缺页中断（如copy A to B,即将逻辑地址A的数据复制到逻辑地址B，而A,B属于不同的页面，就可能产生两次中断，即A的页不在内存中，B的页也不再内存中，可能会产生两次中断）。 我们可以看出缺页中断属于内中断中的故障，但是是可以被程序处理恢复的。 地址变换机构 因为不能保证逻辑地址访问的页在内存中，所以我们首先是需要确定页是否在页表中，如果不在还需要调入页面并修改表项，当然如果内存满了，那么还需要页面置换。所以新增的步骤有： 当然后面的步骤就是根据页号找到内存块号了，然后拼接物理地址最后再访问目标内存单元。 这里我们尤其要注意TLB的机制，他只存放现在在内存中的刚刚被访问过得页表项，所以TLB里的页一定是存在的。 这里面的一些小细节直接用图片给出，这里我们一定要注意绿框中的提示要点。我们可以看出当产生缺页中断时换出旧页面并调入新的页面到内存块后发生了几个重要的事件： 快表直接加上新的表项 不是直接通过慢表拼接出了物理地址然后访存，而是又重新来了一遍这次快表命中了，然后通过快表拼接出了物理地址进行访存。 思考：为什么没有查慢表和查快表一起进行？ 可以，但是没必要，因为此时慢表大概率会慢于快表（如果不是还要TLB作甚）并且查慢表还会出现缺页中断，并行查询也快不了多少。 思考：为什么当有缺页中断时会通过快表命中？ 这就是进程中断的原理了，当在某一个指令处中断时如果进程阻塞了PCB会记录上次停止的位置，然后当进程再次执行时PCB会恢复到上一次停止的指令处然后重新执行中断的指令（大部分情况下），所以此时还会再执行一遍这个指令的逻辑地址但是此时就会通过快表命中了。 总结 页面置换算法 这部分超级重要，我会做适当的扩充，毕竟王道讲的实在是太少了。一定要透彻了解并且会计算。首先我们明确一个目的，由于页面的换入换出需要磁盘I/O，会有较大的开销，因此优秀的页面置换算法应该追求更少的缺页率。 最佳置换算法（OPT） 也叫作最优置换算法（OPT,Optimal):每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样就可以保证最低的缺页率。这里我们知道肯定是最理想的情况，因为这个算法要求我们需要提前知道未来这个所要被调出的页面就是最长时间或者永久不可能再被使用的页面，但是未来不可预测，所以这个算法实际中不可能实现，但是我们需要学习算法思想（毕竟万一未来我们量子预测到未来这个算法那不就可以实现了吗😝） 例题：假设系统为某进程分配了三个内存块，并考虑有以下页面号引用串（会依次访问这些页面）：7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1 那么最终的过程如下： 首先不用想，第一次填入时肯定都是缺页的（这个很重要容易被忽视）所以内存块填入7,0,1就先缺页3次，然后接下来到2，我们需要调出一个页面，此时我们看一下未来的访页顺序发现7最长时间不会被访问了，所以调出7接入2又缺页1次，继续执行到3发现又该调出了，还是看未来的顺序，调出1,…一直这样看未来顺序调出页面最终缺页率还是可观的才45%。这里我们可以看出缺页率的计算公式： 缺页率=缺页中断次数/页面引用次数缺页率=缺页中断次数/页面引用次数 缺页率=缺页中断次数/页面引用次数 最近未使用页面置换算法（NRU） 最近未使用页面置换算法（Not Recently Used)和OPT很相似，既然我不能知道未来的顺序，那么我就往回看，根据经验分析和局部性原理我们知道如果一个页面很久没有被是用来，那么大概率他就会很长时间或者不会再被使用了（根据历史经验推测未来），所以我们每次都选择调出最近未使用的页面。这里我们的做法如下： 当一个页面被访问(读)时设置R(read)位，页面被写入(修改)时设置M(modificate)位。 当启动一个进程时，它的所有页面的两个位都由操作系统初始化为0，R会被定期地（比如在每次时钟中断时）清零以区别最近没有被访问和被访问的页面。 那么当发生缺页中段时就会检查页面，其中页面可以分为4类： 第0类：没有被访问也没有被修改过的页面（R=M=0) 第1类：没有被访问但是已被修改过的页面（R=0,M=1） 第2类：已被访问过但是没有被修改过的页面（R=1,M=0） 第3类：已经被访问过并且也被修改过的页面（R=M=1） 每次都是从类编号小的非空类中随机挑选一个页面淘汰。 思考：问什么第2类比第3类优先被淘汰？ 首先请读一下算法名字，他强调的就是最近未使用，所以重在根据是否最近被访问过来决定页面的重要性，所以2类先被淘汰，毕竟在一个时间嘀嗒中（大约20ms）淘汰一个没有被访问过的已被修改过的页面比淘汰一个被频繁使用的“干净”（没被修改过）的页面好，所以是否“干净”（即是够被修改过）只是一个次级判断条件。其实NRU这种算法优点就是易于理解和有效实现并且虽然性能不是最好的但是已经够用了。 先进先出页面置换算法（FIFO） 同样借鉴了NRU的思路，既然每次都淘汰最近未被使用的页面，那么大多数情况先来的一般会在内存中待较长的时间，根据时间局部性原理，一般他就是那个最近未被使用的页面。所以FIFO算法就是每次选择淘汰的页面是最早进入内存的页面。 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列（FIFO队列），需要换出页面时就选择队头页面即可。所以队列的最大长度取决于操作系统为进程分配了多少个内存块。 例题： 缺页率=9/12=75%,说实话优点小高。那么你一定想到了如果多分几个内存块是不是缺页次数会变得更少，答案是未必，如下： 缺页率=10/12=83%缺页率反而更大了。只有FIFO会产生这种Belady异常现象，所以FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律是不适应的，因为先进入的页面也有可能经常被访问，所以算法性能差，不推荐使用。 第二次机会页面置换算法（SC） 第二次机会页面置换算法（Second Chance)是对FIFO算法进行的一种优化改进。修改的思路其实很简单，就是避免将最先进来的页面却被访问的页面优先调出，所以只需要设置一位R位，如果是0那么这个页面就是既老还没有被使用，可以直接置换掉。如果是1那么就说明这个页面虽然老但是被访问过，所以将R为置为0然后把这个页面放到队尾修改装入的时间就好像它刚被装入一样（即拥有了第二次机会），然后继续搜索队头直至R=0的页面换出。 第二次机会算法就是在寻找一个最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，即队列中所有的页面R都是1了，那么这个算法就是纯FIFO算法了，所以为了避免这种情况此时操作系统会一个接一个地将每一个页面都移动到队尾并将R设置为0。最后又回到原来的表头页面并且此时R位都是0，因此这个页面会被淘汰，所以这个算法总是可以结束不会出现死循环的。 思考：NRU和SC都有R位有什么区别？ NRU和SC的R位都是被访问的意思，但是NRU的R位是最近被访问的概念，而SC的R为只是表示被访问过的意思，所以NRU需要一个时间嘀嗒来设置R在一个时间段后清零，而SC就不需要只是当队列全是1时所有页面都在绕一圈然后R都变为0。 时钟页面置换算法（CLOCK） 对第二次机会算法的改进，我们发现第二次机会算法总是需要在链表中移动页面，这很低效没必要。所以更好的做法是把所有的页面都保存在一个类似钟面的环形链表中，一个表指针指向最老的页面（即最先进入内存的页面）。当发生缺页中断时，首先检查指针指向的页面，如果R位是0，那么就淘汰该页面，并把新的页面插入到这个位置，然后把表指针移到下一个页面，如果R位是1就将R位置为0然后检验下一个位置，重复这个过程一直到找到一个R位为0的页面为止。当所有的R位都是1时，则指针转一圈将所有的页面的R位都清为0。 我们发现实际上CLOCK算法和SC算法思想一模一样，只不过是换了一个数据结构来减少操作的开销。并且我们发现简单的CLOCK算法选择淘汰一个页面最多经过两轮扫描。 思考：能否进一步优化CLOCK算法？ 我们发现NRU不止讨论了是否最近被访问过的问题，还加了一个是否被修改过的判断指标，当都没有被访问时优先会淘汰没有被修改过的页面，这是因为毕竟修改过的页面被淘汰时还需要写回外存有更大的开销不如再等一等万一他一会被访问了不就不用写回外存了嘛。所以优先淘汰的是R=M=0的，那么CLOCK算法也可以借鉴这种思想。 改进型的时钟置换算法（CLOCK v2.0) 因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件均相同时，应该优先淘汰没有被修改过得页面，避免I/O操作。这就是改进型的时钟置换算法的思想。所以也是有下面这四类： 第0类：没有被访问也没有被修改过的页面（R=M=0) 第1类：没有被访问但是已被修改过的页面（R=0,M=1） 第2类：已被访问过但是没有被修改过的页面（R=1,M=0） 第3类：已经被访问过并且也被修改过的页面（R=M=1） 页面的状态用（R,M）表示，所以（1,1）表示最近被访问过且被修改过。 算法规则：将所有可能被置换的页面排成一个钟面型的循环队列。 第一轮：从当前位置开始扫描到第一个（0,0)的帧用于替换，本轮扫描结束。 第二轮：前提是第一轮扫描失败（即没有(0,0)），那么重新扫描，查找第一个（0,1)的帧用于替换。本轮会将所有扫描过得帧访问位设置为0（即第二轮扫描后（1,0)-&gt;(0,0),(1,1)-&gt;(0,1)。 第三轮：前提是第二轮扫描失败（即没有(0,0)和（0,1)），那么重新扫描，查找第一个（0,0）（此时的(0,0)是原先的(1,0)）的帧用于替换。本轮不修改任何标志位。 第四轮：前提是第三轮扫描失败（即没有(0,0),(0,1)和(1,0)），那么重新扫描，查找第一个（0,1)（此时的(0,1)是原先的(1,1)）的帧用于替换。并且此轮一定会扫描成功。 由于第二轮已经将所有的访问位设置为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型CLOCK算法选择一个淘汰页面最多会进行四轮扫描。 思考：改进型CLOCK和CLOCK最大的区别是什么？ 我们仔细对比一下两者的算法思想，我们发现虽然都是使用类似钟的循环队列数据结构，但是算法思想却截然不同，对于简单的CLOCK使用的是SC的思想，而改进型的时钟页面置换算法使用的是NRU+CS的算法思想但是更贴向NRU。 最近最少使用页面置换算法（LRU） 最近最少使用页面置换算法（LRU，Least Recently Used）：每次淘汰的页面是最近最久未使用的页面。 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t，当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。很明显这个非常的科学。 我们以一道例题讲解，假设某系统为某进程分配了4个内存块，并考虑到有以下页面号引用串：1,8,1,7,8,2,7,1,8,3,8,2,1,3,1,7,1,3,7 缺页率=6/20=33%很小。在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号。在逆向扫描过程中最后一个出现的页号就是要淘汰的页面。我们发现这个方法太好啦，就用这个吧，但是实际上这个算法不常见，因为需要专门的硬件支持且实现困难，开销极大。 最不常用页面置换算法（NFU） 最不常用页面置换算法（NFU,Not Frequently Used）:用一个软件模拟LRU，该算法将每个页面与一个软件计数器相关联，计数器的初始值为0，每次时钟中断时，由操作系统扫描内存中的所有页面，将每个页面的R位（他是0或1）加到计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。当发生缺页中断时，则置换计数器上数值最小的页面。 我们发现NFU不忘记任何事情，比如一个页面之前被频繁访问，导致这个计数器很大，但是后来不访问他了，但是由于计数器的值太大，他也一直不会被置换出去，这个缺点太严重，所以也不推荐。 老化算法 老化算法是对NFU算法的修改，其修改包括两个部分，首先，在R位被加进之前将计数器（二进制数）右移一位（相当于除以2）然后将新来的R位的数加在计数器的最左端的位（即次数最大最优决定权）。这样老化算法的计数器中只有有限位数，如果时钟滴答是20ms,8位一般足够了，加入一个页面160ms都没有被访问过，那么他很有可能就不重要了。 工作集页面置换算法(WS) 在讲解算法的实现之前，我们先了解一下几个概念： 思考：什么是工作集？ 工作集：一个进程当前正在使用的页面的集合称为工作集 思考：什么是颠簸现象？ 颠簸现象：程序每执行几条指令就产生一次缺页中断 思考：什么是请求调页？颠簸现象什么时候频繁出现？ 请求调页：在单纯的分页系统中，刚启动进程时，在内存中是没有页面的，所以当cpu尝试读取第一条指令时就会产生一次缺页中断，使操作系统装入含有第一条指令的页面，其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间后，该进程需要的大部分页面都已经在内存中了，进程开始在较少缺页中断的情况下运行 思考：怎么解决程序初期运行的颠簸现象？ 有不少分页系统会设法跟踪进程的工作集，以确保进程运行以前，他的工作集就已经在内存中了，这样运行初期就不会频繁发生颠簸了。这种方法就叫做工作集模型，大大减少了缺页中断率。在进程前装入其工作集页面也称为预先调页。所以工作集随着时间变化的。 实际上大多数的程序会任意访问一小部分页面，工作集缓慢变化。当程序重新开始时，就有可能根据它上次结束时的工作集对要用到的页面作一个合理的推测，预先调页就是在程序IXUS运行之前预先装入推测的工作集的页面。 思考：纯分页式管理的工作集和请求式分页管理的工作集的区别？ 那么按照以前的方法定义工作集为前1000万次内存访问所使用过的页面的集合，那么现在在请求式分页管理中就应该定义为过去10ms中的内存访问所用到的页面的集合。这样的模型更合适和容易实现。并且要注意每个进程都只会计算自己执行的时间，所以当一个进程在T时刻开始然后在T+100ms的时间段内使用了40ms的CPU，那么对于工作集来说就是40ms。一个程序从他开始执行到当前所实际使用处理机的时间总数就是当前实际运行时间。我们通过这个近似的方法定义进程的工作集就是在过去的t秒实际运行时间中他所访问过的页面的集合。 那么现在我们再来探讨下基于工作集的页面置换算法：就是找出一个不在进程工作集中的页面淘汰他。 每个表项至少要包含两条信息： 上次使用该页面的近似时间 最近是否访问过的R位 过程如下： 扫描所有的页面检查R位。 如果R==1：那么设置上次使用时间为当前实际时间，以表示缺页中断时该页面正在被使用 如果R==0&amp;&amp;生存时间&gt;t:那么表示最近没有被访问过且已经不再工作集了，那么就移除这个页面，用新的页面置换它。扫描会继续进行以更新剩余的表项。所以这次扫描后所有不在工作集的页面都会被淘汰掉。 如果R==0&amp;&amp;生存时间&lt;=t:那么表示这个页面没有被访问过但是却还在工作集中，那么就记录下最长生存时间（就是当前时间-最早被使用时间即已经在呆工作集中的时间）。如果最后没有找到任何一个可以淘汰的即所有页面都是1情况除了现在被扫描的这个页面那么就淘汰这个页面，如果有多个3这种情况的即（1,3都有的情况）那么就淘汰生存时间最长的。如果最终所有页面都是1的情况（包括现在被扫描的这个也是1的情况）那么虽然都满足无需淘汰的条件，但是总是得出去一个，那么就尽可能随机淘汰一个“干净”（没有被修改过的）页面这样就无需进行I/O操作了节省开销。 总结 以上涵盖了大部分置换算法，这里列表总结 页面置换算法 算法规则 优点 缺点 最佳置换算法（OPT） 优先淘汰最长时间内不会被访问到的页面 缺页率小，性能最好 预测未来，无法实现 最近未使用置换算法（NRU） 优先淘汰最近未被访问且干净的页面（需要R,M） 性能优秀，实现简便 ———— 先进先出置换算法（FIFO） 优先淘汰最先进入内存的页面 实现简单 性能差，与规律相悖，可能出现Belady异常 第二次机会置换算法（SC) FIFO改良版，对于最近被访问过得放到队尾获得第二次机会 合理，性能适中 链表操作复杂 时钟置换算法（CLOCK） SC的时钟循环链表形式，规则同上 合理，性能适中 未考虑干净页面的I/O开销 改进型的时钟置换算法（CLOCK v2.0) 和NRU思路规则相似使用的是时钟循环链表形式 合理，性能适中，考虑了I/O开销 有时候扫描次数有点多 最近最少使用页面置换算法（LRU） 每次都淘汰上一次被访问时间最早的页 性能好，科学合理 实现复杂，需要特殊地硬件支持，开销大 最不常用页面置换算法（NFU） 计数器记录R的和来表示被访问频率，每次淘汰访问频率小的页面 实现简单 之前访问频率大但是最近不怎么访问的页面迟迟不能被置换 老化算法 NFU改良版 实现适中，性能适中 ———— 工作集算法（WS） 每次都淘汰不在工作集的或者在工作集时间最长的干净的页面 实现适中，性能适中 ———— 页面分配策略 页面分配、置换策略 驻留集 指请求分页存储管理中给进程分配的物理块的集合。在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。如果驻留集太大，就失去了虚拟存储技术的应用意义，导致多道程序并发度下降，资源利用率降低。如果驻留集太小，会导致缺页颠簸，系统需要花费大量时间处理缺页。所以驻留集的大小要合适。 我们考虑一个极端的情况，如果一个进程共有100个页，那么如果驻留集大小为100，那么进程可以全部放入内存运行期间也就不会再发生缺页了，如果驻留集为1，则进程运行期间必定会频繁的缺页。 页面分配策略 固定分配：操作系统为每个进程分配一组固定数目的物理块，在运行期间各个进程的驻留集大小不变。 可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即驻留集大小动态变化。 页面置换策略 局部置换：发生缺页时只能选进程自己的物理块进行置换。 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。 思考：分配策略和置换策略的关系？ 固定分配局部置换：系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。这种策略缺点是很难在刚开始就确定应该为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小，优先级，或是根据程序猿给出的参数来确定为一个进程分配的内存块数） 可变分配全局置换：刚开始为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某个进程发生缺页时，从空闲物理块中取出一块分配给该进程，如果已经没有空闲物理块了，则可以选择一个未锁定的页面换出外存（注意，并不是所有的页面都可以换出外存，比如系统会锁定一些页面，这些页面中的内容不能置出外存比如重要的内核数据等），再将物理块分配给缺页的进程。如果采取这种策略，那么只要进程发生缺页，都将先获得空闲的物理块，只有空闲物理块也没有的时候系统会调出一些其他进程未锁定的页面（这个页可能是任何一个进程的页），然后将腾出的物理块分配给这个缺页的进程。因此这个被选中的进程拥有的物理块会减少，缺页率会增加。 可变分配局部置换：刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。 思考：可变分配全局置换和可变分配局部置换的区别？ 可变分配全局置换是只要缺页系统就会给他分配新的物理块。 可变分配局部置换是根据发生缺页的频率动态增加或减少进程的物理块直至频率趋于稳定。 调入页面的时机 预调页策略 根据局部性原理（主要是空间局部性原理），一次调入若干个相邻的页面可能比一次调入一个页面更加高效。但是如果预先调入的页面大多数没有被访问，那么就会低效。因此可以预测不久之后可能访问到的页面，将他们预先调入内存，但是目前预测成功概率为50%。所以这种策略主要用于进程的首次调入，由程序猿指出应该调入那些部分。 请求调页策略 进程在运行期间发现缺页时才将页面调入内存。这种策略调入的页面一定会被访问，但是每次只能调入一页，而且每次调入都要磁盘I/O操作，所以开销大。 调入页面的区域 当系统拥有足够的对换区空间： 那么页面的调入和调出都是内存和对换区之间进行，这样可以保证页面的调入和调出速度很快，在进程运行前，需要将进程相关的数据从文件区复制到对换区。 当系统缺少足够的对换区空间： 凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的 部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。 独特的UNIX方式： 运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。 颠簸(抖动)现象 刚刚换出的页面马上又换入内存，刚刚换入的内存又要换出内存，这种频繁的页面调度行为就是颠簸或抖动。产生的原因是划分给进程的驻留集太小。 工作集 驻留集：在请求分页存储管理中给进程分配的物理块的集合。 工作集：在某段时间内，进程实际访问页面的集合。 所以工作集大小可能会小于窗口尺寸，系统会根据工作集大小和窗口尺寸的关系动态更改驻留集。比如某个进程的窗口尺寸为5，但是一段时间的检测发现进程的工作集一般最大就是3，那么物理块大小更改为3即可满足需要。所以一般驻留集的大小不能小于工作集的大小，否则就会导致进程运行过程中频繁缺页。 总结"},{"title":"缓冲区&结束语","path":"/wiki/操作系统笔记/缓冲区&结束语/index.html","content":"缓冲区管理 这节接上一张仍然是核心子系统的功能实现，本节是缓冲区管理。 什么是缓冲区 缓冲区我们并不陌生，机组原理中讲过的cache还有操作系统中讲述的高速缓冲tlb都是以中国缓冲区，他们都是一个存储区域，可以由专门的硬件寄存器组成，也可以利用内存作为缓冲区。使用硬件作为缓冲区的成本较高，容量也较小，一般仅用于对速度要求非常高的场合（如存储器管理中的联想寄存器TLB,由于对页表的访问频繁，因此使用速度很快的联想寄存器来存放页表项的副本）。一般情况下，更过的是利用内存部分空间作为缓冲区，“设备独立性软件的缓冲区管理就是要组织管理好这些缓冲区。 这里我们将详细讲述“内存作为缓冲区”的知识点。首先我们先要了解一下缓冲区的作用： 缓和cpu和I/O设备之间速度不匹配的矛盾。 减少对cpu的中断频率，放宽对cpu中断响应时间的限制。 解决数据颗粒度不匹配的问题，例如输出进程每次可以生成一块数据，但是I/O设备每次只能输出一个字符。 提高cpu和I/O设备之间的并行性。 这里我们介绍几种缓冲区管理策略 单缓冲 假设某用户进程请求某种块设备读入若干块的数据，如果采用单缓冲的策略，操作系统会在主存中为其分配一个缓冲区（如果题目中没有特别说明，一个缓冲区的大小就是一个块）。 此时当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出，当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满以后，才可以把缓冲区数据传出。其实特别类似于管道机制 如上图，块设备数据-&gt;缓冲区用时短于cpu处理数据的时间，因此读入的时间更快，那么一段时间后缓冲区就会被充满数据，此时就不能再继续输入数据了，需要等待cpu一直工作到缓冲区为空时才可以继续块设备数据-&gt;缓冲区。所以处理一块数据的平均用时=C+M。 当T&gt;C时，那么cpu处理速度更快，反而不会是的缓冲区被充满，所以此时处理一块数据的平均用时=T+M。所以无论是哪种情况，永远是取速度慢的，所以采用单缓冲策略时，处理一块数据平均耗时Mx(C,T)+M。 双缓冲 假设某用户进程请求某块设备读入若干块的数据。如果采用双缓冲的策略，操作系统会在主存中为其分配两个缓冲区（如果题目中没有说明，一个缓冲区的大小就是一块）。那么此时设备对于将数据写入缓冲区1,2的速度相同并且缓冲区-&gt;工作区的速度相同的。那么此时假设初始状态为：工作区空，其中的一个缓冲区满，另一个缓冲区空。 那么如果T&gt;M+C,此时即设备将数据填满空数据区2时，另一个数据区1已经全部移到工作区并且被cpu处理完了，那么每次都是设备-&gt;缓冲区的速度慢，所以处理一块数据的平均时间就是T。 如果此时T&lt;M=c，那么也就是当满缓冲区1数据移到工作区且被cpu处理完之前，另一个空的缓冲区2已经被填满了，那么此时处理一块数据的平均时间就是M+C。并且在双缓冲策略中，我们发现缓冲区1和缓冲区2是交替进行两个任务：①空的时候就是被设备数据填充②满的时候就是将数据转移到工作区。相应频率是相同的，不会出现一个缓冲区一直空，一个缓冲区一直满的情况，因为两个任务并行进行。所以在双缓冲策略中，处理一个数据块的平均时间为Max(T,M+C)。 使用单/双缓冲在通信时的区别 两台机器之间，可以配置缓冲区用于数据的发送和接受。 当采用单缓冲的时候，显然两个相互通信的机器只设置单缓冲区，那么在任一时刻只能实现数据的单向传输。显然效率并不高。所以一般使用双缓冲策略比较好： 此时两个相互通信的机器设置双缓冲时，则同一时刻可以实现双向的数据传输。我们对比发现实际上管道通信就是一种利用单缓冲区的方法，所以一个管道通信只能实现单一方向的数据传输，而如果想实现双向数据传输，就必须建立两个管道。 循环缓冲区 将过个大小相等的缓冲区链接成一个循环队列。下图中，绿色表示空缓冲区，橙色代表已充满数据的缓冲区。 缓冲池 缓冲池由系统中的共用的缓冲区组成，这些缓冲区按使用状况可以分为：空缓冲队列，装满输入数据的缓冲队列（输入队列），装满输出数据的缓冲队列（输出队列）。另外，根据一个缓冲区在实际运算中扮演的功能不同，又设置了四种工作缓冲区（全部都是以缓冲池的视角命名的）： 用于收容输入数据的工作缓冲区（hin）：存储的是要输入到用户进程的数据，但是要暂时存放到缓冲池，完成的是设备输入数据-&gt;缓冲区 用于提取输入数据的工作缓冲区（sin)：存储的是要输入到用户进程的数据，并且是要离开缓冲池，完成的是缓冲池的输入数据-&gt;用户进程 用于收容输出数据的工作缓冲区（hout)：存储的是要输出到设备的数据，但是要暂时存放到缓冲池，完成的是用户进程输出数据-&gt;缓冲区 用于提取输出数据的工作缓冲区（sout）：存储的是要输出到设备的数据，并且是要离开缓冲池，完成的是缓冲池的输出数据-&gt;设备 总结 结尾语 历时半个月，我终于完成了408–操作系统一周目的学习，20天的熬夜学习换来了丰富的回报，独自一人在图书馆中爆肝王道笔记的场景历历在目，相信经过这次学习更加坚定了长时间战线学习的信念👊，接下来敬请期待我的计算机组成原理学习笔记。–2021.1.18"},{"title":"卡诺图与编译码器","path":"/wiki/数字逻辑与数字系统笔记/卡诺图与编译码器/index.html","content":"使用卡诺图化简表达式 我们接下来回忆总结一下卡诺图化简逻辑函数的过程，首先有以下几个概念： 卡诺图上的每一个圈都代表一个蕴含项 主蕴含项：扩展到最大的蕴含项 奇异“1单元”：卡诺图中仅能被单一主蕴含项覆盖的方格 质主蕴含项：包含着一个或者多个奇异”1“单元的主蕴含项 最终我们是要将逻辑表达式化简为最简与或式，最简与或式就要求化简时： 项数最少，意味着卡诺图中圈数最少 每一项中的变量数最少，意味着卡诺图中的圈尽可能大 有时候可能会存在某个奇异“1”单元，他只能自己单独成一个圈： 或者也有可能一个卡诺图用两个不同的思路化简会得到两个最简式： 但是无论怎样化简我们都要遵循以下规则： 每一个1的方格必须至少被圈一次 每一个圈中包含的相邻小方格数必须为2的整数次幂 为了得到尽可能大的圈，圈和圈之间可以重叠 若某个圈中的所有1方格，已经完全被其他圈所覆盖，则改圈就是多余的，即每一个圈中至少应该有一个标1方格是他特有的。 练习 上面的式子进行化简后可以表示成下方的最简与或式。我们来分析一下：首先四个角被红色框圈起来得到¬B¬D，然后两侧的蓝圈圈出四个方块得到¬A¬D，然后中间竖着的绿色圈圈出四个方格得到¬CD，最后橘色圈圈中两个方法得到ABD。将四个项相加记得到最简式子，我们可以看出每一个标1方格都至少被圈中了一次，并且每一个圈都是尽可能大的，并且每一个圈都有自己圈中的独有的标1方格。 无关项的化简 我们前面所讲的卡诺图化简时要求，一个方格要么是1，要么是0。但是我们之前学到过无关项，他对结果不产生决定作用，因此无论取何值都可以，即你可以把他看成是0也可以把他看成是1。在卡诺图中当输出的值不重要或者相应的输入组合从不处显示，就可以由设计者决定这些输出时0还是1。充分利用无关项，我们可以进一步化简逻辑表达式。比如下图中： 我们发现对于某些组合，其结果是无关项，那么我们就在相应的方格表标记X，由于无关项既可以是0也可以是1，所以我们在化简时就可以用圈尽可能的圈最多的1，同时圈也可以圈X，也可以不圈。如上图，这样在化简时明显就更加简单了。 那么讲了这么多，我们都是在学习卡诺图的构件简化过程，他具体是如何应用的呢？实际上他通常是用来设计某一个复杂功能的元件的电路逻辑的，如下面几个我们分别来介绍卡诺图的应用： 7段数码管驱动电路 7段数码管常用来表示一个十进制数，由于一共是十个数0-9，所以我们使用四个位就可以表示了。 一般7段数码管有两种连接方法，共阴极和共阳极： 无论是哪一种实际上设计思路都是一样的。首先我们列出不同数字对应的应该亮的数码管编号： 然后用D0D1D2D3表示十进制数的0-9，对应的就要使得输出端Sa-Sg输出不同的值： 那么我们列出真值表以后使用卡诺图画出不同数对应的电路，这里以Sa为例： 那么用卡诺图得到Sa的最简表达式以后我们就可以画出电路图了： 编码器 我们前面学习了优先级线路，他的输出信号总是和最高级输入信号的值相同，那么我们之前用了一个很复杂的图来实现这个功能的，那么有没有更好的方法呢？当然有，此时我们就可以使用编码器，那么编码器是如何实现的呢，看下图： 上面是一个4线-2线编码器（因为输入信号是4个线编号0~3，所以只需要2个位就可以表示4个输入线，所以只需要两个输出线，因此叫做4线-2线编码器）。其中X0,X1,X2,X3是输入信号线，输出A0，A1是用来输出有效信号的编号的，EO是用来判断是否存在有效输入的。 我们用编码器模拟了优先级线路，他的工作原理如上图，当没有有效输入时，那么EO=1，此时无论A0,A1是何值都是没有用的。但是当EO=0，那么就说明此时有有效输入了，具体是哪个输入为有效输入，就需要A0,A1来输出表示有效输入的编号了，例如当X3位有效输入时，那么A0=A1=1，即此时二进制编号11即10进制的3号输入信号是有效输入。当然上面的表格我们也可以使用无关项来描述： 表示的意思是一样的。 注意编码器不仅可以用来表示优先级线路，他也可以用来表示更加复杂的有效线路情况，我们需要透彻理解编码器的工作原理。 那么同样的我们也可以使用卡诺图来写出最简逻辑表达式来表示A0,A1和EO，首先EO只有当所有的输入信号都是无效输入0时他才输出1，所以很明显 EO=X0+X1+X2+X3‾EO=\\overline{X_0+X_1+X_2+X_3} EO=X0​+X1​+X2​+X3​​ A0和A1我们根据真值表先对卡诺图进行标1填写： 然后化简我们就得到了A0和A1的最简表达式，这样我们就可以画出编码器的实现电路图了： 当然上面仅是一个4线-2线编码器的电路图，更加复杂的电路图我们需要按照上面的步骤重新推导。 译码器 译码器我们并不陌生，在《机组原理》中我们学习了译码器是用来解析生成片选信号用的，那么译码器到底是如何通过电路实现的呢？实际上译码就是编码的逆过程，所以对于4线-2线的编码器生成的指令，我们需要使用2线-4线译码器来进行译码。并且由于是逆过程，编码器是接收的有效输入信号然后输出有效输入信号的编号，那么译码器就是接受有效输入信号的编号，然后相应的将对应编号的输出端输出信号1。如下： 当接收到10编号，那么就是Y2应该输出有效信号1。那么我们同样可以使用卡诺图进行化简写出表达式然后画出译码器的电路： 思考：编码器和译码器的合作使用有什么优点？ 我们思考一下如果不使用编码器和译码器实际上也可以表示这个有效输出和有效输入之间的关系，只是中间需要许多的复杂线路来实现，逻辑复杂同时功耗大，但是使用编码器和移码以后逻辑简单了许多，同时两者之间的传输信号线也很少，功耗少。实际上编码器和译码器的实现都是卡诺图的应用体现。 当然我们也可以使用译码器实现更加复杂的逻辑，例如实现同或门： 只需要将输出端的输出信号进行更改即可。 多路选择器 多路选择器的功能是可以从选择信号的值从N个可能的输入中选择一个作为输出，他一般需要使用log2N位选择信号作为输入来表示编号X输入信号，控制输入信号的选择，比如： 最简单的就是二选一电路，那么当S=0时说明输出信号Y和输入信号D0相同，当S=1时说明输出信号Y和输入信号D1相同。这种选择器的实现我们也可以使用卡诺图化简得到他的电路表达式： 或者使用三态缓冲器实现： 当然对于更加复杂的多路选择器，我们也需要按照先列真值表，画卡诺图再化简的步骤得到电路表达式甚至可以借用其他组件： 我们回忆一下这四个复杂器件，他们的电路设计都离不开卡诺图的应用，其中设计思路都是以下几个步骤：对实际问题进行抽象，然后定义输入和输出 2. 由实际逻辑问题列出真值表 3. 由真值表写出表达式并构建卡诺图 4. 使用卡诺图化简表达式得到最简式 5. 画出原理图 组合逻辑电路的时序问题 我们发现在设计电路时并不仅仅需要考虑式子的简单与否，还要考虑延迟等外界因素，这就涉及到了组合逻辑电路的时序问题。在实际电路中，输出相应输入的改变是需要一定的时间，而不是理想情况下的立刻改变： 所以我们在设计电路时还要考虑时序问题，即怎样设计电路使得整体的延迟最小。这里我们先学习几个概念： 传播延迟：t_pd即为输入改变直到一个或多个输出改变为最终值所经历的最长时间延迟 最小延迟：t_cd即为输入发生变化直到任何一个输出开始改变的最短时间 如刚才的A-&gt;Y电路，传播延迟就是A开始改变到Y改变稳定所需要的时间，而最小延迟就是A开始改变到Y开始改变的时间，很明显传播延迟总是要大于等于最小延迟。 思考：延迟产生的原因？ 电路中的电阻和电容的充放电 光速的上限 首先我们知道许多门是由mos管实现的，而mos管的原理是PN结偏置实现的，这肯定是有延迟的，同时伴随着科技的发展，速度最大不能快于光速，由于这种速度上限，会产生延迟。 思考：传播延迟总是大于等于最小延迟的原因？ 实际上最理想的情况就是输出端同时改变同时迅速稳定为改变后的值，那么此时最小延迟和传播延迟就会相等，但是实际电路中以下几个原因会造成传播延迟总是更大： 上升沿与下降沿的延迟可能不同（即上升和下降的幅度不同，毕竟我们前面学习了低电平信号和高电平信号都是一个区间范围) 电路存在多个输入和输出时，不同输出的延迟可能不同 电路对温度敏感，电路较热时速度会变慢、 根据不同路径的延迟不同，我们定义： 很明显，一般门越多的电路延迟越大，并且由于我们的目的是为了提升整体的运行性能，即降低整体的延迟，我们一般关注的是关键路径的延迟，降低关键路径的延迟才能大幅提升整体的性能。 毛刺 在电路中还会涉及到“毛刺”的问题，这种问题在电路图中不易察觉，但是在实际电路中却很明显很有可能造成整体电路的错误。那么什么是毛刺呢？实际上就是指一个输入的一个变化可能会引起后面多个输出的多次变化。比如： 当A=0,C=1时，B突然由1变成0，从电路图和卡诺图中我们通常会认为Y不会发生变化还是维持信号1，但是实际上我们分析一下电路信号的传输速度，由于B信号需要经过非门再和非A相或才能得到¬A¬B,而得到BC则不需要经过非门，所以BC会先发生变化变成0，而此时¬A¬B还没有从0变成1，所以有一段时间Y会变成0，待¬A¬B变化完成后变成1了，此时Y才会变回1。所以实际上Y的变化时1-&gt;0-&gt;1，而不是保持1不变。此时如果Y后面还有其他逻辑操作，那么这种微小的变化可能会被无限放大从而造成整体电路的异常。因此毛刺是一种风险，究其原因产生毛刺是因为输入端的变化不能同时到达逻辑门从而可能造成输出端的多次变化： 为了防止毛刺的产生，我们不能一味追求电路的表达式最简，而要同时保证没有毛刺产生。当信号的变化在卡诺图中穿越两个主蕴含项的边缘时就会产生“毛刺”： 如上图两个圈的边缘没有过渡。为了避免，我们只需要增加多余的蕴含项来盖住这些边缘以避免毛刺： 我们发现此时得到的表达式就不是最简式了，但是这样做的意义很重要，他可以有效避免毛刺对整体电路的影响。 注意，毛刺是大多数电路中都存在的现象，但是不用每一个毛刺都避免，毕竟毛刺只是有可能引起输出端的多次变化，实际上大多数情况下这种多次变化都是瞬间的，我们只需要在产生异常时再修改电路避免毛刺即可。同时还要注意多输入（几乎）同时改变也会产生毛刺，这种情况不能通过上面这种增加硬件的方法来避免。 使用卡诺图化简表达式我们接下来回忆总结一下卡诺图化简逻辑函数的过程，首先有以下几个概念： 卡诺图上的每一个圈都代表一个蕴含项 主蕴含项：扩展到最大的蕴含项 奇异“1单元”：卡诺图中仅能被单一主蕴含项覆盖的方格 质主蕴含项：包含着一个或者多个奇异”1“单元的主蕴含项 最终我们是要将逻辑表达式化简为最简与或式，最简与或式就要求化简时： 项数最少，意味着卡诺图中圈数最少 每一项中的变量数最少，意味着卡诺图中的圈尽可能大 有时候可能会存在某个奇异“1”单元，他只能自己单独成一个圈： 或者也有可能一个卡诺图用两个不同的思路化简会得到两个最简式： 但是无论怎样化简我们都要遵循以下规则： 每一个1的方格必须至少被圈一次 每一个圈中包含的相邻小方格数必须为2的整数次幂 为了得到尽可能大的圈，圈和圈之间可以重叠 若某个圈中的所有1方格，已经完全被其他圈所覆盖，则改圈就是多余的，即每一个圈中至少应该有一个标1方格是他特有的。 练习 上面的式子进行化简后可以表示成下方的最简与或式。我们来分析一下：首先四个角被红色框圈起来得到¬B¬D，然后两侧的蓝圈圈出四个方块得到¬A¬D，然后中间竖着的绿色圈圈出四个方格得到¬CD，最后橘色圈圈中两个方法得到ABD。将四个项相加记得到最简式子，我们可以看出每一个标1方格都至少被圈中了一次，并且每一个圈都是尽可能大的，并且每一个圈都有自己圈中的独有的标1方格。"},{"title":"单周期MIPS32","path":"/wiki/数字逻辑与数字系统笔记/单周期MIPS32/index.html","content":"单周期MIPS32处理器的设计 接下来我们来设计一个单周期MIPS32位处理器，我们需要考虑一下几个方面： MIPS指令集 首先我们需要知道MIPS3类指令的主要组成是什么，这里我们只学习最基本的指令集： R-type指令：and,or,add,sub,slt等 存储器指令：lw,sw等 分支指令：beq等 扩展指令：addi等 上面是我们将要实现的MIPS指令（后面我们将学到上面的这种指令分类是根据主译码模块的功能进行分类的）。接下来我们看一下每一个类型指令的功能： 对于R-type类型指令op都是0，并且都对应有三个寄存器类型存储的操作数，并且格式都是 1助记符 目的操作数 源操作数1 源操作数2 这里实际上只有slt指令我们不太熟悉，他是一个比较两个源操作数大小的指令。 L-type类型指令是立即数类型指令，他的特定是有一个源操作数为立即数常数，我们要注意此时op不再是全0并且形式为： 1助记符 源操作数1 目的操作数 源操作数2 J-type类型指令就是地址跳转指令，实现起来比较简单。 思考一个问题，op位数是有限的，这也就意味着可以表示的指令类别是有限的，因此我们为了尽可能多的取表示更多的不同类型的指令，我们只对最基础（即其他指令不能组合表示)的指令进行编写并且为其分配Opcode。 设计目标 我们在编写MIPS处理器结构前，我们需要明确一下型号，这里我们设计的MIPS32处理器的配置： 单周期MIPS32处理器 每一条指令必须在一个时钟周期内完成 32个32位寄存器，哈佛结构，小端存储模式，支持23条指令 数据通路+控制通路 数据通路：完成对指令中操作数的操作、存储等处理工作 控制通路：从数据通路接受指令，并对其进行翻译以告知数据通路如何处理，因此控制电路决定数据的某一部分到哪里去接受什么操作后将目的信息传输到哪里 处理器设计相当于在各个记忆部件之间添加组合逻辑电路，在控制单元的控制下根据当前电路的状态计算出电路的新状态 MIPS32位处理器的概念模型 我们简单的来认识一下上面的概念模型的运行方式，首先我们根据指令，对输入信号进行操作，他可能会需要到其他操作数的帮助，因此我们需要从现态的记忆部件中取出需要的信息，然后进行组合逻辑的运算（实际上就是指令控制着数据的处理），指令在一个时钟周期内完成信息的处理后会产生输出数据，此时我们需要将这个新的输出数据存储起来也就是改变了记忆部件的状态，因此也就是现态，同时我们还需要进行输出信号。因此上图实际上可以看成就是一个取数据-&gt;处理数据-&gt;存放数据的过程，这其中涉及到了组合逻辑电路和时序逻辑电路的合作使用。 记忆部件 分别是存储地址的程序计数器，存储指令的内存块，寄存器以及存储数据内存块他们都是cpu内部的核心部件，需要受到clk时钟周期控制。 在寄存器模块中有六个端口，其中A1对应RD1，A2对应RD2，这两组端口是从寄存器读出数据时需要的，其中A端口用来接收要读出数据到的地址，RD端口使用来输出32位的数据的。而A3是用来接收要从那个地址写入数据的地址，WD3是用来接收要写入的32位数据。WE3是写使能端，控制着此时寄存器是写/读和数据（一次性只能读或写）。 数据存储和寄存器也类似，A和RD是用来读出数据的，WD是用来写入数据的。WE还是控制着内存的读/写。 具体指令的实现 数据通路——LW 此时我们从程序计数器中读出下一个指令的地址，然后到存储指令的存储块中取出指令。我们知道一个指令在MIPS32中也是32位的，但是也可以使用8位16进制码来表示。 这里我们假设的不是J型指令而是I型指令，因此25:21这六位是对应的rs，我们将指令的这六位地址传进去即可获得源操作数rs的值，接下来我们还需要取立即数操作数： 取得立即数后我们得到只是一个16位的，我们需要对齐进行符号扩展为32位立即数 然后我们进行数据的处理，因此将两个源操作数传入到ALU中，同时我们需要告诉ALU进行那种类型的计算，因此传入ALUcontrol信号（实际上这个是由数值计算的指令来操控）。然后这里假设传入的是010，代表是加法，因此ALU此时进行加法，然后要注意我们得到的结果是要到存储数据的内存块中的地址，然后我们将计算结果传送到内存块地址接受端口即可得到我们最终要找到的数。 然后我们将从内存中读出的数据放到寄存器中以便使用，因此使用A3（接受要存放的地址位置）跟WD3（要存入的具体32位数值）端口接受要写入寄存器的数据。我们要注意从存储数据内存块处得到的数据是放到指令的rt目的操作数处，因此我们在写入寄存器时，传进去的是I型指令的20:16区域。 然后我们要进行程序计数器的更新，说来也简单，就是将PC加4就可以得到下一个指令的地址了😃。 思考：为什么要加四？ 我们知道MIPS中是按字节编址的，因此一个地址对应一个字节，而一个指令是32位的对应4个字节，因此加4才是下一条指令的地址。 数据通路——SW 因此我们此时是将寄存器读出的数据写入到数据内存中，我们先用20:16目的操作数地址传进去读出这个目的操作数，然后写入到数据内存中（使用WD接受这个数，同时写使能端要为1代表此时内存可写入数据）。前面的过程都不变，还是可能需要LW的操作来将所需要的数据首先保证存储到了寄存器中。 数据通路——R型指令 之前我们所学习的指令是LOAD指令加载一个内存中的数到寄存器或者SAVE指令集将寄存器中的一个数写回到内存中，现在我们要学习一个更加复杂的R型指令，他是将立即数与源操作数或者两个源操作数进行数值计算处理的结果存储到目的操作数寄存器中，因此我们此时需要先获得源操作数，由于我们可能只需要一个或者2个寄存器存储的操作数，然后在进行计算，我们可能会使用一个从寄存器中取出的源操作数与立即数进行ALU计算或者两个从寄存器中取出的源操作数进行数值计算，因此由ALUSrc来决定（首先有一个寄存器操作数由RD1连接的SrcA给出，另一个是使用RD2的寄存器操作数充当SrcB还是使用立即数来作为SrcB由AluSrc决定）。然后我们最终得到的结果并不是内存地址了，而是一个确切的结果数值了，我们决定是否需要将它写回到寄存器中，因此由MemtoReg来决定，如果需要我们再将数值写回到寄存器中，这需要RegDst来决定使用哪个寄存器地址段（RS还是RT？）来存储这个结果数。最后如果我们需要内存存储这个结果数，还需要通过RD2连接的WriteData线进行写内存的操作来存储结果数到内存中。我们思考一下整个的过程，一个R型指令需要两个源操作数首先存在于寄存器中，如果不存在很明显我们需要在前面的步骤中先使用LW将源操作数数据取出放入到寄存器中，因此在R指令中的数据通路也会涉及到LW的过程，而SW也是有可能的，因为很可能最终寄存器存储的结果数值需要写入数据存储块中存储，这就是一个完整的R型指令可能涉及到的所有数据通路。 数据通路——BEQ指令 上面的BCQ指令是根据是否满足条件进行跳转，因此首先我们需要判断是否满足条件，通过branch控制的与aluzero标志位（结果为0是zero为1）取与操作得到的结果作为是否满足条件的判断结果（当rs与rt值相等时满足条件），只有在满足条件即PCSrc为1时才会进行跳转，那么具体跳转到哪里，是由下面的通路给出的，他是用一个立即数偏移量来决定的，最终的跳转的指令地址为： BTA=(sign_extended)(immediate&lt;&lt;2)+(pc+4)BTA=(sign\\_extended)(immediate&lt;&lt;2)+(pc+4) BTA=(sign_extended)(immediate&lt;&lt;2)+(pc+4) 也就是sign_extended的意思是有符号数位数扩展，我们要注意最终位数扩展后的立即数偏移量是与下一条指令PC+4的值求和得到的跳转地址，而不是当前地址，所以说明跳转前程序计数器已经进行了一次更新指令地址的操作。 思考：上面是如何进行rs与rt是否相等的判断的？ 这里的ALU的zero并不是返还0的意思，他是alu的一个零标志位，只有计算结果为0时zero标志位为1，因此很明显此时alu进行的是相减操作让rs和rt相减，当两者相等时结果为0，zero标志位才能置为1，那么此时PCSrc才能变成1代表满足条件需要跳转。 CPU加入到通路中对记忆器件进行控制 根据上面的MIPS概念图，我们还没有加入控制通路，即需要连接控制单元使得他可以控制我们之前连接起来的记忆组件。如下图我们加入控制单元形成控制通路： 控制单元 上面的控制单元又可以拆分成主解码模块，另一个是ALU解码模块，主解码模块输入的是指令的opcode，主解码模块来识别具体是哪一种类型以便控制分配任务。对于R型指令有许多不同的数值计算功能，因此此时需要ALU解码模块来根据FUNC5:0来解码具体的数值ALU计算功能并分配ALUcontrol信号，当然alu解码模块还受到主解码模块的信号控制。 ALU译码 ALU译码是ALU解码模块根据funct和aluop来解码指令的具体功能同时生成ALU控制信号来告诉ALU进行何种数值操作 ALUOP1:0 Meaning 00 Add加法 01 Subtract减法 10 Look at Funct需要根据funct具体分析功能 11 Not Used不使用 ALUOP1:0 Funct ALUControl2:0 00 X 010(Add) X1 X 110（Subtract) 1X 100000(add) 010(Add) 1X 100010(sub) 110(Subtract) 1X 100100(and) 000(And) 1X 100101(or) 001(Or) 1X 101010(slt) 111(SLT) 主译码 主译码是主解码模块根据op判断不同类型的主要指令来控制数据通路的控制各种选择器的信号以决定数据通路的走向： Instruction Op5:0 RegWrite RegDst AluSrc Branch MemWrite MemtoReg ALUOP1:0 R-type 000000 1 1 0 0 0 0 10 lw 100011 1 0 1 0 0 0 00 sw 101011 0 X 1 0 1 X 00 beq 000100 0 X 0 1 0 X 01 思考：addi拓展指令怎样加入上面的表内？ 首先我们要知道addi是拓展指令，他独立于其他类型的指令，因此我们需要单独为他分配一个opcode，因此他也需要加入到主译码模块： Instruction Op5:0 RegWrite RegDst AluSrc Branch MemWrite MemtoReg ALUOP1:0 addi 001000 1 0 1 0 0 0 00 addi指令和lw相比只是没有内存取出的数加入到寄存器的功能，其他和lw相同，但是addi还需要进行一个加法操作，因此最终还需要到alu移码生成加法控制信号。 J型指令数据通路 我们前面已经学些了跳转指令的工作过程了，他的跳转计算公式就是： BTA=(PC+4)31:28∣∣instr_index∣∣0BTA=(PC+4)_{31:28}||instr\\_index||0 BTA=(PC+4)31:28​∣∣instr_index∣∣0 因此实际上后面补两个0的操作就是乘四左移2位，又因为instr_index26位的限制，我们可以知道跳转指令一次跳转的地址量是有限的，他的能跳转的最远地址是 max=(226−1)∗4max=(2^{26}-1)*4 max=(226−1)∗4 又因为一个地址是4字节，因此能最终跳转的指令个数是 max=226−1max=2^{26}-1 max=226−1 一定要注意BEQ指令与J型指令的跳转地址计算公式是不一样的。BEQ跳转地址的计算是先取出instr的26:0位，然后进行有符号数扩展为32位有符号立即数再左移两位与PC+4进行求和得到跳转地址PCBranch,而对于J型指令，则是直接获取instr的26:0位然后左移两位与PC+4的高四位进行拼接得到32位跳转地址。因此两者的计算方式不同，使用的地址计算线路也是不同的。 J指令主译码控制信号 由于J型指令也是单独的一类指令，因此也需要单独分配一个opcode 单周期处理器的性能分析 表示的是一个程序的时间，它是由以下公式原理给出的： 一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度 一个程序的时间=一个程序的指令数×一个指令所用的时间周期数×一个时间周期的时间长度 我们知道一个程序运行的有效时间是由其关键路径决定的也就是运行时间开销最长的通路，如下图是我们设计出的MIPS处理器的关键路径： 我们可以给出单周期处理器的关键路径时间： Tc=tpaq_PC+tmem+max{tRFread,tsext,tmux}+tALU+tmem+tmux+tRFsetupT_c=t_{paq\\_PC}+t_{mem}+max\\{t_{RFread},t_{sext},t_{mux}\\}+t_{ALU}+t_{mem}+t_{mux}+t_{RFsetup} Tc​=tpaq_PC​+tmem​+max{tRFread​,tsext​,tmux​}+tALU​+tmem​+tmux​+tRFsetup​ 很明显上面的公式难以进行具体的计算，因此我们简化一下上面的公式给出关键路径的计算公式： Tc=tpcq_PC+2tmem+tRFread+tmux+tALU+tRFsetupT_c=t_{pcq\\_PC}+2t_{mem}+t_{RFread}+t_{mux}+t_{ALU}+t_{RFsetup} Tc​=tpcq_PC​+2tmem​+tRFread​+tmux​+tALU​+tRFsetup​ 从上面的公式我们可以看出关键路径的时间开销主要是由内存的访存时间，ALU计算时延，指令加载和回写寄存器数据以及寄存器的读数据时间组成的。 例题 如下图是部分给出的参数，请给出具体的关键路径的计算公式并计算处结果："},{"title":"存储器建模","path":"/wiki/数字逻辑与数字系统笔记/存储器建模/index.html","content":"位单元 上一讲我们学习了存储器阵列，而存储器阵列是由位单元阵列组成的，每一个位单元只存储1位数据，每一个位单元与一个字线（wordline）和一个位线（bitline)相连，如下图： 读写数据主要是通过位线来完成的： 那么现在我们再来从整体上观察一下存储器阵列的结构： 可以得到以下几点规律： 字线与使能端类似 用于控制阵列中一行数据的读/写 对应着唯一的地址 同一时刻至多有一个字线位高电平 一个字线控制着一个数据字 当某个字线为高电平时，那么这行数据就要进行位修改或者位读取，接下来通过位线传入要修改的新的数据，或者读出位单元存储的位数据 我们要注意到由于每次只有一个字线处于高电平，因此虽然位线控制着一列位单元，但是实际上每次每一个位线上也只有一个位单元处于读/写状态，但是同一时刻，可能会有多个处于同一个字线的位单元处于读/写状态。 存储器的类型 这里实际上我们在《计算机组成原理》中介绍过，但是当时并没有从存储器阵列的角度去分析。这里我们会以存储器阵列的角度去介绍，首先我们回忆一下存储器的类型。 随机访问存储器（RAM）：易失的 动态随机访问存储器（DRAM）：计算机的主存 静态随机访问存储器（SRAM)：CPU中的高速缓存 只读存储器（ROM）：非易失的 ROM也是可以随机访问的，大多数现代ROM也已经支持的可读写功能。 DRAMvsSRAM DRAM DRAM是将数据存储在一个电容上，读操作后，存储的数据会被破坏，电容上的存储的电荷量会慢慢泄漏，因此为了维持数据的存在，需要频繁的进行刷新充电（读，然后写），所以被称为动态存储器。如下图： SRAM 而SRAM是将数据存储在一个交叉耦合的反相器中，交叉耦合反相器具有很强的抗干扰能力，因此并不需要频繁的进行刷新，因此被称为静态存储器。 几种存储器的比较 存储器类型 每个位单元的晶体管数 成本 延迟 触发器 ≈20 高 低 SRAM 6 中等 中等 DRAM 1 低 高 ROM虽然也是存储器，他的读速度非常快，但是写速度很慢。 存储器端口 单端口是存储器中常见的端口，即一次性只能读/写。使用同一个端口来接受/输出数据，因此我们需要保证任何时刻，存储的端口只能处于读/写状态。 实现原理实际上就是使用了两个三态缓冲器，保证两个三态缓冲器的使能端任一时刻相反即可，这样即保证了每一次只有一个线路处于通路状态，也就保证了每次只能读入/输出数据。 寄存器文件 寄存器文件通常是一个小型的多端口SRAM存储器阵列，如下图就是一个32寄存器×32的3端口寄存器文件。 注意寄存器文件不是寄存器，他是一个寄存器堆，是CPU中多个寄存器组成的阵列，因此可以多路并发访问不同的寄存器 他有两个读端口A1/RD1和A2/RD2，还有一个写端口A3/WD3，地址线均是5位，可寻址2^5=32个寄存器。他可以同时读两个寄存器和写一个寄存器。 RAM建模 RAM是一个随机访问存储器，他需要接收地址，数据，clk时钟信号等，然后还要有输出端等，结构如下图： 那么我们接下来对他进行建模： 1234567891011121314151617module ram #(parameter N=6,M=32) (input logic clk,we, input logic [N-1:0] adr, input logic [M-1:0] din, output logic [M-1:0] dout ); //注意**是幂运算 //这里的声明mem可以看成是定义了一个mem数组 //他的每一个存储单元的数据是32位 //同时寻址范围是0~32 //因此是一个32×32的存储器阵列 //有32行字线和32列位线，每一个字线对应有32个位单元 logic [M-1:0] mem[2**N-1:0]; always_ff @(posedge clk) if(we) mem[adr]&lt;=din; assign dout = mem[adr];endmodule 上面的赋值语句当且仅当clk处于有效上升沿并且we为高电平时执行，并且注意虽然这里的赋值语句可以使用阻塞赋值，但是为了建模代码的规范，always_ff时序逻辑电路的建模中使用非阻塞赋值语句更好。 ROM建模 虽然ROM在现代的计算机中也实现了写操作，但是在我们的408学习中，一般还是认为ROM是不能进行写操作的，只能进行读操作。接下来我们同样对ROM进行建模，由于这里我们只进行读操作的建模，而读操作可以随时进行读取，并不需要等待有效沿，因此就是一个最简单的组合逻辑模块： 123456789101112module rom(input logic [1:0] adr, input logic [2:0] dout ); //只有读出数据的操作，没有写入修改数据操作\talways_comb case(adr) 2&#x27;b00:dout&lt;=3&#x27;b011; 2&#x27;b01:dout&lt;=3&#x27;b110; 2&#x27;b10:dout&lt;=3&#x27;b100; 2&#x27;b11:dout&lt;=3&#x27;b010; endcaseendmodule 时序 接下来我们讨论一下时序问题，我们前学习到了D触发器只有在时钟的有效沿（上升沿/下降沿）才对输入D进行采样，并赋值给Q，因此在采样的时刻，D必须处于一个稳定的状态，保持为0或者1。这个过程就如同照相，只有在被拍摄的物体静止不动时才能获得清晰的图像，Q想要得到一个明确的电平信号，那么就要求在采样D信号时，D需要保持稳定在一个确定的状态。如果在采样的过程中,D未处于稳定的状态，那么就会产生亚稳态。 输入时序约束 建立时间（Setup time)：t_setup=在时钟有效边沿到来前信号所需要稳定的时间 保持时间（Hold time)：t_hold=在时钟有效边沿到来后在采样时输入信号需要保持稳定的时间 孔径时间（Aperture time)：t_a=在时钟边沿附近输入信号需要维持的总时间 很明显有以下规律： ta=tsetup+tholdt_a=t_{setup}+t_{hold} ta​=tsetup​+thold​ 输出时序约束 前面我们讲到的仅仅是在clk有效时对采样信号D的时序约束要求，但是采样完成以后赋值给Q还有一定的时间。这里的输出时序同样需要加上约束： 传播延迟（Propagation delay)：t_pcq=时钟有效边沿到达后到Q最终稳定所需要的最长时间 最小延迟（Contamination delay)：t_ccq=时钟有效边沿到达后到Q开始改变所需要的最短时间 动态约束 我们在学习了几个有关约束的概念以后，需要添加动态约束，首先同步时序电路中，输入必须在时钟有效边沿附近的孔径时间内保持稳定。即输入信号必须 在时钟有效边沿到达前，至少要稳定t_setup 同时在时钟有效边沿到达后，至少要稳定t_hold 系统时序 时钟周期Tc是指两个时钟上升沿（下降沿）之间的间隔 fc=1/Tc,表示时钟频率f_c=1/T_c,表示时钟频率 fc​=1/Tc​,表示时钟频率 那么提高时钟频率（也就是缩短时钟周期）就可以增加数字系统在单位时间完成的工作量，但是频率不能无限制的增加。 如上图所示，两个寄存器间的延迟具有最小和最大延迟，这些延迟由其中的电路元件的延迟所决定。很明显D2想要变化，首先需要Q1改变完成并稳定，因此T_c有一个最小值，同样的也会有一个最大值。 建立时间约束 建立时间约束由路径R1至R2间的最大延迟所决定： 寄存器的传播延迟t_pcq 组合逻辑电路的传播延迟t_pd 我们通过上图可以容易得到结论，寄存器R2的输入信号D2必须在下一个时钟上升沿的t_setup时间前稳定。 同时D2稳定至少需要t_pd+t_pcq。因此有以下约束公式： {Tc&gt;=tpcq+tpd+tsetuptpd&lt;=Tc−(tpcq+tsetup)\\begin{cases} T_c&gt;=t_{pcq}+t_pd+t_{setup}\\\\ t_{pd}&lt;=T_c-(t_{pcq}+t_{setup}) \\end{cases} {Tc​&gt;=tpcq​+tp​d+tsetup​tpd​&lt;=Tc​−(tpcq​+tsetup​)​ tpd&lt;=Tc−(tpcq+tsetup)t_{pd}&lt;=T_c-(t_{pcq}+t_{setup}) tpd​&lt;=Tc​−(tpcq​+tsetup​) 上式就被成为建立时间约束或者最大延迟约束，即上式限制了我们在设计组合逻辑电路的最大延迟。 在商业设计中： Tc是由研发总监和市场部提出的，以确保产品的竞争性 制造商确定触发器的传播延迟t_pcq和建立时间t_setup t_pcq+t_setup被称为时序开销，由芯片的生产工艺决定 而通常，只有t_pd即组合逻辑电路的最大时间延迟是我们设计人员可以控制的变量，因此我们在设计组合逻辑电路时要保证设计出来的t_pd小于建立时间约束 保持时间约束 保持时间约束由路径R1至R2间的最短延迟所决定： 寄存器的最小延迟t_ccq 组合逻辑电路的最小延迟t_cd 寄存器R2的输入信号必须在时钟上升沿后至少稳定t_hold,也就是D2稳定的时间必须小于变化值传来的时间，毕竟他要改变值了，不能继续hold维持原先的值了，因此规律是： {thold&lt;=tccq+tcdtcd&gt;=thold−tccq\\begin{cases} t_{hold}&lt;=t_{ccq}+t_{cd}\\\\ t_{cd}&gt;=t_{hold}-t_{ccq} \\end{cases} {thold​&lt;=tccq​+tcd​tcd​&gt;=thold​−tccq​​ tcd&gt;=thold−tccqt_{cd}&gt;=t_{hold}-t_{ccq} tcd​&gt;=thold​−tccq​ 上式被称为保持时间约束或者最小延迟约束，其限制了我们设计的组合逻辑电路的最小延迟，因此组合逻辑电路延迟不能太大也不能太小。下面我们介绍一种特殊的情况，触发器背靠背相连： 此时触发器之间没有组合逻辑电路，因此t_cd=0，那么如果要不违反保持时间约束，需要保证 thold&lt;=tccqt_{hold}&lt;=t_{ccq} thold​&lt;=tccq​ 因此一个可靠的触发器，保持时间要比最小延迟短。这样才能保证变化的值不会在D2还在稳定的状态时就抵达。 在实际应用中，经常将触发器设计成t_hold=0，来保证保持时间约束在各种情况下都可以满足 教材中如非特别注明，后面的讨论会忽略保持时间约束 保持时间约束又非常重要，如果一旦违反保持时间约束，必须重新设计电路，这一点与建立时间约束不同，如果违反了建立时间约束，可以通过调整时钟周取Tc来修正，但是保持时间约束无法这样修正 因此一旦违反了保持时间约束后果很严重 思考：建立时间约束和保持时间约束的关系以及由来？ 可能我们会有点懵，不知道建立时间约束和保持时间约束的由来，下面我们来总结一下两个D触发器的工作原理。 如上图，两个D触发器有一个CLK控制，并且R2的输入信号是R1输出信号经过组合逻辑电路进行计算加工得到的。因此在第一个CLK上升沿抵达后Q1会更新，然后会用组合逻辑电路进行计算得到D2，我们需要保证在第二个CLK上升沿抵达前D2已经稳定得到了Q1根据组合逻辑电路计算出来的新信号值，因此有一个建立时间延迟。同时在第一个CLK抵达后第二个CLK抵达前，Q1很快就会变化完成并且经过组合逻辑电路计算得到了新的修改值可以传递给D2了，但是D2并不是得到修改值后马上就能变化，他需要保证维持一个t_hold来保证R2的输出Q2可以正确得到D2的值，当Q2稳定得到D2的值以后D2才能变化更改为新的值，因此新的值不能计算抵达的太快，他需要晚于t_hold，因此也就是保持时间约束。两者共同限制了组合逻辑电路延迟不能过长也不能过短。 时序分析 我们前面学习了时序问题的约束条件，那么接下来我们来以一道例题学习一下时序分析。如下图： 根据题干我们可以知道 {tpd=35ps∗3=105pstcd=25ps\\begin{cases} t_{pd}=35ps*3=105ps\\\\ t_{cd}=25ps \\end{cases} {tpd​=35ps∗3=105pstcd​=25ps​ 因此 {Tc&gt;=tpcq+tpd+tsetup=50+105+60=215pstcd=25ps,thold−tccq=70−30=40ps\\begin{cases} T_c&gt;=t_{pcq}+t_{pd}+t_{setup}=50+105+60=215ps\\\\ t_{cd}=25ps,t_{hold}-t_{ccq}=70-30=40ps \\end{cases} {Tc​&gt;=tpcq​+tpd​+tsetup​=50+105+60=215pstcd​=25ps,thold​−tccq​=70−30=40ps​ 我们得到最大时钟周期至少为215ps,而t_cd=25ps小于要求的40ps，也就是说延迟太小了，违反了保持时间约束。 思考：如何修改电路使其不违反保持时间约束？ 我们只需要将t_cd提升即可，我们发现之前的最短路径是只经过一个门，因此出现t_cd=25ps。我们可以修改电路为使其至少要经过两个门，因此在只经过一个门的电路上增加一个缓冲器门，如下图： 缓冲器就是仅仅减缓了信号传递的速度，这样t_cd就至少为50ps&gt;40ps了，因此也就不违反保持时间约束了。"},{"title":"进程调度算法","path":"/wiki/操作系统笔记/进程调度算法/index.html","content":"调度算法 先来先服务（FCFS) 先来先服务算法（First Come First Serve)强调公平性，按照进程先来先服务的思想调度，在作业调度时，考虑的是那个作业先到达后备队列，用于进程调度的时候，考虑的是哪个进程先到达就绪队列。是一种非抢占式的算法，即不会有进程中途插队的情况出现。 例如各进程到达就绪队列的时间、需要的运行时间如下表所示，如果使用FCFS算法来调度进程，那么下列的各进程的等待时间，平均等待时间，周转时间，平均周转时间和带权周转时间与平均带权周转时间各是多少？ 首先周转时间=完成时间-到达时间，带权周转时间=周转时间/运行时间，等待时间=周转时间-运行时间。按照先来先服务的算法调度，那么就是根据到达的先后顺序调度，当然也就是等待时间越久（说明来的越早）的进程优先得到服务。所以调度的顺序就是P1-&gt;P2-&gt;P3-&gt;P4。如下图： P1先执行，即到达就先运行，运行7个时间单位，在P1运行途中P2，P3和P4实际上已经都到达了就绪队列了，但是P1执行完，P2等待时间肯定是最久的，所以他执行，然后P3,P4。所以周转时间=完成时间-到达时间可以算出各个进程的周转时间如下表： 进程 到达时间 完成时间 周转时间 1 0 7 7 2 2 11 9 3 4 12 8 4 5 16 11 然后计算带权周转时间如下表： 进程 周转时间 运行时间 带权周转时间 1 7 7 1 2 9 4 2.25 3 8 1 8 4 11 4 2.75 等待时间如下表: 进程 周转时间 运行时间 等待时间 1 7 7 0 2 9 4 5 3 8 1 7 4 11 4 7 所以平均周转时间=(7+8+9+11)/4=8.75，平均带权周转时间=(1+2.25+8+2.75)/4=3.5,平均等待时间=(0+5+7+7)/4=4.75，注意本题的进程都是纯计算的进程，一个进程到达要么在等待，要么在运行，如果是又有计算，又有I/O操作的进程，那么其等待时间就是周转时间-运行时间-I/O操作时间（本题不考虑这种情况）。我们通过上面的3个表可以看出当带权周转时间大的时候说明等待时间所占整个的周准事件比例也就越大，所以使用户的满意度也就降低了，并且这种FCFS算法很明显很不合理，对于某些运行时间非常短的且来的较晚的进程，如果其前面具有一个周转时间非常大的进程时，就会出现长时间的等待从而造成带权周转时间很大，从整体来看，也会影响到平均带权周转时间较大（当然FCFS不会造成平均周转时间大），并且这种算法当面对突发紧迫重要的进程任务时也不能及时处理，所以现代的操作系统是不采取这种调度算法的，这种算法对长作业有利，但是对于短作业不利，当然这种算法也不会造成饥饿现象。 思考：什么是饥饿？ 可以理解为排队买东西，老是有人中间插队造成后面的排队的人迟迟无法得到需求。进程亦是如此，当前面的进程总是出现插队现象，就会造成后面的进程一直长时间无法得到相应造成饥饿现象，当然FCFS虽然不合理，但是总是能得到服务的，所以不会造成饥饿现象，而接下来介绍的算法就有可能造成饥饿现象。 短作业优先（SJF） 短作业优先（Shortest Job Fiirst)追求最少的等待时间，最少的平均周转时间，最少的平均带权周转时间，既然FCFS会造成运行时间的短作业长时间等待，那么我就每次都让运行时间短的短作业先进行服务，长时间的大作业多等待一会也不会造成非常离谱的带权周转时间。这种短作业进程优先服务的进程调度算法也是非抢占式的算法，但是也有抢占式的算法例如最短剩余时间优先算法（SRTN,Shortest Remaining Time Next),但是SJF算法有可能会导致饥饿现象。 思考：SJF和SPF的区别？ SJF是对于作业调度（即高级调度）的短作业优先算法，所以叫Shortest Job First而SPF是对于进程调度（低级调度）的短作业优先算法，所以叫做Shortest Process First。 思考:什么是抢占式算法？什么是非抢占式算法？ 你可能会疑惑到SJF里可能会出现晚到但是先执行的情况出现，难道还不是抢占式算法？这里的抢占式是指某个任务在运行过程中还没有运行完时被剥夺cpu占用权，使另一个进程开始在cpu上运行。而SJF虽然会每次都挑选就绪队列中运行时间最短的短作业，但也是一定保证这个任务一次性执行完。所以SJF和FCFS都是非抢占式，而SRTN就是抢占式了，他每次都会实时监视计算那个任务有最短剩余时时间谁就上cpu及时前一个任务还没有执行完也要下cpu等待，当然当这个任务又可以上cpu时还是可以继续执行没完成的部分，不需要重新开始，即PCB会帮助记录状态信息以便恢复，一般SRTN又称作具有抢占式的短作业优先进程调度算法。 接下来，我们也计算一个SJF的题，为了更好的理解抢占式，我们做的是具有抢占式的短作业优先算法题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用抢占式的短作业优先调度算法， 计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。 所以实际上做的是SRTN的算法题。 最短剩余时间算法：每当有进程加入到进程就绪队列时就需要进行调度即使现在还有任务在cpu上运行，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则新进程抢占cpu，当前运行进程在PCB记录相关信息后让出cpu重新回到就绪队列等待直至其又是最短剩余时间的作业时在上cpu。同时，当然运行任务结束后还要执行调度。 如下图： 需要注意的是，每次当有新进程到达时就绪队列都会改变，按照上述的规则进行检查。所以每次到达新进程时都要格外注意计算剩余时间。如上，在0-2时只有进程1，所以其先执行，但是当来到时刻2，插入一个新的作业2，他的剩余时间为4(因为还没有执行过，所以剩余运行时间=运行时间)，而此时作业1还有5的运行时间比作业2长，所以虽然作业1没有运行完也要下cpu,作业2抢占cpu。 所以可以用下表表示整个过程Pi(remain time): 0时刻（P1到达）：P1（7），7上cpu执行。 2时刻（P2到达）：P1（5），P2（4），2上cpu执行 4时刻（P3到达）：P1（5），P2（2），P3（1），3上cpu执行 5时刻（P3完成且P4到达）：P1（5），P2（2），P4（4），2上cpu执行 7时刻（P2完成）：P1（5），P4（4），4上cpu执行 11时刻（P4完成且只剩下1）：P1（5），1上cpu执行 16时刻，所有进程完成，调度算法结束。 我们同样计算一下周转时间： 进程 到达时间 完成时间 周转时间 1 0 16 16 2 2 7 5 3 4 5 1 4 5 11 6 带权周转时间： 进程 周转时间 运行时间 带权周转时间 1 16 7 2.28 2 5 4 1.25 3 1 1 1 4 6 4 1.5 等待时间： 进程 周转时间 运行时间 等待时间 1 16 7 9 2 5 4 1 3 1 1 0 4 6 4 2 所以平均周转时间=(16+5+1+6)/4=7,平均带权周转时间=(2.28+1.25+1+1.5)/4=1.50,平均等待时间=(9+1+0+2)/4=3。我们发现对于短作业优先，其平均的指标要明显低于FCFS算法，同时我们这里给出非抢占式的SJF算法的平均指标： 调度算法 平均周转时间 平均带权周转时间 平均等待时间 SJF 8 2.56 4 SRNT 7 1.5 3 我们会发现抢占式的短作业优先算法比非抢占式的短作业优先算法的平均指标更小，也就意味着平均性能更好。 注意：小细节 如果题目中并未特别说明，所提到的“短作业/进程优先算法”默认都是非抢占式的即SJF。 很多的教材上都会说“SJF调度算法的平均等待时间，平均周转时间”最少，严格来说，这个表述是错误的，不严谨的。之前的例子已经表明，最短剩余时间优先算法（即抢占式的短作业优先算法）还要更少。应该再加上“在所有进程同时可运行时，采用SJF调度算法的平均等待时间，平均周转时间最少”或者“在所有进程几乎同时到达时，采用SJF调度算法的平均等待时间和平均周转时间最少”。否则在判断题中如果未加上上面的条件，那么SRNT是平均等待时间，平均周转时间最少的。 平均等待时间最短未必平均带权周转时间最短，毕竟后者同时由运行时间和周转时间决定。但是一般来说平均等待时间和平均带权周转时间正相关，即平均等待时间较小一般平均带权周转时间也不会太大。 短作业优先调度平均等待时间和平均周转时间短显而易见，但是却不公平，这种进程调度算法对短作业有利，但是对长作业不利，很有可能造成饥饿现象，即在排队过程中总是出现短作业，这样就会一直插队造成长作业一直等待不能得到相应的饥饿现象。 思考：有没有一种较为中和的算法，不会产生过于极端的情况？ 仔细对比发现FCFS和SJF都是很大几率出现较为极端的情况的，前者会对短作业不友好且平均性能不好，后者对长作业不友好，虽然平均性能不错，但是却会造成饥饿现象，那么我们可以发明一种更平和的算法，牺牲部分平均性能，但是对于长短作业都有所考虑，且不会造成饥饿的算法–高响应比优先算法。 高响应比优先算法（HRRN） 高响应比优先算法（Highest Response Ratio Next)要综合考虑作业/进程的等待时间和要求服务的时间，这里我们首先需要引入一个新的概念–响应比 响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1 响应比=等待时间+要求服务时间/要求服务时间=等待时间/要求服务时间+1 要求服务时间就是运行时间，所以可以看出响应比一定是&gt;=1的，自HRRN算法中每次调度时都会计算各个作业/进程的响应比并且选择响应比最高的作业/进程服务。仔细思考响应比我们会发现等待时间更长且运行时间更短的作业/进程会优先选择，这样就实现了既不会让短作业等待也太长时间也不会让短作业永远最先被服务，相应的，也就实现了不会让长作业等待太长时间，折中了SJF和FCFS的优点，并且这种算法也是非抢占式的，只有在该作业/进程运行完毕或者中途主动放弃时才会触发调度，才需要即需要计算响应比，很显然这种算法不会产生饥饿现象。 下面我们还是对于上面的那4个任务按照HRRN算法调度计算： 每次调度时我们都计算响应比，并选择响应比高的上cpu 0时刻：只有P1到达了就绪队列，P1上处理机 7时刻：P1完成，就绪队列中有P2，P3,P4，P2的响应比为((5+4)/4=2.25),P3的响应比为((3+1)/1=4),P4的响应比为((2+4)/4=1.5)，显然选择3，虽然2和4都是一样的运行时间，但是2等待时间更长响应比也就越高。 8时刻：P3完成，此时剩下P2和P4，刚刚就算过两个任务的运行时间一样，经过相同的等待时间，P2还是比P4等待的时间长，所以2上cpu（不信可以计算响应比）。 12时刻：P2完成，还剩下P4，4上cpu 16时刻：所有任务完成，调度算法结束。 我们同样计算一下平均性能，首先计算周转时间 进程 完成时间 到达时间 周转时间 1 7 0 7 2 12 2 10 3 8 4 4 4 16 5 11 带权周转时间 进程 周转时间 运行时间 带权周转时间 1 7 7 1 2 10 4 2.5 3 4 1 4 4 11 4 2.75 等待时间 进程 周转时间 运行时间 等待时间 1 7 7 0 2 10 4 6 3 4 1 3 4 11 4 7 所以平均周转时间=(7+10+4+11)/4=8,平均带权周转时间=(1+2.5+4+2.75)/4=2.56，平均等待时间=(0+6+3+7)/4=4 前三种算法的总结 首先我们对比一下平均性能 算法 平均周转时间 平均带权周转时间 平均等待时间 FCFS 8.75 3.5 4.75 SJF 8 2.56 4 SRNT 7 1.5 3 RHHN 8 2.56 4 我们发现FCFS确实平均性能有点拉胯，而SJF和SRNT虽然平均性能优秀但是饥饿现象导致也不太好，而RHHN不但没有饥饿现象，而且平均性能也较好甚至这题的情况下平均性能和SJF一样优秀，所以RHHN整体应该较为出色，但是每次都要计算响应比又加大了计算开销。 这几种算法主要关心的是对用户的公平性，平均周转时间和平均等待时间等平均性能的指标，但是并不关心响应时间，前面我们也提高到过平均性能一般是操作系统关心的，但是用户关心的是自己的任务能否更快完成，所以上面这几种方法对于用户来说交互性很糟糕，因此这三种算法一般适用于早期的批处理系统，当然FCFS现在也扮演着某些情况的重要角色。但是接下来我们在介绍几种更适合于交互式系统的调度算法。并且要注意上面的这几种算法对于高级调用和低级调用均可以采用。 时间片轮转（RR） 不陌生呀，前面介绍操作系统发展史时分时系统就是时候用的这个时间片从而大幅推进了系统的发展，那么接下来我们就详细了解一下时间片轮转调度算法。时间片轮转（RR,Round-Robin)公平的，轮流的为各个进程服务，让每一个进程在一定的时间间隔内都可以得到相应。按照各进程到达就绪队列的顺序，轮流的让各个进程执行一个时间片（如100ms）。若进程未能在一个时间片内执行完，则剥夺处理机（外中断），将进程重新放到就绪队列队尾重新排列。并且注意此时的时间片轮转只能适用于低级调度（进程调度），因为作业只有放入内存建立了相应的进程后才能分配给处理机时间片，所以高级调度不适用。很明显，RR是一种抢占式的进程调度算法，计时装备由时钟装置完成，到达一个时间片后，就由时钟中断来通知cpu时间已到。因为各个进程都会得到相应，所以不会造成饥饿现象。 例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用时间片轮转调度算法，分析时间片大小分别为2,5时的进程情况。 时间片轮转算法轮流让就绪队列中的进程依次执行一个时间片（每次选择的都是排在就绪队列队头的进程）按照上表，就绪队列如下： 假设现在时间片为2那么 0时刻（P1(5)）：0时刻只有p1到达就绪队列，让P1上处理机运行一个时间片。 2时刻（P2(4)-&gt;P1(3）:2时刻P2到达就绪队列，P1运行完一个时间片，被剥夺处理机，重新放到队尾，此时2排在了队头，因此2上处理机（注意：此时P1由于运行完一个时间片刚下处理机，然后此时插进入了P2，那么默认他是排在刚刚完成的P1的前面即P2插入队尾紧接着P1插入队尾）。 4时刻（P1(3)-&gt;P3(1)-&gt;P2(2)）：4时刻，P3到达，先插到队尾，紧接着P2下处理机也插到队尾，此时又轮到P1上处理机。 5时刻（P3(1)-&gt;P2(2)-&gt;P4(6)）：5时刻，时间片还没结束，此时P4先任务插到末尾，由于一个时间片还没结束，所以此时1任务还在cpu上执行。 6时刻（P3(1)-&gt;P2(2)-&gt;P4(6)-&gt;P1(1)）：6时刻，P1时间片用完，下处理机，重新回到就绪队列的末尾，发生调度，3上处理机。 7时刻（P2(2)-&gt;P4(6)-&gt;P1(1)）：虽然P3的时间片还没用完，但是由于此时P3只需要一个时间，所以7时刻它运行完主动放弃了cpu，因此也发生调度，队头进程2上处理机。 9时刻（P4(6)-&gt;P1(1)）：进程2时间片用完，并且刚好运行结束，发生调度，P4上处理机。 11时刻（P1(1)-&gt;P4(4)）：P4时间片用完，重新回到就读队列队尾，队头任务1上处理机。 12时刻（P4(4)）:此时虽然时间片还有，但是1已运行完，主动放弃处理机，此时只剩下了P4，4上处理机。 14时刻（）：就绪队列为空，P4接着上cpu执行。 16时刻：所有进程运行结束，调度算法结束。 对于时间片5和上面类似，可以自己尝试。 这种RR算法更注重的是响应时间，因而不计算周转时间，一般来说，设计RR算法目的就是要让响应时间合适，即时间片要让切换进程的开销占比不超过10%。比如一个系统中有10个进程在并发执行，如果时间片为1s,则一个进程被相应的时间可能至少需要9s,也就是说用户在自己进程的时间片外通过键盘发出调试命令，可能需要等待9秒才能被系统响应（当然，如果实在自己的时间片内就会被立即响应）。这样时间片的大小也要制定合适，如果太大了，使得每一个任务都可以在 一个时间片内就完成，则时间片轮转调度算法就退化为FCFS算法了，并且会增大进程的响应时间。如果太小的话，进程调度、切换有时间代价（保存、恢复运行环境），因此如果时间片太小会导致花费大量的时间来处理进程切换，从而导致实际用于进程执行的时间比例也减小了。 优先级调度算法（PSA) 优先级调度算法（PSA,Priority Scheduling Algorithm)的提出就是为了适应随着现代计算机的发展，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序的情况。每个作业/进程都有各自的优先级，调度时永远选择优先级最高的作业/进程，这种算法即可用于作业调度，也可用于进程调度，甚至，还会用于之后学习的I/O调度。PSA同时具有抢占式和非抢占式的两种情况，但是面对实际情况，一般的PSA都是抢占式的，非抢占式的实现简单，但是实际应用意义不太大。 思考:抢占式和非抢占式的PSA区别？ 非抢占式的PSA需要在进程主动放弃处理机时进行调度，仍然没能有效解决实现紧急重要任务的初衷问题，而抢占式就是可以在就绪队列变化时检查是否产生了更高的优先级的任务，则进行抢占式切换所以肯定也是外中断了。 我们先来看一下非抢占式的PSA：各进程到达就绪队列的时间，需要运行的时间，进程优先数如下表所示（优先数越大，优先级越高） 非抢占式PSA每次调度选择当前已经到达且优先级最高的进程，当前进程主动放弃处理机时发生调度。 0时刻（P1）：只有P1到达，P1上处理机。 7时刻（P2,P3,P4）：P1运行完成放弃处理机，其余的三个进程都已经到达，选择优先级最高的P3上处理机。 8时刻（P2,P4）：P3完成，P2,P4优先级相同，则等待时间更长的（更早到达就绪队列的）先上，所以P2上处理机。 12时刻（P4）：P2完成，就绪队列只剩下P4,P4上处理机。 16时刻（）：P4完成，没有任务了，算法结束。 同样的我们在采取抢占式的PSA对上面的进程表进行调度： 抢占式的PSA永远要保证运行着的是优先级最高的任务，如果新到的任务优先级比正在运行的优先级高，则抢占，如果相同，则仍然等待（毕竟人家先到的）。 0时刻（P1）：只有P1到达，P1上处理机。 2时刻（P2）：P2到达就绪队列，发现此时P2优先级更高，虽然P1还在运行，抢占，P2上处理机，P1回到就绪队列。 4时刻（P1,P3）：P3到达，优先级比P2还高，虽然P2还在运行，抢占，P3上处理机，P2回到就绪队列。 5时刻（P1,P2,P4）：P3完成了，主动释放处理机，同时，P4也到达，由于P2比P4更先进入就绪队列，所以2上处理机。 7时刻（P1,P4）：P2完成，就绪队列只剩下P1,P4且P4优先级高，P4上处理机。 11时刻（P1）：P4完成，P1上处理机。 16时刻（）：P1完成，所有进程均已运行完，算法结束。 并且在PSA中就绪队列未必就只有一个，可以按照不同的优先级来组织，另外，也可以吧优先级高的进程排在更靠近队头的位置（使用优先级队列）。并且我们又跟据优先级是否动态改变分为了静态优先级和动态优先级两种。 静态优先级：创建进程时优先级确定，之后不发生改变。动态优先级：创建进程时有一个初始值，之后会根据情况动态地调整优先级。 一般系统进程优先级是高于用户进程的，前台进程优先级高于后台进程，操作系统更偏好I/O型进程（或者称为I/O繁忙性进程），这样I/O设备和cpu可以并行工作（注意不是并发）。如果优先让I/O繁忙型进程优先运行的话，则越有可能让I/O设备尽早的投入工作，则资源利用率、系统吞吐量也就会得到提升。因此与I/O型进程相对立的就是计算型进程（或者称为cpu繁忙型进程）。 思考：为什么要存在动态优先级PSA？ 可以从追求公平，提升资源利用率等角度考虑，如果某进程在就绪队列中等待了很长的时间则可以适当的提高其优先级，如果某进程长时间的占用处理机运行了很长时间，则可适当的降低其优先级，如果一个进程频繁的进行I/O操作，则可适当的提升其优先级。并且仔细思考，对于静态优先级的PSA，如果每次就绪队列中都会出现新的优先级高于进程P的进程，那么P就会长时间无法得到相应，造成饥饿现象的出现，所以动态优先级的PSA也可有效避免饥饿现象。 在PSA算法中用优先级区分紧急程度，重要程度，适用于实时操作系统，可灵活的调整对各个作业/进程的偏好程度。缺点是对于静态优先级的PSA可能会造成饥饿。 思考：有没有更好的算法? 思考我们已经介绍过得算法貌似都有自己的优缺点，FCFS公平但平均性能不好，SJF短作业永远优先平均性能优秀但是容易饥饿，高响应RHHN比虽然这种了FCFS和SJF但是对于用户交互糟糕且计算开销大，时间片RR虽然各进程相应但是应急能力一般，优先级PSA灵活调整各种进程服务的机会但是静态优先级易饥饿动态优先级实现较为复杂，所以有没有一种更好的这种考虑以上所有算法优点的同时缺点又不是那么明显的算法？有–多级反馈队列调度算法。 多级反馈队列调度算法（MFQSA） 多级队列反馈队列调度算法（Multilevel Feedback Queue Scheduling Algorithm）综合了上面算法的优点，他是设置多级就绪队列，各级队列优先级从高到低，时间片从小到大，新进程到达时先进入第1级队列队尾，按照FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进入下一个队列的队尾，在等待FCFS分配时间片，如果已经到达了最下级的队列还没执行完就重新放回该队列的队尾（所以永远是以非递增的顺序向低级队列插入），只有当第k级队列为空时，才会为k+1级队头的进程分配时间片用于进程调度。所以从整体来看，各个队列之间有静态PSA的特点，对于某一个队列里的进程又有RR的特点，同时从某个进程来看又有动态PSA和FCFS的特点，真实太妙了。当然这个算法也是抢占式的算法，即在k即队列的进程运行过程中(此时1~k-1级队列应该都已经为空)，若更上级的队列（1~k-1级)中又进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回k级队列的队尾。 例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用MFQSA算法，分析运行情况。 0时刻：只有P1，P1上处理机运行一个时间片，下处理机。 1时刻：P2到达，P1还未能在一个时间1的情况下运行完，P1移动至第二队列，开始执行P2，P2上处理机。 2时刻：P2执行完一个时间片1，也没能执行完，所以也插到队列2，此时队列1空了，开始给队列2分发时间片。此时1先到的队列2，所以P1先执行，再次上cpu 4时刻：P1又执行完一个时间片2，此时还是没能执行完，插到队列3队尾，发现队列2还没空还有P2，P2上处理机。 5时刻：此时P2在cpu上执行了时间片2的一半，还没运行完，但是来了新任务3插入到了队列1末尾，此时队列1不是空的，抢占，2下cpu重新插回到队列2末尾。 6时刻：P3执行了一个时间片1执行完了，下cpu，不用在插入到队列2了，此时队列2的P2重新上cpu。 8时刻：P2又运行完了一个时间片2，此时P2完成，不需要在插到队列3了，此时队列1,2都空了，只剩下了队列3的P1，P1上cpu 12时刻：P1又执行完了一个时间片4，此时已经完成了7/8，还差1，所以重新插回到队列3的队尾，此时队列3只有P1，所以P1又上cpu 13时刻：P1运行完成，所有进程都结束，算法结束。 MFQSA对各类的进程都相对公平（FCFS的优点），每个进程到达都可以很快得到相应（RR的优点），短进程只用较少的时间就可以完成（SPF的优点），不必事先估计进程的运行时间（避免用户作假），可灵活的调整各类进程的偏好程度，比如cpu密集型进程，I/O密集型进程（拓展：MFQSA可将因I/O而阻塞的进程重新放回到原队列，这样I/O型进程就可以保持较高的优先级），唯一的缺点就是还是有可能造成饥饿现象的，但是概率不会像SPF那么大。 后三种算法的总结 比起早期的批处理操作系统来说，由于计算机的造价大幅下降，因此之后的交互式的操作系统（包括分时操作系统和实时操作系统等）更注重系统的响应时间、公平性和平衡性等指标。而这后面的这几种算法能较好的满足交互式系统的需求，因此这三种算法适用于交互式系统。（比如UNIX使用的就是多级反馈队列调度算法）。 总结 经过上面的6个算法的介绍，我们对各个算法都有了一定的了解，并且最好是记住英文缩写名字，因为考试有时候只给英文要对其有印象。前面三种要熟练掌握计算指标的方法，后面的三种方法要可以熟练表述运行过程并且了解优缺点，尤其是最后的MFQSA。这里我列出以下注意点总结希望你可以有所收获。 抢占!=饥饿，对于抢占式动态PSA算法不会造成饥饿。 RR和MFQSA不适用于作业调度（高级调度），因为时间片的原因必须进入内存分配成进程后才能实现。 等待时间最大!=带权周转时间最大，只是成正相关。 有可能造成饥饿的算法：SJF,SPF,SRTN,抢占式的静态PSA和MFQSA。 交互式糟糕的算法：FCFS,SJF,HRRN，交互式好的算法：RR,PSA,MFQSA"},{"title":"设备独立性软件","path":"/wiki/操作系统笔记/设备独立性软件/index.html","content":"I/O软件层次结构 从上图我们可以从总体上看出一个I/O设备相应请求时的全过程，分别经过了以下几个过程。 用户层软件 用户层软件实现了与用户交互的接口，用户可以直接使用该层提供的、与I/O操作相关的库函数对设备进行操作。比如库函数提供的printf()函数，他会被翻译成等价的write系统调用，用户层软件会在系统调用时填入相应参数，这样就可以通过系统调用的方式实现I/O请求。 windows操作系统会向外提供一系列系统调用，但是由于系统调用的格式严格，使用麻烦，所以在用户层上封装了一系列更加方便的库函数接口供用户使用就比如C库等。 设备独立性软件 又称为设备无关性软件，因为与设备的硬件特性无关的功能几乎都在这一层实现。他有以下几个功能： 向上层提供一些统一的调用接口（如read/write系统调用） 原理类似于文件保护，设备被看成是一种特殊的文件，不同用户对各个文件的访问权限不一样。同理也就实现了对设备的访问权限不同，保护设备不会被恶意文件修改 差错处理，设备独立性软件需要对一些设备的错误进行处理。 设备的分配与回收 数据缓冲区的管理，可以通过缓冲技术屏蔽设备之间数据交换单位大小和传输速度的差异 建立逻辑设备名到物理设备名的映射关系，根据设备类型选择调用相应的驱动程序。用户和用户层软件发出I/O操作相关系统调用的时，需要指明此次要操作的I/O设备的逻辑设备名。设备独立性软件通过“逻辑设备表（LUT，Logical Unit Table）”来确定逻辑设备对应的物理设备，并且找到该设备对应的设备驱动程序。 操作系统可以采用两种方式管理逻辑设备表LUT： ①整个系统就设置一张LUT，这就意味着所有用户不能使用相同的逻辑设备名，因此这种方式只适用于单用户操作系统。 ②为每一个用户都设置一个LUT，这样各个用户使用的逻辑设备名可以重复，适用于多用户操作系统，系统在用户登录时为其建立一个用户管理进程，而LUT就存放在用户管理进程的PCB中。 思考：为什么不同的设备需要不同的设备驱动程序？ 我们前面提到过，不同的厂商提供的设备信号规则不同，有的厂商对于生产的设备0代表空闲1代表忙碌，但是有的厂商生产的设备0代表忙碌1代表空闲。所以根据不同的信号需要正确识别信息，而这些不同设备的内部硬件特性只有厂商才知道，所以厂商需要提供与设备的对应的驱动程序，这样cpu才能够正确执行驱动程序的指令序列，来完成设置设备寄存器，检查设备状态等工作。（如果你不能够理解，那么就以这个例子为比喻：你通过介绍人录用了一个外国小伙当你的公司总监，但是你们之间的语言不通所以你无法知道他所返还的信息，所以介绍人在介绍外国小伙的同时还需要提供一个中间翻译即设备驱动程序，他能够为你们两个之间的信息交流提供翻译桥梁）。 设备驱动程序 设备驱动程序主要负责对硬件设备的具体控制，将上层发出的一系列命令（如read/write)转换成特定设备“能够听懂”的一系列指令操作，包括设置设备寄存器，检查设备状态等。不同的I/O设备有不同的硬件特性，具体细节只有设备的厂家才知道，因此厂家需要根据设备的硬件特性设计并提供相应的设备驱动程序。 中断处理程序 当I/O任务完成后，I/O控制器会发送一个中断信号，系统会根据中断信号类型找到相对应的中断处理程序并执行。中断处理程序的流程如下： 所以我们以一个I/O请求任务为例分别经过一下啊几个阶段才能够完成这次任务相应： 用户通过用户层软件提供的库函数发出的I/O请求 用户层软件通过“系统调用”请求设备独立性软件层的服务 驱动程序向I/O控制器发出具体命令 等待I/O设备完成的进程应该被阻塞，因此需要进程切换，而进程切换必然需要中断处理 总结 I/O软件各个层次之间的顺序要理解，要能够推理判断出某个处理属于哪个层次，通常直接涉及到硬件具体细节。且和中断无关的操作肯定是在设备驱动程序层完成的，没有涉及到硬件。对各个设备都需要进行的管理工作都是在设备独立性软件层完成的。 I/O核心子系统 I/O核心子系统是属于操作系统内核的一部分，所以肯定涉及到了调度，设备保护还有互斥等问题，下面就详细介绍这几种功能的具体实现 功能所属层次 我们知道这些功能都是由I/O核心子系统实现的，并且I/O核心子系统是由设备独立性软件、设备驱动程序、中断处理程序三个层次组成的，所以理论上这些功能肯定都是属于这三个层次。 但是实际上假脱机技术即SPOOLING技术（前面讲过是一种解决死锁的方法，即让个进程都产生这个临界区是自己的从而实现临界资源共享打破互斥条件来解决死锁）需要请求“磁盘设备”的设备独立性软件的服务，因此一般来说假脱机技术是在用户软件成实现的，但是408大纲又将假脱机技术归为了“I/O核心子系统”的功能，所以这里我们也认为假脱机技术是I/O核心子系统的功能。 I/O调度 与进程调度类似，I/O之间肯定也是需要有调度算法的，毕竟I/O设备就那么多，进程之间肯定是需要等待轮流使用I/O设备的。我们这里实际上已经学过了一些I/O调度算法，比如磁盘调度算法(FIFO算法，最短寻道优先算法，SCAN算法，C-SCAN算法， LOOK算法，C-LOOK算法等)。当多个磁盘I/O请求到来时，用某种调度算法确定满足I/O请求的顺序。同理打印机等设备肯定也有类似的FIFO，优先级算法，短作业优先等算法来确定I/O调度顺序。 设备保护 操作系统需要实现文件保护功能，不同的用户对各个文件有不同的访问权限（如：只读、读和写等）在UNIX系统中，设备被看作是一种特殊的文件，每个设备也会有对应的FCB（文件控制块，存储文件在磁盘中的相关信息）。当影虎情趣访问某个设备时，系统会根据FCB中记录的信息来判断该用户是否有相关的访问权限，以此实现“设备保护”的功能。 总结 这里只是介绍了部分简单的功能，下面将逐一介绍比较复杂的功能。 假脱机技术（SPOOLING技术） 产生的原因 在手工操作阶段主机直接从I/O设备获得数据，由于设备速度慢，主机速度快，人际速度矛盾明显，主机需要浪费很多时间来等待设备。而在批处理阶段，就引入了假脱机技术，缓解了cpu与慢速I/O设备之间的速度矛盾，另一方面，即使cpu在忙碌，也可以提前将数据输入到磁带，技术速度慢的输出设备正在忙碌，也可以提前将数据输出到磁带。 输入井和输出井 假脱机技术又称为&quot;SPOOLING技术&quot;，使用软件方式模拟脱机技术，SPOOLING系统的组成如下： 这样主机就不在需要长时间等待输入了，而是直接从磁盘即输入井中拿取数据，而慢速的技术输入就是将数据放入到磁盘中，这样就类似于吃自助餐，服务员（用户层软件）将数据直接提前放到餐台（磁盘）上，而餐客（设备）需要数据时就直接从餐台上拿取相应的数据了，输出亦是如此，这样就减少了长时间的数据等待时间了。 输入/输出缓冲区 实际上就是上面所讲的餐台。 共享打印机原理 这个就是我们之前讲的实现数据区共享以防止死锁的技术应用。 独占式设备：只允许各个进程串行使用设备，一段时间内只可以满足一个进程的请求。 共享设备：允许多个进程“同时”使用设备（宏观上是同时使用，实际上微观上是交替使用，即并发使用）可以满足多个进程的使用请求。 当多个用户进程提出要输出打印的请求时，系统会答应他们的请求，但是并不是真正把打印机分配给他们，而是由假脱机管理进程为每个进程做两件事： 在磁盘输出井中为每一个进程分配一个空闲缓冲区（也就是说，这个缓冲区是在磁盘上的），并将要打印的数据送入其中。 为用户进程申请一张空白的打印请求表，并将用户的打印请求填入表中（其实就是用来说明用户的答应数据存放位置等信息的），再将该表挂载到假脱机文件队列上。 当打印机空闲时，输出进程会从文件队列的队头取出一张打印请求表，并且根据表中的要求将要打印的数据从输出井传送到输出缓冲区，在输出到打印机进行打印。用这种方式可依次处理完全部的打印任务。 因此假脱机文件队列实际上就是打印任务队列，假脱机技术(SPOOLING技术)可以把一台物理设备虚拟成逻辑上的多台设备，可将独占式设备改造成共享设备。 总结 设备的分配与回收 设备分配时应考虑的因素 设备的固有属性可以分为三种： 独占设备：一个时段只能分配给一个进程（如打印机） 共享设备：可同时分配给多个进程使用（如磁盘），各进程往往是宏观上同时共享使用设备，而微观上是交替使用，即并发性的特点。 虚拟设备：采用SPOOLING技术将独占设备改造成虚拟的共享设备，可同时分配给多个进程使用（如采用SPOOLING技术实现的共享打印机） 设备的分配算法：FIFO,优先级算法，短作业优先SJF等。 从进程的安全性上考虑，设备分配有两种方式： 安全分配方式：为进程分配一个设备后就将进程阻塞，本次I/O完成后才将进程唤醒。这样一个时间段内每个进程只能使用一个设备，优点是破坏了请求和保持条件，不会死锁，缺点是对于一个进程来说，cpu和I/O设备只能串行工作，效率较低。 不安全分配方式:进程发出I/O请求后，系统为其分配I/O设备，进程可以继续执行，之后还可以发出新的I/O请求，只要某个I/O请求得不到满足时才将进程阻塞。这样一个进程可以同时使用多个不同的I/O设备，优点是进程的计算任务和I/O任务可以并行处理，是进程迅速推进，缺点是有可能发生死锁（死锁避免，死锁的检测和解除来解决此问题）。 静态分配和动态分配 静态分配：进程运行前为其分配全部所需资源，运行结束后归还资源，破坏了请求和保持条件，不会发生死锁。 动态分配：进程运行期间动态申请设备资源，但是可能会发生死锁。 设备分配管理中的数据结构 一个管道可以控制多个设备控制器，每个设备控制器可以控制多个设备。其中每个层次都会有自己的信息表如下： 设备控制表（DCT） 在进程管理中我们知道系统会根据阻塞原因的不同，将进程PCB挂到不同的阻塞队列中。因此设备队列的队首指针指向的一定是因为等待这个设备而导致阻塞的PCB队列。 控制器控制表（COCT） 每个设备控制器都会对应着一张COCT，操作系统会根据COCT的信息对控制器进行操作和管理。 通道控制表（CHCT） 每一个通道也都会对应着一个CHCT，操作系统会根据CHCT的信息对通道进行操作和管理。 系统设备表（SDT） 记录了系统中全部设备的情况，每一个设备对应一个表目。 设备分配的步骤 根据进程请求的物理设备名查找SDT（注意物理设备名是进程请求分配设备时提供的参数） 根据SDT找到DCT，若设备忙碌则将进程挂到设备等待队列中，不忙碌则将设备分配给进程 根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列，不忙碌则将控制器分配给进程。 根据COCT找到CHCT，若通道忙碌则将进程PCB挂到控制器等待队列，不忙碌则将通道分配给进程。 只有设备、控制器、通道三者都分配成功时，这次设备分配才算成功，之后便可以启动I/O设备进行数据传送了。 有没有什么缺陷？如何解决？ 有，我们发现进程请求时需要提供“物理设备名”，但是底层细节对用户不透明，不方便编程，因此如果一旦换了物理设备，那么这个程序就无法运行了，并且如果进程请求的物理设备正在忙碌，那么即使系统中还有同类型的设备，这个进程也会阻塞等待。改进方法就是建立逻辑设备和物理设备之间的映射机制，用户编程时只需提供逻辑设备名。 设备分配步骤的改进 根据进程请求的逻辑设备名查找SDT（注意物理设备名是进程请求分配设备时提供的参数） 根据SDT找到DCT，若设备忙碌则将进程挂到设备等待队列中，不忙碌则将设备分配给进程 根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列，不忙碌则将控制器分配给进程。 根据COCT找到CHCT，若通道忙碌则将进程PCB挂到控制器等待队列，不忙碌则将通道分配给进程。 逻辑设备表LUT建立了逻辑设备名和物理设备名之间的映射关系，当某个用户进程第一次使用设备时使用逻辑设备名向操作系统发出请求，操作系统会根据用户进程指定的设备类型（逻辑设备名）查找系统设备表，找到一个空闲设备分配给进程，并在LUT中增加相应表项。如果之后用户进程再次通过相同的逻辑设备名请求使用设备，则操作系统会通过LUT表即可知道用户进程实际要使用的是哪个物理设备了，并且也能知道该设备的驱动程序入口地址了。但是我们前面也讨论过：如果整个系统就一张LUT，那么各个用户所使用的逻辑设备名不允许重复，适用于单用户操作系统，而每个用户都拥有一种LUT，那么不同用户的设备逻辑名可以重复，使用于多用户操作系统。 总结"},{"title":"时序逻辑电路","path":"/wiki/数字逻辑与数字系统笔记/时序逻辑电路/index.html","content":"时序逻辑电路 时序逻辑电路的输出由当前时刻的输入和之前时刻的输入共同决定的逻辑电路。也就是说时序逻辑电路内部具有记忆性。其中时序逻辑电路有以下概念： 状态：用于解释电路未来所需要的信息 锁存器和触发器：用于存储1比特状态的模块 同步时序逻辑电路：一类由组合逻辑电路和一组电路状态的触发器所构成的电路 思考:时序逻辑电路的特征？ 时序逻辑电路是按照一定输入和输出时序实现的功能电路模块，它具有记忆性，并且输出与输入之间具有反馈电路，如下图： 时序逻辑电路和组合逻辑电路最大的一个区别就是组合逻辑电路输入和输出之间没有反馈回路，即输出永远只能受输入影响。而在时序逻辑电路中输入和输出之间是可以有反馈电路的，这也就是说明在时序逻辑电路中，输出信号反过来是可以影响输入信号的。 存储电路状态的模块 电路中的状态会影响电路未来的行为，而下面是一些常见的可以存储电路状态的模块： 双稳态电路 SR锁存器 D锁存器 D触发器 我们可以理解为触发器是锁存器的一个改良模块。那么接下来我们分别来详细了解一下各个存储电路状态的模块的具体功能实现。 双稳态电路（bistable) 首先双稳态电路是其他存储模块的基础，其他的存储电路状态的模块都是根据双稳态电路衍生而来的。如下图是常见的双稳态电路图： 我们可以看出双稳态电路有以下几个特点： 对称性：即电路总是对称的，有一个对称轴，对称轴两侧的电路元件相同 有两个输出：Q和非Q 没有输入 我们分析一下双稳态电路是如何稳定存储电路的1比特状态的。首先我们知道电路理论上只有两种状态即1和0，因此我们想要Q和非Q可以稳定存储这两个状态。那么假设此时Q存储的是0，那么很明显非Q可以很稳定的存储1，并且反过来他又会影响Q的输入从而维持Q稳定存储0状态，因此两者相互影响从而实现稳定存储电路的0和1两个状态。同样的，假设Q存储的是1，那么不难看出此时非Q也会稳定存储0状态。 因此双稳态电路可以稳定存储电路的0和1两种状态。但是我们发现双稳态电路存在一个缺陷，即改电路没有输入端，因此我们无法认为的控制电路中状态的存储，也就是说当一个双稳态电路模块在制作完成后就已经确定了两个输出端存储的电路状态了不能再改变，这很不好。 SR锁存器（Latch) 为了解决双稳态电路的这一缺陷，因此改良产生了SR锁存器，如下图： 此时就是在双稳态电路中加入了R和S两个输入端，同时门元件换成了或非门，因此在SR锁存器中： 总是存在两个输入端用来输入激励信号 两个输出端用来输出存储的电路状态 此时我们同样分析一下SR锁存器的功能实现，我们发现有以下四个不同的状态。 状态一：置位（SET） 当S=1,R=0时，那么此时SR锁存器的状态稳定为： 即Q永远存储的是1，而非Q永远存储的是0，此时这种状态我们称之为置位。 状态二：复位（RESET） 当S=0,R=1时，那么，此时SR锁存器的状态稳定为： 即Q永远存储的是0，而非Q永远存储的是1，此时这种状态我们称之为复位。 我们形象的记忆：首先SR锁存器的这两种状态输入端和对应的输出端信号状态总是相反的，同时S=1（SET=1)是置位，R=1（RESET=1)是复位。 状态三：保持态 当S=R=0时，那么次此时我们既没有置位，也没有复位，此时Q和非Q的值会保持之前的状态。我们先看一下保持态的图： 我们不难看出当S=0,R=0时，上面的Q和非Q的两种状态是都有可能出现的，那么何时出现的是左侧的图，何时出现的是右侧的电路状态呢？这取决于在保持态出现之前的状态，加入，保持态出现之前是置位态，那么切换到保持态时就会稳定成右侧的状态图，若保持态出现之前是复位态，那么切换到保持态后就会维持成左侧的状态图。因此保持态实际上就是时序逻辑电路中最能体现具有记忆性特点的状态。 状态四：非稳态 这种情况一般出现在S=R=1时出现，他是一种非稳态会导致输出端出现随机的状态，因此一般是避免的： 我们发现虽然S=R=1时确实电路状态维持成了Q=非Q=1的状态，当时当切换成其他状态时就会出现Q和非Q不可预测的情况。因此这种状态称为非稳态，他并不是指自身不能稳定，而是值切换到其他状态时会导致不稳定的输出状态，因此称为非稳态，一般我们要避免这种情况出现。 四个状态总结 SR锁存器是一个基于双稳态电路衍生改良出现的可以存储1比特电路状态的功能模块，其中两个输入端S表示置位（Set)，R表示复位（Reset) 通过控制S和R的信号输入，我们可以控制切换SR锁存器的输出稳定状态（这是比双稳态电路优秀的地方）： Set置位:S=1,R=0-&gt;Q=1 Reset复位：R=1,S=0-&gt;Q=0 保持：S=R=0-&gt;使Q和非Q维持保持态之前的状态 非稳态：S=R=1，禁止出现 上图是一个SR锁存器的状态波形图，他展示了输入不同的激励信号S和R后产生的状态切换过程。我们可以假设一开始初始状态为0，那么初始时S=R=0，也就是保持态，因此Q维持为初始态0，当S=1时，此时R=0，切换成为了置位态，因此Q变成了1，然后S又变成了0，那么此时又处于S=R=0的保持态，但是此时保持态会维持之前的置位态的输出，因此此时Q=1，然后R=1，此时S=0因此切换成了复位态，因此Q复位成0，然后R又变成了0，此时S=R=0，因此电路又变成了保持态，因此Q又维持复位态的输出，即Q=0。我们从上面的过程可以直观的感受到SR锁存器的强大的存储状态的功能，同时我们还可以看到上面的过程中总是保证了S和R只有一个为高电平，从而避免了非稳态的出现。 D锁存器 D锁存器同样是一种可以存储电路状态的功能模块，他的电路符号如下图: D锁存器的特点是包含了两个输入端CLK和D，CLK控制存储器状态发生改变的时间，D是数据输入端，控制下一个状态的值。 实际上CLK可以更加形象的理解为使能端，当CLK=1时，那么Q跟随输入端D随时变化，即D锁存器此时可以看成是透明不存在的，此时就是一个组合逻辑电路的特点，输出随时跟随输入端变化， 但是当CLK=0时，那么Q就维持之前的状态，即类似于SR锁存器的保持态，此时输出端并不会跟随D改变，因此体现了“锁存”的特点，是时序逻辑电路具有记忆性特点的体现。其具体的功能实现： 我们不难看出实际上D锁存器是在SR锁存器的基础上进行改良的版本，他的主要优点是即实现了与SR锁存器相同的置位、复位、保持功能，同时还避免了非稳态的出现，更加安全。也就是此时D锁存器只有三个状态，没有了非稳态： 注意此时D同时实现了复位和置位两种状态，当D=1时实现的是与SR锁存器相同的置位功能，D=0时实现的就是与SR锁存器相同的复位功能，而CLK主要是用来切换保持态的。 我们同样可以分析一下他的波形图： 如上图，初始时CLK为0，因此此时是保持态，Q保持为初始态0，因此当D升为1以后由于此时CLK=0，因此是保持态，Q不会跟随D发生变化，当CLK变成1以后，D同时为1时，Q才会跟着变成1信号。 D触发器（Flip-flop) D触发器实际上并没有相较于D锁存器有什么改进，因为D锁存器已经很完美了，D触发器只是另一种不同的状态切换方式的模块。D触发器的电路符号如下图: 注意D触发器和D锁存器的电路符号的区别，D触发器多了个下三角符号。为了更加明显的区分两者，使用右侧的符号更好。 D触发器的特点是包含两个输入端CLK和D，实际上和D锁存器一样。 但是D触发器的功能即状态切换与D锁存器不太一样，首先D触发器同样是有三个状态。但是只有在CLK的上升沿才会对D进行采样，即只有当CLK的信号从0到1的瞬间过程，Q被修改为当前时刻D的值，其他时刻Q都处于保持状态。也就是说Q只会在CLK上沿的时刻可能发生信号值的改变。 主从式D触发器的实现电路如下图： 可以看到D触发器是通过两个D锁存器实现的。两个D锁存器L1和L2顺序串联，同时有一组相反的时钟信号所控制。 当CLK=0时 主锁存器L1是透明的 从锁存器L2是不透明的 因此N1跟随D发生变化，但是Q和非Q不会跟随N1变化 当CLK=1时 主锁存器L1是不透明的 从锁存器L2是透明的 从锁存器的状态跟随N1变化，即此时N1不跟随D变化，但是Q和非Q会跟随N1变化 因此一个完整的Q跟随D变化实际上是上面两个过程的结合体，也就是在时钟的上升沿（CLK从0-&gt;1）时刻，完成一次Q被D赋值的功能 同样的我们分析一下他的状态波形图： 起初CLK是0，因此是保持态，即Q（触发器）此时是初始态1，而当CLK处于第一次上升沿时由于此时D=0，而Q（触发器）处于1与D不同，因此Q（触发器）变成0，而Q（锁存器）同样也变成0是因为最终CLK会处于1状态，那么Q（锁存器）就可以更改Q跟随D取值。但是当CLK还保持为1的同时，D变成1的时候我们可以看到此时D触发器和D锁存器的输出端发生了不同的情况，对于Q（触发器）由于此时CLK=1，因此Q还可以跟随D变化，因此Q（锁存器）变成了与D相同的1状态，但是此时触发器由于CLK一直稳定为状态1而不是上升沿，因此此时Q（触发器）不发生变化还维持0。因此我们可以总结出D锁存器和D触发器还是有区别的，即D触发器中CLK=0或是CLK=1时都是保持态，这是和D触发器最大的不同。 寄存器 寄存器可以存储CPU暂时不需要的信息，那么寄存器是如何实现的呢？实际上一个N为寄存器就是由一个共享的CLK输入和N个D触发器组成的，如下图： 由于此时N个D触发器共享一个CLK，因此寄存器的N个D触发器肯定是同时更新数据的，并且只有在CLK处于上升沿的时候才能更新数据，寄存器的所有位同时被更新，这是大多数时序逻辑电路中的关键组件。 思考：为什么寄存器要设置成N个D触发器共享一个CLK？ 我们知道寄存器一般存储的是一个N为二进制数据，那么很明显这个数据是一次性存储到寄存器中的，因此数据的每一位同时存储到寄存器的一个D触发器当中。 带使能端的D触发器 实际上就是在D触发器的基础上有添加了一个使能端EN如下图： 使能端EN是用来控制D是否能被触发器存储的，此时功能是： EN=1时且在时钟上升沿时，Q才能被更新为当前D的值 EN=0时即使时钟处于上升沿，Q也不能更新为D的值 因此只是相较于D触发器又增加了一个条件使得Q更新为D值的条件更加苛刻了。 带复位功能的D触发器 我们思考一个问题，前面我们学习D触发器的时候，学习到D=0且CLK处于上升沿时可以将Q置位0，即类似于SR锁存器的复位功能，但是我们发现D触发器想实现这个功能条件过于严苛了，需要同时满足D=0且CLK处于上升沿，我们想改进为D=1时也可以对Q进行恢复为0的复位功能，此时就产生了带复位功能的D触发器。如下图： 此时Reset=1时，那么无论D是何值，都可以将Q强制设置为0，Reset=0是就是正常的D触发器，此时我们又可以将带复位功能的D触发器分类为同步复位和异步复位： 同步复位：只在CLK处于上升沿时可以进行复位 异步复位：只要Reset信号为1有效，那么无论CLK是否处于上升沿都可以进行复位 带置位功能的D触发器 同样的，我们也可以类比得到带置位功能的D触发器： 当Set=1时无论D取何值，Q都被强制设置为1，当Set=0时D触发器正常工作。同样的也有同步置位和异步置位的区分。 非稳态电路 非稳态电路是一种特殊的时序逻辑电路，他的特点是输出端不稳定，会发生周期性的翻转变化，如下图是一个非稳态电路： 此时这个电路是一个具有回路的，且输出端会反馈到输入端的时序逻辑电路，我们分析一下可以轻松的发现输出结果会发生周期性的翻转变化，即X,Y,Z不断的在0和1信号之间切换，此时他们的波形图是： 上面的这种非稳态电路可以应用为环形振荡器。 同步时序电路 对于上面的这种非稳态的时序逻辑电路，我们在信号传播的途径中插入寄存器来断开电路中的环路，此时就会使得电路变成一个组合逻辑电路和寄存器的集合体，也就是同步时序逻辑电路。他的特点是： 寄存器包含着系统的下一个要切换的状态 状态仅在时钟边沿（注意上升沿或者下降沿都可以）到达发生变化，也就是状态同步于时钟信号 如果时钟足够慢，使得在下一个时钟沿到达之前，输入到寄存器的信号都可以稳定下来，那么所有的冒险都将会被消除 一个同步时序电路包含一组有限的离散状态{S0,S1,…,Sk-1} 同步时序电路有一个时钟输入 上升沿表示电路状态转变发生的时间，其中涉及到两个状态 现态：当前系统的状态 次态：下一个时钟沿后系统将进入的状态 同步时序逻辑电路的功能主要是描述当前状态和输入的各种组合对应的下一个状态与输出的电路，他需要明确建立时间和保持时间。这样每隔一个CLK就会自动切换到下一个给定输入所对应的输出状态。组成一个同步时序逻辑电路需要满足以下规则： 电路中的模块或者是寄存器或者是组合逻辑电路 模块中应该至少包含一个寄存器 所有的寄存器都共用一个时钟信号 电路的每个环路中至少包含一个寄存器 其中常见的两个同步时序逻辑电路是有限状态机（FSM）和流水线 下面我们看一下一个最简单的同步时序逻辑电路模块： 一个D触发器本身实际上就是一个最简单的同步时序逻辑电路，它包含一个输入D，一个时钟信号CLK和一个输出Q，同时也具有两个离散的不同状态{0,1}，并且D触发器下一个状态就是D，Q就是当前状态,，而D触发器本身就是一个寄存器。 思考：下列哪些电路是同步时序电路？ 对于上面的CL符号表示逻辑电路，因此上面的这些电路模块中，只有4,5是同步时序电路，其他的模块之所以不是同步时序逻辑电路的原因是： 1：就是一个组合逻辑电路，肯定不是时序逻辑电路更不是同步时序逻辑电路 3：注意那个不是D触发器，而是D锁存器，所以不是 6：没有D触发器 7：如果三个clk是共享一个时钟沿那么就是同步时序逻辑，否则就不是 所以同步时序逻辑电路就是一个在组合逻辑电路基础上增加了记忆组件触发器的电路系统，并且还要求所有的触发器的时钟沿共享一个时钟输入。正式由于拥有了记忆组件D触发器，才能实现时序逻辑的当前输出由当前输入和以前输入共同决定的特点。 思考：时序逻辑电路到底有没有回路？ 都可以，有没有回路都是可以的，只是有回路时更加复杂，此时的时序逻辑电路不仅输出由当前输入与以前输入决定，而且当前输入也由当前的输入与之前的输出共同决定。只要有组合逻辑电路+D触发器那么就是一个时序逻辑电路。当所有clk共享一个时钟输入时就是同步时序逻辑电路，否则就是异步时序逻辑电路。 异步时序电路 非同步时序电路就是异步时序电路，很明显异步时序电路并不需要在特定的CLK变化沿时才可以切换电路状态，而是只要满足条件就可以切换。这种系统的时序不受时钟控制的寄存器所约束的异步时序电路实际上在实际应用中更加广泛。但是实际生活中，所有的系统本质上都是同步的，因为同步时序电路比异步时序电路更容易设计实现，最典型的就是CPU中切换线程时的RR（时间片轮转方法）。虽然不是最优情况，但是在最低的实现成本情况下可以实现较优的策略。"},{"title":"建模方法拓展与测试","path":"/wiki/数字逻辑与数字系统笔记/建模方法拓展与测试/index.html","content":"结构化建模 结构化建模也称为层次化建模，特点是将一个比较复杂的数字逻辑电路划分为多个子模块，再分别为每一个子模块建模，然后将这些子模块组合在一起，完成所需要的电路。因此，结构化建模描述了一个模块是怎样由简单的模块组成的。 其中根据建模的过程分为自顶向下的设计和自底向上的设计，两者只是在模块构建逻辑上有所差异，但是最终达到的效果是一样的。 我们以一道例题体会一下结构建模，比如我们要将3个2-1多路选择器组合成一个4-1多路选择器。我们可以轻易写出2-1多路选择器的建模形式： 因此接下来我们只是需要用适当的方式自底向上组成4-1多路选择器。因此在4-1多路选择器的建模过程中需要引入二路选择器的实例组件。假设我们现在已经得到了4-1多路选择器的结构图如下： 思路很简单，sel[0]用来决定lowmux和highmux的两个二路选择器的选择信号，sel[1]充当finalmux的选择信号。因此lowmux和highmux分别都有2种可能输出的信号，而finalmux又决定了选择lowmux或者highmux的其中一个输出信号，因此又有2中选择，因此一共有2*2=4可能选择的情况，刚好和4路选择器的功能一致。接下来我们只需要根据上图进行建模了： 123456789module mux4(input logic D0,D1,D2,D3,input logic [1:0]s,output logic y);\tlogic low,high; //使用2路选择器模块进行实例化\tmux2 lowmux(D0,D1,s[0],low);\tmux2 highmux(D2,D3,s[0],high);\tmux2 finalmux(low,high,s[1],y);\tendmodule 我们发现实际上结构化建模和java的类的使用很相似，就是使用已经建模完成的模块来组装更加高层次复杂的结构化模块。 模块实例化 在结构化建模中，父模块对子模块的调用通过模块实例化实现，其格式如下： 1模块名 实例化名 （信号列表） 模块名：定义子模块时，紧跟在module关键字后面的名字，例如上例中的mux2 实例化名：父模块为所调用的子模块命名的名称，是该子模块的唯一标识，例如上例中的lowmux,highmux和finalmux 信号列表：父模块与子模块之间端口信号的关联方是，用于实现子模块与父模块的通信。通常有位置关联法和名称关联法。 位置关联法就是我们通常上理解的使用函数是传参的格式，即实例化模块时，按照子模块定义时端口出现的顺序建立端口的连接关系。例如： 123//mux2定义的形式module mux2(input logic D0,D1,intput logic [1:0]s,output logic y);mux2 lowmux(D0,D1,sel[0],low) 那么D0就是mux2模块的第一个形参关联的端口参数，D1就是第二个。 但是由于在建模时可能一个模块有多达数十个端口信号，那么此时在使用位置关联法就很容易出现错误，因此还有一种名称关联法，就是实例化子模块时，直接通过名称显式建立子模块端口的连接关系，不考虑排列顺序（注意，此时所有的参数又要显式的声明和一个形参绑定）。如： 12345//mux2定义的形式module mux2(input logic D0,D1,intput logic [1:0]s,output logic y);//实例化一个mux2//注意实参写在形参后面的小括号后面 mux2 lowmux(.D0(D0),.D1(D1),sel(.sel[0]),y(.low)); 此时就与位置无关了，因为每一个实参端口信号都显式的和一个形参端口信号建立了连接。这种方法适用于端口信号很多的模块实例化中。 一定要注意对于名称关联法，形参在外，括号内是传进来的实参信号，同时形参前面有一个.。 接下来我们以mux4的两种实例化方法直接对比： 门级建模 门级建模是一种低层次的结构化建模方法，他通过调用SystemVerilog HDL提供的基本逻辑元件描述他们之间的连接，建立数字逻辑电路的模型。 门级建模可以理解为将逻辑电路图转化为SystemVerilog HDL描述的建模过程。门级建模只能用于描述组合逻辑电路，不能用来描述复杂的时序逻辑电路，这是因为门级建模使用的都是逻辑门元件。因此门级建模实例化的语句：‘ 1门级元件名&lt;实例名&gt;(端口列表) 其中实例名可以忽略不写，即为一个匿名门元件实例。一般常用到的门级元件有： 假设我们现在要使用门级建模构造一个mux2二路选择器，那么根据下面的图 我们可以建模: 1234567module mux2(input logic D0,D1,sel,output logic y)\tlogic a,b,sel_inv;\tnot N1(sel_inv,sel);\tand N2(a,D0,sel_inv);\tand N3(b,D1,sel);\tor(y,a,b);//注意实例名可以忽略endmodule 结构化建模总结 模块只能以实例化的方式嵌套在其他模块中（和java的外部类的实例化引用思路一样），嵌套层次是没有限制的，但是不能在一个模块内部使用关键词module和endmodule取定义另一个模块，也不能再always语句内部引用子模块。 实例化的子模块可以是一个在SystemVerilog文件中定义好的模块，或者是用别的HDL语言（例如Verilog,VHDL)设计的模块，还可以是IP（Intellectual Property,知识产权)核模块。 在一条实例化子模块的语句中，不能一部分端口用位置关联，另一部分用名称关联，即不能混用这两种方式建立端口之间的链接。 原则上在一个模块中可以使用行为建模和结构化建模，但是为了便于设计层次化、模块化，建议在一个模块中不要混用两种建模方式。 参数化建模 在SystemVerilog HDL中，参数化建模是指使用关键字“parameter&quot;声明一个标识符来代表一个常量，程序中凡是出现这个常量的位置，都可以用这个标识符来代替，从而大大增加了设计的灵活度和程序的可读性。参数化建模最常见的用法就是参数化建模，如下图： 左边的模块中定义了字符&quot;#&quot;同时声明为WITH代表位宽8，那么所有的[WIDTH-1:0]代表的都是一个位宽为8的线信号量，当我们需要修改时只需要修改定义语句即可完成对全部模块的相对应的位宽信号的修改。我们再看中间的模块和右侧模块定义的都是一个4路选择器，只是中间定义的是位宽为8的信号，那么当我们需要修改为32位宽时，只能手动逐一的对每一个[7:0]进行修改为[31:0]，这很麻烦耗时，而右侧的使用了参数化建模，所有的#只要定义为32位宽即可完成所有的信号的位宽更新，这就是参数化建模的优点。 我们可以将parameter语句置于模块内部，与参数化建模的区别是对模块化实例化时无法修改该参数的值。并且通过预编译指令`define(即宏定义指令)可以声明一个标识符来代表一个常量，通常位于模块外部，该常量是一个全局常量，其作用范围是从定义起点到整个程序的结束，既可以对多个文件起作用。这样parameter只能决定一个模块自身内部的信号的更新，而`define指令定义的是对多个模块起修改作用的全部常量语句，两者搭配，可以高效的完成所有文件的信号的更新操作。如下： parameter语句只对mux2内部的信号量起作用，而通过`define指令声明的WIDTH可以修改所有文件的信号位宽。同时要注意宏定义指令结尾处不需要分号。 generate语句 generate语句（即生成语句）可以动态的生成SystemVerilog HDL代码，可以大大简化程序的编写过程。generate语句结合参数化建模方法可以生成可变数量的硬件，此外，generate语句还可用于对向量信号中的多个位进行重复操作，或者对一个模块进行多次实例化，或者根据参数的定义来确定程序中是否应该包含某段SystemVerilog代码。 generate语句通过“generate…endgenerate&quot;来确定生成的代码范围，可以动态生成模块（实例化）、持续赋值语句（assign)、always过程块等内容。通常generate语句还可以和for,if和case语句组合使用。 如下图是generate生成一个由多个2路选择器组成的N路选择器的模块： 这里的几个注意事项见上图。 思考：为什么要用generate语句来包裹而不是直接调用for语句？ 在建模过程中，我们通常定义一个变量时都是定义为信号量，并且这个信号量是一个具体的确定值，但是我们分析上面的代码实际上x并不是一个信号量，他是一个由i决定的若干个信号量的一个抽象表示。具体生成多少个x信号量以及对于第i个信号量x的定义都需要由i来决定。同时a信号量也会再generate语句中多次使用表示不同的值。因此generate语句的引入是有必要的，当我们不使用generate语句包裹时，那么如果想创建10000个类似于x的相同作用的信号量，那么首先需要构建10000个不同名的信号变量值，这显然不现实。 SystemVerilog的测试程序 前面我们简单学习过仿真验证的概念，他是在线平台上通过模拟来对一个为构建的组合逻辑电路模块进行建模检测，查看是否完美符合预期功能。 电路验证是确认所设计的电路功能正确性的过程，而仿真是进行电路验证的主要手段，它可以及早发现所存在的设计问题，从而降低了设计风险，节约了设计成本。通常，仿真是通过编写测试程序完成的，测试程序也称为测试台，他是用于测试待测模块功能是否正确的一端SystemVerilog HDL代码，是不可综合的，由激励信号、DUT和输出响应三部分组成。 思考：什么是综合？ 综合是真正在组件一个模块元件时所必要的完成功能构建的语句。不可综合的语句一般是不用于完成元件功能的语句，在最终制造阶段舍弃，例如验证语句虽然在构建模块时进行编写，但是在测试完成后构建元件时，这部分代码不会被综合，不参与最终元件的功能实现中。 我们看一个测试程序的例子： 上面的代码就是用于验证的测试代码，它是用来测试一个数学计算模块是否正确的语句： 我们从上面的例子中不难看出我们分别测试的激励信号组合分别是： 也就是说每一次在验证时输入的信号是持续的，当改变信号时，只需要输入需要被修改的信号值即可，未被修改的信号是维持不变的。如上面的第一组激励信号测试组合为a=0,b=0,c=0并且持续时间为10个单位时间，然后我们修改了c的信号值为1，因此第二个激励信号组合为a=0,b=0,c=1并且测试时间也是10个单位长度。因为每一个激励信号的测试时间都是10个单位长度，因此最终屏幕上的输出脉冲为等宽。 测试程序的语句 首先我们可以总结出测试程序的模板如下： 123456module testbench_name //testbench为顶层模块，不会被其他模块实例化，因此不需要任何端口 //信号定义 //模块实例化，很重要，我们需要实例化一个待测模块 //添加激励信号 //显示输出结果（可以不添加任何显示打印语句，那么只生成波形图）endmodule 施加激励信号 在SystemVerilog中，施加激励就是想DUT添加输入信号（即测试向量），主要由三种方法： 通过initial过程过施加（线性）激励 通过always过程块施加（循环）激励，主要用于产生时钟信号（后面有一章专门介绍，这里不细讲）。 通过文件施加激励（比较人性化） 首先，通过initial块施加激励就和上图的那个例子一样，每一个仿真时刻只用列出需要改变的信号值，initial只执行一次改变语句。在一个测试程序中可以包含多个initial块，并且他们都是同时并行执行。 需要注意同一个initial块中的激励信号语句是串行执行的，initial块中的激励信号语句是并行执行的，并且在同一个仿真时刻避免为同一个信号赋予不同的信号值，否则将会冲突。 当通过文件施加激励时，只需要将激励（测试向量）存放在一个文本文件中，测试程序从文件中读取激励，对DUT进行测试。 这种方式更加高效，可以预先存储上万个不同的测试样例，测试验证时只需导入测试文件即可。 输出响应 在SystemVerilog中，输出响应是指在向DUT施加激励以后，通过观察DUT输出结果，并与预期结果进行比较，以验证电路是否正确。这个过程可以通过直接观测波形图或者借助SystemVerilog HDL提供的一系列系统任务显示输出结构来实现。毕竟有时候看图不好发现错误，那么可以打印输出信息。 在SystemVerilog中常用的系统任务包括： 系统任务 方法 获取仿真时间 $time，$stime,$realtime 显示信号值 $display,$monitor(常用) 结束/中断仿真 $finish,$stop 文件输入 $readmemb,$readmemh,$fopen,$fclose,$fdisplay,$fmonitor 文件输出 $fopen,$fclose,$fdisplay,$fmonitor 获取仿真时间的系统任务的返回值使用由`timescale宏定义指令声明的时间为单位时间，只是$time返回的是一个64位整数时间值，$stime返回的是32位整数时间值，$realtime返回的是一个实数时间值。例如： 1$monitor($time,&quot;a=%b b=%b c=%b y=%b&quot;,a,b,c,y); 一定要注意$time和$stime是会取整的，因此不是精确值，而$realtime返回的才是实数准确时间值。 对于显示信号值的系统任务$display和$monitor，相当有C中的printf函数，输出变量的值显示在控制台上，语法格式为 12$display($time,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$monitor($time,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;); 显示格式控制符有： %h %o %d %b %c %s %t %m 16进制 8进制 10进制 2进制 ASCII 字符串 时间 模块名 例如： $display和$monitor的区别在于前者只有执行到该语句时才进行显示操作，而后者就像一个监视器，只要输出变量列表中的某个变量发生变化，就执行一次显示操作，后者更加方便实用。 结束/中断仿真的系统任务包括：$finish和$stop两种，其格式如下： 1234$finish();$finish(n);$stop();$stop(n); 其中参数n可以取0,1等值，0表示不输出任何信息，1表示给出仿真时间。 在SystemVerilog HDL中文件输入不需要打开文件操作，直接读取文件即可，也有$readmemb和$readmemh两种，其中前者读取2进制数据，后者读取16进制数据，语法格式如下： 12$readmemb(&quot;数据文件名&quot;,数组(存储器)名,&lt;起始地址&gt;,&lt;结束地址&gt;);$readmemh(&quot;数据文件名&quot;,数据(存储器)名，&lt;起始地址&gt;,&lt;结束地址&gt;); 其中起始地址和结束地址也可以缺省。并且输入文件格式有以下细节： 可以使用&quot;_&quot;提高数据的可读性 可以包含单行或者多行注释 可以使用空格或者换行来区分单个数据 可以设定一个特定地质，规定其后的数据从该地址开始存储。地址必须是16进制，且不区分大小写，并且@和地址之间不允许有空格，即 1地址写法：@hex_addr 假设现在有一个输入文件如下： 现在我们打开这个文件： 那么最终我们读取文件到stim数组的地址数据如下图： 也就是前三个地址是连续的，然后从3-255是空缺的没有地址，然后从256（十六进制的@100）有一个单独的地址数据为1111_1100，然后257-1022又是空缺的，到达1023时再继续存储定义的地址。 文件输出操作需要首先用系统任务$fopen打开文件，然后通过系统任务$fdisplay和$fmonitor将需要的保存的信息输入到指定文件中。 例如现在要打开一个MCD文件： 12345int MCD;MCD=$fopen(&quot;文件名&quot;,&quot;操作模式&quot;);$fdisplay(MCD,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$fmonitor(MCD,&quot;显示格式控制符&quot;,&lt;输出变量(信号)列表&gt;);$fclose(MCD);//一定要记住关闭文件呀 $fopen是打开指定文件并且返回一个32位整数，如果打开失败了则返回0，操作模式为w,w+,a,a+。$fclose是关闭打开的文件，而$display和$fmonitor的用法与$display和$monitor的用法类似，区别在于不是将输出响应输出到控制台，而是将信息输出到文件中。 自动化测试 我们思考一下无论上面的那种测试方法，最终我们还是需要自己去对比输出结果是否正确，这对于上万个输出响应的测试程序来说，人工复查太难了，因此我们需要机器来自动帮助我们比对判断输出响应是否正确，因此就产生了自动化测试。 实际上自动化测试的过程和仿真验证类似，只是多了一步自动将输出响应和预期结果比对的过程。具体的写法见上图。 测试程序总结 测试程序由激励信号、待测模块DUT和输出响应三部分组成，其本身也是一个SystemVerilog代码(这很重要，需牢记)。并且是最顶层的模块，当没有端口，不可综合。 由于测试程序不会变为电路，因此在测试程序中可以使用所有的SystemVerilog语句。 为了便于复用和管理，测试程序可以通过文件施加激励。 进行验证时，尽量采用自动化对比方式，毕竟人工复查还是容易出错。 虽然观察波形图寻找错误开始时比较困难，但是习惯以后发现波形图能够帮助我们发现那些控制台输出不易察觉的问题。 以上的测试程序本质上都是对使用SystemVerilog HDL所编写的程序进行仿真测试，并没有考虑门延迟，线延迟等问题，因此也称为行为仿真或者前仿真，虽然行为仿真可以发现很多设计问题，但是并不意味着通过了行为仿真电路就一定没有问题了，后面还是需要进行大量的测试的。"},{"title":"常用逻辑器件","path":"/wiki/数字逻辑与数字系统笔记/常用逻辑器件/index.html","content":"复用器 复用器（多路选择器）是一种多输入单输出的组合逻辑电路，常用MUX来表示，具有k个数据输入端口的复用器，即为k:1复用器，数据输入端口数目k和选择控制器的数目n应该满足k&lt;=2nk&lt;=2^nk&lt;=2n。如下图： 复用器的功能就是当使能端有效时，根据选择控制端口的值从多个数据输入中选择一个送到输出端（每个数据输入端的宽度可以是1位或者多位）。我们可以使用SystemVerlog HDL进行建模。这里我们以4:1复用器为例，首先我们列出真值表： EN S1S_1S1​ S2S_2S2​ Y 0 X X 0 1 0 0 D0D_0D0​ 1 0 1 D1D_1D1​ 1 1 0 D2D_2D2​ 1 1 1 D3D_3D3​ 因此我们根据真值表可以使用卡诺图求解逻辑表达式，然后建模： 上面一个基于过程块的建模，实际上对照着真值表逻辑很容易想清楚。 译码器和编码器 实际上前面我们已经讲过了，这里复习一下。译码器是一种将输入翻译成特定输出信号（独热码）的组合逻辑电路，它具有n个输入端和m个输出端，满足m&lt;=2nm&lt;=2^nm&lt;=2n。因此即为n:m译码器。 译码器就是接受要输出信号的端口的编号，然后在对应的编号端口进行输出。他和多路选择不同，多路选择器是决定唯一的输出端和哪一个输入端电平信号相同，而译码器是翻译出哪一个哪一个输出端电平有效。 译码器功能：使能端有效时，对应每一组输入，仅有一个输入端为有效电平，其他均是无效电平，否则，所有输出端都是无效电平，如果有效电平是1，那么无效电平就是0。 同样的我们也可以使用SystemVerilog HDL对其建模，我们这里以2:4的译码器为例，首先我们也是列出真值表： 然后我们根据真值表进行建模： 虽然查看真值表建模的方法对于大型电路不适用，但是学习阶段我们完全可以参考真值表进行建模，而不用使用非常复杂的方法。 编码器是一种将特定输入（独热码）转化为一个编码输出的组合逻辑电路，是译码器的逆过程，具有m个输入和n个输出，因此需要满足的端口数量条件是m&lt;=2nm&lt;=2^nm&lt;=2n。 编码器功能是使能端有效时，用n位二进制码对m个输入中的当前有效信号进行编码输出，标志信号VALID有效（VALID信号用于标识所产生的编码是否合法），如果m个输入信号均无效或使能端无效，那么VALID信号无效，编码输出可以为任何值（一般为0）。 编码器是将多个输入信号中选出一个有效输入，然后输出端输出这个有效输入端的编码的二进制码。所以我们不难总结出译码器总是输入端少于输出端，而编码器输入端多于输出端。 我们也可以使用SystemVerilog HDL对编码器进行建模，同样先列真值表： 我们以4:2编码器为例，最终建模的代码是 思考：复用器，编码器和译码器的异同？ 首先他们都有一个使能端用来表示当前的输入端是否有效，复用器是多输入一输出，永远选择一个输入端，使得输出端的电平信号和输入端相同。编码器是多输入多输出，并且输入端多于输出端，输出端输出的是有效输入端的编号的二进制码。而译码器也是多输入多输出，但是输入端少于输出端，输出端对应的输入编号的信号的电平有效位1。 1位加法器 1位加法器是算术电路元件的一种，其中又分为半加器和全加器，但是这两者都是针对的二进制码的某一位的算术运算。 1位半加器 半加器有两个输入A和B，两个输出S和C_&#123;out&#125;​。S是A和B之和，C_&#123;out&#125;​本位产生的进位信号。如下图： 其实上面的加法并不全面，他没有考虑从自己的低一位传进来的进位信号，因此为半加器。我们可以看到上图右侧的公式就是S和C_&#123;out&#125;​的计算方法。A异或B决定的就是本位的填写数值，A与B就是进位信息，很明显只有A=B=1时才能产生有效进位Cout=1C_{out}=1Cout​=1 1位全加器 1位全加器在半加器的基础上增加了一个进位输入CinC_{in}Cin​,此时得到的才是一个通常意义上的一位加法，实际上这部分内容在《计算机系统基础》学习过了，这里就不再细讲计算原理。 多位加法器（CPAs) 一个N位加法器将两个N位输入（A和B）与一个进位C_&#123;in&#125;​相加，产生一个N为结果和一个输出进位C_&#123;out&#125;​。因为在N为加法器内部，一位进位将传播到下一位，所以这种加法器通常又称为进位传播加法器。 很明显多位加法器实际上就是由许许多多的一位加法器组合形成的，因此不同的组合形式会形成性能不同的多位加法器。这里分为了三种： 行波进位加法器（慢速） 先行进位加法器（快速） 前缀加法器（更快速） 对于高位宽的加法器，先行进位和前缀更具优势，但需要消耗更过的硬件资源（实际上就是空间换时间的思想），这部分内容实际上也在《计算机系统基础》中讲过，只不过那里讲的是组合形式的原理，这里我们会对比学习。 行波进位加法器 行波进位加法器实际上应用的就是我们之前学习的一位全加器的串行进位连接方式，如下图： 对比计算机组成原理的图： 两者是一样的原理表示。我们不难看出这种进位一级一级的从低位传输到高位的形式，当N较大时即很多位时，计算延迟也会非常大，即延迟量tripplet_{ripple}tripple​随着位数的增加而增加。 假设一个一位全加器的延迟为tFA,假设一个一位全加器的延迟为t_{FA}, 假设一个一位全加器的延迟为tFA​, 那么tripple=N∗tFA那么t_{ripple}=N*t_{FA} 那么tripple​=N∗tFA​ 因为第i位必须等待第i-1位的进位信号传进来以后才会进行计算。我们以一道例题分析： 上图是一个四个模块组成的算术逻辑电路，很明显总延迟取决于局部模块中延迟量最大的关键路径的延迟量之和，因此上图的延迟量为9T。 先行进位加法器 先行进位加法器是一种快速的进位传播加法器，他把加法器分解成若干块，当每块一有进位时就会快速确定此块内的所有加法器的进位信号，从而实现块内的位加法器并行计算，因此他不需要等待通过一块内的所有加法器，而是直接先行通过该块。因此原理是单级先行进位方式： 对比计算机组成原理的图： 具体的原理请看《计算机系统基础》，这里就不细讲了。 这里我们计算一下两者的延迟，假设对于32位行波进位加法器和4位块组成的先行进位加法器的延迟。假设每个输入门电路的延迟为100ps，全加器的延迟是300ps。 那么32位的行波进位加法器的传播延迟就是(此时没有门电路延迟，全是全加器延迟) tripple=N∗tFA=32∗300ps=9.6nst_{ripple}=N*t_{FA}=32*300ps=9.6ns tripple​=N∗tFA​=32∗300ps=9.6ns 而32位的先行进位加法器的传播延迟就是（此时只有4个全加器延迟加上7个进位信号的传播延迟） tCLA=tpg+tpg_bloack+(N/K−1)tANDOR+ktFAt_{CLA}=t_{pg}+t_{pg\\_bloack}+(N/K-1)t_{AND_OR}+kt_{FA} tCLA​=tpg​+tpg_bloack​+(N/K−1)tANDO​R​+ktFA​ =(100+600+7∗200+4∗300)ps=3.3ns=(100+600+7*200+4*300)ps=3.3ns =(100+600+7∗200+4∗300)ps=3.3ns 我们可以对比发现此时的先行进位逻辑电路要快了许多。 实际上他还可以更快速，因为此时低二CLA的C_4​还是必须等待最低CLA计算出来以后才可以计算，因此此时的C_&#123;12&#125;、C8C_8C8​、C4C_4C4​的不是并行产生的，因此我们可以再次提速，也就是计算机组成原理所讲的多级先行进位： 具体的讲解间计算机组成原理。 我们也尝试使用SystemVerilog HDL对多位加法器CPA进行建模，HDL提供了+运算符来描述多位加法器的CPA。EDA工具在满足速度要求的前提下会自动的从众多可能实现的方法中选择成本最低(逻辑门最少)的设计，因此我们只需要直接写出逻辑表达式即可，具体的哪一种计算组成形式由HDL来决定。下面是一个有进位输入/输出的CPA： 减法器 实际上减法只是特殊一点的加法而已，参考这篇《定点数的减法运算》以后我们知道减法运算实际上最终还是转换成了加法运算。即减法运算可以表示为 [A−B]补=[A]补+[−B]补=[A]补+[B]补‾+1[A-B]_补=[A]_补+[-B]_补=[A]_补+\\overline{[B]_补}+1 [A−B]补​=[A]补​+[−B]补​=[A]补​+[B]补​​+1 所以减法器就是对补码进行一定的转换以后调用加法器： 在计算机中所有的数据都用补码表示，因此计算机中是没有减法器的，加法和减法都是通过加法器实现，如下图： 当sub为0时，那么就是A+B，因此执行a+b,当sub为1时我们观察上图可以看出B走左侧的线路，他先经过了一个取反加一的过程，然后再和A相加，也就是a+~b+1实际上实现的就是减法运算，之所以b要取反加一是因为此时要从正数补码转化为负数补码。 比较器 比较器是判断两个N位二进制数A和B是否相等，或者一个比另一个大还是小，常见的有两种类型： 相等比较器，产生一个输出，表示A是否等于B（A==B) 数值比较器，产生一个或多个输出，表示A和B的关系（&gt;,&lt;)。 如下图： 我们同样可以使用SystemVerilog进行建模： 算术逻辑单元 算术逻辑单元是将各种算术和逻辑运算组合到一个单元模块中，典型的ALU算术逻辑单元可以执行加法、减法、量值比较、逻辑运算等，ALU是大多数计算机的核心。 F是三位，可以表示8中可能的运算方式，但是实际上011是没有用到的。这里我们给出ALU的模型图： 移位器和循环移位器 这部分内容实际上计算机系统基础也讲过，这里作为复习。我们主要是了解各种移位运算的方式： 逻辑移位器 将数据向左（LSL）或向右（LSR）移动指定位数，空出的位置补0。 11001&gt;&gt;2=00110 11001&lt;&lt;2=00100 算术移位器 算术左移（ASL）和LSL相同，算术右移（ASR）时使用数据的最高位(符号位)填充空位 11001&gt;&gt;2=11110 11001&lt;&lt;2=00100 循环移位器 循环移动数据，从一端移走位重新填充到另一端的空位上。 11001 ROR 2=01110 11001 ROL 2=00111 这里实际上也可以使用SystemVerilog HDL进行建模，N位移位器可以用N个N:1复用器构成： 左移时乘法一个特例，即A&lt;&lt;N=A*2N2^N2N 00001&lt;&lt;2=00100(1*222^222=4) 11101&lt;&lt;2=10100(-3*222^222=-12) 当然如果左移位数太多会造成溢出。 算术右移是除法的一个特例，即A&gt;&gt;N=A÷2N2^N2N 01000&gt;&gt;2=00010(8/222^222=2) 10000&gt;&gt;2=11100(-16/222^222=-4) 注意对于左移包含了算术左移和逻辑右移都是表示乘2，但是对于右移只有算术右移表示除以2的运算。 乘法和除法的具体运算实现请参考《定点数的乘法和除法》。估计太难，也不会考，这里给出乘法器的模型图： 他的SystemVerilog HDL建模的代码为："},{"title":"指令集体系","path":"/wiki/数字逻辑与数字系统笔记/指令集体系/index.html","content":"指令集体系结构 不同的处理器会有不同的指令集，但是无论是哪一种，最终要解决的问题就是兼容性问题，即可以使得一个软件在不同的系统上运行，我们在学习了OS后知道操作系统实际上就是一个服务软件，用来协调硬件系统和上层软件之间的合作运行。而指令集来充当一个服务的翻译官，使得不同的软件可以在可兼容的硬件系统中将运行的指令翻译为硬件系统可以识别的命令供处理器运行。因此一个软件可以运行在装配有不同intel处理器的个人电脑上，也可以同时运行在装配有不同ARM处理器的安卓手机上，实际上就是指令即完成的可兼容功能。因此通过指令集的可兼容功能，不同类型，不同品牌的硬件产品只要使用相同的指令集，就可以进行组合使用。 思考：操作系统和指令集体系结构谁更靠近底层？ 我们前面讲到了操作系统是本质上一个服务软件，因此他如果想在不同的硬件系统中进行运行，也需要可兼容性，因此需要指令集体系结构来实现翻译功能，因此指令集体系结构更靠近底层。 如上图是一个计算机不同层次的模块，可以看到指令集体系结构更靠近底层，因此他会向os提供服务。并且指令集体系结构属于硬件模块层次。 定义：什么是指令集体系结构？ 指令集体系结构（ISA，也称为指令系统），是对处理器硬件细节的抽象描述，即设计规范，他定义了处理器能够做什么，也是对系统级程序员所能看到的处理器的属性。 指令集体系结构之所以能够定义处理器能够做什么，是因为他为处理器提供最基础的命令，处理器只能组合使用指令集体系结构提供的指令来实现软件需要的功能。比如指令集体系结构提供了add功能，那么处理器才能识别并完成add功能。并且要注意指令体系结构不仅仅局限于指令功能的编码，他还包括一些其他的硬件机制。 下面这些功能也都属于指令集体系结构中： 软件就是使用指令集体系结构给出的规则恰当的使用硬件来完成功能。 拓展：ISA中的“五朵金花” 五大主流生产指令集体系结构的厂商，x86常用于桌面，arm，power常用于移动端设备,mips常出现于通信系统中。 其中MIPS指令集（无内部互锁流水级处理器）是最经典的RISC处理器，由斯坦福大学校长Hennessy领导的小组在1981年开始设计，MIPS的理念就是使用相对简单的指令，结合优秀的编译器以及应用流水线技术执行指令，从而使用更少的晶体管生产处更快的处理器。我们后面的实验就是要设计实现一个简单的MIPS指令集体系结构。 思考：指令集系统结构为什么很重要？ 通过层次图我们可以看到指令集体系结构起到了协调硬件与软件之间协调兼容的作用，只有硬件与软件使用同一套指令集体系结构，两者才能合作工作形成一个计算机。因此指令集体系结构是计算机产业的枢纽，连接着软件与硬件行业。 一个指令集体系结构并无好坏之分，但是明显被更多地区，行业广泛接受支持的指令集体系结构是更具有影响力的，当前最主流的计算机体系结构就是x86指令集体系结构，但是这并不能说明x86在功能上就一定是最好的isa，只是被更多的行业产商所接受。所以在设计软、硬件时生产商需要参考x86指令集体系结构来实现其在其他使用x86指令集体系结构应用的兼容性，所以指令集体系结构还是计算机软硬件的重要标准，当isa被更多人普遍接受，那么会被更多人所参考，也就逐渐形成了重要的行业标准。 并且指令系统决定了系统的性能和实现复杂性，例如RISC,CISC提供的指令复杂度不同，那么系统工作时的性能也会受到影响，再比如32/63位，媒体向量，向量指令等不同的ISA会采用不同的应用方式，也就决定了系统工作性能的高低。 微体系结构 微体系结构是指令集体系结构的一种具体硬件实现，如指令的数据通路结构，计算单元的电路结构（加法器等），存储器体系（寄存器文件、主存的结构）等等。 我们可以看到x86进一步拆分出了许多微体系结构，不同的微体系结构模块有不同的功能。 汇编语言 汇编语言就是从机器易于识别的机器语言到人能易于理解的高级语言的一个过渡语言，他能够使用标注符号（助记符）将高级语言简化成贴近机器语言的形式，更便于我们人来阅读理解机器语言的功能。 其中汇编语言包括汇编指令，伪指令（标签）、宏指令等。而机器语言仅仅是01编码。汇编语言可以将高级语言的复杂功能拆分简化，使得汇编指令和机器指令一一对应，然后汇编指令的不同搭配即可实现高级语言的功能。这里我们主要学习MIPS汇编指令，也就是学习MIPS指令集体系结构中的指令。 我们以加减法指令为例，学习一下汇编语言得基本格式： 1助记符 目的操作数 源操作数 助记符是用来区分不同的汇编指令的符号，目的操作数是计算输出数据最终的去向，源操作数是输入数据的来源。在MIPS指令集系统结构中设计的准则是 指令格式前后一致 操作数格式一致 易于在硬件编码和处理 因此MIPS仅仅包含了非常简单常用的指令，使得硬件编码和指令指令变得简单，短小和快速。但是同样对于复杂的指令操作就只能使用许多简单的指令搭配组合去实现，而intel的x86则引入了更加复杂功能强大的指令，这也导致了x86指令集体系结构的硬件阶码和指令执行速度慢于MIPS。因此MIPS为RISC(精简指令)，而intel的x86为CISC（复杂指令）。 在汇编操作中，以下三个形式可能是操作数： 寄存器（存储操作数） 存储器（存储操作数) 常数（立即数,自身就是操作数） MIPS32位寄存器 MIPS定义了32个32位的寄存器组成的寄存器文件，我们学习过OS和机组原理后知道寄存器的访问速度是要快于内存的，但是存储容量确是有限的，因此我们要尽可能的使得寄存器能够存储更多的数据。MIPS中的寄存器操作的数据宽度为32位数据，因此MIPS又被称为32位体系，这体现了“越小的设计越快&quot;的设计准则。 通用寄存器（General Purpose Register) 32个寄存器，并且每一个寄存器的操作数据长度为32位，寄存器文件/寄存器堆是一个32×32位的通用寄存器组成的，这32个通用寄存器都是被程序员可见的寄存器。 特殊寄存器 特殊寄存器一般被定义来实现一些特殊的存储功能，如用于存储乘/除法结果的寄存器HI和LO，这些特殊寄存器程序员是可见的，但是用于存储指令地址的PC（程序计数器，功能是存储下一条要被cpu进行处理的指令的地址的寄存器），这种寄存器程序员是不可见的。 系统控制状态寄存器 例如CP0协处理中的寄存器，一般也是程序员不可见的，他是用来存储记录当前系统状态操作数的寄存器，他能决定系统是否处于目态，很明显为了安全，是不允许程序员看见并修改的。 思考：在汇编语言中我们如何区分识别当前使用的是哪一个寄存器？ 为了对我们使用的寄存器加以区分，我们对每一个不同的寄存器都设置了唯一的寄存器编号，如下图： 一定要注意寄存器的助记符是要在数字编号前加上一个$符号的！例如$0代表的就是0号寄存器 我们观察上表可以看出并不是所有的寄存器都可以随意存储操作数的，有一些寄存器有专有用途，如： $0总是表示立即数0 $0-$7为保存寄存器，用于保存变量 $0-$9为临时寄存器，用于存储大型计算中的中间值 当然了大部分还是通用寄存器，在我们学习过程中，可以默认为处了$0寄存器，其他寄存器都是可以任意使用来充当通用寄存器的 下面我们最后看几个包含寄存器的汇编指令： MIPS存储器 存储器可以存储更多的数据，并且访问时间更长，但是访问的时间开销也更大，因此常用的数据常放在寄存器中，而不常用的大量数据会存储到存储器中，当某个存储器的数据被使用后会放到寄存器中以便接下来一段时间可能会经常使用（局部性原理的体现）。MIPS中存储器和寄存器的综合搭配使用的机制实际上和页面调度算法中tlb和内存的工作机制是类似的。 对于MIPS而言，存储器的地址为32位，一个存储字的长度也是32位。注意在MIPS中只采用按字节编址存储器，每一个字节有一个单独的地址，但是我们可以按字节、半字和字的方式进行寻址。 按字编址和寻址 按字编址时，一个字对应一个地址，如上图此时是一个词（字）对应着一个地址，而不是，他相较于按字节编址，一个地址对应着更多的数据（四个字节）。 读存储器的指令称为加载指令（load)指令，他一次性加载一个字的指令助记符为lw（load a word)。例如： 1lw $s0,5($t1) 上面是一个读存储器的指令，作用是把某个地址对应的字数据加载到s0寄存器，后面的5($t1)实际上返还的是访存的地址。计算方式为： 访存地址=基地址($t1寄存器中的值)+偏移(5) 1.注意$t1是一个通用寄存器,只是这里刚好基地址存储在t1寄存器，实际上基地址可以存储在任意一个寄存器中 2. 一个字对应四个字节 , 写存储器的指令称为存储指令（store指令），他一次性存储一个字的指令助记符为sw（store a word)。例如： 1sw $s0,5($t1) 同样的访存地址还是($t1+5)，但是此时的作用是将t0寄存器中的字写入到这个主存地址中。因此lw和sw时一个对立的指令，两者搭配使用，完成读/写存储器的功能。 按字节编址 此时一个字节对应着一个地址，因此一个字会分成4个字节存储到4个存储器的地址单元中。此时根据一次性读/写1,2,4个字节可以分类成一下几种指令，他们都是读/写存储器的指令，但是一次性读/写对应的数据字节大小不同： 读/写1个字节：lb(load a byte),sb(store a byte) 读/写半字（2个字节）：lh(load half byte),sh(store half byte) 读/写字（4个字节）：lw(load a word),sw(store a word) info, 一个字(32bit=4byte)为4字节，字地址按4递增，字节地址按1递增 因此，如果我们想在按字编址的存储器中读一个字节只能先取出一个字，在拆分处相应的需要的字节数据，而在一个按字节编址的存储器中如果我们想要读一个字的数据，那么应该一次性读4个字节的信息，因此访存地址应为4的倍数，即地址最后两位均为0，否则会出错。 假设我们现在想从存储器地址4处，加载一个字到寄存器$3中，那么MIPS汇编代码如下： 1234#基地址为0，因此$0永远存储的是常数0，请区分$s0和$0寄存器#因此偏移4个单位对应的访存地址就是000000004#又因为使用的是lw按字读，因此一次性读4个字节lw $s3,4($0) 因此最终$3寄存器存储的数据时0xF2F1AC07。 写按字节编址存储器也是类似的，假设我们现在想要将$t7寄存器中的值写入到存储器地址44处，那么MIPS汇编代码是： 1sw $t7,44($0) 总之，我们要会区分按字和按字节编/寻址的操作，同时我们要注意具体的指令如何操作，取决于存储器的编址方式，我们学习的是使用按字节编址的MIPS存储器，因此大部分操作使用都是按字节读/写操作。 大端和小端 在按字节编址的存储器中，根据一个字中的字节的存储顺序将存储器的组织方式为两种：大端和小端。 大端：一个字中，最高有效字节存储在低地址 小端：一个字中，最高有效字节存储在高地址 两种组织方式，字地址都是相同的，只是字中的字节存储的地址是不同的。大端/小端由ISA确定，对于MIPS而言，两者都可以。 一定要注意，大端存储并不是指大的数存储到低地址，而是高有效字节的数据存储在低地址。小端存储并不是指小的数存储到低地址，而是低有效字节的数据存储在低地址。 我们以下面的例子来具体区分一下大端和小端存储的区别： 因此我们发现对于一个数00112233H，大端存储就是正常的高位数从左到右存储，因此高位有效数存储到了低字节地址处。而小端存储反而相反，高位有效数存储到了高字节地址处，也就造成了实际上一个字的数拆分成4个字节后是从右到左存储的，因此读出来的数要逆序一下才是真正的数值。 例题 假设$s0中的初始值为0x23456789,对于大端和小端组织形式，下面程序执行后，$s0的值是多少？ 12sw $s0,0($0)lb $s0,1($0) 对于大端存储：首先将0x23456789存储到了地址0处，并且存储的顺序从低字节地址到高字节地址为23 45 67 89，因此再lb取1处的一个字节的数据时得到的是45 而对于小端存储：首先将0x23456789存储到了地址0处，并且存储的顺序从低字节地址到高字节地址为89 67 45 23，因此再lb取1处的一个字节的数据时得到是67 思考：如果上面的代码改写为lw $s0,1($0)可以吗？ 不可以，因此lw一次取一个字也就是四个字节，又因为从0开始存储第一个字，因此地址一定是4的倍数才行，但是1这里对应的并不是一个字的地址起点，因此是不可行的。 思考：如何用一段C程序，来判断运行机器采用的是大端存储还是小端存储？ 实际上我们只需要先将一个四字节的信息存储到四字节的参量中，然后取出一个字的信息即可判断，如下： 123456bool big_little_endian()&#123;\tint i=0x23456789; char *c=(char*)&amp;i; //返还true就是大端存储，返还false就是小端存储 return (*c==0x23);&#125; 实际上上面我们所学习的按字/字节编寻址与大小端存储方式在之前的计算机系统基础中都有学习过，可以参考下面的文章： https://coolchong.cn/2021/02/03/comsys-note4/,https://scholar.coolchong.cn/%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F, 操作数–立即数 立即数既不来自寄存器，也不来自存储器，而是直接来自指令，他通常使用16位二进制补码来表示，直接嵌入在汇编指令中使用。 如上图所示，4和-12就是立即数，他们可以直接在指令中嵌入使用，而不是通过寄存器，存储器等方式进行取操作后再使用。 机器语言 在MIPS指令集中我们可以将指令根据32位指令代码区域划分规则的不同而分类： 寄存器类型指令（R型指令） 立即数类型指令（I型指令） 跳转类型指令（J型指令） 寄存器类型指令（R型指令） MIPS指令集是32位的，因此每一个指令都使用32位代码，其中按照上面的规则进行划分，每一个区域都有特定的功能： op字段：操作码，通常为全0（在nemu实验中opcode_table中的各种指令名的名称大多相似） func字段与op字段一起决定指令的功能（在nemu实验中opcode_table中相同地址地址的指令虽然前缀相似，但是后面有些许不同的后缀，实际上就是func，两者共同决定一个指令类型） rs字段和rt字段是寄存器编号，表示两个源操作来自于哪两个寄存器 rd字段用来表示目的寄存器的编号 sa(shamt)字段只在移位指令中使用，表示移位位数，对于其他R-型指令sa字段全为0 上面的指令由两个源操作加上一个目的操作数，并且所有的操作数都来源与寄存器，因此称为寄存器类型指令（Register command),也就是R-型指令。下面是一个寄存器类型指令的例子： 他们的指令划分（下表中的数据都使用十进制真值来表示)如下： 我们一定要注意rs,rt,rd各对应的是谁，在mips指令add和sub等寄存器指令，书写时的规则是 123#助记符 目的操作数 源操作数1 源操作数2 add $s0 $s1 $s2sub $t0 $t3 $t5 和划分的区域略有顺序的不同。因此在机器中的代码存储如下; 然后在使用16进制代码表示整个的32位指令，因此一个指令是由8为十六进制数表示。 立即数类型指令（I型指令） 划分规则： op字段表示操作码 rs字段为寄存器编号，表示一个源操作数来自于寄存器 imm字段是一个16位立即数，表示另一个操作数，需要扩展为32位再使用 rt字段表示目的寄存器的编号，用于存放指令运行结果 我们发现此时的指令所有的操作数中有一个是立即数，因此称为立即数类指令，要注意此时的目的操作数夹在两个源操作数之间，但是在书写指令时，仍然为操作数在最前面： 123456#助记符\t目的操作数\t源操作数1\t源操作数2（立即数）addi rt, rs immlw rt, immsw rt, immlw rt, rs sw rt, rs 最终再机器码中还要将十进制真值数改用二进制数表示，然后最终的汇编代码再将32位的二进制码转换为8位16进制码来表示： 跳转型指令（J型指令) op字段表示操作码，用于确定指定的类型 instr_index用于产生跳转的目的地址，但是我们知道一个应该是32位，因此我们需要对instr_index进行一定的处理; (PC+4)31:28∣∣instr_index∣∣0(PC+4)_{31:28}||instr\\_index||0 (PC+4)31:28​∣∣instr_index∣∣0 实际上就是使用instr_index处理PC+4这个数想办法使其表示不同的32位地址数。 注意上面的||不是取或的意思，而是地址拼接的意思，我们是将下一条地址的31:28这4位和instr_index26位拼接再在低两位拼接两个0形成跳转地址。并且后面拼接两个0实际上就是&lt;&lt;2的操作，因此后面我们学习到跳转指令的数据通路时会用移位操作实现。 总结 一定要注意无论是哪种指令都是对一个32为二进制码进行划分，然后指令使用8位16进制码来简单表示，同时要注意上面的这种划分规则只是MIPS指令集的规则，对于intel的x86等并不适用。指令可以根据opcode和后面的低16位的划分规则来进行判别类型。"},{"title":"有限状态机","path":"/wiki/数字逻辑与数字系统笔记/有限状态机/index.html","content":"有限状态机的结构 有限状态机就是同步时序逻辑电路的最典型应用，因此有限状态机的结构实际上和同步时序逻辑电路的特点很类似： 即有限状态机有状态寄存器和组合逻辑电路两大组成部分，其中状态寄存器存储当前时刻的状态，并且状态在下一个有效时钟沿会发生改变，更新为次态的状态。而组合逻辑电路通常就是根据输入来计算次态，和根据现态计算出输出值。 有限状态机的分类 有限状态机有两大类，分别是Moore机和Mealy型有限状态机。两者的区别在于： Moore型有限状态机中，输出仅由当前状态所决定，而对于Mealy型状态机，输出由当前状态和输入共同决定。但是无论是哪种状态机，都属于同步时序逻辑电路。 状态机是一种很特殊的同步时序逻辑电路，他的特殊性就在于一定拥有一个回路连接着输入端与触发器的输出端，从而保证状态机的次态一定是由当前的输入以及之前的输出即之前的电路状态共同决定的。 Moore型有限状态机的应用 接下来我们用一到例题来详细学习Moore型有限状态机的应用和具体的工作原理。假设现在有一个十字路口，那么X轴方向的两个对立的红绿灯我们设置为La,Y轴方向的两个对立的红绿灯我们设置为Lb如下图： 那么很明显会存在两个输入即两个交通传感器Ta和Tb,当X轴上有小轿车等待时，那么Ta传感器返还true，即输入端Ta的值是1，否则为0。同理对于Y轴当有轿车等待时Tb为1否则为0。 同时有两个输出，即La和Lb红绿灯的颜色。 我们设置CLK周期为5s，因此每一个时钟沿到达时，灯会根据交通传感器来改变。同时还存在一个复位按键，可以使交通灯控制器回到初始状态。那么很明显有限状态器的寄存器黑盒视图如下： 这就是有限状态机的输入，输出的设置。接下来我们来分析一下有限状态机黑盒内部的具体状态转换结构是什么样子的。我们画出状态转换图如下图： 上面就是有限状态机根据不同的输入转换成不同的状态的循环图了。我们其实可以类比成计算机网络Rdt中的发送接收端的状态转换图，原理是类似的。此时： 图中的每一个圆圈代表一个状态 图中的每一个圆弧代表两个状态之间的转换 圆弧上的项表示实现状态所需要的输入 状态转换发生在时钟有效沿产生的时刻 Moore型状态机的状态转换图中，输出信息都是标在圆圈内部的，因此上图中的圆圈内部的La和Lb的颜色就是输出。 那么下面我们分析一下状态转换图是如何正确表示Moore型有限状态机的转换的： S0表示的是La绿灯，Lb红灯的情况，即X轴车可以通过十字路口，Y轴的车需要等待的情况。但是当输入端Ta不是1即非Ta是1的情况时，表示此时X轴没有车了，那么此时就从S0切换到S1即X轴的红绿灯La闪烁一段黄灯后继续转换到S2状态，即Y轴的车可以通过狮子路口，同时X轴的车需要排队。同理的，当Tb=0即Y轴没有车时，那么Lb闪烁一段黄灯以后，切换回到S0状态，即X轴绿灯。同时我们考虑到如下情况，可能Ta一直为1，表示X轴一直有车，那么此时X轴就要一直亮绿灯即S0圆圈右上角闭环的情况出现，同理，也会存在Y轴正在通车且Y轴一直有车的情况，那么此时就需要一直Lb亮绿灯也就是S2左下角闭环的情况。同时我们还要有一个复位Reset端来使得我们可以在任何时段强制恢复成S0的状态。自此我们发现上图的状态转换过程是正确的，可以表示出不同情况下十字路口的红绿灯状态。 因此我们根据上图的状态转换图可以总结出下图的状态真值表： 即根据不同的输入Ta和Tb以及现态来决定次态的情况。（这里的现态决定次态就是带有回路的同步时序逻辑特有的特点）我们可以总结出上图的表格，然后对状态进行编码，即使用若干个逻辑表达式来整理表示出次态和现态与输入的关系： 要注意，此时的中间的真值表的现态是有两位二进制码S1S0来表示的，这是因为状态转换一共有4个不同的状态，需要至少使用2位二进制码才能表示出来，因此此时00表示状态S0，01表示状态S1,10表示状态S2，11表示状态S3。同时次态很明显也会有4中状态，因此也是使用2位二进制编码表示。然后我们即可得到逻辑表达式： {S1′=S1⊕S0S0′=S1S0TA+S1S0TB\\begin{cases} S_1&#x27;=S_1⊕S_0\\\\ S_0&#x27;=S_1S_0T_A+S_1S_0T_B \\end{cases} {S1′​=S1​⊕S0​S0′​=S1​S0​TA​+S1​S0​TB​​ 这就是有限状态机根据输入端的输入值和现态来计算次态的公式。因此此时我们只得到了有限状态机前半部分用来计算次态的组合逻辑电路的表示式，接下来我们还要得到根据现态计算出输出的组合逻辑表达式。 我们知道此时由状态寄存器输出的现态有S1‘S0’表示,但是最终我们要得到的输出时La个Lb。因此可以根据S1‘S0’和状态转换图列出以下真值表： 即现态和输出的关系。由于La和Lb都有三种状态，因此需要使用2位二进制码才能表示出来，因此最终的输出并不是La和Lb两个输出端，而是4个输出端。如下图： 这就是一个完整的表示十字路口红绿灯的有限状态机的同步时序逻辑电路。我们发现有限状态机黑盒（也是状态寄存器）只是其中的核心部位，他还需要左右两侧的组合逻辑电路来根据输入计算次态，以及根据现态计算输出。因此有限状态机总是可以抽象为： 下面我们根据得到的状态机，可以实时的画出有限状态机的端时序图： Moore型有限状态机设计方法 我们根据上面的案例可以总结出Moore型有限状态机的设计方法一定是遵循以下步骤得到的： 根据问题进行抽象，确定输入和输出对应的逻辑含义 画出状态转换图 列出状态转换表 对状态进行编码，并列出次态计算方程 列出输出表 对输出进行编码，并列出输出的计算方程 绘制原理图 思考：上面的红绿灯设计是否存在缺陷？ 有一个明显的设计漏洞。我们思考易得，当此时处于S0状态，并且Ta一直为1即X轴正在通车且X轴一直有车的情况，那么根据我们列出的状态转换图，此时会一直处于S0状态，这明显不符合实际。因为Y轴方向的车不可能一直排队等待，而是现需要在经过一段时间后强制转换成Y轴通车即S2状态，即使此时X轴还有车。因此我们设计的红绿灯状态转换图是有缺陷的。 思考：此时如何修改来弥补缺陷？ 没办法在已经列出的状态装换图上进行修改，只能重构状态转换图来重新制作有限状态机的电路图。 状态编码 我们在上面的案例设计与实现中发现经常需要用到编码来抽象表示状态转换图，因此学习状态编码是很有必要的。首先我们要知道不同的状态编码和输出编码会产生不同的电路，因此需要在设计中一直使用一套标准的状态编码，例如个案例中00就表示S0状态，自此不能改变这个编码的意义。同时进行合理的编码，可以产生一个逻辑门更少且传播延迟更短的电路，因此我们在对状态进行编码时要选取合适的编码规则。最常用的两种编码规则就是二进制编码与独热码。 二进制码：4中状态：00,01,10,11 独热编码：实际上我们对此并不陌生，对于编码器实际上就是独热编码的应用。即状态的每一位（1bit)表示一种状态，任何时候都只有一位是’热’的(true或者1)，例如：0001,0010,0100,1000等。使用独热编码相较于二进制编码，更容易表示次态逻辑和输出逻辑表达式。 Mealy型状态机 我们前面讲到了Mealy型状态机，他和Moore型状态机最大的不同就是输出不仅仅由现态计算得出，还会受到输入端的影响（注意不是现态的影响）。 一定要区分输入输出和次态现态。输入和输出是时序电路最外层的接口，而次态和现态只是状态寄存器的输入和输出。次态需要用输入经过组合逻辑计算后才能得到，而输出需要用次态（或者次态+输入端）经过组合逻辑计算后才能得到。 现在我们还是以一道案例来学习： 举一个形象的例子，假设现在有一串二进制码100101100,假设蜗牛每次走过位需要1s,那么这个蜗牛会在4s和6s时对我们微笑。现在我们需要设计有限状态机来表示。 我们先使用Moore型状态转换图来分析： 很明显状态转换图如上图形式，S0是未记住任何一位时的状态即不笑的状态，而S1是已经经过了一个0位时的状态即马上要笑的状态，而S2就是刚好经过的最后两位是01的状态即笑的状态。那么未出发时或者刚刚走过01时处于S0状态，当向后走了一位后得到一个0时，那么就到达S1状态，只要再在下一步经过1就能够微笑即转换为S2状态。但是假设S1时又经过一个0，那么就还处于S1状态，即S1状态左下角闭环的情况。同样的当S0状态经过了一个1，那么仍然处于S0状态，即右上角闭环情况。当处于S2状态并且下一位是1时那么就换成S0状态，否则是0就转换成S1状态。我们分析一下蜗牛走100101100时每一位的状态应该是S0-&gt;S0(1)-&gt;S1(0)-&gt;S1(0)-&gt;S2(1)-&gt;S1(0)-&gt;S2(1)-&gt;S0(1)-&gt;S1(0)-&gt;S1(0)。因此上面的状态转换时逻辑正确的，接下来按照之前所讲的步骤即可得到Moore型有限状态机的电路图，这里就不给出具体过程了。 我们接下来尝试使用Mealy型状态转换图表示，由于Mealy型状态转换机的现态同时受次态和输入决定，因此只会存在马上要笑和不笑的两个状态，而不会存在马上要笑的状态，即状态会更少，如下图： 此时S0表示未记住任何一位时的状态即不笑的状态，因此当处于S0并且接收到输入时0时就已经可以判断出输出是不笑即0了，然后转换到S1马上要笑的状态，当S1状态时得到输入为0，那么仍保持在S1状态，否则就笑输出1然后转换到S0状态。我们发现此时和Moore型状态转换图的逻辑是一样的，只是此时的表示更加简洁，少了一个状态图相应的也就降低了电路的复杂度。 思考：Mealy型状态转换相较于Moore型转换在哪里更加简单了？ 究其原因，两者的状态切换和输出存在差异，对于Moore型状态转换，是先进性状态切换再输出，这是因为Moore型状态机中，输出总是需要等待现态切换成次态以后才能计算得到。而对于Mealy型状态机状态切换和输出是同时执行的，因为输出可以提前得到输入来进行计算。因此Mealy型状态转换图中输出是在圆弧上，而Moore型输出是在状态圈中。 接下来我们同样得到状态转换真值表： 我们发先Mealy型的状态转化表更加简单，因为只有两个状态，所以编码只需要使用一位。最终我们可以得到Mealy型状态转换机的电路图： 我们发现Mealy型状态转换机电路图更加简洁，但是实际上实现的逻辑功能和Moore型没有差别。最终我们同样给出Mealy型状态机时序图： 我们发现对于同样的输出Y的变化，由于Mealy型状态更少，因此中间的状态转换过程也更少，因此Mealy型Y的变化整体比Moore型要快。 Mealy型有限状态机设计方法 我们同样给出Mealy型有限状态机的设计步骤： 根据问题抽进行象，确定输入输出以及对应的逻辑含义 画出状态转换图 列出状态转换表和输出表（可以同时列出，原因是输出可提前得到输入因此状态转换的计算和输出的计算可以同时进行） 对状态和输出进行编码，并列出次态方程和输出方程 绘制原理图 Moore型状态机和Mealy型状态机的总结"},{"title":"硬件描述语言","path":"/wiki/数字逻辑与数字系统笔记/硬件描述语言/index.html","content":"硬件描述语言的起源 有名为HDL，是一种和C++,JAVA不同的硬件描述语言。他产生的原因是因为我们发现对于复杂逻辑的元件设计，使用卡诺图和组合逻辑电路很难实现，即使实现也会有许多细节上的纰漏，比如毛刺，延迟过大等问题，所以此时我们就需要学习硬件描述语言了。硬件描述语言和电子设计自动化工具搭配使用，可以轻松优化电路得到我们最满意的电路设计图。 我们首先要知道，HDL是具有特殊结构能够对硬件逻辑电路的功能和时序进行描述的一种高级编程语言，称之为硬件描述语言，他和我们之前学习的C++,JAVA等软件描述语言有以下的本质区别： 信号连接：硬件描述语言一般是使用涉及循环，变量等语句描述门元件之间的连接形式的，而软件描述语言不会涉及到底层门元件的连接的 功能时序：硬件描述语言反映了门元件的时序，延迟等信息，而软件描述语言不会考虑到这些问题 抽象层次：可以在多种层次上进行建模设计等，而软件描述语言仅仅限制于软件算法层 并行特性：和软件描述语言有很大不同，在HDL中，指令都是并行的，而不是串行的，因此指令的顺序并不会影响功能的实现 上图给出了两种不同的语言实现功能的方法，软件描述语言中是通过编译器将程序编译成01二进制代码来执行。而SystemVerilog(我们要掌握的一种硬件描述语言)编写的程序是通过综合器生成电路网表文件（即描述组合逻辑电路的文件）最终交给厂商去制造某一个元件。 我们前面提到过HDL可以在抽象层次上进行建模设计，如下图： 一个硬件描述语言可以在开关机，门级和寄存器传输级的任意一个层次上进行建模设计数字逻辑电路。而软件描述语言只能在算法级层次上进行设计。本次我们主要是学习在RTL寄存器传输级进行硬件描述语言应用的知识学习。 逻辑综合 在HDL中并不是所有语句都被综合形成描述逻辑电路的文件，只有一部分语句是被综合为逻辑电路的，称之为可综合HDL，而不能被综合的语句一般用于仿真验证（后面会讲到，实际上就是用来对设计的电路进行模拟测试的）。 一个门级网表的实现需要经过许多步骤，其中翻译，逻辑优化和实现与布局布线是非常重要的步骤，我们分别介绍： 翻译：翻译过程就是将RTL描述（即我们设计的语言程序）被EDA工具转换为一个未经优化的内部表示，不考虑目标工艺和设计约束。也就是仅仅将一个问题的解决办法生成为一个布尔表达式。 逻辑优化：取出冗余逻辑，使用大量与工艺无关的布尔逻辑优化技术，产生优化后的内部表示。即我们之前学到的卡诺图等优化方法将逻辑函数进行简化。 实现与布局布线：EDA工具接受内部表示，使用工艺库提供基本逻辑门进行实现，并根据设计约束进行优化。即使用代工厂（你可以理解为零件厂商）提供的门元件进行实现，这其中需要考虑成本，性能等问题来对设计进行约束优化（毕竟在实际电路实现中，并不是表达式越简越好）。 在实现与布局布线中我们发现有两个方面的内容，首先是工艺库，一般是由代工厂提供的门元件组成的标准单元库，我们在对设计进行实现和布局时要使用这些不同功能的门单元和宏单元（类似于一位加法器，乘法器等器件）。这些工艺元件由Foundry工厂提供，如：中兴国际（工艺在20nm左右），台积电（10nm左右），三星（10nm）和intel(7nm)。 注意英特尔虽然既设计电路，又提供实现电路的工艺元件，但是他只会为自己提供，即不为其他国家公司提供工艺库服务，所以虽然掌握最尖端的技术但是只是自己使用。 设计约束就是为了考虑整体电路性能（速度，工作频率），面积（成本）、功耗等外界因素对电路进行优化。 仿真验证 仿真验证实际上就是对我们设计的电路进行测试，以防出现漏洞或错误，但是我们不可能造出来这个门网表再进行测试，这样的话即使检测出来是有错误的也不能修改只能报废掉了，所以我们一般是使用虚拟仿真技术对我们设计的电路先进行测试。如下图： 在特定的时间将激励信号送入待测模块（DUT）的输入端口 EDA工具根据DUT的逻辑功能模拟信号在电路中的运算和传输过程 检查（人工或自动）输出相应以判断所涉及模块的功能是否正确 最终输出的信号是右图中脉冲形式的信号图 SystemVerilog HDL程序的基本结构 一个硬件描述语言创建的模块结构如下图： 这是一个二选一电路的模块功能的设计，我们发现其实和软件描述语言的函数很类似。他有以下几个特点： SystemVerilog HDL程序的文件名通常以扩展名.sv结尾 代码中第一行和第八行通过&quot;module…endmodule&quot;定义了一个名字为mux2的逻辑电路模块，该模块一共具有3个输入端口（由input定义）和1个输出端口（由output定义） 代码第三行定义了两个logic类型的中间变量（内部信号）a和b，实际上中间变量就类似于函数的局部变量，只能模块内部使用，不能作为对外输出使用。 代码中4-6行定义了模块mux2的逻辑功能，他是实现某个元件功能的核心语句部分 模块 模块是SystemVerilog的基本建模单位，他用于描述逻辑电路的功能，一个模块可以包括整个系统或者一部分，他的定义关键词就是一module开始，以endmodule结束。模块声明的格式是 1234module 模块名 (端口1，端口2,...);endmodule 注意没有大括号包裹，模块名是一个模块唯一的标识。 端口 端口是模块与外界进行通信的接口，他的定义需要指明四个要素（方向、类型、位宽、名字），其中类型和位宽可以缺省： input [类型] [位宽] 端口名1，端口名2，端口名3,… output [类型] [位宽] 端口名1，端口名2，端口名3,… inout [类型] [位宽] 端口名1，端口名2，端口名3,… input标识输入端口，output表示输出端口，inout表示双向端口。所有相同类型的端口都统一一起声明即可（都排列在一个关键字后面即可）。类型有logic等，位宽就是信号的位数，一般默认是1位，当然也可以声明为多位。端口的声明可以有多种方式，如下： 这三种都是正确的，也就是说在模块声明处可以将端口所有的属性全部声明完，也可以只声明一部分属性（但是无论如何端口名称必须在module声明语句中），然后再在内部对端口的方向，类型，位宽进行声明。 内部变量 上图中a和b都是内部变量，他们只在模块内部使用，主要是负责存储中间信号量，最终的输出信号需要若干个中间变量信号的逻辑组合来形成。 逻辑功能 逻辑功能的定义是一个模块中最核心的部分，明确了模块的行为和数据流动例如上面的4-6行，在SystemVerilog HDL中，定义模块的逻辑功能主要有两种建模（描述）风格： 行为建模：描述输入和输出之间的因果关系（其中又分为基于持续赋值语句的建模和基于过程语句的建模) 结构建模：调用其他已经定义过的模块对整个电路的功能进行描述。 在一个System HDL程序中，其代码模板如下： 要注意module语句后面是有分号的，而endmodule后面是不用分好的，其他中间的语句也是严格要求分号结尾的。 我们要注意声明部分必须写在逻辑功能定义部分的前面，而对于逻辑功能定一部分，由于HDL的并行性的特点，语句是并行的而不是串行的，因此语句之间的顺序并不会影响功能的实现，即下面的y定义语句也可以写在最前面： 但是为了便于我们理解，我们最好还是根据一定的逻辑顺序来构建代码。接下来我们再来学习以下HDL的语法要素。 HDL语法要素 间隔符和注释 即可以换行，他不会影响语句的实现，只是要注意语句的最后要加分号来表示一个语句的结束。一定的空格和换行使得代码风格优雅，同时注释规则和C一样，分为单行注释//和多行注释/*…*/。 标识符和关键字 接下来就是标识符和关键字，标识符用来给逻辑电路中的对象（如模块、输入和输出端口、中间变量）取名，规则和C一样，对字母大小写敏感。如： 关键字就是预留的表示特殊意义的字符串，用来定义语言的结构，通常是小写的，比如module,input,assign等。关键字不能作为标识符来使用。 逻辑值 在HDL中为了表示数字逻辑电路的逻辑状态，SystemVeilog规定了4种逻辑值，如下表： 逻辑值 电路的逻辑状态 0 逻辑零，逻辑假 1 逻辑1，逻辑真 x或X 不确定的值（未知状态） z或Z 高阻态（浮空） 一般情况下，逻辑门的输出端口产生0或者1，对于三态门，在非连通状态下输出为高阻态Z，对于正常的运行的电路，逻辑X是不能存在的，必须在设计时就杜绝（例如一个节点连接多个输出端口导致的信号线同时驱动两个不同值的情况）。 常量 SystemVerilog HDL有三种常量：整数型常量、实数型常量和字符串型常量，其中整数型常量是可以综合的。 整数型常量的格式如下： &lt;+/−&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt;&lt;+/-&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt; &lt;+/−&gt;&lt;位宽&gt;&lt;进制&gt;&lt;数值&gt; 其中除了数值，其他项都可以缺省。&lt;+/-&gt;表示正负，&lt;位宽&gt;用10进制数来描述常量对应的二进制数的宽度，&lt;进制&gt;定义了整数型常量的进制格式，可以是二进制（用b或者B表示）、八进制表示（用o或O表示）、十进制数（用d或D表示)，十六进制（用h或者H表示），数值表示具体的取值，EDA工具按照无符号数进行处理，因此如果是二进制格式，可以是0,1,x和z,如果是十六进制格式，那么A-F不区分大小写。 如果常量带有负号，那么EDA工具按照有符号数的补码进行处理。 上图给出了部分常量的表示方法，一定要注意位宽一定是二进制表示的位数，而负数常量是要按照有符号数补码的格式在EDA中表示。求补码的方法见《机组原理》 为了增加数字的可读性，可以在数字之间增加下划线（类似于银行显示余额时使用的逗号），比如8’b1001_0011就是表示的位宽为8位的二进制常量数10010011。 并且如果没有给出位宽，那么该常量被指定为当前表达式的位数当位宽比数值的实际二进制位数少时，高位部分被舍去即截取时永远从低位向高位截取，当位宽比数值的实际二进制位数多时，那么高位补0。比如assign w=b1101(没有声明位宽)，那么如果w是2位，w=2’b01即只要低2位，当w时6位，那么w=6’b001101即高位补0，只有当w=4时，w=4’b1101。 注意低位截断时数值会发生变化可能不等于右侧表达式的值了，但是当位宽大于等于右侧表达式的长度时，那么数值并不会发生变化。 如果没有给出进制，那么默认是10进制，并且此时常量EDA工具将其作为有符号数，使用补码来处理。比如10=(01010)_补，-15=(10001)_补。 我们需要注意，某一个常量在电路中就是一个由0/1组成的二进制串，所以在电路层面并不会区分该常量是有符号数还是无符号数，或者是原码还是补码，这些信息都是由设计者或软件（EDA工具）负责解释的。比如： 数据类型 除logic外的其他变量类型，都属于二态类型（即只有0/1），如下所示： bit：定义1位信号 byte：定义8位信号（1个字节），类似于C/C++的字符型 shortint：用于定义16位信号，类似于C/C++的short类型 int：定义32位信号（即4个字节），类似于C/C++的int类型 bit和logic很像，标量信号和向量信号均可以定义，并且支持域选，但是bit类型只有0/1两种取值： 12345678//定义了两个16位的向量信号，每位只能是0或1//注意是16-0位，其实可以类比于数组bit [15:0] addrbus,databus;//定义了两个1位的标量信号，每位只能是0或1bit a,b;//域选就是截取，这里可以域选bit的15-7位//所以gugu向量信号的数值用addrbus的15-7位填充bit [8:0] gugu=addrbus[15:7]; byte、shortint、int都具有预定义向量宽度（即固定的位宽），所以定义变量时不能使用位宽，也不支持域选。 12345//正确，定义了两个32位的向量信号，每位只能是0或者1int addrbus,databus;//错误，不能使用位宽//int向量信号只能是32位int [16:0] addrbus; SystemVerilog HDL中的线网类型主要包括：wire,tri等。wire类型只能定义单源驱动信号，因为常使用logic来代替wire,在SystemVerilog中wire类型已经被弃用（但是端口信号默认为wire类型）。tri类型可以用于定义多源驱动信号，例如： 123module tristate(input logic a,input logic en,output tri y);\tassign y=en?A:1&#x27;bz;endmodule 思考：单源驱动信号和多源驱动信号的区别？ 单源驱动信号就是这个信号由一个输入信号来驱动，最常见的就是X-&gt;Y,因此wire信号完全可以用logic信号来代替，而多源驱动信号就是一个输出信号由多个输入信号决定，类似于{X1,X2}-&gt;Y。这种信号不同于前面讲到的常量信号，他可能会根据不同的情况变换，所以是多源线网型信号，需要使用tri来定义，很显然三态缓冲器和译码器等输出信号就是使用多源驱动信号。 tri类型信号的定义格式和logic几乎是一样的，支持域选和自定义位宽： 1234//定义了两个16位的tri类型向量信号tri[15:0] addrbus,databus;//支持域选out[3:0]=addrbus[7:4] 运算符 先给出所有的运算符的含义和优先级。然后我们讲解几种细节问题： 当两个位数不同的操作数进行单符号位运算时表示的是按位进行处理，位数少的操作数需要进行零扩展到相同位数，比如： a=4’b1011 b=8’b01010011 那么c=a|b时，a需要先零扩展为8’b00001011 我们之前学过这种按位的操作总是需要两个操作数，比如a&amp;b,a^b等，但是在SystemVerilog HDL中也可以是单操作数自己进行这种运算，即为缩减运算，他的特点就是将操作数的各个位之间进行或，与等操作，最终一个很长位数的操作数就会变成一位数，比如： 12345module and8(intput logic [7:0]a,output logic y);\tassign y=&amp;a;\t//那么就等同于下面的操作\t//assign y=a[7]&amp;a[6]&amp;a[5]&amp;a[4]&amp;a[3]&amp;a[2]&amp;a[1]&amp;a[0];endmodule 假设a是10000000，那么最终的y输出信号就是0，如果a是11111111，那么y就是1。类似的还有|a等。 而当使用的是多符号是那么是将两个数的真值进行处理，并且所有非零的真值数都是按照1处理，零真值是0。比如： 在SystemVerilog HDL中还会经常使用到算术运算，算术运算包括加减乘除，其中除和取模是不可综合的。并且当两个位数不同的操作数进行算术运算时，如果操作数是无符号数，那么位数少的进行零扩展即可，如果操作数是有符号数，咋位数少的操作数需要进行位数扩展到相同位数。比如： 移位运算实际上和计算机系统基础中的移位操作相同，规则： 逻辑左移：将操作数无符号数左移若干位，右侧产生的空余位使用0填充 逻辑右移：将操作数无符号数右移若干位，左侧产生的空余位使用0填充 算术左移：将操作数有符号数左移若干位，右侧产生的空余位使用0填充 算术右移：将操作数有符号数右移若干位，左侧产生的空余位使用符号位填充 关系运算就是比较大小然后返还0/1（假/真）。注意如果表达式中有一个操作数为无符号数，那么表达式的其余操作数均会被当做无符号数进行处理： 123456//-3和5都是有符号数(前面讲过10进制数默认是按有符号数处理)(-3*5)&lt;10//4&#x27;d5是无符号数，所以-3的二进制串也被当为无符号数处理//(-3)_补=(1101)_补，那么作为无符号数被处理为13//13*5=65&gt;10(-3*4&#x27;d5)&lt;10 再次强调，在SystemVerilogHDL中所有的数最终都是在硬件上进行二进制运算，所以这里的-3,5等都只是一个符号，他不能说明值是多少，最终数值都是取决于他们的二进制01串被处理后得到的真值。还有就是在HDL中没有true和false布尔值，都是用1来代表真，0代表假。 当然HDL中也存在条件运算–三目运算。和C的一样： 123module mux2(intput logic [3:0]d0,d1,intput logic s,output logic [3:0] y);\tassign y=s?d1:d0;endmodule 这里再介绍一下特有的位混合（拼接）和复制运算，说来也简单，位混合运算就把多个信号的某些位拼接起来形成新的信号。格式为： {信号1[n1:m1],信号2[n2:m2],...,信号n[nn:mn]}\\{信号1[n_1:m_1],信号2[n_2:m_2],...,信号n[n_n:m_n]\\} {信号1[n1​:m1​],信号2[n2​:m2​],...,信号n[nn​:mn​]} 位混合运算中的每一个操作数必须是确定位宽的数，不允许出现未指定位宽的常数。如果要多次拼接同一个操作数可以使用复制运算，格式为 {n{A}}\\{n\\{A\\}\\} {n{A}} 我们来看几个例子： 小练习"},{"title":"状态机建模","path":"/wiki/数字逻辑与数字系统笔记/状态机建模/index.html","content":"根据电路图导出状态机 有时候我们并不是事先了解到需求功能后设计电路图，而是在给定电路原理图的情况下推断电路的逻辑功能，也就是电路设计的逆过程。此时我们需要按照如下步骤进行： 检查电路，标明输入输出和状态位 写出次态方程和输出方程 列出状态表和输出表 删除不可达状态以简化状态表 给每个有效状态编码指定状态名称 用状态名称重写状态表和输出表 画出状态转换图 使用文字描述有限状态机的功能 下面我们用一个案例来学习根据电路原理图导出状态机：如下图是一个键盘锁电路，包含两个输入和一个输出，当输出为1时表示开锁成功，试分析，如何进行输入才能使电路产生开锁信号 首先我们要检查电路图，标明输入，输出和状态位： 输入A0,A1 输出unlock 状态位S0,S1 电路的输出只取决于状态位Unlock=S1 很明显这个电路使用个Moore型状态机 接下来我们写出次态和输出的计方程： 观察上面的电路图，我们可以直接对照着写出次态的计算方程 {S1′=S0A1‾A0S0′=S1S0‾A1A0\\begin{cases} S_1&#x27;=S0\\overline{A_1}A_0\\\\ S_0&#x27;=\\overline{S_1S_0}A_1A_0 \\end{cases} {S1′​=S0A1​​A0​S0′​=S1​S0​​A1​A0​​ 同样输出的计算方程我们也可以轻松推得： Unlock=S1Unlock=S_1 Unlock=S1​ 接下来我们要根据上面的方程枚举所有的情况列出状态表和输出表： 然后我们将状态表填写完整，进行不可达状态的删除： 我们发现状态S1:0=11从未在表中作为次态出现过，即无论输入A1,A0取何值都不可能计算得到次态的11，因此将状态表和输出表对应不可达状态S1:0=11的一栏删除。同时对于现态S1:0=10，总是得到次态S1:0=00，因此此时与输入无关，可以使用无关项X来进一步化简。最终我们得到化简后的状态表和输出表如下图： 接下来我们为状态表和输出表中的每一个有效状态编码指定状态名称，从而使得更容易知道输入情况同时也方便后面进行状态转换图的绘制： 我们规定有效状态编码对应的名称如下图： 因此将上面的化简后的两个表使用新的名称来表示： 此时我们根据已经用状态名称标注的状态表和输出表进行状态转换图的绘制，要注意因为是Moore型状态转换机，因此输出应该是写在状态圆圈的内部的。 最后我们再观察状态转换图，进行以下逻辑整理，便可以描述出这个电路图要实现的功能了，如上图，在复位状态下，只有先后输入了3和1才能到达解锁状态S2，这也就说明这个键盘输入锁的密码就是31。 基于SystemVerilog HDL的时序逻辑设计 前面我们学习了使用建模语言设计组合逻辑电路，那么接下来我们来学习使用SystemVerilog HDL来设计时序逻辑电路。首先我们需要注意SystemVerilog使用一些特殊的编码风格（IDIOMS)描述锁存器、触发器和状态机。其他的编码风格虽然可以正确的进行仿真，但是综合后会产生错误的电路。 这里我们学习一下如何使用always过程块进行时序逻辑电路的建模: always过程块分为三类： always_comb(描述组合逻辑) always_latch always_ff 其中后面两个都是描述时序逻辑电路的声明语句。always过程块结构： 12always @(sensitivity list) statements; sensitivity list是敏感事件列表，当列表中的事件产生时，过程块的语句就开始工作。下面我们就来用几个实例来具体学习一下使用always过程块进行时序逻辑器件的建模。 寄存器建模 寄存器是一个典型的时序逻辑器件，他在同一时刻更新存储多位信息。其结构如下： 那么我们的建模代码如下 123456module flop(input logic clk, input logic[3:0] d, output logic[3:0] q); always_ff @(posedge clk) q&lt;=d;endmodule 我们使用正边沿D触发器来实现这个寄存器的功能，always_ff用来表示触发器，@后面括号中的posedge clk就是敏感事件，其实就是时刻监视clk，即clk就是时序逻辑电路的条件，当满足时就执行内部的代码，posedge clk表示信号上升沿有效，因此当clk处于有效上升沿时，q的更新赋予d的值。其中这里的赋值符号不是=，而是&lt;=，这在前面其实将结果是非阻塞赋值的意思，这里我们还不用深究，暂时可以把它视为普通的赋值语句。 那么接下来我们来尝试为这个寄存器增添一个复位端，使其能够恢复到最初始的状态。我们前面学到了复位有两种方式： 同步复位：只有在clk处于上升沿时可以进行复位 异步复位：只要reset=1，那么无论是clk是否处于上升沿都可以强制进行复位，也就是说只要reset处于有效沿，那么就可以执行复位代码。 这里我们给出两种不同复位方式的寄存器建模代码： 我们可以看到对于同步复位功能的寄存器，他的敏感事件只有clk，因此只有clk处于有效沿时才能执行always内部的代码，因此只有在clk有效时才可能进行reset的判断以及复位。但是对于异步复位的寄存器，敏感事件有两个即新增了一个reset，也就是说此时只要reset或者clk处于有效沿，都可以执行过程块内部的语句，因此此时是异步复位。 一定要注意senitivitylist只要有一个事件满足就可以进行过程块下的代码，因此条件之间是或的关系 进一步我们还可以为具有复位功能的寄存器添加一个使能端，只有使能端en=1时才能将Q更新为采样的输入值D： 锁存器建模 接下来我们再来实现以下锁存器的建模，实际上并不是所有的综合工具都能够很好地支持锁存器，除非你能明确的知道那些工具支持锁存器，否则最好不要优先使用锁存器，而是使用边沿触发器来替代。同时我们还要防止HDL意外生成锁存器。 我们思考一下锁存器的功能，实际上就是只有在clk=1有效状态时，才能让Q时刻跟随采样的输入值D变化，否则就维持之前的值。因此建模代码很简单： 123456module latch(input logic clk, input logic[3:0] d, output logic[3:0] q); always_latch if(clk) q&lt;=d;endmodule 阻塞赋值语句= VS 非阻塞赋值语句&lt;= 我们前面学习过非阻塞赋值语句和阻塞赋值语句区别： &lt;=是非阻塞赋值语句，他的特点是可以和其他的语句同时执行 =是阻塞赋值语句，他的特点是按照语句的在代码中的顺序依次工作 但是当时我们很难理解两者的应用上有何异同，接下来我们使用一个案例来分析一下： 我们发现上面的两个建模代码很相似，只是在赋值的时候使用了不同的赋值语句，最终对应的电路图有很大的区别，这就是非阻塞赋值语句和阻塞赋值语句造成的。首先我们分析一下左侧使用非阻塞赋值语句的建模代码，由于非阻塞赋值语句是并行执行的，而不是阻塞式的串行，因此上面两个赋值代码是同时执行的，也就是说q被赋予的是n1还没被更新成d的值。举个例，假设初始时n1=0,d=1，那么执行上面的非阻塞赋值语句后n1=1,q=0，我们发现q的值是n1之前的值0，而不是被更改为d后的1值，这是因为n1和q同时更新值，从q的视角来看，此时n1还是0值，只有当q更新为0以后n1才变成了新的值1。 而阻塞赋值语句就很好理解了，就是我们通常意义上的与C和java等高级软件编程语言都类似的串行赋值，因此n1先更新成了1，然后q才被赋予了n1的值也就是1，因此对于右侧阻塞赋值语句最终的结果q=n1=1。 我们发现正是这两种不同的赋值语句导致了最终实现的电路图是不同的，左侧最终实现的是两个串联的D触发器，而右侧的是一个D触发器。我们还可以进一步尝试将左侧的非阻塞赋值语句用阻塞赋值语句来表示： 123456//下面两个代码是等同效果的n1&lt;=d;q&lt;=n1;//等同于q=n1;n1=d; 赋值语句使用规则 因此我们可以对各种建模方式的赋值语句进行一个总结： 当使用同步时序逻辑电路要使用always_ff @(posedge clk)和非阻塞赋值语句是代码如下： 12always_ff @(posedge clk)\tq&lt;=d; 而当对于简单的组合逻辑电路中可以使用赋值语句assign 1assign y=a&amp;b; 而对于使用always_comb和阻塞赋值语句=的描述复杂组合逻辑电路的语句如下： 123456always_comb begin\tp=a^b;\tg=a&amp;b;\ts=p^cin;\tcout=g|(p&amp;cin)end 注意不要在多于1个always语句块或者连续赋值语句中对同一个信号赋值 计数器建模 N位二进制计算器如下图： 他的输入有时钟信号clk,复位信号reset，同时输出就是一个N位二进制计数结果。功能是每次在时钟上升沿到达时将结果加1并输出。能够实现循环计数：000,001,010，…。因此这是一个时序逻辑器件，他常用数字时钟和程序计数器（PC）中。 下面我们来对他进行建模： 123456789module counter #(paramer N=8) (input logic clk, input logic reset, output logic [N-1:0] q); //很明显是异步复位 always_ff @(posedge clk,posedge reset) if(reset)q&lt;=0; else q&lt;=q+1;endmodule 注意上面的赋值语句虽然使用阻塞赋值语句也不会有问题（这是因为每种情况只会有一个赋值代码），但是为了规范可以在任何综合工具上都能综合，因此还是要求使用&lt;=来进行赋值。 移位寄存器 移位寄存器输入有时钟信号clk,串行输入信号Sin,输出由串行输出Sout以及N位并行输入的Qn-1:0。移位寄存器的功能就是在时钟信号的每一个上升沿，从Sin移入一个新的位，并将寄存器的整体向前（高位）移动一位，因此最前面（最高位）会出来位移如Sout。我们可以将其看成是一个串行到并行的转换器，每一个周期从Sin输入一位，N个周期后可以通过Qn-1:0直接访问N位输入。因此在将内容整体移位时很明显是需要并行同时执行赋值更新操作的，因此是用非阻塞赋值语句的同步时序逻辑来实现，使用的实现器件就是将N个D触发器串联即可。 下面我们对这个移位寄存器进行优化，使其可以并行加载，什么意思？ 此时输入增加了Load信号和并行输入信号Dn-1:0。我们思考一下，之前如果我们想要先将这个N位寄存器加载一个N位数，那么需要先执行N次移位操作，才能将这个N为二进制码加载进去，这很麻烦，因此使用并行输入信号同一时刻并行的为每一个位进行赋值从而实现单位时间不用移位就完成移位寄存器对于一个N为二进制数的加载。此时功能是： Load=1时，并行加载一个N位二进制数 Load=0时，移位寄存器进行移位操作，每一次clk上升沿整体向高位移动一次，最低位由Sin填入 那么此时可以实现串行转并行：Sin到Qn-1:0，同时还有并行转串行Dn-1:0到Sout。那么此时我们来实现一个建模： 123456789101112131415161718module shiftreg #(parameter N=8) (input logic clk, input logic reset,load, input logic sin, input logic [N-1:0] q, output logic [N-1:0] q, output logic sout); //很明显又是一个异步复位 always_ff @(psoedge clk,posedge reset) //复位 if(reset)q&lt;=0; //同时并行赋值同一时刻完成N位二进制数的加载 else if(load)q&lt;=d; //移位，注意要将sin拼接到最低位 else q&lt;=&#123;q[N-2],sin&#125;; //同时记录sout值 assign sout=q[N-1]endmodule 有限状态机建模 我们之前学习的建模都是只是将最核心的同步时序电路部分进行了建模，使用的是always_ff实现的，但是实际上对于一个状态机来说，他在状态寄存器的两侧还存在输入到现态的计算的组合逻辑电路，还有右侧连接的根据现态计算出输出的组合逻辑电路，因此实际上在对一个有限状态机进行建模时即需要alwalys_ff的同步时序过程块，也需要alwyas_comb组合逻辑过程块。如下： 这是一个最简单的3分频计数器，他就是一个moore型的有限状态机，输入是一个时钟输入信号，一个输出，功能是每3个周期后输出产生一个周期的高电平。因此状态转换图如上图，输出是时钟的3分频。因此建模代码如下： 12345678910111213141516171819202122module divideby3FSM(input logic clk, input logic reset, output logic q);\t//枚举类型集合的声明,类似于结构体的声明\ttypedef enum logic [1:0] &#123;S0,S1,S2&#125; statetype;\t//statetype枚举集合的实例化\tstatetype [1:0] state,nextstate;\t//核心状态寄存器使用同步时序逻辑\talways_ff @ (posedge clk,posedge reset) if(reset) state&lt;=S0; else stats&lt;=nextstate;\t//次态的计算使用次态组合逻辑计算\talways_comb case(state) S0:nextstate=S1; S1:nextstate=S2; S2:nextstate=S0; default:nextstate=s0; endcase\t//输出逻辑\tassign q=(state==S0);endmodule 我们会发现上面又添加了两个组合逻辑过程块分别同来计算输入到次态和现态到输出，同时由于SystemVerilog HDL硬件语言具有并行性的特点，因此nextstate虽然先在always_ff的同步时序逻辑过程块中使用了，但是其具体值其实是通过下面的次态组合逻辑过程块计算得到的。 一定要注意SystemVerilogHDL的代码具有并行性的特点，因此信号的调用和声明赋值无先后顺序。 存储器阵列 接下来我们学习一个重要的器件–存储器阵列，他是一种有效的可以存入大量数据的模块，每一个N位地址都可以读出或者写入M为数据。 数据：存储的内容 地址：数据的索引 存储器由一个二维存储单元阵列构成，每一各位单元存储一位数据，每一行存储的是一个M位二进制码数据，由于地址编码是N为，因此一共有2^N行，也就是说可以存储2^N个M位二进制码数据。 对一个N位地址M位数据的阵列： 有2^N行和M列 深度（Depth)：阵列的行数 宽度（Width)：阵列的列数 阵列的总大小（Array Size)：深度×宽度=2^N×M 字（Word)：每行数据成为一个字 例如一个2位地址和3位数据的存储器阵列： 他的阵列深度会是4行，同时数据字个数也就是4个，每一个字的字长是3位。如上图所示，10地址存放的数据就是100。"},{"title":"逻辑电路基本元件","path":"/wiki/数字逻辑与数字系统笔记/逻辑电路基本元件/index.html","content":"逻辑门 大部分逻辑门我们在《机组原理笔记》中已经学习了大部分逻辑门，这里不再细讲，但是这里补充一个门。 这个门并未改变数值，也就是说逻辑功能上来讲和导线并未区别，但是一个电流在经过多个逻辑门以后电压难免会降低，但是电压又是用来表述0和1值的。为了位置数值不变即电压稳定，这个门可以为电流提供稳定的能量驱动，从而保障电流电压的稳定即数值的正确性。 逻辑电平 你可能会疑惑在逻辑门中如何区分传进来的值是0还是1。其实是通过电平的高低来区分。理想情况下使用离散电压来表示0和1，即各用一个电平值来表示。比如0V是0,5V是1，但是电平能量是连续的，肯定会存在4.99V，3.2V等，因此用离散电平来表示仅是理想情况，不易实现。所以一般使用一个区间来表示两个值，比如[0,2.5]的电平区间表示0，[2.6,5]的电平区间表示1，这样就可以用连续的电平来表示两个离散的二进制位数值0和1了。 噪声 任何使得信号衰减的事物都是噪声，例如给电源供电时耦合到传输线中的阻抗等就是噪声，如下图： 那么如果不巧刚好高电平的信号受噪声干扰降为了低电平，那么就相当于应该表示1的信号衰减为了0信号，这就是错误了。因此为了尽量避免这种情况，我们应该经过一段时间加入一个驱动Buf门来保证电平的稳定性。 类似的，传输信号的距离越长，也会导致信号衰减越强，因此每隔一段距离需要一个Buf。 静态约束 即为了保障有效的逻辑输入，所有的电路单元产生有效的逻辑输出，我们使用有线的电压范围来表示离散的数值1和0。如下图： 作为输出端高电平表示1的范围是VOH，低电平是VOL，然而其中间范围的空白区域既不用来表示1也不表示0，而是作为错误信号区域，这样，当输出的信号总是在空白区域及说明输出信号段器件已损坏，需要及时修复。而作为接收端，原理也类似，但是要注意接受端的高电平范围会更大即临界值更小，低电平范围也会更大即临界值更大。 VIH&gt;VOH,VIL&lt;VOLV_{IH}&gt;V_{OH},V_{IL}&lt;V_{OL} VIH​&gt;VOH​,VIL​&lt;VOL​ 原因很简单，因为噪声的干扰，可能高电平的信号会略微降低，低电平的信号略微增强，那么接收端可以适当的增大误差接受范围来保证信号的接受率。这里的误差范围： NMH=VOH−VIH,NML=VIL−VOLNM_H=V_{OH}-V_{IH},NM_L=V_{IL}-V_{OL} NMH​=VOH​−VIH​,NML​=VIL​−VOL​ 如果接收端的信号也常处于Fobidden Zone，那么需要增加Buf来稳定电平信号或者确定输出端器件完好。 这里我们可以轻松记住这几个信号值，VOH表示的是out出去的High电平，VIL表示的是in进来的Low电平。因此带O的都是输出端的，带I的都是接收端的。并且H表示高电平信号1，L表示低电平信号0。 思考：为什么中间要留白一部分范围？ 我们假设[0,2.5]为低电平信号，[2.6,5]是高电平信号，那么干扰信号的事物很多，可能有一些事物会降低电平信号，但是也有一些会增强电平信号。那么现在有一个2.54V的电平信号，我们就不好判断到底是本身就是高电平的2.54V信号，还是由2.49低电平信号受到噪声干扰增强到2.54V的信号了。因此中间有一个分割区是必须的。 直流传输特性 通过下图我们可以看出，左图是理想的电平信号，即0和1信号之间的电平是骤增的，这样就没有中间过渡变量信号值了，但是实际生活中，直流传输特性都是如右图的，所以我们需要用区间来划分高低电平信号。 并且误差区间NMH和NML一般不会大于VDD/2(VDD就是逻辑器件可表示的最大信号电平值，即表示范围的最大值）,即陡峭的部分一般不会过大。当然判断一个器件性能是否足够好，可以通过观察其从低电平到高电平的增长曲线斜率是否大（是否陡峭）。越陡峭表示误差范围越小，从低电平到高电平的增长越快，性能也就越好。 逻辑电平系列 逻辑器件系列 VDD VIL VIH VOL VOH TTL 5（4.75~5.25） 0.8 2.0 0.4 2.4 CMOS 5（4.5~6） 1.35 3.15 0.33 3.84 LVTTL 3.3（3~3.6） 0.8 2.0 0.4 2.4 LVCMOS 3.3（3~3.6） 0.9 1.8 0.36 2.7 CMOS晶体管 他是其中一种逻辑电平系器件，它是通过半导体来实现的。如下图： 类似的C,SI等都是半导体，他们是通过共用电子对连接的，稳定性强。共价键的强结合力，是原子排列规则，形成晶体。这样自由电子就很少，共价键中的两个电子都被紧紧束缚在共价键之中，称为束缚电子，常温下束缚电子很难脱离称为自由电子，因此本征半导体中（就是不含杂质的半导体）的自由电子很少，所以导电能力弱。 现在我们将一些C换成高价磷如下： 那么就会多出一个自由电子，这样磷原子就成了不能移动的带正电离子了，我们将次时的结构称为N型半导体。 思考：为什么是正电离子？ 虽然会有自由电子，但是我们想一想之前的P是2,8,5结构缺少三个电子，得到一个电子才会变为负离子，但是现在确实和其他的C原子共享了其中的4个电子，因此他呈现了正价+4。因此是正电，在英文中为Positive因此是P型半导体。 同样的我们也将一些C换成三价元素如硼或者铟等，那么就会少一个电子即为空穴如下： 那么此时的结构我们称为P型半导体。 思考：为什么是N型负电半导体？ 上图中的空穴位置画错了，应该是在硼原子旁产生一个空穴，由于他缺少一个电子和别人共享，所以会产生一个空穴，因此需要一个自由电子，所以刚好可以和P型半导体结合。空穴越多，他的导电性也就越强。和P型结构相反，因此是Negative即N型半导体。实际上此时空穴会向左移动和自由电子结合形成PN结。 PN结 那么我们在同一个半导体基片上，分别制造P型半导体和N型半导体，经过载流子的扩散，在他们的交界处就会形成PN结如下图： PN结正向偏置 那么我们知道随着越来越多的自由电子和空穴结合，在P,N中间区域就会形成许多PN结也就导致了导电性变差了，同时由于自由电子和空穴的减少，PN型半导体的导电性会减弱。因此PN型半导体导电性如果不在外界的影响下，导电性会逐渐自动变差。我们为了避免这种情况，维持其导电性，接入如下的电源： 那么PN半导体内自由电子会自动向右移动去和空穴结合形成PN结堆积在中间部分使得虚线包括部分逐渐变厚（因为有许多的自由电子和空穴形成的呈电中性的PN结）。但是现在我们加入了如上图的电源，其电流方向和半导体内的电流方向刚好相反，也就阻碍了PN半导体内的自由电子向右移动去和空穴集合，因此PN结会变少，中间部分也就会变薄，同时由于会PN结形成的少，说明空穴和自由电子也就更多，维持了PN半导体的导电性强。上图是PN结正向偏置。 PN结反向偏置 那么如果电源反接，那么就会促进PN结的形成，也就造成了中间部分变厚，同时PN半导体的导电性会加速削弱，如下图： 这是PN结反向偏置。我们发现上面两种情况都是PN解单向导电特性的体现。正反向偏置利用PN结单向导电性的特点可以实现半导体的功能，时而断点，时而通电。 半导体二极管 半导体二极管如硅二极管就是半导体正向偏置和反向偏置的应用。首先我们给出硅二极管伏安特性曲线： 也就是说明只有电压大于0.5V才能产生电流。那么导通时 就类似于电源闭合，允许电流通过，实际上就是半导体正向偏置维持其导电性所以可以通过电流。而截至时 就类似于电源断开，不允许电流通过。实际上就是半导体反向偏置加速了半导体导电性削弱直至到0，所以不允许通过电流。 类似的还有如下形式：MOS晶体管是多个PN结形成 nMOS 通电和断点就是使用Gate是否接入来决定导电性的，也就模拟出了半导体的特性。 pMOS 当然上面的是npn形式的我们称为nMOS，同样也有pnp形式的我们称为pMOS，只是Gate信号相反了如下： 一定要注意两个符号不一样，pMOS多了一个圈表示取反的意思，因此Gate信号功能刚好相反。那么两个晶体管的功能如下： 也就是nMOS可以更好的导电0信号,pMMOS导电1信号。他们两个组合就可以形成一个非门如下： 此时当输入信号为A时，那么nMOS关闭Gate，导致不导电0信号GND，而此时正相反pMOS打开Gate，可以导电高电平VDD，因此Y输出信号1，也就实现了非门的功能了。当然如果反一下，nMOS接VDD，pMOS接GND那么就是一个驱动BUF门了。 注意区分pMOS和nMOS的区别是有无圆圈，同时带三角的是GND低电平。 同样更复杂的连接还可以形成与非门： 此时两个pMOS并联为P1,P2分别受A,B控制，同时两个nMOS串联为N1,N2分别受A,B控制。那么只要N1,N2有一个Gate，那么就不能输出低电平，因此只有A=1&amp;B=1的时候才能输出低电平信号0，其他情况只要A=1||B=1，那么并联的P1,P2就可以输出高电平信号1。刚好满足与非门的功能，因此再复杂的门我们都可以通过不同的pMOS和nMOS来进行拼接组合表示出来。并且都是体现了半导体PN结单向导电的性质和正向偏置与反向偏置的应用。"},{"title":"逻辑电路的表达式","path":"/wiki/数字逻辑与数字系统笔记/逻辑电路的表达式/index.html","content":"晶体管功耗 功耗就是单位时间内消耗的能量，这里分为两种：静态功耗和动态功耗。 动态功耗 对栅极电容进行充电所消耗的能量，对电容充电到电压VDD所消耗的能量为CVDD^2即： Pdynamic=1/2∗C∗VDD2fP_{dynamic}=1/2*C*V_{DD}^2f Pdynamic​=1/2∗C∗VDD2​f 其中C就是电容，单位法拉第，当晶体管以频率f来工作，充电的消耗为f/2，放点的频率也是f/2，因为放电过程不需要消耗能量，因此动态功耗中还乘了一个1/2f。 静态功耗 当系统处于空闲状态时，晶体管处于截止状态，单仍然会泄露少量的电流，因此会产生静态功耗，静态功耗由电源和地直接的漏电流IDD产生，正比于漏电流。公式如下： Pstatic=IDD∗VDDP_{static}=I_{DD}*V_{DD} Pstatic​=IDD​∗VDD​ 思考：对比前面学到的PN结知识，我们可以怎样理解动态功耗和静态功耗？ 动态功耗充电就是可以看成借助外界力量解除堆积的PN结，从而增强导电能力，而静态功耗就是可以看成自然状态下自动向PN结形成的过程，他会产生微小电流也就是漏电流同时由于产生PN结从而降低了导电能力。 例题 估算如下无限手持设备的功耗，假如此时VDD=1.2V,C=20nF,f=1GHz,IDD=20mA。那么晶体总功耗是多少？ Pdynamic=1/2∗C∗VDD2f=1/2∗(20nF)∗(1.2V)2∗(1GHz)P_{dynamic}=1/2*C*V_{DD}^2f=1/2*(20nF)*(1.2V)^2*(1GHz) Pdynamic​=1/2∗C∗VDD2​f=1/2∗(20nF)∗(1.2V)2∗(1GHz) Pstatic=(20mA)∗(1.2)VP_{static}=(20mA)*(1.2)V Pstatic​=(20mA)∗(1.2)V P=Pdynamic+Pstatic=14.4WP=P_{dynamic}+P_{static}=14.4W P=Pdynamic​+Pstatic​=14.4W 数字逻辑电路 数字逻辑电路是一个可以处理离散值变量的网络。它主要是使用一种逻辑门电路图来显示各种逻辑计算的实现原理，例如我们上面画的非门和异或门的图就是数字逻辑电路。数字逻辑电路具有如下几个特点： 一个或多个离散值输入端 一个或多个离散值输出端 描述输入和输出关系的功能规范 描述当输入改变时输出相应延迟的时序规范 结点和模块 电路由结点和模块组成，结点是一段导线，通过电压传递离散值变量，结点可以分为如下几种： 输入结点：接收外部的值，比如上图中的A,B,C是三个输入结点，个输如一个0/1信号值 输出结点：输出值到外部，是输入信号经过门电路处理后输出的离散值信号 内部节点：不属于以上两者的结点，比如n1 模块本身是一个带有输入、输出、功能规范和时序规范的电路（注意buf逻辑也是一个模块，它具有驱动的功能）。每一个电路都是一个电路，一般会有逻辑门组合，例如上图中的E1,E2,E3。 数字逻辑电路的分类 组合逻辑电路 任一时刻的输出仅由该时刻的信号决定 无记忆的，与电路状态无关 时序逻辑电路 任一时刻的输出由该时刻的输入和电路该时刻的状态共同决定 具有记忆性，与电路状态有关 思考：组合逻辑电路与时序逻辑电路的延迟？ 首先我们需要明确无论是哪种逻辑电路，都是一定会有延迟的即输出会晚于输入一段时间才输出，因为都需要通过逻辑门对输入进行处理才可以输出。但是组合逻辑电路无外界或电路状态的影响，会随着输入信号即刻改变，例如非门，当输入信号为0，那么输出信号就是1，但是一旦输入信号改变成了1，那么输出信号也会立刻改变成1，所以不会受到电路状态的影响。而对于时序逻辑电路，例如一个时序逻辑模块的功能是对于输入信号A和B，只有当B信号为1时才可以对A信号取非，那么此时即使A传进来1了，也需要等待电路状态改变成接收到了B信号1才可以对A进行信号取非，即此时会受到电路状态影响，同时如果此时B不为1，那么模块也会记录输入信号A为1，所以有记忆性。 一定要注意基本上每一个模块都是一个组合逻辑模块（毕竟一般是多个逻辑门的组合，功能会复杂）。如下图： 对于组合逻辑电路，每一个电路节点或者叫线交汇点只可能是两种情况：①电路的输入结点②只连接电路模块的一个输出端。毕竟如果一个电路结点连接着两个输出端的话，当两个输出不同即一个信号为1一个信号为0时，那么交汇结点就会出现信号冲突。 并且要注意电路中应该不能存在回路，因为也可能会造成信号冲突。 组合逻辑电路的错误状况 图二错误，就是因为存在回路可能会造成冲突。比如假设此时传入的两个信号都是1，那么经过异或门后应该输出的是0，但是还有一部分1信号却通过短接的回路到达了输出导线上，那么此时输出导线上同时有接收到的0和1会产生信号冲突，所以不正确。 图四错误，由于一个结点接受了两个输出端的信号，可能会产生信号冲突。 图六也是错误的，由于有回路同样也有可能会产生信号冲突（分析一下就很容易知道）。所以数字逻辑电路中是坚决要避免回路或者连接多个输出端的结点的。 布尔代数的定义 我们在前面也知道了数字逻辑电路通过不同门组成了有不同功能的模块，每一个模块实际上就是使用的0/1信号的逻辑运算来模拟各种复杂的数学计算的。（如果学习了机组原理，我们知道实际上ALU中的一位加法器也是使用的各种逻辑门实现的）。那么明显布尔代数对于数字逻辑电路的规划设计很重要，所以我们详细介绍一下布尔代数。在布尔代数中变量只能取&quot;真&quot;或者&quot;假&quot;。1代表的就是真，0代表的就是假。并且有三种最基本的逻辑运算： 与运算：A·B或者AB 或运算：A+B 非运算：—A（假装横线在A上面） 布尔表达式 实际上就是一些布尔代数的复杂运算表达公式，一般是来描述组合逻辑电路中输入与输出之间的功能规范的。比如： 实际上我们不难发现上面的这个布尔表达式就是模拟的加法。这种加法运算实际上已经是需要复杂的布尔表达式来表示的了。 布尔代数的公理 下面我们给出以下布尔代数常用的公理，理解最重要： 对偶规则 F为任意逻辑表达式，若将F中所有运算和常量作如下变换： 所得到的的新的表达式就是F的对偶式F’，比如： 我们发现就是分别将数值和符号进行了上面的对偶规则的改变，那么我们可以得出以下结论: 对偶式相互的，F和F’互为对偶式 对偶规则：两个逻辑表达式F和G相等，那么对偶式F’和G’也是相等的 一定要注意对偶规则不是逻辑表达式的整体取反，他是在原有的顺序不变的基础上，对于每一个元素进行了逻辑取反。其主要是为了使用第二个特点来描述两个表达式的内在关系。 单变量定理 那么对于上面这几种定理，我们都可以使用组合逻辑电路表示： 如果你对门的符号还不太熟悉，请快速跳转《机组原理门符号》 多变量定理 这部分就有点难理解了，可能需要思考一段时间或者画韦恩图分析。一定要注意这里的值只能取0或1，所以上面的吸收律等才可以成立。 思考：上面的一致律如何推得的？ 我们以左边的式子为例： 实际上就是补1法，缺哪个就用X+非X补。右边的式子也类似，我就不讲解了。同样的买也可以使用组合逻辑电路表示： 最小项 最小项就是一种特殊的乘积项（或者叫做&quot;与&quot;项）。即元素之间只能是乘积，并且还要求对于n个变量逻辑函数的每一个最小项，必须同时包含有n个因子的乘积，即各个最小项中，每一个变量必须以原变量或者反变量形式作为因子出现一次，而且仅出现一次，（毕竟n个变量只够每一个变量因子出现一次）。 如上面，都是最小项，我们就可以理解每一个元素因子为什么只能出现一次了，如果有一个元素出现了两次，那就必定有一个元素没出现过，那么就不是最小项了，因为最小项要求n位最小项必须由n个元素。并且我们可以知道： 最小项个数=2n(n是元素种类数)最小项个数=2^n(n是元素种类数) 最小项个数=2n(n是元素种类数) 最小项的编号 最小项用mi来编号（i从0开始递增），最小项的编号值是由使最小项取值为1决定的，比如： 那么很明显编号为零的就会非A非B非C，只有三个元素取值都为0整体才为1。这里我们给出三变量的最小项： 我们不难看出每一个最小项只有一组变量能使其值为1，而其他各组取值该最小项都为0.由于这种函数真值表中1的个数最少，因此称为最小项。 最小项的性质 性质1 变量任取一组值，仅有一个最小项为1，其他最小项为0 性质2 n变量的全体最小项（共有2^n个)之和为1，毕竟有一个最小项会为1，那么整体之和就是1了。 ∑n=02n−1mi=1\\sum_{n=0}^{2^n-1}{m_i}=1 n=0∑2n−1​mi​=1 性质3 n个变量任意两个不同的最小项相与，结果恒为0，毕竟每次只有一个最小项为1，其他最小项都是0，所以取交就是0。 性质4 如果两个最小项仅有一个变量因子不同，那么我们就成这两个最小项相邻。两个最小项相邻，相邻最小项相或，可以合并成一项，并且可以消去一个变量因子，比如： 性质5 任一n变量的最小项，必定有n个不同最小项相邻（即n位变量因子有一个取反就成为了他的相邻最小项），比如： 最大项 最大项是一种特殊的和项（又称为&quot;或&quot;项）。即元素之间只能是或，并且还要求对于n个变量逻辑函数的每一个最大项，必须同时包含有n个因子的或，即各个最大项中，每一个变量必须以原变量或者反变量形式作为因子出现一次，而且仅出现一次，（毕竟n个变量只够每一个变量因子出现一次）。比如： 最大项的编号 最大项用Mi来编号（i从0开始递增），最大项的编号值是由使最大项取值为0决定的，比如： 如上面，都是最大项，我们就可以理解每一个元素因子为什么只能出现一次了，如果有一个元素出现了两次，那就必定有一个元素没出现过，那么就不是最大项了，因为最大项要求n位最小项必须由n个元素。并且我们可以知道： 最大项个数=2n(n是元素种类数)最大项个数=2^n(n是元素种类数) 最大项个数=2n(n是元素种类数) 其实和最小项的结论很相似。可以对比着记忆。 那么很明显编号为零的就会ABC，只有三个元素取值都为0整体才为0。这里我们给出三变量的最大项： 每一个最大项只有对应的一组变量取值为0，而其他各组取值该最大项都为1.由于这种函数真值表中1的个数最多，因此称为最大项。 最大项的性质 性质1 变量任取一组取值，仅有一个最大项为0，其他最大项为1 性质2 n变量的全体最大项之和为0（毕竟有一个最大项取值为0，那么整体就是0了）。 ∏n=12n−1Mn=0\\prod_{n=1}^{2^n-1}{M_n}=0 n=1∏2n−1​Mn​=0 性质3 不同的最大项相或结果为1，毕竟每一次只有一个最大项取值为0，其他的最大项取值都是1，所以取或就是1。 性质4 两个最大项如果仅有一个变量因子不同，其他变量均相同，则称这两个最大项相邻。两个相邻的最大项相&quot;与&quot;，可以合并成一项（等于相同因子之和），并且可以消去一个因子。 性质5 任一n变量的最大项，必定有n个不同的相邻最大项（n位中任意一个变量因子取反就是一个相邻最大项）。 最小项和最大项的关系 编号下标相同的最小项和最大项互为相反数，即 Mi=mi‾或者mi=Mi‾M_i=\\overline{m_i}或者m_i=\\overline{M_i} Mi​=mi​​或者mi​=Mi​​ 标准与或式 由最小项之和构成且最小项之间取或的运算逻辑表达式，如下： 我们可以使用编号和运算求和符号来简写表达式。那么他的真值表如下： 我们发现有如下几个特点： 每一个最小项都对应真值表中值为1的一行 标准与或式是最小项之间的或运算，不存在其他运算 标准与或式与真值表间一一对应 从标准与或式中可以直接判断哪些变量取值可以使表达式为1（就是有一个最小项取1的时候可以使表达式值为1） 我们发现一个规律：任一逻辑函数都可以表达为最小项之和的形式，而且是唯一的，比如： 标准或与式 由最大项之积构成且最大项之间取乘积的运算逻辑表达式，如下： 我们可以使用编号和运算求乘积符号来简写表达式。那么他的真值表也和标准与或式一样有以下几个特点： 每一个最大项都对应真值表中值为0的一行 标准或与式是最大项之间的与运算，不存在其他运算 标准或与式与真值表间一一对应 从标准或与式中可以直接判断哪些变量取值可以使表达式为0（就是有一个最大项取0的时候可以使表达式值为0） 我们同样发现一个规律：任一逻辑函数都可以表达为最大项之积的形式，而且是唯一的，再联系任一一个逻辑函数也可以唯一表示成一个标准与或式，所以我们可以推出一个结论，相同的逻辑函数对应的标准与或式和标准或与式可以互相转化。 标准与或式和标准或与式的关系 那么我们接下来就给出他们之间转换的关系公式： F=∑imi=∏j≠iMjF=\\sum_{i}{m_i}=\\prod_{j≠i}{M_j} F=i∑​mi​=j=i∏​Mj​ 证明如下： 那么也就是说对于3位逻辑表达式F如果标准与或式使用了编号1,3,7的最小项，那么标准或与式就是用了编号0,2,4,5,6的最大项。 一定要求是标准与或式或者标准或与式，如果不是，那么需要用补1法进行变换使之转化成标准式。 布尔表达式到真值表的转化 我们对于一个布尔表达式，可以将它表示为标准式，然后使用编号就可以轻易求得一个式子取得不同值所需要的变量组了。比如： 我们将这个非标准化布尔表达式首先用补1法转换成标准式，然后转换成标准与或式，那么编号有3,6,7的最小项，所以只有ABC取011,110和111时可以使表达式为1，其他情况都是0，并且是3位表达式，所以一共真值表有8行对应8个情况： 我们可以用标准或与式再求解以下上面的布尔表达式，那么F就会转化成标准或与式： ∏M(0,1,2,4,5)\\prod{M(0,1,2,4,5)} ∏M(0,1,2,4,5) 那么也就是说当ABC,000，001,010,100,101的时候表达式会为0，其他情况为1，发现和上面的真值表一样。这样我们也就证明了标准与或式和标准或与式的转换定理是正确的。"},{"title":"行为建模","path":"/wiki/数字逻辑与数字系统笔记/行为建模/index.html","content":"在SystemVerilog HDL中，行为建模是指将数字逻辑电路的功能以较高的抽象形式描述出来，他通过输入和输出之间的因果关系直接建立电路模型，行为建模包括两种描述风格： 基于持续赋值语句（assign）的建模 基于过程块（always和initial）的建模 基于过程块语句的建模相比基于持续赋值语句的建模具有更高的抽象层次，编程也更加便捷。 基于持续赋值语句的建模 基于持续赋值语句的建模是指根据信号量之间的逻辑关系，采用持续赋值语句（assign）描述数字逻辑电路的方式，也称为数据流建模，其使用方法如下： 1assign &lt;#延迟量&gt; 信号名=逻辑表达式//&lt;#延迟量&gt;可以缺省 比如： 1234logic [3:0]out1,out2,A,B;assign out1=A+B;//经过5个单位时间延迟后赋值给out2assign #5 out2=~(A&amp;B); 我们注意到行为建模语句主要是基于已经定义的变量，来定义输入变量和输出变量之间的某种关系，即为行为建模。基于持续赋值语句的建模的特点是只要“=”右侧表达式中的任意变量发生变化，那么这个表达式就会立即重新计算并赋值给左边的变量。如果定义了延迟量，那么赋值将在相应的单位时间内（默认为纳秒，ns）后再完成。 一定要注意延迟量主要用于仿真，是不可以综合的。 并且持续赋值语句左侧可以是变量类型（如logic)的信号，也可以是线网类型（如tri）信号，也可以是信号的拼接形式。对于持续赋值语句，任何输入的变化都会立即影响输出结果，体现了组合逻辑电路的特征，即变化瞬时性，因此，基于持续赋值语句的建模只能用来描绘组合逻辑电路。而且基于持续赋值语句的建模方式提供了使用逻辑表达式描述电路的一种方式，不必考虑电路的组成结构以及元组之间的连接。 刚刚上面我们已经给出了基于持续赋值语句的建模例子了，建模语句主要是用来描述信号之间的行为关系，下面我们给出基于持续赋值语句的建模模板： 12345678910module 模块名 (端口列表);\t//中间变量声明\tlogic 信号1，信号2... //逻辑功能定义\tassign 赋值语句1;\tassign 赋值语句2;\t...\tassign 赋值语句n;endmodule 下面我们以一道例题来讲解如何进行基于赋值语句的建模，我们这里以译码器为例，我们前面学习过译码器是根据接收的信号所组成的编号，从而让特定的输出信号输出高电平真值。比如2线-4线译码器： 我们可以根据真值表列出不同信号取真值的表达式（简单的当然也可以使用卡诺图进行简化），然后定义译码器模块来进行建模： 123456789module dec2to4(input EN,A,output Y);\tlogic EN;\tlogic [1:0] A;\tlogic [3:0] Y;\tassign Y[0]=EN&amp;~A[1]~A[0];\tassign Y[1]=EN&amp;~A[1]&amp;A[0];\tassign Y[2]=EN&amp;A[1]&amp;~A[0];\tassign Y[3]=EN&amp;A[1]&amp;A[0];endmodule 当然我们还可以通过这个方法来实现机组原理中讲到的一位全加器： 他的建模语言代码如下： 1234567module fulladder(A,B,cin,sum,cout);\tinput logic A,B,cin;\toutput logic sum,cout; assign sum=A^B^cin;\tassign cout=(A^B)&amp;cin;endmodule 如果我们在基于持续赋值建模中的代码中使用了延迟量，那么虽然最后得到的电路完全相同，但是在仿真综合时是会出现不同的结果的，我们前面学习了最终仿真综合平台的结果会以脉冲的形式显示在图上，那么当增加了延迟后，脉冲出现的时间就会发生改变，如下： 未加延迟量的结果： 增加了延迟量的结果： 基于过程块的建模 前面我们介绍了基于持续赋值语句的建模方式，接下来我们来学习一下另一种建模方式–基于过程块的建模。基于过程块的建模关注数字逻辑电路输入输出的因果关系（行为特性），即在何种输入条件下，产生何种输出（即完成什么操作），并不关注电路的内部结构细节。这种建模适用于规模庞大、复杂的电路设计，配合EDA工具，构成了现代超大规模集成电路（VISI）的设计基础。 基于过程块的建模使用关键字initial和always定义，通过块标识符begin…end（相当于大括号）包围起来的过程块对电路进行描述。initial主要用于仿真验证，always则主要用于电路建模，也可以用于仿真。always过程块是一个无限循环，每一个always块描述了一个独立的电路功能。 always过程块分为三中类型：always_comb（描述组合逻辑），always_ff和always_latch（描述时序逻辑）。这里我们主要关注always_comb。他的代码模板如下： 12345678910module 模块名 (端口列表);\t//中间变量声明(如果需要)\tlogic 信号1，信号2，...,信号n; //逻辑功能定义（过程块）\talways_comb begin 过程赋值语句 高级语言结构\tendendmodule 基于过程块的建模最重要的就是一定记住块标识符类型的声明以及begin…end包裹。这里我们给出二路选择器的建模板子： 我们发现上面的代码中是使用条件语句结构推动描述某几个信号之间的因果关系来进行行为建模的，但是仅仅使用条件语句明显是无法完成建模行为描述的，他也可以像基于持续赋值语句建模一样使用过程赋值语句即对某些变量信号进行赋值，但是他不需要使用assign声明，并且“=”左边的信号必须是变量类型（如logic类型），并且不能是线网类型，“=”右边的信号的类型无限制。如下： 123456789101112131415module adder(input a,b,cin,output[1:0] out);\tlogic half_sum,half_carry;\talways_comb begin //正确 half_sum=a^b^cin; //正确 half_carry=a&amp;b|a&amp;~b&amp;cin|~a&amp;b&amp;cin; //错误，端口信号如果不显示声明为变量类型 //那么默认为wire类型，即线网类型 out=&#123;half_carry,half_sum&#125;; //下面的是正确的语句 logic out; out=&#123;half_carry,half_sum&#125;;\tendendmodule 阻塞赋值 在之前一讲的最后我们学习到了基于过程块的建模中的过程赋值语句，在SystemVerilog中，过程赋值语句可以分为两类：阻塞赋值（=）和非阻塞赋值(&lt;=)，其格式如下面所示。其中延迟量意义不变，也是不可以综合的。阻塞语句用来描述组合逻辑电路，非阻塞赋值用于描述时序逻辑电路。 12#5 out =a&amp;b;//阻塞赋值out[3:0]&lt;=&#123;b[2:0],1&#x27;b1&#125;;//非阻塞赋值 阻塞语句在该语句结束后就会立即完成赋值操作，如果在一个过程块有多条阻塞赋值语句，在前面的赋值语句没有完成之前，后面的赋值语句就不能执行，仿佛被阻塞了一般、由此可以，阻塞赋值中输入的变化会立即影响输出，故用于描述组合逻辑电路。 思考：阻塞语句貌似是串行的，这和SystemVerilog的并行性不冲突吗？ 不冲突，两者强调的方面不一样。并行性是指语句的执行之前没有串行机制，因此假设 12logic a=5;logic b=7; 那么两个指令是并行执行的，没有变量的先后创建之分，这是并行性，他值得是语句的执行没有串行机制。但是对于一个变化来说，一定是前面的先变化，然后后面的赋值语句再接收到前面的变化后，在执行这个变化，因为对于后面的语句来说变化在未传达之前是不可预知的，因此必须先等待前面的赋值语句做出改变。 思考：阻塞语句和非阻塞语句的区别？ 其实就是组合逻辑电路与时序逻辑电路的区别。我们前面学习了时序逻辑电路并不是接收到变化后立刻发生改变，而是需要等待所有的条件全部具备以后在发生变化，因此非阻塞语句就是等待全部变化赋值以后才可以执行。而阻塞语句就是接收到改变立刻修改赋值的语句，只能用于逻辑组合电路。 很明显上面额y想要变化，首先需要a和b更新赋值才可以。这就是逻辑上的串行，但是同时这几条指令是同时执行的，即a和b时同时发生变化的，因此是并行的，当y接收到a和b的变化后会立刻发生改变。 分支结构 在SystemVerilog中，分支结构有if…else语句和case语句。If…else语句是可综合的，主要用于生成多路选择器，其格式如下。if…else语句支持多层嵌套，可以使用begin…end增加可读性（类似于大括号）。 一定要注意在SystemVerilog中使用if…case语句尽量要考虑所有的条件（完整分支），即所有的情况都进行处理，这样才能产生组合逻辑电路，否则将综合出带有锁存器的时序电路。 也就是说即使某些情况我们不需要进行任何操作，最好也要加以讨论，如： 我们发现水位最高位14m,而我们使用的是4位表示，那么最高可以表示15，即使15的时候什么等也不亮，我们最好也加上一个灭灯的操作使得讨论完整。即总是要加上一个else总是好的。不要像写oj题一样只写if不写else。 同样的case语句也是一种分支结构语句，也是可以综合的，他主要用于生成多路选择器、译码器等。格式如下，同样的，对于case尽量也要考虑全面，这样才能产生组合逻辑电路，否则，将综合出带有锁存器的时序电路。也就是说，最后要加上default使得讨论完整。 并且某个分支项item_expr中的某位无关值，用？表示，那么该位的比较就不予考虑，即意味着比较结过永远为“真”。如下图： 下面我们来看一下如果未讨论完整所有的情况，那么综合时就会出现锁存器。 对于上面将2位的4中情况全部都讨论了，那么没事正常运行。如果出现下面这种少讨论的情况，那么就会出现锁存器，实际上锁存器很好理解。EN是使能端，只有EN为1时，输出端才会随着输入端立刻变化，即如果是a,b,c的某一种情况，那么Dout也会瞬间会根据不同的情况输出相对应的值，但是如果是未讨论的d情况出现了，那么此时EN会变为0，但是此时他和三态缓冲器不同，他的输出端并不是变为浮空，而是被锁住一直维持最后一次的输出状态，即如果在d情况之前Dout一直输出的是a的输出信号，那么锁住以后就一直维持输出a情况的输出信号直至d情况结束。如果d情况之前Dout一直输出的是c的输出信号，那么此时就会一直维持c情况的输出。 循环结构 在SystemVerilog中，循环结构主要包括for、repeat、while和forever。 for:满足条件表达式时执行（和C一样） repeat：直接循环预先给定的次数 while()：满足条件时执行 forever:一直循环下去 在这4种循环语句中，for语句是可综合的，可以用于数字电路的建模，其他三种语句多用于仿真当中，不一定能被综合工具支持。 注意这里的循环变量i等一定要设置为int或者其他的二态变量型，而不要使用logic向量型，否则会造成死循环。 行为建模总结 在行为建模中我们分别学习了基于持续赋值语句的建模和行为建模两个不同风格的建模。这里做一个总结： 基于持续赋值语句的建模只能用于描述组合逻辑电路 在过程块中，过程赋值“=”左边的信号必须是变量类型，不能是线网类型，而对右边的表达式则没有任何限制。 基于过程块的组合逻辑电路建模可以通过always_comb和阻塞赋值语句完成 基于过程块的组合逻辑电路，使用if…else和case…语句时要特别注意需要列出所有可能的条件，否则，综合得到的将不是组合逻辑电路。（对于case,必要时不忘记default语句） 基于持续赋值语句的建模方式和基于过程块的建模方式在一个模块设计中可以混用，并且没有顺序关系。"},{"title":"表达式化简与三态缓冲器","path":"/wiki/数字逻辑与数字系统笔记/表达式化简与三态缓冲器/index.html","content":"定理化简表达式 我们学习了标准与或式和标准或与式以后，那么以后对于任何一个逻辑表达式都可以使用这种方法进行化简了，最终表示成标准与或式或者标准或与式。如下面这道题： 根据布尔表达式绘制原理图 我们知道任何一个逻辑表达式最终都可以转化成最简的标准与或式或者标准或与式，那么接下来我们在进行原理图绘制主要需要解决的问题就是如何绘制标准与或式或者标准或与式。这里我们只需要使用两级门电路即可以轻松表示与或式和或与式。 例如标准与或式，那么我们先试用一级与门写出所有最小项，然后在使用二级或门将所有的最小项相加即可，如当我们要用电路图表示下面的标准与或式时： Y=AˉBˉCˉ+ABˉCˉ+ABˉCY=\\bar{A}\\bar{B}\\bar{C}+A\\bar{B}\\bar{C}+A\\bar{B}C Y=AˉBˉCˉ+ABˉCˉ+ABˉC 我们先分别用一级与门分别表示出了三个最小项，然后在使用了一个三输入或门相加就得到了上面的逻辑表达式。 电路原理图绘制原则 原理图绘制需要遵循一致的风格，以便于阅读和检查错误，绘制的原则如下： 输入在原理的左边（或顶部） 输出在原理的右边（或底部） 门电路流应从左到右或者从上到下 尽量使用直线连接 T型接头表示两条线有连接 两条线交叉的地方有一个点，表示有连接 两条线交叉的地方没有点，表示没有连接 并且还要尽可能的使用更少的门以降低成本，例如下图中右侧的德摩根表示电路就要好于左边，因为右边的门更少： 多输出电路 多输出电路顾名思义就是有多个输出出口的电路，一般他也会对应着多个输入入口，但是每次只有一个输出出口的信号有效，比如我们这里介绍一下优先级电路。优先级电路，是一种特殊的电路，他在所有输入为真的信号中，选择其中最重要的信号所对应的输出为1，其余输出为0。如下图： 这里的Ai中i越大表示优先级越高，所以当A3为0时，那么Y3就输出0了，，A2A1A0无论是多少都为0。这就是一个多输出的优先级电路。那么我们是如何实现的呢？实际上我们只需要三个门就可以实现如下图： 我们发现为了减少门的使用，实际上使用了更加复杂的三输入甚至四输入门，并且还有不同的取非功能。 多级组合逻辑 所以我们可以知道在多级组合逻辑电路中我们要遵循的规则： 规则1：减少硬件 所有的逻辑表达式都可以转化为与或式，理论上与或式可以使用两级门电路来实现即先与后或，但是二级逻辑可能会带来更高的成本，所以使用多输入门又称为扇入门。但是门电路的扇入数不可能无限制的增加（受工艺、成本等方面的制约）。 这里我们以三输入异或门的实现为例： 我们发现三输入异或门可以用来顶替右侧的复杂的组合逻辑电路，这无疑是更加高效的，但是三输入异或门同样造价高昂，且实现起来很复杂，更不要说五输入异或门等了。所以有时候我们需要在门数和们元件的选择上作一个这种考虑如下： 实际上我们也可以使用两个造价更便宜的异或门来顶替三输入异或门。所以减少硬件的目的并不是盲目追求组合逻辑电路的门数量减少，而是尽可能的使用更加直观简单的电路形式来表示逻辑表达式。 规则2：推气泡 实际上我们发现对于一个标准与或式或者标准或与式的逻辑表达式总是会使用与非门和或非门，即器件上有许多小圆圈符号表示取非，但是我们在绘制组合逻辑电路时如果照搬表达式会有许多取非的过程（同时一般商家也不会卖最后输出端取非的门元件），这很不直观同时也不符合实际情况，但是又难以直接化简逻辑表达式。所以我们可以在照搬逻辑表达式绘制出组合逻辑电路后使用推气泡的方法来简化电路。首先我们介绍一下推气泡的规则： 一定要注意推气泡后门也变了，别光顾着画气泡了。 那么现在我们就可以优化电路了，如下图： 此时我们推完气泡以后发现有4个气泡，实际上是取非输出后又取非了，那么就相当于双重取反等于没去反，所以可以将这四个气泡都消掉。所以我们给出一个规则： 推气泡要从输出端向输入端推 将气泡从电路最后的输出端开始推 如果当前门有一个输入气泡且上一级输出门无气泡，则消除这个门的输入气泡，然后在上一级门的输出加上气泡 如果当前门有一个输入气泡且上一级输出门也有气泡，那么就同时消除两端的气泡 最终我们就会得到一个所有取非都在输入端的门电路，这个才是一个逻辑清晰同时符合实际的电路，如下图： 我们推完气泡以后得到了如下电路（逻辑功能完全相同）: （画的丑，见谅，但是注意门也改变了）。具体的推气泡过程如下： 非法值（illegal):X 我们其实前面已经讲过了讲个输出电路不能直接相交汇，即节点不能同时连接两个输出，否则会出新冲突，实际上就是节点同时被0和1驱动，0是对应着电压0,1是对应着VDD，那么如果冲突了电压值就会介于0~VDD，那么这个信号可能是0也可能是1，也可能处于禁止区域内（前面将多有一个禁区表示既不是0也不是1，不懂了请看第1讲）。这时我们就成为交汇后的信号值为非法值X，一般出现这种竞争情况都是电路设计缺陷引起的，我们要避免此种情况，因为他会导致电路功耗变大，电路发热，并导致电路损坏。 无关项（Don’t Care):X 无关项一般会出现在优先级电路中，例如之前讲过的优先级电路： 那么很显然如果输入信号A3位输入，那么就不需要考虑其他输入量，此时对于不需要考虑的输入信号量就是用X来表示。 浮空值（floating):Z 浮空值称为悬空、高阻态、高Z态、开路、断路等，即次数电路断开的意思。首先我们要注意，浮空值Z就是指电路断开了，此时信号会介于0~VDD之间，具体是多少不知道，所以使用电压表并不能判断哪个电路节点处于浮空状态（可能这个信号就是0，也可能这个信号是浮空Z并且恰好Z是0），且测量断路节点的电压和接地点的电压，在电压表上的读数都为0。所以浮空值输出不确定，产生浮空节点常见的原因是忘记将电压连接到输入端。 注意浮空就是电路断开，所以输出信号就会自然变化，并不一定是0这和物理上的理想电路是不同的，其次浮空节点并不意味电路一定出错，浮空有时是人为设定的可以来制造某些特殊逻辑器件。 三态缓冲器（tristate buffer) 三态缓冲器就是使用了浮空，他可以用来防止节点处于竞争状态，具体实现如下： 当一个节点同时连接了n个输出时，若其中n-1个输出处于浮空状态（即断开状态），那么当前的节点值就等于驱动正常电平输出端的值。所以使用三态缓冲器就可以允许节点连接多个输出端了，这无疑优化了电路。例如上面的三态缓冲器，有三种输出状态：高电平VDD表示1信号，低电平0表示0信号以及浮空状态表示线路断开。 例如此时A是输入端，Y是输出端，使能端E是控制何时断开的，那么此时当使能端为0时，输出端浮空，表示A-&gt;Y的线路断开，那么这个输出信号Y暂时不等于A了，而是浮空值Z了，所以Y就暂时不参与下一级门的逻辑运算了，当E=1时，那么线路连接，Y=A的信号值，所以就可以看成一个导线了，那么Y就会以A信号值参与下一个门的逻辑运算。 三态缓冲器的应用 那么很明显在连接多个芯片的总线时，会用到三态缓冲器，许多不同的设备同时连接到同一总线上，但是某一时刻只允许一个芯片的信号有效，并向总线输出数据，其他芯片的输出必须浮空，以防止总线竞争，任何芯片在任何时刻都可以通过总线读取信息： to bus表示的就是从设备向总线输出数据的信号，每一次只有一个设备的三态缓冲器使能端为1表示每一次总线只会接受一个设备的信号。但是from bus表示的是设备从总线获取的信号，那么如果这个设备需要，就可以让from bus线上的三态缓冲器使能端为1接受来自总线的信号，并且同一时刻可以有多个设备都接受总线的信号，但是他们接受的信号是相同的。 使用卡诺图化简布尔表达式 我们回忆一下之前我们学习的补1法将布尔表达式转化成标准与或式，他可以使得式子更加符合电路逻辑，便于我们绘制组合逻辑电路，但是对于人类思维却不友好，因此如果我们现在知道标准与或式，我们希望可以将它化简成比较简洁清晰的形式，即变量尽可能的少，此时我们就可以使用卡诺图进行化简。 卡诺图的思想很简单，他就是通过合并项来化简布尔表达式。那么我们该合并哪些项呢？就是相邻最小项，比如PA和P非A，他们相加合并就可以变成P。卡诺图化简法是将逻辑表达式用一种称为“卡诺图”的图形来表示，然后在卡诺图上进行函数化简。下图就是几个卡诺图化简时的中间过程： 我们首先来介绍一下卡诺图的构成： 卡卡诺图是一种包含一些小方块的几何图形，图中的每一个小方块称为一个单元，每个单元对应一个最小项（注意一定要是最小项）。两个相邻的最小项在卡诺图中也必须是相邻的，卡诺图中相邻的含义： 几何相邻性，即几何位置上相邻，也就是左右上下紧挨 对称相邻，即图形中对称位置的单元是相邻的 注意，卡诺图里的相邻只要满足上面的两个条件之一即可，所以在卡诺图中两个相邻的最小项可能是左右上下紧挨的，也可能是对称的，但是在卡诺图中都称为相邻。 思考：为什么卡诺图使用的是最小项，而不是最大项？ 实际上很好解释，我们知道卡诺图的核心就是合并，那么合并肯定是相加，而与或式就是相加的，他的每一个元素就是最小项，所以使用最小项，而最大项之间的运算是相交，很明显不符合卡诺图的需求。 思考：能否更加详细的解释卡诺图中的相邻？ 如下图： {AˉBˉCˉ和AˉBˉC是左右相邻AˉBˉCˉ和ABˉCˉ是上下相邻AˉBˉCˉ和AˉBCˉ是对称相邻\\begin{cases} \\bar{A}\\bar{B}\\bar{C}和\\bar{A}\\bar{B}C是左右相邻\\\\ \\bar{A}\\bar{B}\\bar{C}和A\\bar{B}\\bar{C}是上下相邻\\\\ \\bar{A}\\bar{B}\\bar{C}和\\bar{A}B\\bar{C}是对称相邻 \\end{cases} ⎩⎪⎪⎨⎪⎪⎧​AˉBˉCˉ和AˉBˉC是左右相邻AˉBˉCˉ和ABˉCˉ是上下相邻AˉBˉCˉ和AˉBCˉ是对称相邻​ 并且要注意这里的相邻方块内的最小项也是相邻的。即任何两组相邻，只有一位变量取值不同，即符符号循环码排列规则。 思考：卡诺图还有哪些特点 除了方块相邻，我们还要注意对于n为元素，那么就会有2^n个卡诺方块，即2^n个最小项，并且卡诺图的横纵栏排列也是有讲究的，比如上图中的BC一行的值每一次都是只有一个位发生变化：00-&gt;01-&gt;11-&gt;10，所以BC的排列不能是00-&gt;01-&gt;10-&gt;11因为第2个位置和第3个位置两位都不同。并且卡诺图的编号就是按字典序的元素取值拼接出的二进制数，比如上图中的A(0)BC(00)就是二进制的000，所以m编号为0，在比如A(1)BC(01)就是二进制的101，所以m编号是5。 那么接下来我们来举例几个卡诺图熟悉一下卡诺图的特点，首先我们来观察一下二变量和四变量卡诺图： 注意A(AB),B(CD)谁在横向菜单栏，谁在纵向菜单栏无要求，看习惯，但是要注意编号时必须是按照字典序的顺序拼接组成二进制数。并且能对称，尽量使得卡诺图对称。 那么接下来我们看一个较为复杂的五变量卡诺图，他一共会有32个方格，一种编号如下： 一定要注意CDE和AB的排列编号要保证相邻的只有一位取值不同。 使用卡诺图表示逻辑函数 上面我们主要是讲解了卡诺图的构成和对卡诺方块的编号，那么接下来我们来学习以下每一个方格填的值来表示给出的需要化简的布尔表达式，实际上就是布尔表达式中出现的最小项对应的方格填1，其他地方默认填写0。如： F(A,B,C)=AˉBC+ABˉC+ABCF(A,B,C)=\\bar{A}BC+A\\bar{B}C+ABC F(A,B,C)=AˉBC+ABˉC+ABC 那么我们的卡诺图应该如下图： 3,5,7处对应的最小项就是布尔表达式中出现的，所以这几个地方填0。那么接下来我们来介绍一下卡诺图上合并最小项的规则，即化简的规则： 当卡诺图中有最小项相邻时（即：有标1的方格相邻），可以利用最小项相邻的性质，对最小项进行合并。 卡诺图上任何两个相邻的两个标1的方格，可以合并为1项，并可消去1个（取值取反的）变量。 卡诺图上四个标1方格合并，可合并为一项，并可以消去2个变量 四个标1方格的特点是四个方格同在一行或一列，或者同在一个田字格 根据上面的规则，我们可以将卡诺图中的5,7合并，3,7合并： 5,7左右相邻，且标号均为1同时观察菜单栏发现B的标号不同，所以可以消去变量B，同时3,7号合并，变量A取值不同，所以可以消去A，这样我们就得到了F的化简表达式了。 但是规则还没有结束，这只是对应着一种相邻的情况，我们知道还有对称的情况，所以下面的卡诺图也可以进行合并： 0000和0010由于对称相邻，所以可以合并，C取值不同所以合并后消去C，1101和1111左右相邻，可以合并，C不同，所以消去C，所以我们根据上面的卡诺图可以得知这个布尔表达式的原先表达和化简后的表达应为： F=AˉBˉCˉDˉ+AˉBˉCDˉ+ABCˉD+ABCDF=\\bar{A}\\bar{B}\\bar{C}\\bar{D}+\\bar{A}\\bar{B}C\\bar{D}+AB\\bar{C}D+ABCD F=AˉBˉCˉDˉ+AˉBˉCDˉ+ABCˉD+ABCD F=AˉBˉDˉ+ABDˉF=\\bar{A}\\bar{B}\\bar{D}+AB\\bar{D} F=AˉBˉDˉ+ABDˉ 所以我们发现补1法是将布尔表达式转换成标准与或式，而卡诺图化简就是逆过程，是将复杂的标准与或式化简成简单的形式。那么接下来我们再来尝试相除4个格的，如下： 同样的，四个格同在一行，或者同在一列或者同在一个田字格也可以进行合并消除化简。并且此时是2^2个相邻格，所以可以一次消除两个变量，我们横看可以消除一个变量，纵看又可以消除一个方格。 思考：如果我就要按照两个两个的消除可不可以？ 可能你会产生疑惑，为什么要按照4个格相邻进行消除，而不是继续看成许许多多个2个格相邻进行消除，我们知道最终要得到的式子尽可能的最简，对比上面两个图我们发现右边的式子最终并不是最简式，因此为了得到最简式，我们必须用尽可能最大的圈去包裹1矩阵。 那么接下来我们练习一下四个格相邻的消除，同时你也可以自己尝试按照2个格消除，最终对比一下化简得到的布尔表达式是否一样。 那么既然可以合并4个，当然也就可以合并8个啦，那么合并8个格的规则是8个格子相邻组成一个8元素矩阵或者有对称的行和列也可以： 最终我们会消除3个变量。如上图图1最终只剩下了一个非A，图2只剩下了非B。 思考：那么可不可以16个格进行合并消除，甚至更多？ 当然可以，我们枚举了这几种情况可以总结出如下规律： 在n变量的卡诺图中，会有2^n个方格，只有2的i次方个相邻的标1方格（必须排列成方形格或者矩阵形格的形状）才能圈在一起，合并为一项（当然，有对称的也可以）。该项保留了n-i个相同的变量，也就是说明会消除i个不同的变量。 注意一般我么也就会用到4个格的合并，8个的都很少，首先是因为随着n和i的增大，合并的规则会比较复杂，同时也很难出现许多多相邻的标1的格。"},{"title":"I/O管理概述","path":"/wiki/操作系统笔记/I/O管理概述/index.html","content":"I/O设备的基本概念与分类 接下来我们介绍以下I/O设备管理的知识，首先我们学习认识一下I/O设备 什么是I/O设备 顾名思义，就是输入/输出设备（Input/Output)。I/O设备可以将数据传入到计算机，或者可以接受计算机输出数据的外部设备，属于计算机的硬件部分。 这里的输入和输出都是以计算机的视角来看的。所以显示器是计算机线束输出数据所以为输出设备。在UNIX系统中将外部设备抽象为了一种特殊的文件，用户可以使用与文件操作系统相同的方式对外部设备进行操作。例如write操作就是向外部设备输出数据，read操作就是从外部设备读入数据。 I/O设备根据使用特性的分类 可以分为： 人机交互类外部设备（数据传输速度慢） 存储设备（数据传输速度快） 网络通信设备（数据传输速度介于两者之间） I/O设备根据传输速度分类 低速设备 中速设备 高速设备 I/O设备根据信息交换的单位分类 块设备（传输速率较高，可以寻址，即对他可以随机的读/写任意一块） 字符设备（传输速率慢，不可寻址，在输入输出时常采用中断驱动方式） 总结 I/O控制器 I/O控制器主要由机械部件和电子部件组成，这里我们依次介绍。 I/O设备的机械部件 I/O的机械部件主要用于执行具体的I/O操作，如鼠标/键盘的按钮，显示器的LED屏，移动硬盘的磁臂，磁盘盘面等。 而I/O的电子部件通常是一块插入主板扩充槽的印刷电路板。 I/O设备的电子部件（I/O控制器） CPU无法直接控制I/O设备的机械部件，因此I/O设备还要有一个电子部件作为CPU和I/O设备机械部件之间的桥梁，勇于实现CPU对设备的控制，这个电子部件就是I/O控制器，又称为设备控制器。CPU可以控制I/O控制器，所以可以通过I/O控制器来控制设备的机械部件。 I/O控制器主要有以下功能： 接受和识别CPU发出的命令（如CPU发来的read/write命令，I/O控制器中会有相应的控制寄存器来存放命令与参数） 向cpu报告设备的状态（I/O控制器有相应的状态寄存器，用于记录I/O设备的当前状态，1表示空闲，0表示忙碌，当然也有的控制器为1表示忙碌，0表示空闲，这个看厂商的设定） 数据交换（I/O控制器会设置相应的数据寄存器。输出时，数据寄存器用于暂存CPU发来的数据，之后再由控制器传达给IO设备。输入时，数据寄存器暂存设备发来的数据，之后CPU从数据寄存器中取走数据） 地址识别（类似于内存的地址，为了区分不同设备控制器中的各个寄存器，也需要给各个寄存器设置一个特定的寄存器，I/O控制器通过CPU提供的地址来判断CPU要读/写的是哪一个寄存器） I/O控制器的组成 所以①一个I/O可能会对应多个设备②数据寄存器，控制寄存器，状态寄存器等可能会有多个（例如每一个控制/状态寄存器对应一个具体的设备），且这些寄存器都要有相应的地址，才能方便CPU的操作。有的计算器会让这些寄存器占用内存地址的一部分，称为内存映像I/O，另外一些计算机则采用I/O专用地址即寄存器独立编址。 思考：两种寄存器地址组成形式有什么区别？ 所以我们可以看出内存映像I/O貌似性能更好。 总结 I/O控制方式 那么I/O控制器具体通过什么方法来控制I/O设备呢？我们也会有多种形式其中主要会影响到读/写操作的流程，CPU的干预频率，数据传送的单位，数据流向等问题。 程序直接控制 我们以读操作为例 ①CPU向控制器发出读数据的命令。于是I/O控制器设备启动并且状态寄存器设置为1（未就绪）然后开始做准备工作让输入设备准备输入数据同时控制器自身准备接受数据到数据寄存器 ②CPU轮询检查控制器的状态是否就绪，即CPU时刻准备与控制器进行工作 ③输入设备准备好数据后将数据传给控制器同时报告自身状态 ④控制器将输入的数据放到数据寄存器，并且将自身的状态更改为0（表示已就绪和CPU进行交换工作） ⑤CPU发现控制器设备已经就绪，那么就将数据寄存器中的数据读入到CPU的寄存器中同时把CPU寄存器中的内容放到内存以便进行数据交换 ⑥如果还要继续读入数据，那么CPU继续发出读的指令 CPU干预频率：这样的方式CPU的干预频率很频繁，I/O操作开始之前，完成之后需要CPU介入，并且等待I/O完成的过程中需要不断地轮询检查。 数据传送单位：每次读/写一个字 数据流向： 读操作（数据输入）：I/O设备-&gt;CPU(包括CPU寄存器)-&gt;内存 写操作（数据输出）：内存-&gt;CPU(包括CPU寄存器)-&gt;I/O设备 每个字的读/写都需要CPU的帮助 优点：实现简单，在读/写指令后加上循环检查的一系列指令即可。 缺点：CPU和I/O设备只能串行工作，CPU需要一直轮询检查，长期处于忙碌状态，CPU利用率低。 中断驱动方式 引入中断机制，由于I/O设备很慢，因此CPU发出读/写命令以后可以将等待I/O的进程阻塞，先切换到其他进程。当I/O设备完成后，控制器会向CPU发送一个中断信号，CPU检测到中断信号后保存当前进程的运行环境信息，然后转去执行中断处理程序来处理中断。处理中断的过程中，CPU从I/O控制器中读一个字的数据传送到CPU寄存器，再写入主存。接着，CPU恢复等待I/O的进程（或其他进程）的运行环境，然后继续执行。 这样就不是cpu主动一直询问控制器设备是否就绪了，而是当控制器就绪后主动告诉CPU。这里我们要注意： ①CPU会在每个指令周期的末尾检查中断 ②中断处理过程中需要保存，恢复进程的运行环境，这个过程是需要一定的时间开销的。可见，如果中断发生的频率也会降低系统性能。 CPU干预频率：每次I/O操作开始之前，完成之后需要CPU的介入。等待I/O完成的过程中CPU可以切换到别的进程执行。 数据传送单位：每次读/写一个字 数据的流向： 读操作（数据输入）：I/O设备-&gt;CPU(包括CPU寄存器)-&gt;内存 写操作（数据输出）：内存-&gt;CPU(包括CPU寄存器)-&gt;I/O设备 每个字的读/写都需要CPU的帮助 优点：和程序直接控制方式相比，CPU不用一直不停的轮询，CPU和I/O设备可以并行工作，CPU利用率得到明显的提升 缺点：每个字在I/O设备和内存之间的传输，都需要经过CPU。并且频繁的中断也会消耗较多的CPU时间。 DMA方式 与“中断驱动方式”相比，DMA（Direct Memory Access,直接存储器存取，主要用于块设备的I/O控制）有这样几个改进： 数据的传送是“块”，不再是一个字，一个字的传送 数据流向是设备直接放到内存，或者内存到设备，不再需要CPU的帮助 仅在传送一个或多个数据块的开始和结束时，才需要CPU干预 DMA控制器 所以这个方法需要DMA控制器来服务。DMA控制器结构如下： DR(Data Register,数据寄存器)：暂存从设备到内存，或者从设备到内存的数据 MAR(Memory Address Register,内存地址寄存器)：在输入时，MAR表示数据应该放到内存中的什么位置，输出时MAR表示要输出的数据放在内存中的什么位置 DC(Date Counter,数据计数器)：表示剩余要读/写的字节数 CR（Command Register,命令/状态寄存器)：用于存放CPU发来的I/O命令，或设备的状态信息。 CPU干预频率：仅在传送一个或多个数据块的开始和结束时，才需要CPU干预 传送数据的单位：每次读/写一个或多个块（注意每次读写的都是连续的多个块，且这些块读入内存后在内存中也必须是连续的） 数据流向（不需要CPU帮助）： 读操作（数据输入）：I/O设备-&gt;内存 写操作（数据输出）：内存-&gt;I/O设备 优点：数据时以“块”为单位，CPU介入频率进一步降低。数据的传输不在需要经过CPU在写入内存，数据效率高。CPU和I/O设备的并行性也进一步提升。 缺点：CPU每发出一条I/O指令，只能读/写一个或多个连续的数据块。如果要读/写多个离散的存储块，或者将数据分别写到不同的内存区域时，CPU要分别发出多条I/O指令，进行多次中断处理才能完成。 通道控制方式 通道：一种硬件，可以理解为“弱鸡版CPU”，也是可以识别并执行一系列通道指令 和CPU相比，通道可以执行的指令很单一，并且通道程序是放在主机内存中的，也就是说通道与CPU共享内存。 CPU干预频率：极低，通道会根据CPU的知识执行相应的通道程序，只有完成一组数据块的读/写操作后才需要发出中断信号，请求CPU干预 数据传送的单位：每次读/写一组数据块 数据的流向（在通道的控制下进行）： 读操作（数据输入）：I/O设备-&gt;内存 写操作（数据输出）：内存-&gt;I/O设备 优点：CPU,通道，I/O设备并行工作，资源利用率很高 缺点：实现复杂，需要专门的通道硬件支持 总结 控制方式 完成一次读/写的过程 CPU干预频率 每次I/O的数据传输单位 数据流向 程序直接控制方式 CPU发出I/O命令后需要不断轮询 极高 字 设备-&gt;CPU-&gt;内存内存-&gt;CPU-&gt;设备 中断驱动方式 CPU发出I/O命令后可以做其他事，本次I/O完成后设备控制器发出中断信号 高 字 设备-&gt;CPU-&gt;内存内存-&gt;CPU-&gt;设备 DMA方式 CPU发出I/O命令后可以做其他事，本次I/O完成后，DMA控制器发出中断信号 中 块 设备-&gt;内存内存-&gt;设备 通道控制方式 CPU发出I/O命令后可以做其他事，通道会执行通道程序以完成I/O，完成后通道向cpu发出中断信号 低 一组块 设备-&gt;内存内存-&gt;设备 每一个阶段的优点都是上一个阶段的最大缺点，总体来看，整个发展过程就是尽量减少CPU干预，把CPU从繁杂的I/O控制事务中解脱出来，以便更多的完成数据处理任务。"}]